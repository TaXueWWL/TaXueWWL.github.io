<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>朝·闻·道</title>
  <subtitle>SnoWalker&#39;s Blog</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://wuwenliang.net/"/>
  <updated>2019-12-31T16:17:29.254Z</updated>
  <id>http://wuwenliang.net/</id>
  
  <author>
    <name>SnoWalker</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>初心，改变--致2019</title>
    <link href="http://wuwenliang.net/2019/12/31/%E5%88%9D%E5%BF%83%EF%BC%8C%E6%94%B9%E5%8F%98-%E8%87%B42019/"/>
    <id>http://wuwenliang.net/2019/12/31/初心，改变-致2019/</id>
    <published>2019-12-31T03:58:34.000Z</published>
    <updated>2019-12-31T16:17:29.254Z</updated>
    
    <content type="html"><![CDATA[<p>2019，岁末。</p>
<p>迟迟没有动笔，不知从何讲起。</p>
<p>2019，变化的一年，踏实的一年，平静的一年。</p>
<p>变化，在于工作。原计划2020年六月的行动，提前半年实施。</p>
<p>坐在新的办公桌前，我敲下这段文字，生活就是这样，一个个选择造就了现在的自己。关于工作更迭，不再多言，已经在之前的文章中详细写过。</p>
<a id="more"></a>
<p>踏实，在于爱情终成正果。感谢她，曾经的女友，现在的妻子，一直给我支持与鼓励，耐心倾听，默默陪伴，共享欢乐，分担忧愁。因为有你所以做事有了方向，你就是人间的四月天。</p>
<p>1016，一个平常日子里，我们结婚了。</p>
<p>于是今后的日子里，有你为伴。</p>
<p>感恩，并幸福地前行着。</p>
<p>平静，在于心态。九月，母亲生病，手术，所幸一切安好。</p>
<p>当时得知情况的自己就像挨了一记闷棍，惊醒了，于是知道身边人是最为重要的。</p>
<p>年中讨论热烈的 “996-ICU”，我亲历，明白身体真是的本钱。</p>
<p>之所以平静，是因为经历了这些，原本以为自己明白的普通道理，变得如此真切。</p>
<p>平静，倒不如说成长。</p>
<p>成长，总是伴随着阵痛，注定不会太轻松。</p>
<p>说的纷乱，思绪万千。</p>
<p>工作里，挑战接踵而至，已经不会再像初入职场那般惊慌。</p>
<p>有问题，解决问题，不多争辩，实事求是，多找找主观上的问题，少给自己开脱。适当的，自嘲一下，笑过之后继续做事。</p>
<p>有争执，放下争执，求同存异，事后再行复盘。</p>
<p>对技术，初心不灭。一年里，专注于消息队列技术，不断深挖，分享文章，参与社区，结识了一帮牛人，也因此受益良多。</p>
<p>心态已经趋于平常，虽热量依旧，但锐气已散。我欣然，渐进而立，是需要看开一些事，看重一些事。</p>
<p>就这么多吧，已过了洋洋洒洒写下数千字的年纪，朴实话语也能抵得过锦绣文字。</p>
<p>惟精惟一，始终谨记。</p>
<p>继续吧，12.31只是一个符号。</p>
<p>继续吧，未知的前方让我向往。</p>
<p>继续吧，平静地迎接新年的到来。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;2019，岁末。&lt;/p&gt;
&lt;p&gt;迟迟没有动笔，不知从何讲起。&lt;/p&gt;
&lt;p&gt;2019，变化的一年，踏实的一年，平静的一年。&lt;/p&gt;
&lt;p&gt;变化，在于工作。原计划2020年六月的行动，提前半年实施。&lt;/p&gt;
&lt;p&gt;坐在新的办公桌前，我敲下这段文字，生活就是这样，一个个选择造就了现在的自己。关于工作更迭，不再多言，已经在之前的文章中详细写过。&lt;/p&gt;
    
    </summary>
    
      <category term="年度总结" scheme="http://wuwenliang.net/categories/%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="年度总结" scheme="http://wuwenliang.net/tags/%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot之整合邮件发送功能</title>
    <link href="http://wuwenliang.net/2019/12/11/SpringBoot%E4%B9%8B%E6%95%B4%E5%90%88%E9%82%AE%E4%BB%B6%E5%8F%91%E9%80%81%E5%8A%9F%E8%83%BD/"/>
    <id>http://wuwenliang.net/2019/12/11/SpringBoot之整合邮件发送功能/</id>
    <published>2019-12-11T14:49:19.000Z</published>
    <updated>2019-12-11T14:50:44.244Z</updated>
    
    <content type="html"><![CDATA[<p>我们在开发中通常会使用邮件方式进行告警，传统的邮件发送整合起来较为繁琐，因此Spring Boot提供了一套更为简洁易用的整合方案，对Java Mail进行了封装，能够让业务更快的具备邮件发送能力。</p>
<p>本文主要讲解如何为Spring Boot应用添加邮件发送能力。</p>
<h2 id="依赖引入"><a href="#依赖引入" class="headerlink" title="依赖引入"></a>依赖引入</h2><p>首先还是要有一个Spring Boot应用，这个就不再赘述了。在maven中央仓库搜索Spring Boot邮件发送模块，将坐标添加到项目的pom下。（这里以2.2.1RELEASE举例）</p>
<pre><code>&lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-mail --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-mail&lt;/artifactId&gt;
    &lt;version&gt;2.2.1.RELEASE&lt;/version&gt;
&lt;/dependency&gt;
</code></pre><a id="more"></a>
<h2 id="进行配置"><a href="#进行配置" class="headerlink" title="进行配置"></a>进行配置</h2><p>Spring Boot强调约定优于配置，因此我们需要进行必要的配置。在application.properties中添加以下配置：（这里以qq邮箱举例）</p>
<pre><code>########################################################################
#
#     邮件配置
#
#########################################################################
# 邮件发送smtp服务域名
spring.mail.host=smtp.qq.com
# 发送账号
spring.mail.username=你的qq邮箱
# 发送授权码
spring.mail.password=发送授权码
# 邮件编码格式
spring.mail.default-encoding=UTF-8
# 是否进行认证
spring.mail.properties.mail.smtp.auth=true
spring.mail.properties.mail.smtp.starttls.enable=true
spring.mail.properties.mail.smtp.starttls.required=true
# smtp服务端口
spring.mail.port=465
spring.mail.properties.mail.smtp.socketFactory.port = 465
spring.mail.properties.mail.smtp.socketFactory.class = javax.net.ssl.SSLSocketFactory
spring.mail.properties.mail.debug=true
spring.mail.properties.mail.smtp.socketFactory.fallback = false
</code></pre><blockquote>
<p>smtp服务域名在linux下可能会有无法解析的问题，只需要将域名更换为ip地址即可。具体的做法是在命令行中通过ping命令来获取并替换即可。</p>
</blockquote>
<p>使用这个配置前需要在自己的qq邮箱中开通smtp服务，具体的步骤如下：</p>
<ol>
<li>首先登陆qq邮箱，点击顶部的导航栏的 <strong>“设置”</strong> 按钮</li>
<li>进入设置选项页面，在账户选项卡下方找到 <strong>POP3/SMTP</strong> 服务，单机后方的“开启”按钮，将功能开放。</li>
</ol>
<blockquote>
<p>在开启 <strong>POP3/SMTP</strong> 服务的过程中，需要根据引导发送短信，当操作完成之后，我们会获取到一个发送邮件授权码，这个授权码需要保存下来，以便在应用中进行配置（配置项为 <strong>spring.mail.password</strong>）</p>
</blockquote>
<ol>
<li>当获取到授权码之后，发送前的准备工作就基本完成。</li>
</ol>
<h2 id="编写代码"><a href="#编写代码" class="headerlink" title="编写代码"></a>编写代码</h2><p>基础配置完成，我们就可以编写代码进行邮件发送的测试。</p>
<p>在项目中编写一个邮件发送类，并标记为一个Spring的Bean。</p>
<pre><code>@Component
public class MailSenderClient {

    private static final Logger LOGGER = LoggerFactory.getLogger(MailSender.class);

    @Autowired
    JavaMailSender javaMailSender;

    public void sendSimpleMail(MailEntity mailEntity) {
        // 组装邮件发送实体
        SimpleMailMessage simpleMailMessage = new SimpleMailMessage();
        simpleMailMessage.setFrom(mailEntity.getFrom());
        simpleMailMessage.setTo(mailEntity.getTo());
        simpleMailMessage.setCc(mailEntity.getCc());
        simpleMailMessage.setSubject(mailEntity.getSubject());
        simpleMailMessage.setText(mailEntity.getContent());
        javaMailSender.send(simpleMailMessage);
        LOGGER.info(&quot;邮件发送完成: mailEntity={}&quot;, JSON.toJSONString(mailEntity));
    }

    /**
     * 邮件发送实体
     */
    public static class MailEntity {
        // 发件人
        private String from;
        // 收件人
        private String to;
        // 抄送
        private String cc;
        // 邮件主题（标题）
        private String subject;
        // 邮件正文，如果正文是HTML则需要手动拼接
        private String content;

        ...省略getter setter...
    }
}
</code></pre><p>核心逻辑很简单，我们要做的就是将JavaMailSender注入到发送邮件的bean中，构造一个SimpleMailMessage，设置发件人、收件人、抄送者（为空表示不抄送）、邮件主题、邮件正文，通过 <strong>javaMailSender.send(simpleMailMessage);</strong> 方法将邮件发送出去即可。</p>
<p>具体的调用方式如下，我们只需要通过这种方式，在需要进行邮件发送的地方如此调用即可。</p>
<pre><code>@Test
public void testSendMail() {
    MailSenderClient.MailEntity mailEntity = new MailSenderClient.MailEntity();
    mailEntity.setFrom(&quot;121xxxx591@qq.com&quot;)
            .setTo(&quot;xxxx@xxxx.com&quot;)
            .setCc(&quot;122xxxx121@xxxxxx.com&quot;)
            .setSubject(&quot;文件内容为空，请关注!&quot;)
            .setContent(&quot;截止到当前时间，分析结果文本中内容为空，请关注!&quot;);
    mailSender.sendSimpleMail(mailEntity);
}
</code></pre><p>运行该测试用例，查看控制台日志（由于在配置中设置了开启debug，因此能够看到详细的握手报文）。</p>
<pre><code>......
DEBUG SMTP: connected to host &quot;smtp.qq.com&quot;, port: 465
EHLO 10.3.4.197
250-smtp.qq.com
250-PIPELINING
250-SIZE 73400320
250-AUTH LOGIN PLAIN
250-AUTH=LOGIN
250-MAILCOMPRESS
250 8BITMIME
......
DEBUG SMTP: STARTTLS requested but already using SSL
DEBUG SMTP: protocolConnect login, host=smtp.qq.com, user=xxxxx@qq.com, password=&lt;non-null&gt;
......
DEBUG SMTP: Using mechanism LOGIN
DEBUG SMTP: AUTH LOGIN command trace suppressed
DEBUG SMTP: AUTH LOGIN succeeded
DEBUG SMTP: use8bit false
MAIL FROM:&lt;xxxxx@qq.com&gt;
250 Ok
RCPT TO:&lt;xxxxx@xxxx.com&gt;
250 Ok
RCPT TO:&lt;xxxxxxxx@xxxxxx.com&gt;
250 Ok
DEBUG SMTP: Verified Addresses
......
DATA
354 End data with &lt;CR&gt;&lt;LF&gt;.&lt;CR&gt;&lt;LF&gt;
Date: Wed, 11 Dec 2019 11:11:08 +0800 (CST)
From: xxxxxx@qq.com
To: xxxxxxx@xxxx.com
Cc: xxxxxx@xxxxx.com
Message-ID: &lt;1117448897.0.1576033868771@[10.3.4.197]&gt;
Subject: =?UTF-8?B?5o6o6I2Q5rGg5paH5Lu25YaF5a655Li656m677yM6K+35YWz5rOoIQ==?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: base64
......
.
250 Ok: queued as 
DEBUG SMTP: message successfully delivered to mail server
QUIT
221 Bye
......
</code></pre><p>这就表明邮件发送成功，我们要做的就是打开邮箱进行查看即可。</p>
<h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><p>到此我们就完成了Spring Boot对邮件发送功能的整合。需要补充的是，很多情况下，我们发送的邮件正文是具备一定格式的，</p>
<p>本文讲解的案例则是简单的文本格式邮件正文，实际上，文章中讲解的方式也是能够支持HTML内容发送的，我们要做的就是在</p>
<p>邮件发送的正文中，手动的拼接html文档，只要能够保证html文档拼接的正确性，邮件发送成功后，在邮箱客户端我们就能看到</p>
<p>渲染后的样式。虽然有一定的工作量，不过能够解决问题就是我们的直接目的。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我们在开发中通常会使用邮件方式进行告警，传统的邮件发送整合起来较为繁琐，因此Spring Boot提供了一套更为简洁易用的整合方案，对Java Mail进行了封装，能够让业务更快的具备邮件发送能力。&lt;/p&gt;
&lt;p&gt;本文主要讲解如何为Spring Boot应用添加邮件发送能力。&lt;/p&gt;
&lt;h2 id=&quot;依赖引入&quot;&gt;&lt;a href=&quot;#依赖引入&quot; class=&quot;headerlink&quot; title=&quot;依赖引入&quot;&gt;&lt;/a&gt;依赖引入&lt;/h2&gt;&lt;p&gt;首先还是要有一个Spring Boot应用，这个就不再赘述了。在maven中央仓库搜索Spring Boot邮件发送模块，将坐标添加到项目的pom下。（这里以2.2.1RELEASE举例）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-mail --&amp;gt;
&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spring-boot-starter-mail&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;2.2.1.RELEASE&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
      <category term="spring-boot" scheme="http://wuwenliang.net/categories/spring-boot/"/>
    
    
      <category term="spring-boot" scheme="http://wuwenliang.net/tags/spring-boot/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot之整合MongoDB</title>
    <link href="http://wuwenliang.net/2019/12/06/SpringBoot%E4%B9%8B%E6%95%B4%E5%90%88MongoDB/"/>
    <id>http://wuwenliang.net/2019/12/06/SpringBoot之整合MongoDB/</id>
    <published>2019-12-06T01:20:29.000Z</published>
    <updated>2019-12-06T01:23:25.389Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>MongoDB 是由C++语言编写的，是一个基于分布式文件存储的开源数据库系统。 在高负载的情况下，添加更多的节点，可以保证服务器性能。 MongoDB 旨在为WEB应用提供可扩展的高性能数据存储解决方案。 MongoDB 将数据存储为一个文档，数据结构由键值(key=&gt;value)对组成。MongoDB 文档类似于 JSON 对象。字段值可以包含其他文档，数组及文档数组。 – 引用自runnoob</p>
</blockquote>
<p>一个MongoDB的BSON数据结构如下：</p>
<p><img src="/2019/12/06/SpringBoot之整合MongoDB/./mongo-document.png" alt="BSON"></p>
<h2 id="引入spring-boot-starter-data-mongodb依赖"><a href="#引入spring-boot-starter-data-mongodb依赖" class="headerlink" title="引入spring-boot-starter-data-mongodb依赖"></a>引入spring-boot-starter-data-mongodb依赖</h2><p>首先当然需要建立一个SpringBoot项目，接着在项目的pom.xml中引入spring-boot-starter-data-mongodb。坐标如下：</p>
<pre><code>&lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-data-mongodb --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt;
    &lt;version&gt;2.2.1.RELEASE&lt;/version&gt;
&lt;/dependency&gt;
</code></pre><a id="more"></a>
<h2 id="配置mongodb"><a href="#配置mongodb" class="headerlink" title="配置mongodb"></a>配置mongodb</h2><p>在项目的application.properties中添加Mongodb连接配置</p>
<pre><code>###################################################################
#                           MongoDB
###################################################################
# 进行认证的db，一般就是admin
spring.data.mongodb.authentication-database=admin
# 需要进行交互的db，需要实现创建
spring.data.mongodb.database=snowalker
# mongodb所在机器的ip/域名
spring.data.mongodb.host=127.0.0.1
# mongodb对外提供服务的端口，默认为27017
spring.data.mongodb.port=27017
# 用户名及密码，可主动在admin库中添加并授权
spring.data.mongodb.username=root
spring.data.mongodb.password=root
</code></pre><h2 id="编写实体类"><a href="#编写实体类" class="headerlink" title="编写实体类"></a>编写实体类</h2><p>需要编写一个实体类，该实体类就是一个POJO。这里我们以书籍信息为例</p>
<pre><code>public class BookInfo {

    private String id;
    private String name;
    private String author;

    // 省略getter setter
</code></pre><h2 id="编写Mongodb操作持久层"><a href="#编写Mongodb操作持久层" class="headerlink" title="编写Mongodb操作持久层"></a>编写Mongodb操作持久层</h2><p>这一步较为核心，我们通过编写一个MongoDB的交互接口，实现对MongoDB的操作。这一切只需要让自定义的接口继承MongoRepository接口即可，整体的风格类似于JPA。</p>
<pre><code>public interface BookInfoRepository extends MongoRepository&lt;BookInfo, String&gt; {
    List&lt;BookInfo&gt; findByAuthorContains(String author);
    BookInfo findByNameEquals(String bookName);
}
</code></pre><p>我们的接口一旦继承了MongoRepository就能够使用最基本的CURD等操作，而且我们可以根据自己的需求进行操作的扩展。</p>
<h3 id="扩展：SpringData方法扩展"><a href="#扩展：SpringData方法扩展" class="headerlink" title="扩展：SpringData方法扩展"></a>扩展：SpringData方法扩展</h3><p>这里介绍一下如何进行方法扩展。</p>
<p>实际上，在SpringData中，只要方法的定义符合既定规范，则Spring Data就可以分析出开发者的意图，从而避免开发者自定义一些诸如SQL、指令等操作。当然这就仁者见仁智者见智了，笔者认为，对于简单的操作，用这种方法可以很好的提升开发效率，但如果需要针对业务有一些复杂的操作，则自定义SQL、指令应当更加灵活。</p>
<blockquote>
<p>常见的命名规则如下：</p>
</blockquote>
<p>如果是简单条件查询的场景，如：需要对某一个实体类或者集合进行查询。</p>
<p>按照Spring Data的规范的规定，查询方法应当以 <strong>find | read | get开头</strong>（如：find、findBy、read、readBy、get、getBy）。</p>
<p>涉及到查询条件时，条件属性需要用条件关键字进行连接。这里需要注意：条件属性首字母应当大写。当框架进行方法名解析时，会先把方法名的多余前缀截取掉，然后对剩下部分进行解析。</p>
<p>对于直接在接口中定义的查询方法，如果符合规范的，则可以不用写实现，目前支持的关键字写法如下：</p>
<p><img src="/2019/12/06/SpringBoot之整合MongoDB/spring-data-method.png" alt="SpringData方法命名规范"></p>
<h2 id="编写测试接口"><a href="#编写测试接口" class="headerlink" title="编写测试接口"></a>编写测试接口</h2><p>到此我们就基本上完成了对MongoDB的整合，接下来就编写一个测试接口对MongoDB进行操作，验证整合是否有效。</p>
<pre><code>@RestController
public class BookInfoController {

    @Autowired
    BookInfoRepository bookInfoRepository;

    @GetMapping(value = &quot;mongo&quot;)
    public BookInfo testMongo() throws JsonProcessingException {

        List&lt;BookInfo&gt; bookInfos = new ArrayList&lt;&gt;();
        // 添加数据
        for (int i = 0; i &lt; 3; i++) {
            String uuid = UUID.randomUUID().toString();
            BookInfo bookInfo = new BookInfo();
            bookInfo.setId(i + &quot;_&quot; + uuid).setAuthor(&quot;刘慈欣&quot;).setName(&quot;三体_&quot; + uuid);
            bookInfos.add(bookInfo);
        }
        // 入Mongo
        bookInfoRepository.insert(bookInfos);
        // 查询By author
        List&lt;BookInfo&gt; queryList = bookInfoRepository.findByAuthorContains(&quot;刘慈欣&quot;);
        ObjectMapper objectMapper = new ObjectMapper();
        String s = objectMapper.writeValueAsString(queryList);
        System.out.println(s);
        // 查询by Name
        BookInfo bookInfo =  bookInfoRepository.findByNameEquals(&quot;三体_89e9a1e3-6597-4415-9699-b5bfb33632ae&quot;);
        if (bookInfo == null) {
            return new BookInfo();
        }
        return bookInfo;
    }
}
</code></pre><p>对上述的测试方法testMongo()稍作总结：</p>
<ol>
<li>我们定义了一个List，用于暂存待持久化的书籍信息</li>
<li>构造三个BookInfo对象并添加到List中</li>
<li>通过调用bookInfoRepository.insert(bookInfos);将list持久化到mongoDB中，这个insert方法就是MongoRepository为我们提供的，我们直接调用即可</li>
<li>接着我们通过自定义的查询方法对前面持久化的数据进行查询。</li>
</ol>
<p>启动项目，访问测试接口： <a href="http://localhost:10880/mongo，返回如下json串：" target="_blank" rel="external">http://localhost:10880/mongo，返回如下json串：</a></p>
<pre><code>{&quot;id&quot;:&quot;2_89e9a1e3-6597-4415-9699-b5bfb33632ae&quot;,&quot;name&quot;:&quot;三体_89e9a1e3-6597-4415-9699-b5bfb33632ae&quot;,&quot;author&quot;:&quot;刘慈欣&quot;}
</code></pre><p>这表明，我们对Mongodb的整合是ok的，并且成功实现了数据的插入和查询等操作。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文我们主要介绍了在SpringBoot中如何通过整合spring-boot-starter-data-mongodb实现对MongoDB的操作。</p>
<p>当我们对spring-data使用的更加熟练，就会感受到Spring对于开发者的友好，通过各种封装的组件实现了对不同底层数据源的统一封装，接口对开发者保持风格一致，降低了开发者的学习成本。这种封装思想也同样值得我们去学习借鉴。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;MongoDB 是由C++语言编写的，是一个基于分布式文件存储的开源数据库系统。 在高负载的情况下，添加更多的节点，可以保证服务器性能。 MongoDB 旨在为WEB应用提供可扩展的高性能数据存储解决方案。 MongoDB 将数据存储为一个文档，数据结构由键值(key=&amp;gt;value)对组成。MongoDB 文档类似于 JSON 对象。字段值可以包含其他文档，数组及文档数组。 – 引用自runnoob&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;一个MongoDB的BSON数据结构如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/12/06/SpringBoot之整合MongoDB/./mongo-document.png&quot; alt=&quot;BSON&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;引入spring-boot-starter-data-mongodb依赖&quot;&gt;&lt;a href=&quot;#引入spring-boot-starter-data-mongodb依赖&quot; class=&quot;headerlink&quot; title=&quot;引入spring-boot-starter-data-mongodb依赖&quot;&gt;&lt;/a&gt;引入spring-boot-starter-data-mongodb依赖&lt;/h2&gt;&lt;p&gt;首先当然需要建立一个SpringBoot项目，接着在项目的pom.xml中引入spring-boot-starter-data-mongodb。坐标如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-data-mongodb --&amp;gt;
&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spring-boot-starter-data-mongodb&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;2.2.1.RELEASE&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
      <category term="spring-boot" scheme="http://wuwenliang.net/categories/spring-boot/"/>
    
    
      <category term="spring-boot" scheme="http://wuwenliang.net/tags/spring-boot/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot动态定时任务开发指南</title>
    <link href="http://wuwenliang.net/2019/12/03/SpringBoot%E5%8A%A8%E6%80%81%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97/"/>
    <id>http://wuwenliang.net/2019/12/03/SpringBoot动态定时任务开发指南/</id>
    <published>2019-12-03T15:30:38.000Z</published>
    <updated>2019-12-03T15:31:12.028Z</updated>
    
    <content type="html"><![CDATA[<p>一般情况下，如果想在Spring Boot中使用定时任务，我们只需要@EnableScheduling开启定时任务支持，在需要调度的方法上添加@Scheduled注解。这样就能够在项目中开启定时调度功能了，并且这种方法支持通过cron表达式灵活的控制执行周期和频率。</p>
<p>上述的方式好处是快捷，轻量，缺点是周期一旦指定，想要更改必须要重启应用，如果我们想要动态的对定时任务的执行周期进行变更，甚至动态的增加定时调度任务则上述方式就不适用了。</p>
<p>本文我将讲解如何在Spring 定时任务的基础上进行扩展，实现动态定时任务。</p>
<a id="more"></a>
<h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><ol>
<li>动态增加定时任务</li>
<li>热更新定时任务的执行周期（动态更新cron表达式）</li>
</ol>
<h2 id="方案1：仅实现动态变更任务周期"><a href="#方案1：仅实现动态变更任务周期" class="headerlink" title="方案1：仅实现动态变更任务周期"></a>方案1：仅实现动态变更任务周期</h2><blockquote>
<p>首先介绍的方案1能够实现动态变更已有任务的执行频率/周期。</p>
</blockquote>
<p>首先建立一个Spring Boot应用，这里不再展开。</p>
<p>建立一个任务调度类，实现接口SchedulingConfigurer，标记为Spring的一个bean。注意一定要添加注解 <strong>@EnableScheduling</strong> 开启定时任务支持。</p>
<pre><code>@EnableScheduling
@Component
public class DynamicCronHandler implements SchedulingConfigurer {

    private static final String DEFAULT_CRON = &quot;0/5 * * * * ?&quot;;
    private String taskCron = DEFAULT_CRON;

    @Override
    public void configureTasks(ScheduledTaskRegistrar scheduledTaskRegistrar) {
        scheduledTaskRegistrar.addTriggerTask(()-&gt;{
            LOGGER.info(&quot;执行任务&quot;);
        }, triggerContext -&gt; {
            // 刷新cron
            CronTrigger cronTrigger = new CronTrigger(taskCron);
            Date nextExecDate = cronTrigger.nextExecutionTime(triggerContext);
            return nextExecDate;
        });
    }
</code></pre><p>scheduledTaskRegistrar.addTriggerTask接受两个参数，分别为需要调度的任务实例（Runnable实例），Trigger实例，这里通过lambda方式注入，需要实现nextExecutionTime回调方法，返回下次执行时间。</p>
<p>通过该回调方法，在Runnable中执行业务逻辑代码，在Trigger修改定时任务的执行周期。</p>
<pre><code>    public DynamicCronHandler setTaskImplement(Runnable taskImplement) {
        this.taskImplement = taskImplement;
        return this;
    }

    public DynamicCronHandler setTaskCron(String taskCron) {
        this.taskCron = taskCron;
        return this;
    }

    public DynamicCronHandler taskCron(String taskCron) {
        System.out.println(&quot;更新cron=&quot; + taskCron);
        this.taskCron = taskCron;
        return this;
    }

    ...省略getter...

}
</code></pre><p>编写一个测试类，进行测试：</p>
<pre><code>@RequestMapping(&quot;execute&quot;)
@ResponseBody
public String executeTask(@RequestParam(value = &quot;cron&quot;, defaultValue = &quot;0/10 * * * * ?&quot;) String cron) {
    LOGGER.info(&quot;cron={}&quot;, cron);
    dynamicCronHandler.taskCron(cron);
    return &quot;success&quot;;
}
</code></pre><p>暴露一个http接口，接受参数cron，启动应用并访问/execute，首次传入参数cron=0/1 <em> </em> <em> </em> ?，表示每秒执行一次任务。日志如下：</p>
<pre><code>2019-12-03 15:32:40.001  INFO 7196 --- [TaskScheduler-1] c.s.s.t.d.d.DynamicCronHandler           : 执行任务
2019-12-03 15:32:41.001  INFO 7196 --- [TaskScheduler-1] c.s.s.t.d.d.DynamicCronHandler           : 执行任务
2019-12-03 15:32:42.001  INFO 7196 --- [TaskScheduler-1] c.s.s.t.d.d.DynamicCronHandler           : 执行任务
2019-12-03 15:32:43.001  INFO 7196 --- [TaskScheduler-1] c.s.s.t.d.d.DynamicCronHandler           : 执行任务
2019-12-03 15:32:44.001  INFO 7196 --- [TaskScheduler-1] c.s.s.t.d.d.DynamicCronHandler           : 执行任务
</code></pre><p>可以看到每秒执行一次。</p>
<p>更改cron的值为0/5 <em> </em> <em> </em> ?，观察到控制台输出发生变化：</p>
<pre><code>更新cron=0/5 * * * * ?
2019-12-03 15:33:30.001  INFO 7196 --- [TaskScheduler-1] c.s.s.t.d.d.DynamicCronHandler           : 执行任务
2019-12-03 15:33:35.001  INFO 7196 --- [TaskScheduler-1] c.s.s.t.d.d.DynamicCronHandler           : 执行任务
2019-12-03 15:33:40.001  INFO 7196 --- [TaskScheduler-1] c.s.s.t.d.d.DynamicCronHandler           : 执行任务
</code></pre><p>此时定时任务执行频率更新为5秒一次，表明通过SchedulingConfigurer.configureTasks回调，动态的更新了定时任务执行频率。</p>
<h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><p>到目前为止，实现了动态变更定时任务的执行频率，但是不能实现动态的提交定时任务。方案二就是为了解决这个疑问而实现的，</p>
<h2 id="方案二：动态提交定时任务并更新任务执行频率"><a href="#方案二：动态提交定时任务并更新任务执行频率" class="headerlink" title="方案二：动态提交定时任务并更新任务执行频率"></a>方案二：动态提交定时任务并更新任务执行频率</h2><p>首先建立一个DynamicTaskScheduler类，内容如下：</p>
<pre><code>@Scope(value = &quot;singleton&quot;)
@Component
@EnableScheduling
public class DynamicTaskScheduler {

    private ScheduledFuture&lt;?&gt; future;

    @Autowired
    private ThreadPoolTaskScheduler threadPoolTaskScheduler;

    @Bean
    public ThreadPoolTaskScheduler threadPoolTaskScheduler() {
        return new ThreadPoolTaskScheduler();
    }

    public void startCron(Runnable task, String cron) {
        stopCron();
        future = threadPoolTaskScheduler.schedule(
                task, new CronTrigger(cron)
        );
    }

    public void stopCron() {
        if (future != null) {
            future.cancel(true);
            System.out.println(&quot;stopCron()&quot;);
        }
    }
}
</code></pre><p>这里通过startCron提交一个新的任务，通过cron表达式进行调度，在开始之前进行判断是否关闭老的，必须关闭老的才能开启新的。</p>
<p>通过stopCron对老任务进行关闭。</p>
<p>编写一个测试方法测试该动态任务调度类。</p>
<pre><code>@RequestMapping(&quot;execute1&quot;)
@ResponseBody
public String executeTask1(@RequestParam(value = &quot;cron&quot;, defaultValue = &quot;0/10 * * * * ?&quot;) String cron) {
    LOGGER.info(&quot;cron={}&quot;, cron);
    dynamicTaskScheduler.startCron(
            () -&gt; {
                LOGGER.info(&quot;模拟执行作业,cron={}&quot;, cron);
            },
            cron
    );
    return &quot;success&quot;;
}
</code></pre><p>启动方法中初始化一个 ThreadPoolTaskScheduler 实例。</p>
<pre><code>@SpringBootApplication
public class SnowalkerTestDemoApplication {

    public static void main(String[] args) {
        SpringApplication.run(SnowalkerTestDemoApplication.class, args);
    }

    @Bean
    public ThreadPoolTaskScheduler threadPoolTaskScheduler() {
        ThreadPoolTaskScheduler executor = new ThreadPoolTaskScheduler();
        executor.setPoolSize(20);
        executor.setThreadNamePrefix(&quot;taskExecutor-&quot;);
        executor.setWaitForTasksToCompleteOnShutdown(true);
        executor.setAwaitTerminationSeconds(60);
        return executor;
    }

}
</code></pre><p>运行启动类，访问测试接口/execute1，先传入cron=0/1 <em> </em> <em> </em> ?，表示每秒执行一次任务。日志如下：</p>
<p>更改cron的值为0/5 <em> </em> <em> </em> ?，观察到控制台输出发生变化：</p>
<p>可以看到这种方式同样实现了动态的变更定时任务执行频率，相比上述的方法，该方式更加灵活，能够动态的增加任务到线程池中进行调度，我们可以定义一个Map保存future，从而实现创建并维护多个定时任务，具体可以参考这篇文章 <a href="https://blog.csdn.net/qq_32711309/article/details/84944534" target="_blank" rel="external">ThreadPoolTaskScheduler的使用，定时任务开启与关闭</a> ，思路如下：</p>
<ol>
<li>自定义Task类，实现Runnable，定义属性name</li>
<li>定义一个ConcurrentHashMap,KEY=name,value=ScheduledFuture</li>
<li>通过 <strong>ScheduledFuture&lt;?&gt; schedule(Runnable task, Trigger trigger)</strong> 进行任务调度时，传入自定义Task，构造/setter 注入任务名称（全局唯一）, 并将该task实现类设置到步骤2的map中，key=name，value=当前通过schedule调度返回的ScheduledFuture</li>
<li>停止该任务时，通过name在map中找到ScheduledFuture实例，调用scheduledFuture.cancel(true);方法停止任务即可</li>
</ol>
<p>核心代码如下：</p>
<blockquote>
<p>任务存储Map</p>
</blockquote>
<pre><code>public static ConcurrentHashMap&lt;String, ScheduledFuture&gt; map = new ConcurrentHashMap&lt;&gt;();
</code></pre><blockquote>
<p>启动任务</p>
</blockquote>
<pre><code>@Component
@Scope(&quot;prototype&quot;)
public class DynamicTask {


    @Autowired
    private ThreadPoolTaskScheduler threadPoolTaskScheduler;
    private ScheduledFuture future;

    public void startCron() {
        cron = &quot;0/1 * * * * ?&quot;;
        System.out.println(Thread.currentThread().getName());
        String name = Thread.currentThread().getName();
        future = threadPoolTaskScheduler.schedule(new myTask(name), new CronTrigger(cron));
        App.map.put(name, future);
    }
</code></pre><blockquote>
<p>停止任务</p>
</blockquote>
<pre><code>    public void stop() {
        if (future != null) {
            future.cancel(true);
        }
    }
}
</code></pre><blockquote>
<p>自定义Task定义</p>
</blockquote>
<pre><code>public class MyTask implements Runnable {
    private String name;

    myTask(String name) {
        this.name = name;
    }

    @Override
    public void run() {
        System.out.println(&quot;test&quot; + name);
    }
}
</code></pre><blockquote>
<p>测试接口</p>
</blockquote>
<pre><code>@Autowired
private DynamicTask task;

@RequestMapping(&quot;/start&quot;)
public void test() throws Exception {
    // 开启定时任务，对象注解Scope是多利的。
    task.startCron();

}

@RequestMapping(&quot;/stop&quot;)
public void stop() throws Exception {
    // 提前测试用来测试线程1进行对比是否关闭。
    ScheduledFuture scheduledFuture = App.map.get(&quot;http-nio-8081-exec-2&quot;);
    scheduledFuture.cancel(true);
    // 查看任务是否在正常执行之前结束,正常返回true
    boolean cancelled = scheduledFuture.isCancelled();
    while (!cancelled) {
        scheduledFuture.cancel(true);
    }
}
</code></pre><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>以上就是SpringBoot动态定时任务相关的讲解，这种方式在轻量级环境下能够很好的工作。如果我们的定时任务要求分布式，高可用，则需要引入额外的组件，如果有必要则需要引入如ejob，xxl-job，quartz等定时调度组件。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://segmentfault.com/a/1190000018788967" target="_blank" rel="external">SpringBoot中并发定时任务的实现、动态定时任务的实现</a></p>
<p><a href="https://my.oschina.net/kevin2kelly/blog/1548237" target="_blank" rel="external">使用ThreadPoolTaskScheduler实现定时关单</a></p>
<p><a href="https://blog.csdn.net/qq_32711309/article/details/84944534" target="_blank" rel="external">ThreadPoolTaskScheduler的使用，定时任务开启与关闭</a></p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一般情况下，如果想在Spring Boot中使用定时任务，我们只需要@EnableScheduling开启定时任务支持，在需要调度的方法上添加@Scheduled注解。这样就能够在项目中开启定时调度功能了，并且这种方法支持通过cron表达式灵活的控制执行周期和频率。&lt;/p&gt;
&lt;p&gt;上述的方式好处是快捷，轻量，缺点是周期一旦指定，想要更改必须要重启应用，如果我们想要动态的对定时任务的执行周期进行变更，甚至动态的增加定时调度任务则上述方式就不适用了。&lt;/p&gt;
&lt;p&gt;本文我将讲解如何在Spring 定时任务的基础上进行扩展，实现动态定时任务。&lt;/p&gt;
    
    </summary>
    
      <category term="spring-boot" scheme="http://wuwenliang.net/categories/spring-boot/"/>
    
    
      <category term="spring-boot" scheme="http://wuwenliang.net/tags/spring-boot/"/>
    
  </entry>
  
  <entry>
    <title>我的编码备忘录</title>
    <link href="http://wuwenliang.net/2019/12/02/%E6%88%91%E7%9A%84%E7%BC%96%E7%A0%81%E5%A4%87%E5%BF%98%E5%BD%95/"/>
    <id>http://wuwenliang.net/2019/12/02/我的编码备忘录/</id>
    <published>2019-12-02T14:05:27.000Z</published>
    <updated>2020-01-07T16:04:41.633Z</updated>
    
    <content type="html"><![CDATA[<p>本文将主要记录在日常开发中遇到的各种问题。以技术类别进行章节划分，作为个人的编码备忘录随时进行查阅，并长期进行置顶。</p>
<h2 id="JavaCore相关"><a href="#JavaCore相关" class="headerlink" title="JavaCore相关"></a>JavaCore相关</h2><blockquote>
<p>该模块主要记录JavaCore相关的技术点</p>
</blockquote>
<h3 id="bigdecimal四舍五入"><a href="#bigdecimal四舍五入" class="headerlink" title="bigdecimal四舍五入"></a>bigdecimal四舍五入</h3><pre><code>BigDecimal.ROUND_HALF_UP: 遇到.5的情况时往上近似,例: 1.5 -&gt;;2
BigDecimal.ROUND_HALF_DOWN : 遇到.5的情况时往下近似,例: 1.5 -&gt;;1
</code></pre><h3 id="bigDecimal转换为百分比，保留若干小数"><a href="#bigDecimal转换为百分比，保留若干小数" class="headerlink" title="bigDecimal转换为百分比，保留若干小数"></a>bigDecimal转换为百分比，保留若干小数</h3><pre><code>DecimalFormat decimalFormat = new DecimalFormat(&quot;0.00%&quot;);
BigDecimal decimal = new BigDecimal(count.intValue()).divide(new BigDecimal(allCount), 5, ROUND_HALF_UP);
String formatted = decimalFormat.format(sdPercent);
</code></pre><h3 id="bigDecimal精确度"><a href="#bigDecimal精确度" class="headerlink" title="bigDecimal精确度"></a>bigDecimal精确度</h3><pre><code>BigDecimal.setScale(5,  BigDecimal.ROUND_HALF_UP)  --&gt;保留五位小数,最后一位遇到.5的情况时往上近似
</code></pre><a id="more"></a>
<h3 id="bigDecimal除法"><a href="#bigDecimal除法" class="headerlink" title="bigDecimal除法"></a>bigDecimal除法</h3><ol>
<li>Java的BigDecimal在使用除法（divide方法）时，应该手动指定精度和舍入的方式。</li>
<li>如果不指定精度和舍入方式，在除不尽的时候会报异常。</li>
</ol>
<h3 id="bigdecimal详解"><a href="#bigdecimal详解" class="headerlink" title="bigdecimal详解"></a>bigdecimal详解</h3><p>这里直接参考别人的文章：</p>
<p>(BigDecimal的用法详解)[<a href="https://www.cnblogs.com/jpfss/p/8072379.html" target="_blank" rel="external">https://www.cnblogs.com/jpfss/p/8072379.html</a>]</p>
<h3 id="java8的optionnal"><a href="#java8的optionnal" class="headerlink" title="java8的optionnal"></a>java8的optionnal</h3><p><a href="https://www.cnblogs.com/zhangboyu/p/7580262.html" target="_blank" rel="external">理解、学习与使用 JAVA 中的 OPTIONAL</a></p>
<p>举个例子：</p>
<pre><code>public static void main(String[] args) {
    Double d = 2.2;
    Optional.ofNullable(d).ifPresent(a -&gt; {
        System.out.println(a);
    });
    Double a = null;
    System.out.println(Optional.ofNullable(a).orElse(2.2));
}

ofNullable：如果对象即可能是 null 也可能是非 null，你就应该使用 ofNullable() 方法：不会抛出NullPointerException

ifPresent：检查是否有值的。该方法除了执行检查，还接受一个Consumer(消费者) 参数，如果对象不是空的，就对执行传入的 Lambda 表达式：

orElse：如果有值则返回该值，否则返回传递给它的参数值
</code></pre><h2 id="并发框架"><a href="#并发框架" class="headerlink" title="并发框架"></a>并发框架</h2><blockquote>
<p>这部分主要讲并发框架相关</p>
</blockquote>
<ol>
<li>CompletableFuture用法</li>
</ol>
<p>CompletableFuture需要单独总结，这里直接放一个参考链接。 <a href="https://www.jianshu.com/p/6bac52527ca4" target="_blank" rel="external">CompletableFuture 使用详解</a></p>
<h2 id="集合框架"><a href="#集合框架" class="headerlink" title="集合框架"></a>集合框架</h2><blockquote>
<p>本模块主要记录集合相关的问题</p>
</blockquote>
<h3 id="如何对一个list进行subList操作"><a href="#如何对一个list进行subList操作" class="headerlink" title="如何对一个list进行subList操作"></a>如何对一个list进行subList操作</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">List&lt;Object&gt; list = new Arraylist&lt;&gt;();</div><div class="line">List&lt;Object&gt; subList = list.subList(0, 5);</div><div class="line">其中subList(0, 5)取得的是下标为0到4的元素,不包含下标为5的元素.</div></pre></td></tr></table></figure>
<p>注意：subList看起来好像是取出了原list的子list，实际上仅仅是取到原list的引用。</p>
<blockquote>
<p>subList方法的返回值，只是ArrayList的一个映像而已。</p>
</blockquote>
<p>也就是说，当我们使用子集合subList进行元素的修改操作时，会影响原有的list集合。</p>
<p>如果要生成原有list的子集合，还是采用硬复制的方式比较好，也就是新建一个新的list，对原list集合进行解析后装载到新的list中。</p>
<h3 id="集合如何进行排序操作？（如：如何对一个list中的元素进行排序）"><a href="#集合如何进行排序操作？（如：如何对一个list中的元素进行排序）" class="headerlink" title="集合如何进行排序操作？（如：如何对一个list中的元素进行排序）"></a>集合如何进行排序操作？（如：如何对一个list中的元素进行排序）</h3><p>集合排序，一般有三种方法。</p>
<blockquote>
<p>利用集合框架提供的Collections.sort实现排序，待进行排序的实体需要实现比较器Comparable接口的compareTo方法。</p>
</blockquote>
<p>返回当前入参的实体和this对象的属性差（该属性为排序依据），</p>
<pre><code>属性差如果为负数表示当前入参比本身小，

属性差如果为0表示当前入参与本身相等，

属性差如果为正数表示当前入参比本身大，
</code></pre><p>最后调用Collections.sort(temp);返回的集合排序方式为自然排序。</p>
<blockquote>
<p>通过调用 <strong>Collections.sort(List<t> list, Comparator&lt;? super T&gt; c)</t></strong> 方法，传入Comparator实现，这种方式下，实体不需要实现Comparable接口。</p>
<p>对于JDK1.8，可以通过stream流实现排序，对象本身不需要实现Comparable接口，示例代码如下</p>
</blockquote>
<pre><code>//3.利用Java8的stream流和Comparator实现集合排序
list = list.stream().sorted(Comparator.comparing(Person::getAge)).collect(Collectors.toList());
</code></pre><h2 id="数据库相关-包含Dao相关组件"><a href="#数据库相关-包含Dao相关组件" class="headerlink" title="数据库相关(包含Dao相关组件)"></a>数据库相关(包含Dao相关组件)</h2><blockquote>
<p>本章节主要记录数据库相关的技术点，包含Dao相关组件的使用，如JPA、Mybatis等</p>
</blockquote>
<h3 id="mybatis-update自动追加逗号-“-”"><a href="#mybatis-update自动追加逗号-“-”" class="headerlink" title="mybatis update自动追加逗号 “,”"></a>mybatis update自动追加逗号 “,”</h3><p>一个推荐的SQL如下：</p>
<pre><code>&lt;update id=&quot;updateOne&quot;  parameterType=&quot;com.inspur.search.data.EntityRelation&quot;&gt;
    UPDATE ENTITY_RELATION
        &lt;trim prefix=&quot;set&quot; suffixOverrides=&quot;,&quot;&gt;
        &lt;if test=&quot;srcId!=null&quot;&gt;SRC_ID=#{srcId},&lt;/if&gt;
        &lt;if test=&quot;srcType!=null&quot;&gt;SRC_TYPE=#{srcType},&lt;/if&gt;
        &lt;if test=&quot;destId!=null&quot;&gt;DEST_ID=#{destId},&lt;/if&gt;
        &lt;if test=&quot;destType!=null&quot;&gt;DEST_TYPE=#{destType},&lt;/if&gt;
        &lt;if test=&quot;relType!=null&quot;&gt;REL_TYPE=#{relType},&lt;/if&gt;
        &lt;if test=&quot;status!=null&quot;&gt;STATUS=#{status},&lt;/if&gt;
        &lt;if test=&quot;snId!=null&quot;&gt;SN_ID=#{snId},&lt;/if&gt;
        &lt;/trim&gt;
    WHERE id=#{id}
&lt;/update&gt;
</code></pre><p>这种方式是动态SQL拼接，使用trim是为了删掉最后字段的“,”</p>
<p>不用单独写SET了，因为set被包含在trim中了</p>
<h3 id="mybatis使用truncate语句"><a href="#mybatis使用truncate语句" class="headerlink" title="mybatis使用truncate语句"></a>mybatis使用truncate语句</h3><p>在mybatis中使用truncate语句刷新表。</p>
<pre><code>&lt;update id=&quot;truncateTable&quot;&gt;
    truncate table [表名]
&lt;/update&gt;
</code></pre><h3 id="mybatis使用-Param传参以及批量插入"><a href="#mybatis使用-Param传参以及批量插入" class="headerlink" title="mybatis使用@Param传参以及批量插入"></a>mybatis使用@Param传参以及批量插入</h3><blockquote>
<p>@Param Parameter N/A 如果你的映射器的方法需要多个参数, 这个注解可以被应用于映射器的方法参数来给每个参数一个名字。否则,多参数将会以它们的顺序位置来被命名 (不包括任何 RowBounds 参数) 比如。 #{param1} , #{param2} 等 , 这是默认的。 </p>
<p>如果使用 @Param(“person”), 则参数应该被命名为 #{person}。</p>
</blockquote>
<p>这里重点总结一个场景，批量insert。对应sql如下：</p>
<pre><code>&lt;insert id=&quot;batchInsertIdList&quot; parameterType=&quot;java.util.List&quot;&gt;
    insert into idlist_tmp (id, record_date) values
    &lt;foreach collection=&quot;tmpInfos&quot; item=&quot;tmpInfo&quot; separator=&quot;,&quot;&gt;
        (#{tmpInfo.id}, #{tmpInfo.recordDate})
    &lt;/foreach&gt;
&lt;/insert&gt;
</code></pre><p>这里通过#{tmpInfo.id}指定insert参数为对象tmpInfo的某个属性</p>
<pre><code>int batchInsert(@Param(value = &quot;tmpInfos&quot;) List&lt;TmpInfo&gt; tmpInfos);
</code></pre><p>这里通过@Param指定insert的sql中的参数引用。</p>
<h3 id="MySQL建表时设置timestamp精度到毫秒"><a href="#MySQL建表时设置timestamp精度到毫秒" class="headerlink" title="MySQL建表时设置timestamp精度到毫秒"></a>MySQL建表时设置timestamp精度到毫秒</h3><pre><code>CREATE TABLE `table1` (
`tab1_id` VARCHAR(11) DEFAULT NULL,
`create` TIMESTAMP(3) NULL DEFAULT NULL,
`create2` DATETIME(3) DEFAULT NULL
) ENGINE=INNODB DEFAULT CHARSET=utf8
</code></pre><p>设置精度的方式为：</p>
<pre><code>TIMESTAMP(3)与 DATETIME(3)意思是保留3位毫秒数

TIMESTAMP(6)与 DATETIME(6)意思是保留6位毫秒数
</code></pre><p>修改字段精度的方式为：</p>
<pre><code>ALTER TABLE tb_financial MODIFY CREATE_TIME DATETIME(3) DEFAULT NULL COMMENT &apos;录入时间&apos;;
</code></pre><p>插入日期可以用NOW(3)来控制精确的毫秒数，如：SELECT CURRENT_TIMESTAMP(3);也是可以的</p>
<h3 id="mybatis批量插入"><a href="#mybatis批量插入" class="headerlink" title="mybatis批量插入"></a>mybatis批量插入</h3><p><a href="https://www.jianshu.com/p/c3c890e17e4c" target="_blank" rel="external">mybatis 批量插入数据</a></p>
<p><a href="https://www.cnblogs.com/shuaifing/p/9327465.html" target="_blank" rel="external">mybatis批量保存的两种方式(高效插入)</a></p>
<h3 id="MySQL的case-when语法"><a href="#MySQL的case-when语法" class="headerlink" title="MySQL的case when语法"></a>MySQL的case when语法</h3><p>语法如下：</p>
<pre><code>select 字段1, 字段2,       
    case 字段3     
    when 值1 then 新值       
    when 值2 then 新值      
    end as 重新命名字段3的名字       
from table      
where ……      
order by ……  
</code></pre><p>如：</p>
<pre><code>SELECT
    m.id AS id0,
    v.id AS id1,
    v.user_id AS userId,
    v.app_id AS appId
    (
    CASE
            WHEN v.label = 0 THEN
            &apos;清晰&apos; 
            WHEN v.label = 1 THEN
            &apos;模糊&apos; 
            WHEN v.label = 2 THEN
            &apos;超清晰&apos; ELSE &apos;其他&apos; 
        END 
        ) AS &apos;清晰度&apos;
    FROM
        video_info v,
        media_info m 
    WHERE
        v.id = m.id 
        AND m.id IN (
            &apos;123123&apos;,
            &apos;123124&apos;,
            &apos;123125&apos;
        )
</code></pre><p>参考资料: <a href="https://blog.csdn.net/helloxiaozhe/article/details/78124138" target="_blank" rel="external">MySQL 的CASE WHEN 语句使用说明</a>    </p>
<h2 id="工具技巧"><a href="#工具技巧" class="headerlink" title="工具技巧"></a>工具技巧</h2><blockquote>
<p>本章节主要记录各种工具使用的技巧，如IDEA GIT等</p>
</blockquote>
<h3 id="跨主机进行文件复制"><a href="#跨主机进行文件复制" class="headerlink" title="跨主机进行文件复制"></a>跨主机进行文件复制</h3><p><a href="https://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/scp.html" target="_blank" rel="external">参考链接</a></p>
<blockquote>
<p>从本地服务器复制到远程服务器</p>
</blockquote>
<p>复制文件:</p>
<pre><code>$scp local_file remote_username@remote_ip:remote_folder
$scp local_file remote_username@remote_ip:remote_file
$scp local_file remote_ip:remote_folder
$scp local_file remote_ip:remote_file
指定了用户名，命令执行后需要输入用户密码；如果不指定用户名，命令执行后需要输入用户名和密码；
</code></pre><p>复制目录:</p>
<pre><code>$scp -r local_folder remote_username@remote_ip:remote_folder
$scp -r local_folder remote_ip:remote_folder
第1个指定了用户名，命令执行后需要输入用户密码； 第2个没有指定用户名，命令执行后需要输入用户名和密码；
</code></pre><p>注解</p>
<blockquote>
<p>从远程复制到本地的scp命令与上面的命令一样，只要将从本地复制到远程的命令后面2个参数互换顺序就行了。</p>
</blockquote>
<p>使用示例</p>
<p>实例1：从远处复制文件到本地目录</p>
<pre><code>$scp root@10.6.159.147:/opt/soft/demo.tar /opt/soft/
说明： 从10.6.159.147机器上的/opt/soft/的目录中下载demo.tar 文件到本地/opt/soft/目录中
</code></pre><p>实例2：从远处复制到本地</p>
<pre><code>$scp -r root@10.6.159.147:/opt/soft/test /opt/soft/
说明： 从10.6.159.147机器上的/opt/soft/中下载test目录到本地的/opt/soft/目录来。
</code></pre><p>实例3：上传本地文件到远程机器指定目录</p>
<pre><code>$scp /opt/soft/demo.tar root@10.6.159.147:/opt/soft/scptest
说明： 复制本地opt/soft/目录下的文件demo.tar 到远程机器10.6.159.147的opt/soft/scptest目录
</code></pre><p>实例4：上传本地目录到远程机器指定目录</p>
<pre><code>$scp -r /opt/soft/test root@10.6.159.147:/opt/soft/scptest
说明： 上传本地目录 /opt/soft/test到远程机器10.6.159.147上/opt/soft/scptest的目录中
</code></pre><h3 id="idea自动导包"><a href="#idea自动导包" class="headerlink" title="idea自动导包"></a>idea自动导包</h3><pre><code>IDEA自动导包配置方式如下：

在菜单中选择如下选项：
 Settings→
    Editor→
        General→
            Auto Import 
然后勾选Add unambiguous imports on the fly以及Optimize imports on the fly
</code></pre><p>解释一下含义：</p>
<pre><code>Add unambiguous imports on the fly：        快速添加明确的导入。
Optimize imports on the fly：               快速优化导入，优化的意思即自动帮助删除无用的导入。
</code></pre><h2 id="打包运行相关"><a href="#打包运行相关" class="headerlink" title="打包运行相关"></a>打包运行相关</h2><blockquote>
<p>本章节主要记录打包相关的问题</p>
</blockquote>
<h3 id="如何通过命令行传递带空格的参数"><a href="#如何通过命令行传递带空格的参数" class="headerlink" title="如何通过命令行传递带空格的参数?"></a>如何通过命令行传递带空格的参数?</h3><p>通过参数引用即可解决该问题，在UNIX环境下，通过引号将带空格的参数括起来即可，如：</p>
<pre><code>$ java PrintFileSizes &quot;/home/steve/Test File.txt&quot;
</code></pre><h3 id="Linux下找出进程正在侦听的端口号"><a href="#Linux下找出进程正在侦听的端口号" class="headerlink" title="Linux下找出进程正在侦听的端口号"></a>Linux下找出进程正在侦听的端口号</h3><p>在Linux下快速查到正在侦听的端口号，命令如下：</p>
<pre><code># 安装工具包，默认已安装，centos下为yum install
sudo apt install net-tools
# 查看侦听中的端口
sudo netstat -ltnp
</code></pre><h3 id="nohup的作用"><a href="#nohup的作用" class="headerlink" title="nohup的作用"></a>nohup的作用</h3><p>举个例子，有启动命令如下</p>
<pre><code>nohup java -jar XXX.jar &gt; /dev/null 2&gt;&amp;1 &amp; 
</code></pre><p>nohup表示：不挂断运行命令,当账户退出或终端关闭时,程序仍然运行。</p>
<p>/dev/null 是一个特殊的文件，写入到它的内容都会被丢弃；这里表示”禁止输出”。我们应当在程序内配置日志打印。</p>
<p>其他用法：<a href="https://blog.csdn.net/wngpenghao/article/details/83022185" target="_blank" rel="external">linux环境下nohup的执行jar</a></p>
<h3 id="git更新带子module的工程"><a href="#git更新带子module的工程" class="headerlink" title="git更新带子module的工程"></a>git更新带子module的工程</h3><ol>
<li><p>首先克隆父工程</p>
<pre><code>git clone ssh://xxxxxx.git

查看子模块

git submodule

子模块前面有一个-，说明子模块文件还未检入（空文件夹）。
</code></pre></li>
<li><p>然后在父工程根路径下初始化子工程</p>
<pre><code>git submodule init

初始化模块只需在克隆父项目后运行一次。
</code></pre></li>
<li><p>更新子工程</p>
<pre><code>git submodule update
</code></pre></li>
</ol>
<h2 id="方法2–递归方式"><a href="#方法2–递归方式" class="headerlink" title="方法2–递归方式"></a>方法2–递归方式</h2><p>递归克隆整个项目</p>
<pre><code>git clone ssh://xxxx.git assets --recursive 
</code></pre><p>递归克隆整个项目，子模块已经同时更新了，一步到位。</p>
<h2 id="Spring相关"><a href="#Spring相关" class="headerlink" title="Spring相关"></a>Spring相关</h2><blockquote>
<p>这部分主要整理Spring框架相关的问题，包括SpringBoot</p>
</blockquote>
<h3 id="Spring中通过-Value-设置默认值"><a href="#Spring中通过-Value-设置默认值" class="headerlink" title="Spring中通过 @Value 设置默认值"></a>Spring中通过 @Value 设置默认值</h3><pre><code>1.1 字符串类型的属性设置默认值

    @Value(&quot;${some.key:my default value}&quot;)
    private String stringWithDefaultValue;

    如果默认值设为空，也将会被设置成默认值。

    @Value(&quot;${some.key:}&quot;)
    private String stringWithBlankDefaultValue;

1.2 基本类型设置默认值

    布尔类型
    @Value(&quot;${some.key:true}&quot;)
    private boolean booleanWithDefaultValue;

    数字类型
    @Value(&quot;${some.key:42}&quot;)
    private int intWithDefaultValue;

1.3 包装类型设置默认值

    布尔类型
    @Value(&quot;${some.key:true}&quot;)
    private Boolean booleanWithDefaultValue;

    数字类型
    @Value(&quot;${some.key:42}&quot;)
    private Integer intWithDefaultValue;

1.4 数组的默认值使用逗号分割

    @Value(&quot;${some.key:one,two,three}&quot;)
    private String[] stringArrayWithDefaults;

    @Value(&quot;${some.key:1,2,3}&quot;)
    private int[] intArrayWithDefaults;

1.5 使用 Spring Expression Language (SpEL) 设置默认值

    @Value(&quot;#{systemProperties[&apos;some.key&apos;] ?: &apos;my default system property value&apos;}&quot;)
    private String spelWithDefaultValue;

    这表示：在systemProperties属性文件中，如果没有设置 some.key 的值，my default system property value 会被设置成默认值。
</code></pre><h2 id="Jersey相关"><a href="#Jersey相关" class="headerlink" title="Jersey相关"></a>Jersey相关</h2><blockquote>
<p>这里记录Jersey相关的内容</p>
</blockquote>
<h3 id="Jersey常用方法"><a href="#Jersey常用方法" class="headerlink" title="Jersey常用方法"></a>Jersey常用方法</h3><p><a href="https://blog.csdn.net/itchiang/article/details/50582979" target="_blank" rel="external">jersey获取各个参数的总结</a></p>
<h3 id="查看Jersey-REST服务的WADL服务定义"><a href="#查看Jersey-REST服务的WADL服务定义" class="headerlink" title="查看Jersey REST服务的WADL服务定义"></a>查看Jersey REST服务的WADL服务定义</h3><p>查看WADL服务定义通过下方URL即可访问到。</p>
<pre><code>http://ip:port/应用根路径/application.wadl
</code></pre><h2 id="Json解析相关"><a href="#Json解析相关" class="headerlink" title="Json解析相关"></a>Json解析相关</h2><blockquote>
<p>这里主要解析Json解析相关的技术点。</p>
</blockquote>
<h3 id="Jackson整理"><a href="#Jackson整理" class="headerlink" title="Jackson整理"></a>Jackson整理</h3><ol>
<li><p>在Jackson中将JsonNode转换为Object</p>
<p>mapper.convertValue(jsonNode, MyPojo.class)</p>
</li>
<li><p>Jackson中的TypeReference</p>
<p> 一般情况下如果没有TypeReference的话，JsonNode转换过来的是LinkedHashMap而不是对象本身，因此<br> 需要使用TypeReference来进行Json的解析</p>
<p> 如：</p>
<pre><code>List&lt;TableColumns&gt; columns = mapper.convertValue(params.get(&quot;columns&quot;), new TypeReference&lt;List&lt;TableColumns&gt;&gt;() {});

对于复杂Json的转换，需要通过TypeReference解析，TypeReference可以正确反序列化嵌套多层的List或Map，例如List&lt;Map&lt;String,String&gt;&gt;
</code></pre><p> 举个实际的例子，</p>
<pre><code>Map&lt;String, MarkDetail&gt; markDetailMap = objectMapper.convertValue(haveMarkDetails, new TypeReference&lt;Map&lt;String,MarkDetail&gt;&gt;() {});

Map&lt;String, String&gt; dataDetailMap = objectMapper.convertValue(dataDetailJsonNode, new TypeReference&lt;Map&lt;String, String&gt;&gt;() {});
</code></pre><p> 可以看到，convertValue的第二个参数是一个TypeReference实例。通过这种方式能够将复杂json类型进行正确解析。</p>
</li>
</ol>
<h2 id="ffmpeg"><a href="#ffmpeg" class="headerlink" title="ffmpeg"></a>ffmpeg</h2><p>ffmpeg的几个工具基本用法</p>
<blockquote>
<p>ffmpeg是用于转码的应用程序。</p>
</blockquote>
<p>一个简单的转码命令可以这样写：</p>
<pre><code>将input.avi转码成output.ts，并设置视频的码率为640kbps

ffmpeg -i videoplayback.mp4 -b:v 640k output.ts
</code></pre><blockquote>
<p>用于播放的应用程序。</p>
</blockquote>
<pre><code>一个简单的播放命令可以这样写：

播放test.avi

ffplay test.avi
</code></pre><blockquote>
<p>ffprobe是用于查看文件格式的应用程序。</p>
</blockquote>
<p>这个就不多介绍了。</p>
<pre><code>ffprobe videoplayback.mp4
</code></pre><h2 id="维护多个sshkey"><a href="#维护多个sshkey" class="headerlink" title="维护多个sshkey"></a>维护多个sshkey</h2><blockquote>
<p>在公司与开源社区之间切换，有多个git账户，因此需要一个策略用于维护多个sshkey</p>
</blockquote>
<p>由于有两个账号，生成密钥时通常都是三个回车一撸到底，那么后执行的会覆盖先执行的。</p>
<p>三个回车中，第一个回车的意思是保存地址，那我们不直接回车，而是输入保存地址就可以。</p>
<h3 id="具体步骤"><a href="#具体步骤" class="headerlink" title="具体步骤"></a>具体步骤</h3><ol>
<li><p>生成第一个密钥</p>
<pre><code>ssh-keygen -t rsa -C &quot;myoschina@qq.com&quot;
</code></pre></li>
</ol>
<p>连续三个回车，将oschina的密钥默认保存</p>
<ol>
<li>生成第二个密钥</li>
</ol>
<p>在C盘/Users/用户名/.ssh下建立一个新的目录，如：github</p>
<p>接着运行命令生成第二个sshkey</p>
<pre><code>ssh-keygen -t rsa -C &quot;github@gmail.com&quot;
</code></pre><p>出现Enter file in which to save the key时输入</p>
<pre><code>/c/Users/用户名/.ssh/github/id_rsa
</code></pre><p>表示将本次生成的key保存在建立的github目录下</p>
<ol>
<li>创建config文件</li>
</ol>
<p>C盘/Users/用户名/.ssh下新建config文件，该文件没有后缀名的，用途是配置映射功能，填入下面代码：</p>
<pre><code>#github配置
Host github.com
HostName github.com
IdentityFile ~/.ssh/github/id_rsa
User git

#gitoschina的配置
Host git.oschina.net
HostName git.oschina.net
IdentityFile ~/.ssh/id_rsa
User git
</code></pre><blockquote>
<p>HostName是服务器域名，IdentityFile 是密钥的地址.</p>
</blockquote>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将主要记录在日常开发中遇到的各种问题。以技术类别进行章节划分，作为个人的编码备忘录随时进行查阅，并长期进行置顶。&lt;/p&gt;
&lt;h2 id=&quot;JavaCore相关&quot;&gt;&lt;a href=&quot;#JavaCore相关&quot; class=&quot;headerlink&quot; title=&quot;JavaCore相关&quot;&gt;&lt;/a&gt;JavaCore相关&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;该模块主要记录JavaCore相关的技术点&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;bigdecimal四舍五入&quot;&gt;&lt;a href=&quot;#bigdecimal四舍五入&quot; class=&quot;headerlink&quot; title=&quot;bigdecimal四舍五入&quot;&gt;&lt;/a&gt;bigdecimal四舍五入&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;BigDecimal.ROUND_HALF_UP: 遇到.5的情况时往上近似,例: 1.5 -&amp;gt;;2
BigDecimal.ROUND_HALF_DOWN : 遇到.5的情况时往下近似,例: 1.5 -&amp;gt;;1
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;bigDecimal转换为百分比，保留若干小数&quot;&gt;&lt;a href=&quot;#bigDecimal转换为百分比，保留若干小数&quot; class=&quot;headerlink&quot; title=&quot;bigDecimal转换为百分比，保留若干小数&quot;&gt;&lt;/a&gt;bigDecimal转换为百分比，保留若干小数&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;DecimalFormat decimalFormat = new DecimalFormat(&amp;quot;0.00%&amp;quot;);
BigDecimal decimal = new BigDecimal(count.intValue()).divide(new BigDecimal(allCount), 5, ROUND_HALF_UP);
String formatted = decimalFormat.format(sdPercent);
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;bigDecimal精确度&quot;&gt;&lt;a href=&quot;#bigDecimal精确度&quot; class=&quot;headerlink&quot; title=&quot;bigDecimal精确度&quot;&gt;&lt;/a&gt;bigDecimal精确度&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;BigDecimal.setScale(5,  BigDecimal.ROUND_HALF_UP)  --&amp;gt;保留五位小数,最后一位遇到.5的情况时往上近似
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
      <category term="Java" scheme="http://wuwenliang.net/categories/Java/"/>
    
    
      <category term="Java" scheme="http://wuwenliang.net/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Spring Boot整合Jersey开发RESTful服务</title>
    <link href="http://wuwenliang.net/2019/11/19/Spring-Boot%E6%95%B4%E5%90%88Jersey%E5%BC%80%E5%8F%91RESTful%E6%9C%8D%E5%8A%A1/"/>
    <id>http://wuwenliang.net/2019/11/19/Spring-Boot整合Jersey开发RESTful服务/</id>
    <published>2019-11-19T12:19:33.000Z</published>
    <updated>2019-11-19T12:24:44.087Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>本文整理一下在Spring Boot中整合Jersey实现RESTful接口的开发。</p>
</blockquote>
<p>最官方的，当然是Spring Boot的官方文档，<a href="https://docs.spring.io/spring-boot/docs/2.2.1.RELEASE/reference/htmlsingle/#boot-features-jersey" target="_blank" rel="external">官方文档中关于整合Jersey的说明</a></p>
<p>我们主要关注如下步骤</p>
<blockquote>
<p>To get started with Jersey, include the spring-boot-starter-jersey as a dependency </p>
</blockquote>
<p>想要在Spring Boot中使用Jersey首先需要引入Jersey支持，坐标如下(我的项目是基于2.2.1.RELEASE构建的)：</p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-jersey&lt;/artifactId&gt;
    &lt;version&gt;2.2.1.RELEASE&lt;/version&gt;
&lt;/dependency&gt;
</code></pre><a id="more"></a>
<blockquote>
<p>and then you need one @Bean of type ResourceConfig in which you register all the endpoints, as shown in the following example:</p>
</blockquote>
<p>引入依赖之后，需要定义一个ResourceConfig资源配置，并且将需要对外暴露为RESTful接口的方法所在的类注册给jersey</p>
<pre><code>@Component
public class JerseyConfig extends ResourceConfig {

    public JerseyConfig() {
        register(Endpoint.class);
    }
}
</code></pre><p>JerseyConfig继承了ResourceConfig，在构造中对Endpoint进行了注册，Endpoint为对外暴露RESTful接口的实现类。</p>
<p>这里需要注意的是，jersey无法通过扫描package的方式扫描可执行jar以及WEB-INF/classs中的包中的endpoints。解决方法也很直接，避免使用package方法进行扫描，改为对每个endPoint类单独进行注册，也就是上面提到的这种方式。<strong>这里想表达的是，ResourceConfig.register方法支持链式调用，我们可以一次性将所有需要对外暴露的endPoint类都注册给ResourceConfig</strong></p>
<blockquote>
<p>For more advanced customizations, you can also register an arbitrary number of beans that implement ResourceConfigCustomizer.</p>
</blockquote>
<p>官网在这里补充到，我们还可以通过实现ResourceConfigCustomizer接口从而实现endPoint资源的注入，一个样例如下：</p>
<pre><code>@Component
public class DemoResourceConfigCustomizer implements ResourceConfigCustomizer {
    @Override
    public void customize(ResourceConfig config) {
        config.register(SpringbootResource.class);
    }
}
</code></pre><p>这里我建立了一个实现ResourceConfigCustomizer接口的配置类DemoResourceConfigCustomizer，实现它的回调方法customize，通过ResourceConfig.register同样实现了资源的注册。</p>
<blockquote>
<p>All the registered endpoints should be @Components with HTTP resource annotations (@GET and others), as shown in the following example:</p>
</blockquote>
<p>完成前面的整合，进入了最为关键的阶段，官网告诉我们，每一个注册的endPoint都应该是一个Spring的bean（标注了@Component，@Service等注解，声明为一个Spring的bean），并且需要在类上，方法上标注javax.ws.rs注解，如：<strong>@GET、@Path等</strong>。</p>
<p>到此我们就完成了基本的Jersey整合Spring Boot的操作，启动应用，通过@Path声明的路径调用我们的接口即可。</p>
<p>来看一个最简单的endPoint代码样例，我直接引用官方的代码样例：</p>
<pre><code>@Component
@Path(&quot;/hello&quot;)
public class Endpoint {

    @GET
    public String message() {
        return &quot;Hello&quot;;
    }

}
</code></pre><p>对于使用过SpringMVC的开发者，这段代码就很亲切了，它其实就类似于SpringMVC中的controller。</p>
<p>总的来说，还是比较简单直观的，习惯了使用SpringMVC之后，换一种开发方式也不失为一种新的体验，更重要的，Jersey框架不仅实现了JAX-RS规范,还提供了自有API以扩展JAX-RS, 它作为官方的实现是值得我们去学习的。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://docs.spring.io/spring-boot/docs/2.2.1.RELEASE/reference/htmlsingle/#boot-features-jersey" target="_blank" rel="external">官方文档中关于整合Jersey的说明</a></p>
<p><a href="https://www.jianshu.com/p/c14a9028e6e7" target="_blank" rel="external">Jersey 开发RESTful（十八） Springboot集成Jersey</a></p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文整理一下在Spring Boot中整合Jersey实现RESTful接口的开发。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;最官方的，当然是Spring Boot的官方文档，&lt;a href=&quot;https://docs.spring.io/spring-boot/docs/2.2.1.RELEASE/reference/htmlsingle/#boot-features-jersey&quot;&gt;官方文档中关于整合Jersey的说明&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;我们主要关注如下步骤&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;To get started with Jersey, include the spring-boot-starter-jersey as a dependency &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;想要在Spring Boot中使用Jersey首先需要引入Jersey支持，坐标如下(我的项目是基于2.2.1.RELEASE构建的)：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spring-boot-starter-jersey&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;2.2.1.RELEASE&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
      <category term="spring-boot" scheme="http://wuwenliang.net/categories/spring-boot/"/>
    
    
      <category term="spring-boot" scheme="http://wuwenliang.net/tags/spring-boot/"/>
    
  </entry>
  
  <entry>
    <title>音视频相关业务名词解释</title>
    <link href="http://wuwenliang.net/2019/11/18/%E9%9F%B3%E8%A7%86%E9%A2%91%E7%9B%B8%E5%85%B3%E4%B8%9A%E5%8A%A1%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/"/>
    <id>http://wuwenliang.net/2019/11/18/音视频相关业务名词解释/</id>
    <published>2019-11-18T03:23:11.000Z</published>
    <updated>2019-11-18T03:27:50.291Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>本文为扫盲文，为刚进入音视频行业的同学提供一些专业名词的解释，方便更快熟悉音视频相关的业务。</p>
</blockquote>
<h2 id="视频上传"><a href="#视频上传" class="headerlink" title="视频上传"></a>视频上传</h2><p>顾名思义，<strong>视频上传</strong> 即通过使用相关工具，将视频从本地导入到云端服务器进行存储的过程。</p>
<a id="more"></a>
<h2 id="stream视频流"><a href="#stream视频流" class="headerlink" title="stream视频流"></a>stream视频流</h2><p>视频流是指视频数据的传输，例如，它能够被作为一个稳定的和连续的流通过网络处理。</p>
<p>因为流动，客户机浏览器或插件能够在整个文件被传输完成前显示多媒体数据。</p>
<blockquote>
<p>视频流式传输的优点：</p>
<ol>
<li>启动时延大幅度缩短，边下边播，不需要等待所有内容下载完成才开始浏览。网络状况较好的情况下，卡顿较少，但快进、快退需要时间等待</li>
<li>对系统缓存容量的需求大大降低， 由于Internet是以包传输为基础进行断续的异步传输，数据被分解为许多包进行传输，动态变化的网络使各个包可能选择不同的路由，故到达用户计算机的时间延迟也就不同。所以，在客户端需要缓存系统来弥补延迟和抖动的影响和保证数据包传输顺序的正确，使媒体数据能连续输出，不会因网络暂时拥堵而使播放出现停顿。虽然流式传输仍需要缓存，但由于不需要把所有的动画、视音频内容都下载到缓存中，因此，对缓存的要求降低。</li>
<li>流式传输的实现有特定的实时传输协议采用RTSP等实时传输协议，更加适合动画、视音频在网上的流式实时传输。</li>
</ol>
</blockquote>
<h3 id="流媒体的组成部分"><a href="#流媒体的组成部分" class="headerlink" title="流媒体的组成部分"></a>流媒体的组成部分</h3><ol>
<li>编码工具：用于创建、捕捉和编辑多媒体数据，形成流媒体格式</li>
<li>流媒体数据</li>
<li>服务器：存放和控制流媒体的数据</li>
<li>网络：适合多媒体传输协议甚至是实时传输协议的网络</li>
<li>播放器：供客户端浏览流媒体文件 这5个部分有些是网站需要的，有些是客户端需要的，而且不同的流媒体标准和不同公司的解决方案会在某些方面有所不同。 3、各种多媒体信息的流媒体传输格式 在Internet上所传输的多媒体格式中，基本上只有文本、图形可以照原格式在网上传输。动画、音频、视频等虽然可以直接播放在网上播放，但文件偏大，即使使用专线上网，也要等完全下载后才能观看，这三种类型的媒体均要采用流式技术来进行处理以便于在网上传输。另外，还有一些如PowerPoint文件、多媒体课件等内容也需要用流式技术进行传输。 流媒体格式是将一个资料（动画、影音等）分段传送，用户不必等待整个内容传送完毕，就可以观看到即时的连续的内容，甚至可以随时的暂停、快进、快倒。由于不同的公司发展的文件格式不同，传送的方式也有所差异，因此，我们必须非常清楚各种流媒体文件的格式。</li>
</ol>
<h3 id="视频播放"><a href="#视频播放" class="headerlink" title="视频播放"></a>视频播放</h3><p>流媒体是从英语Streaming Media中翻译过来，它是一种可以使音频、视频和其它多媒体能在Internet及Intranet上以实时的、无需下载等待的方式进行播放的技术。流媒体文件格式是支持采用流式传输及播放的媒体格式。流式传输方式是将动画、视音频等多媒体文件经过特殊的压缩方式分成一个个压缩包用户不必像非流式播放那样等到整个文件全部下载完毕后才能看到当中的内容，而是只需经过几秒或几十秒的启动延时即可在用户的计算机上利用相应的播放器或其它的硬件、软件对压缩的动画、视音频等流式多媒体文件解压后进行播放和观看，多媒体文件的剩余部分将在后台的服务器内继续下载。</p>
<h3 id="流式下载编辑"><a href="#流式下载编辑" class="headerlink" title="流式下载编辑"></a>流式下载编辑</h3><p>下载边播放的BT软件,下载时必须要从电影的开头下载,而并非是其它BT软件的下载方式.，这种可以边下载边播放的下载 方式,就可以称为流式下载… 　如果想要边下载边播放的话,就推荐你用流式下载. 　如果是其它无法在线播放的资源,推荐使用非流式下载. 　媒体是指采用流式传输的方式在Internet播放的媒体格式。 　流式传输方式则是将整个A/V及3D等多媒体文件经过特殊的压缩方式分成一个个压缩包，由视频服务器向用户计算机连续、实时传送。在采用流式传输方式的系统中，用户不必像采用下载方式那样等到整个文件全部下载完毕，而是只需经过几秒或几十秒的启动延时即可在用户的计算机上利用解压设备(硬件或软件)对压缩的A/V、3D等多媒体文件解压后进行播放和观看。此时多媒体文件的剩余部分将在后台的服务器内继续下载。 　与单纯的下载方式相比，这种对多媒体文件边下载边播放的流式传输方式不仅使启动延时大幅度地缩短，而且对系统缓存容量的需求也大大降低。（ChinaByte）</p>
<h2 id="H264-H265"><a href="#H264-H265" class="headerlink" title="H264 H265"></a>H264 H265</h2><p>H.265与H.264有何不同,同等画质体积仅为一半、带宽占用省一半、画质更细腻等诸多优势  首先分别介绍一下：H.264与H.265</p>
<p>1、H.264也称作MPEG-4AVC(Advanced Video Codec，高级视频编码)，是一种视频压缩标准，同时也是一种被广泛使用的高精度视频的录制、压缩和发布格式。H.264因其是蓝光光盘的一种编解码标准而着名，所有蓝光播放器都必须能解码H.264。H.264相较于以前的编码标准有着一些新特性，如多参考帧的运动补偿、变块尺寸运动补偿、帧内预测编码等，通过利用这些新特性，H.264比其他编码标准有着更高的视频质量和更低的码率</p>
<p>2、H.265/HEVC的编码架构大致上和H.264/AVC的架构相似，也主要包含：帧内预测(intra prediction)、帧间预测(inter prediction)、转换 (transform)、量化 (quantization)、去区块滤波器(deblocking filter)、熵编码(entropy coding)等模块。但在HEVC编码架构中，整体被分为了三个基本单位，分别是：编码单位(coding unit，CU)、预测单位(predict unit，PU) 和转换单位(transform unit，TU )。<br>H.265是新的编码协议，也即是H.264的升级版。</p>
<h2 id="视频拆条"><a href="#视频拆条" class="headerlink" title="视频拆条"></a>视频拆条</h2><p>视频拆条是因互联网视频和新媒体短视频内容平台的需要，对传统电视媒体节目进行二次加工，将原来完整的一条节目内容，按照某种逻辑思维或特定需要，将其拆分成多条视频。</p>
<p>互联网视频内容的主要来源包括传统电视媒体的节目、各类机构视频成品、影视公司影视作品，通过将这些视频拆条，可以深度挖掘有价值的信息，重新编目后，可用于IPTV、OTT、手机电视和新媒体短视频平台，满足新媒体视听节目碎片化要求，是视音频编目行业一个新的尝试和探索。</p>
<h2 id="视频抽帧"><a href="#视频抽帧" class="headerlink" title="视频抽帧"></a>视频抽帧</h2><p>从视频流中截取关键的帧</p>
<p>简单的说，视频抽帧就是从视频中把要做抽帧的片段在轨道里放到能看见一帧帧画面的模式，用刀片再割断删除你要去除的某帧，比如每隔一帧去除一帧，或者每隔三帧去除二帧<del>~</del>等等等等，然后将剩下的帧移动紧挨对齐，这就是抽帧。</p>
<h3 id="视频帧率"><a href="#视频帧率" class="headerlink" title="视频帧率"></a>视频帧率</h3><p>视频帧率（Frame rate）是用于测量显示帧数的量度。所谓的测量单位为每秒显示帧数(Frames per Second，简：FPS）或“赫兹”（Hz）。此词多用于影视制作和电子游戏。</p>
<p>视频帧率（Frame rate）是用于测量显示帧数的量度。所谓的测量单位为每秒显示帧数(Frames per Second，简：FPS）或“赫兹”（Hz）。此词多用于影视制作和电子游戏。</p>
<h2 id="视频分发"><a href="#视频分发" class="headerlink" title="视频分发"></a>视频分发</h2><p>一般视频分发基于算法进行</p>
<p>视频来源多样化，有的基于UCG（用户主动生成），有些基于爬虫，爬取其他平台的内容（一般都有水印）</p>
<p>视频分发还可以配合精准推荐算法，进行定向广告投放</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">在爱奇艺头条的商业化上，爱奇艺与百度合作力求让信息流广告更精准：依托从百度搜索引擎的数据，知道每个爱奇艺用户过去三十天在百度上搜索过什么类型关键词，根据他的消费兴趣爱好，可以帮助广告主投放定向广告。无论对于广告主、视频创作者还是爱奇艺，这都是件好事。</div></pre></td></tr></table></figure>
<h2 id="视频缩略图"><a href="#视频缩略图" class="headerlink" title="视频缩略图"></a>视频缩略图</h2><p>一般会抽取视频第一帧作为视频缩略图，或者支持后台上传图片作为视频缩略图</p>
<h2 id="ffmpeg"><a href="#ffmpeg" class="headerlink" title="ffmpeg"></a>ffmpeg</h2><p>FFmpeg是一个开源免费跨平台的视频和音频流方案，属于自由软件，采用LGPL或GPL许可证（依据你选择的组件）。它提供了录制、转换以及流化音视频的完整解决方案。它包含了非常先进的音频/视频编解码库libavcodec，为了保证高可移植性和编解码质量，libavcodec里很多codec都是从头开发的。</p>
<p>这个项目最早由Fabrice Bellard发起，现在由Michael Niedermayer维护。许多FFmpeg的开发人员都来自MPlayer项目，而且当前FFmpeg也是放在MPlayer项目组的服务器上。项目的名称来自MPEG视频编码标准，前面的”FF”代表”Fast Forward”。</p>
<p>FFmpeg是一套可以用来记录、转换数字音频、视频，并能将其转化为流的开源计算机程序。它包括了目前领先的音/视频编码库libavcodec。 FFmpeg是在Linux下开发出来的，但它可以在包括Windows在内的大多数操作系统中编译。这个项目是由Fabrice Bellard发起的，现在由Michael Niedermayer主持。可以轻易地实现多种视频格式之间的相互转换，例如可以将摄录下的视频avi等转成现在视频网站所采用的flv格式。</p>
<h2 id="misc转码"><a href="#misc转码" class="headerlink" title="misc转码"></a>misc转码</h2><p>个人认为这是混合转码的一种综合说法</p>
<h2 id="视频加工"><a href="#视频加工" class="headerlink" title="视频加工"></a>视频加工</h2><p>通过工具对视频进行基本分析（长宽），格式校验，压缩，编解码，格式转换，缩略图抽取等操作</p>
<h2 id="视频格式"><a href="#视频格式" class="headerlink" title="视频格式"></a>视频格式</h2><blockquote>
<p>问题：本地视频文件常见有MP4、MKV、AVI等，这些都是什么？有什么区别？</p>
</blockquote>
<p>首先，MP4、AVI、MKV都是本地视频文件的后缀，在windows系统下，用于提示操作系统应该采用哪个应用程序打开。而在流媒体领域，这些都被称为『视频封装格式』，因为除了音视频流之外，它们还包含了一些辅助信息以及组织视音频的方式。不同格式的视频在不同平台上用户体验不同，很大原因在于对视音频的组织方式带来的差异。笔者以为百度百科上的解释蛮通俗易懂的（维基百科的说法不够直白）：</p>
<p>视频格式是视频播放软件为了能够播放视频文件而赋予视频文件的一种识别符号。<br>简言之，视频格式规定了和播放器的通信协议。</p>
<h2 id="视频协议"><a href="#视频协议" class="headerlink" title="视频协议"></a>视频协议</h2><blockquote>
<p>问题：在腾讯视频、哔哩哔哩网上看的视频，与本地播放的MP4、MKV、AVI文件，有什么区别？</p>
</blockquote>
<p>『视频协议』是针对网络流媒体而言的，也就是只有在有网络时通过浏览器或者移动端APP才能看到的视频，目前常见的协议有RTSP、RTMP、HLS、HTTP等。笔者短暂地接触过GStreamer开发，在连接到RSTP视频时，发现除了视音频流和metadata之外，还携带了播放的信令。</p>
<p>也有文章会把『视频协议』归入『视频封装格式』。笔者看来，这么分类也有其道理：『视频协议』和『视频封装格式』都同时携带了视音频和metadata，以及协议/格式需要的其他信息。以FFMpeg为例，并不区分视频格式和视频协议；但是GStreamer的话，还时需要指定『视频协议』，但是不区分『视频封装格式』。</p>
<p>剥开『视频封装格式』和『视频协议』的外壳，接下来了解视音频流本身，这才是流媒体领域中真正的主角。本文仅介绍视频流。</p>
<h2 id="视频流-以及-编解码-视频转码"><a href="#视频流-以及-编解码-视频转码" class="headerlink" title="视频流 以及 编解码 / 视频转码"></a>视频流 以及 编解码 / 视频转码</h2><p>就视频流而言，相信大家平时一定经常听到类似“h264码流”、“yuv流”、“编码流”、“解码流”，“原始流”、“裸流”，“压缩后的流”或者“未压缩的流”等等。归纳而言，提到『视频流』的时候，一定只有两种形式：</p>
<p>经过压缩算法压缩的流数据，称为『编码流』，又因为目前压缩/编码算法以H264为主，因此也常常称为『H264码流』。<br>未经压缩的流数据，是解码后的流数据，称为『原始流』，可以想象视频是由一幅一幅在时间上连续的“图像”组成的，而因为视频内部的“图像”是『YUV』（后文将介绍），因此也常常称为『YUV流』。<br>总结出现的名称，“h264码流”、“编码流”、“压缩后的流”是压缩/编码后的视频流；而“yuv流”、“解码流”、“未压缩的流”则是未经压缩/编码的视频流。“裸流”是一个具有歧义的词，是上下文内容，既可以是前者，也可以是后者。</p>
<p>因此，如果以后阅读任何流媒体相关的文章时，看到『视频流』都应该搞清楚，这究竟是编码/压缩的，还是没有。在生活中，接触到的视频文件绝大部分都是编码/压缩后的；在网络传输场景中，绝大部分也是编码/压缩后的。只有在视频播放时，观众观赏到的时一帧帧被『转码』为『RGB』的解码后视频流。</p>
<p>编码/压缩在流媒体领域是一项非常重要的技术：从『H264码流』到『YUV流』的过程称为解码，反之称为编码。</p>
<h2 id="常见的帧名词"><a href="#常见的帧名词" class="headerlink" title="常见的帧名词"></a>常见的帧名词</h2><ol>
<li>帧率（FPS）<br>『帧率』，FPS，全称Frames Per Second。指每秒传输的帧数，或者每秒显示的帧数，一般来说，『帧率』影响画面流畅度，且成正比：帧率越大，画面越流畅；帧率越小，画面越有跳动感。一个较权威的说法：<br>当视频帧率不低于24fps时，人眼才会觉得视频时连贯的，称为“视觉暂留”现象。<br>因此，才有说法：尽管『帧率』越高越流畅，但在很多实际应用场景中24fps就可以了。</li>
<li>分辨率（Resolution）<br>『分辨率』，也常被俗称为『图像的尺寸』或者『图像的大小』。指一帧图像包含的像素的多少，常见有1280x720（720P），1920X1080（1080P）等规格。『分辨率』影响图像大小，且与之成正比：『分辨率』越高，图像越大；反之，图像越小。</li>
<li>码率（BPS）<br>『码率』，BPS，全称Bits Per Second。指每秒传送的数据位数，常见单位KBPS（千位每秒）和MBPS（兆位每秒）。笔者认为这个概念真正要理解起来还是需要好好说明的，网上一说：“『码率』与体积成正比：码率越大，体积越大；码率越小，体积越小”；另一说：“『码率』越大，说明单位时间内取样率越大，数据流精度就越高，这样表现出来的的效果就是：视频画面更清晰画质更高”；还有说法是：”『码率』就是『失真度』“。但是笔者有一段时间就是不理解，每秒传输的数据越大，为什么必然就对应画面更清晰？还有体积怎么理解呢？且看下文”三者之间的关系“。</li>
</ol>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://baike.baidu.com/item/%E8%A7%86%E9%A2%91%E6%B5%81" target="_blank" rel="external">https://baike.baidu.com/item/%E8%A7%86%E9%A2%91%E6%B5%81</a></p>
<p><a href="https://www.cnblogs.com/LLBFWH/p/11660530.html" target="_blank" rel="external">https://www.cnblogs.com/LLBFWH/p/11660530.html</a></p>
<p><a href="https://www.pingwest.com/a/120094" target="_blank" rel="external">https://www.pingwest.com/a/120094</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/36109778" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/36109778</a></p>
<p><a href="https://blog.csdn.net/shenhuan1104/article/details/72824076" target="_blank" rel="external">https://blog.csdn.net/shenhuan1104/article/details/72824076</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/61747783" target="_blank" rel="external">视频和视频帧：视频和帧基础知识整理</a></p>
<p><a href="https://www.bgteach.com/article/134" target="_blank" rel="external">视频文件格式知多少 | avi、mpeg、mp4、mov、ProRes、DNxHR、mfx、mkv、wmv、flv、rmvb、webm…</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文为扫盲文，为刚进入音视频行业的同学提供一些专业名词的解释，方便更快熟悉音视频相关的业务。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;视频上传&quot;&gt;&lt;a href=&quot;#视频上传&quot; class=&quot;headerlink&quot; title=&quot;视频上传&quot;&gt;&lt;/a&gt;视频上传&lt;/h2&gt;&lt;p&gt;顾名思义，&lt;strong&gt;视频上传&lt;/strong&gt; 即通过使用相关工具，将视频从本地导入到云端服务器进行存储的过程。&lt;/p&gt;
    
    </summary>
    
      <category term="音视频" scheme="http://wuwenliang.net/categories/%E9%9F%B3%E8%A7%86%E9%A2%91/"/>
    
    
      <category term="音视频" scheme="http://wuwenliang.net/tags/%E9%9F%B3%E8%A7%86%E9%A2%91/"/>
    
  </entry>
  
  <entry>
    <title>精诚所至,我的跳槽之路</title>
    <link href="http://wuwenliang.net/2019/11/01/%E7%B2%BE%E8%AF%9A%E6%89%80%E8%87%B3-%E6%88%91%E7%9A%84%E8%B7%B3%E6%A7%BD%E4%B9%8B%E8%B7%AF/"/>
    <id>http://wuwenliang.net/2019/11/01/精诚所至-我的跳槽之路/</id>
    <published>2019-11-01T03:56:16.000Z</published>
    <updated>2019-11-01T05:58:09.402Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>天行健，君子以自强不息。 – 《周易·乾·象》</p>
</blockquote>
<p>踏出熟悉的公司大门，我回头，知道以后应该不会经常回来，抬手，拍照，朋友圈里，我留下了“莫愁前路无知己，天下谁人不识君”的文字。</p>
<p>再见了，我将拥抱新的生活。再见了，我会有新的工作。</p>
<a id="more"></a>
<p>别人看起来我走的突然，但换工作是迟早的事情，是我的主观选择，年初就着手开始准备。</p>
<p>裸面是大忌，因此我指定了计划，分模块进行复习:</p>
<ul>
<li>java核心：集合框架，重点复习HashMap、ConcurrentHashMap、ArrayList、LinkedList</li>
<li>java核心：多线程，重点复习synchronized、volitaile、JMM模型、Lock</li>
<li>缓存：重点复习Redis</li>
<li>消息队列：重点复习RocketMQ</li>
<li>RPC：重点复习Dubbo</li>
<li>Spring：以IOC、AOP为核心，了解其源码，同时看了事务相关的源码</li>
<li>JVM相关：主要从项目出发，学习整理了JVM结构以及调优相关的知识</li>
<li>数据库：重点复习了索引、redoLog、undoLog、MVCC以及简单看了看调优</li>
<li>数据结构和算法：我没有复习很多，主要是在面试之前把二分查找、快排、二叉树、链表的核心代码看了看就去面试了</li>
<li>分布式协议，如RAFT，Gossip等，这部分是我给自己的要求</li>
<li>项目：主要总结了核心流程，能够做到胸有成竹的画出各种流程图，对于项目中的遇到的问题能够流畅的表达出来</li>
</ul>
<p>有了计划，在执行中，重点学习了极客时间的专栏，这里不是打广告，极客时间的高并发和MySQL两个专栏对我帮助很大。文末会放出参考资料。</p>
<p>在上下班的路上，每天能有30-50分钟时间学习，基本上是看极客时间，高并发专栏我来来回回看了三遍，在后面的面试中，基本上没有没被问住。</p>
<p>在整个面试的准备过程中，我花心思多准备了消息队列相关的东西，用了三个月左右的时间把RocketMQ的重要源码都看了一遍并在博客中写了源码分析文章。在后面的面试中，只要问到MQ相关的问题，我都能滔滔不绝的和面试官聊，基本上能够从架构聊到应用再深入到底层，这里也要感谢老东家给我实战的机会，让我能够更加直观体会到MQ带来的便利和优越性，并以此为契机，让我能够加入到RocketMQ的社区中。</p>
<p>我想说的是，如果想要找一个满意的岗位，前期的准备是必不可少的，虽然我没有像少数的同学，废寝忘食，但是功夫还是下了的，至少在MQ和JVM上，我投入了大量的精力，这也让我很受益。</p>
<blockquote>
<p>如何在面试中展示自己的亮点，让自己能够吸引面试官的注意呢？</p>
</blockquote>
<p>对于这个问题，我在很多地方都回答过，说起来并不难。</p>
<ul>
<li>一个稳定更新的github，有互动有文档，有一定数量的star；</li>
<li>一个稳定更新的博客，公众号，如果有一定的知名度那更好；</li>
<li>能够积极参与开源社区，有一定的贡献；</li>
<li>对某方面技术有较为深刻的认识或研究</li>
</ul>
<p>上述这些，如果满足一项，都会超出很多人，但没有一个不需要花费半年甚至更多的时间去准备。</p>
<p>说说我的经验吧，我写了五年多博客，参与过开源社区，写过很多轮子，对于造轮子的思考以及总结都及时发布到自己的博客中。</p>
<p>三年里没有说每天起早贪黑，也差不多就是每天持续学习两小时左右。</p>
<p>在面试的过程中，我用一周时间拿到三个互联网offer，当然和那些面经中的大佬们比还是差距很大，但我已经很满意。</p>
<p>怎么说呢，一句话就是皇天不负有心人。道理大家都明白，但是客观上就是会有明显的差异。</p>
<p>有的人喜欢问别人在面试的过程中被问了哪些问题，包括我看过的很多面经都是对自己面试经过的复述，基本上就是一个面试问题的记录。不能说没用吧，从这些问题中是能够分析出一些共性的，但我不想这么写。我认为，好的方法要胜过知识本身，当一个人有了一套自己的学习方法与思考框架，那么他做什么事情都能够游刃有余。所谓，授之以鱼不如授之以渔，大概就是这个道理的体现。</p>
<p>在真实的面试中，面试官问什么问题是取决于我们面试的岗位，更重要的，是取决于面试者简历上展示的能力以及项目中的亮点，如果能够准备一份亮眼的简历，并且刻意去进行引导，相信不需要问别人也大致能够知道自己需要准备哪些问题。毕竟面试这个事儿，还是因人而异。</p>
<p>我在文章的开始部分，罗列了我自己的复习计划，基本上这就是Java开发岗都需要关注并掌握的核心知识，到哪里都逃不开的。知识的复习，是一个体系的建立，所以指望问别人几道题就能够通过面试，这种侥幸心理是要不得的，功夫不负有心人，不愿付出努力，不愿总结就想要轻松通过面试，斩获大厂offer，我觉得不是不可能，但至少可能性不会很大。</p>
<p>之前也加过一些群，看着群里不断有同学拿到了好offer，然后一帮人在后面追问学习方法，面试问题，我只觉得好笑。学习方法可以借鉴，但不能照搬，一方面，我为这些拿到满意offer的同学感到佩服，另一方面，我也暗下决心，有一天，我也会找到我想要的工作，去做我想做的事情。</p>
<p>君子以自强不息，好的执行力，是成功的必要条件。我享受计划的制定与实施，客观的对自己的优劣势进行分析，不断复习，整理，复盘，总结，对简历持续进行打磨，在某个事情的刺激下，国庆节前，我开始了简历的投递。</p>
<p>国庆节，是漫长的等待。节后，我陆续收到了面试邀约，连续面试一周，高强度的持续实战与复盘，我最终收获了心仪的offer，也最终选择了爱奇艺。</p>
<p>“简单想，简单做”。</p>
<p>这是实干家的乐园。</p>
<p>这里分享一个面试的技巧，如果能画图就多画图，用画图的方式表达自己的思路，能够变被动为主动，而且也可以让自己的心态放松，从而更加条理清晰的表达出自己的观点。面试官也基本上会从面试者画的图中进行提问，从而有效避免了一问一答的“审问”式面试。</p>
<p>或许有人会认为我的经验难以实践，但我曾经也是一个迷茫的小菜鸟，也曾在群里发问，问题的简单与无脑让我现在回想起来都觉得可爱。</p>
<p>但我始终相信梦想的力量，相信实践的力量，相信持续的付出一定会有所收获。</p>
<p>我始终感谢大二时候的我做出的决定，我要写博客。这一写，就是五年。这也是我到现在坚持最久的一个习惯，当你开始着手实施一个看起来不可能完成的任务，并不断坚持从而变成习惯的时候，这件事也就不那么困难，每天进步一点点，当多年以后，曾经的那颗幼苗，已经长成了大树。</p>
<p>我纷乱的表达，只为了向你分享一个观点，想清楚再做，比盲目去做要更容易接近所谓的成功。想明白自己要什么，树立一个明确的目标，并制定适合自己的计划，坚持执行下去，一切都是水到渠成。</p>
<p>没有什么成功，生活是没有终点的，如果有，那就是死亡。</p>
<p>我还有呼吸，我还有心跳，我未来的每一天都是未知且新奇的，不断的反思过往，不断的树立目标并坚持完成，这是我生活的乐趣。与己斗，其乐无穷。</p>
<p>感谢遇到的每一个人，感谢经历的每一个挫折，感谢低谷中不服输的自己，感激并不断努力着。</p>
<p>精诚所至，金石为开。一切都没结束，一切才刚刚开始，这是我平凡的跳槽之路，这是一个普通人的内心独白。这是我的狂欢，这是我的舞台。</p>
<p>–写于午后。</p>
<h2 id="附录：复习资料"><a href="#附录：复习资料" class="headerlink" title="附录：复习资料"></a>附录：复习资料</h2><ul>
<li>MySQL实战45讲（极客时间）</li>
<li>Java并发编程实战（极客时间）</li>
<li>《Java并发编程的艺术》</li>
<li>《MySQL技术内幕：InnoDB存储引擎》</li>
<li>《RocketMQ技术内幕》</li>
<li>《Redis 深度历险：核心原理与应用实践》</li>
<li>《深入理解Apache Dubbo与实战》</li>
<li><a href="https://github.com/doocs/advanced-java" target="_blank" rel="external">java工程师面试突击笔记</a></li>
<li><a href="https://www.bilibili.com/video/av71505947" target="_blank" rel="external">java工程师面试突击视频</a></li>
</ul>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;天行健，君子以自强不息。 – 《周易·乾·象》&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;踏出熟悉的公司大门，我回头，知道以后应该不会经常回来，抬手，拍照，朋友圈里，我留下了“莫愁前路无知己，天下谁人不识君”的文字。&lt;/p&gt;
&lt;p&gt;再见了，我将拥抱新的生活。再见了，我会有新的工作。&lt;/p&gt;
    
    </summary>
    
      <category term="随笔" scheme="http://wuwenliang.net/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="随笔" scheme="http://wuwenliang.net/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>探秘CouchDB之centos下搭建CouchDB</title>
    <link href="http://wuwenliang.net/2019/10/22/%E6%8E%A2%E7%A7%98CouchDB%E4%B9%8BCouchDB%E6%90%AD%E5%BB%BA/"/>
    <id>http://wuwenliang.net/2019/10/22/探秘CouchDB之CouchDB搭建/</id>
    <published>2019-10-22T05:34:49.000Z</published>
    <updated>2019-10-22T07:35:20.204Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>CouchDB 是一个开源的面向文档的数据库管理系统，它具有高度可伸缩性，提供了高可用性和高可靠性。</p>
<p>CouchDB发布于2005年，2008年成为Apache软件基金会项目。CouchDB是一个面向文档的NoSQL数据库。</p>
</blockquote>
<p>本系列笔者将记录对CouchDB的学习实战相关内容。</p>
<p>作为本系列第一篇，本文主要介绍如何在centos下搭建CouchDB，以及CouchDB的简单使用。</p>
<a id="more"></a>
<h2 id="安装EPEL库"><a href="#安装EPEL库" class="headerlink" title="安装EPEL库"></a>安装EPEL库</h2><blockquote>
<p>在Centos7上安装CouchDB之前需要安装基础EPEL基础环境，使用以下命令添加EPEL存储库。</p>
</blockquote>
<pre><code>yum -y install epel-release
</code></pre><h2 id="安装Apache-CouchDB"><a href="#安装Apache-CouchDB" class="headerlink" title="安装Apache CouchDB"></a>安装Apache CouchDB</h2><blockquote>
<p>由于CouchDB提供了RedHat的rpm包，因此我们能够直接从apache的库中安装CouchDB。</p>
</blockquote>
<p>执行以下指令，编辑apache-couchdb.repo文件</p>
<pre><code>cd /etc/yum.repos.d/
vim apache-couchdb.repo
</code></pre><p>添加以下内容到apache-couchdb.repo中</p>
<pre><code>[bintray--apache-couchdb-rpm]
name=bintray--apache-couchdb-rpm
baseurl=http://apache.bintray.com/couchdb-rpm/el$releasever/$basearch/
gpgcheck=0
repo_gpgcheck=0
enabled=1
</code></pre><p>保存并退出编辑器，执行install安装couchDB</p>
<pre><code>yum -y install couchdb
</code></pre><p>等待安装完成，设置couchDB为开机自启：</p>
<pre><code>systemctl start couchdb
systemctl enable couchdb
</code></pre><p>设置完成之后，执行状态检查及服务器端口检查</p>
<pre><code>systemctl status couchdb
netstat -plntu
</code></pre><p>到此，couchDB便被成功安装到centos7机器上，运行的默认端口为5984。</p>
<h2 id="启用CouchDB的图形化界面"><a href="#启用CouchDB的图形化界面" class="headerlink" title="启用CouchDB的图形化界面"></a>启用CouchDB的图形化界面</h2><blockquote>
<p>CouchDB提供了一个图形化界面，供我们进行友好的交互，支持开发者进行可视化的数据库创建、删除、数据同步等操作。</p>
</blockquote>
<p>这里我们配置启用CouchDB的图形化界面。</p>
<p>进入CouchDB的 <strong>/opt/couchdb</strong> 目录，编辑’etc/‘目录下的’default.ini’配置文件。</p>
<pre><code>cd /opt/couchdb
vim etc/default.ini
</code></pre><p>跳转到 <strong>[chttpd]</strong> 配置行，将bind_address的值设置为本地ip地址。</p>
<pre><code>[chttpd]
port = 5984
bind_address = 0.0.0.0
</code></pre><p>保存并退出，重启CouchDB服务。</p>
<pre><code>systemctl restart couchdb
</code></pre><p>进入CouchDB管理页面，在浏览器输入服务器ip地址，如： <strong><a href="http://ip:5984/_utils/" target="_blank" rel="external">http://ip:5984/_utils/</a></strong></p>
<p><strong>注意</strong> </p>
<p>如果服务器上运行了firewalld，需要使用firewall-cmd命令开放couchdb端口5984</p>
<pre><code>firewall-cmd --add-port=5984/tcp --permanent
firewall-cmd --reload
</code></pre><p>如果是iptables则，使用如下命令开放5984端口</p>
<pre><code>/sbin/iptables -I INPUT -p tcp --dport 5984 -j ACCEPT
</code></pre><p>如图，便是CouchDB后台页面：</p>
<p><img src="/2019/10/22/探秘CouchDB之CouchDB搭建/ui.png" alt="ui.png"></p>
<h2 id="配置管理员帐户CouchDB"><a href="#配置管理员帐户CouchDB" class="headerlink" title="配置管理员帐户CouchDB"></a>配置管理员帐户CouchDB</h2><p>首次登陆图形化管理页面按照提示设置管理员账户即可，一定要记住账户密码，后续使用命令进行操作的时候也需要指定账户/账户密码。</p>
<h2 id="通过curl简单使用CouchDB"><a href="#通过curl简单使用CouchDB" class="headerlink" title="通过curl简单使用CouchDB"></a>通过curl简单使用CouchDB</h2><p>这里介绍一下如何在命令行界面下通过curl简单使用CouchDB。关于图形化方式的使用，读者可以自行摸索。</p>
<p>要获得有关已安装的couchdb服务器的信息，我们可以使用’ GET ‘参数，如下所示。</p>
<pre><code>curl -X GET http://localhost:5984/  
</code></pre><p>通过无密码方式创建新的数据库【这种方式在设置了管理员账户之后会失效】</p>
<pre><code>curl -X PUT http://localhost:5984/hakase_db
</code></pre><p>通过带密码的方式创建新的数据库</p>
<pre><code>curl -X PUT curl -X PUT http://账户名:密码@localhost:5984/hakase_db
</code></pre><p>本文我们就主要讲解一下如何安装及简单使用CouchDB，更多的原理及使用细节，在后续的文章中将逐步呈现。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;CouchDB 是一个开源的面向文档的数据库管理系统，它具有高度可伸缩性，提供了高可用性和高可靠性。&lt;/p&gt;
&lt;p&gt;CouchDB发布于2005年，2008年成为Apache软件基金会项目。CouchDB是一个面向文档的NoSQL数据库。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;本系列笔者将记录对CouchDB的学习实战相关内容。&lt;/p&gt;
&lt;p&gt;作为本系列第一篇，本文主要介绍如何在centos下搭建CouchDB，以及CouchDB的简单使用。&lt;/p&gt;
    
    </summary>
    
      <category term="CouchDB" scheme="http://wuwenliang.net/categories/CouchDB/"/>
    
    
      <category term="CouchDB" scheme="http://wuwenliang.net/tags/CouchDB/"/>
    
  </entry>
  
  <entry>
    <title>跟我学RocektMQ之理解长轮询机制</title>
    <link href="http://wuwenliang.net/2019/09/22/%E8%B7%9F%E6%88%91%E5%AD%A6RocektMQ%E4%B9%8B%E7%90%86%E8%A7%A3%E9%95%BF%E8%BD%AE%E8%AF%A2%E6%9C%BA%E5%88%B6/"/>
    <id>http://wuwenliang.net/2019/09/22/跟我学RocektMQ之理解长轮询机制/</id>
    <published>2019-09-22T08:35:26.000Z</published>
    <updated>2019-09-24T03:34:02.409Z</updated>
    
    <content type="html"><![CDATA[<p>RoceketMQ提供了两种消息消费者，DefaultMQPushConsumer、DefaultMQPullConsumer。我们都知道DefaultMQPullConsumer是基于拉模式的消费，而DefaultMQPushConsumer是基于推模式的消费。我们先简单复习一下推拉模式的概念。</p>
<blockquote>
<p>推模式：当服务端有数据立即通知客户端，这个策略依赖服务端与客户端之间的长连接，它具有高实时性、客户端开发简单等优点；同时缺点也很明显，比如：服务端需要感知与它建立链接的客户端，要实现客户端节点的发现，服务端本身主动推送，需要服务端对消息做额外的处理，以便能够及时将消息分发给客户端。</p>
<p>拉模式：客户端主动对服务端的数据进行拉取。客户端拉取数据，拉取成功后处理数据，处理完成再次进行拉取，循环执行。缺点是如果不能很好的设置拉取的频率，时间间隔，过多的空轮询会对服务端造成较大的访问压力，数据的实时性也不能得到很好的保证。</p>
</blockquote>
<p>基于对上述两个策略的优缺点的综合考虑，RocketMQ的DefaultMQPushConsumer采用了结合了推拉模式两者优点的长轮询机制，对消息进行消费。这样，既能保证主动权在客户端，还能保证数据拉取的实时性。</p>
<p>本文我们就对RocketMQ的长轮询机制进行分析讲解，从而更好的理解RocketMQ的设计精巧之处。</p>
<p>首先了解一下什么是 <strong>长轮询</strong> 机制：</p>
<a id="more"></a>
<h2 id="什么是“长轮询”机制"><a href="#什么是“长轮询”机制" class="headerlink" title="什么是“长轮询”机制"></a>什么是“长轮询”机制</h2><blockquote>
<p>长轮询机制，顾名思义，它不同于常规轮询方式。常规的轮询方式为客户端发起请求，服务端接收后该请求后立即进行相应的方式。</p>
<p>长轮询本质上仍旧是轮询，它与轮询不同之处在于，当服务端接收到客户端的请求后，服务端不会立即将数据返回给客户端，而是会先将这个请求hold住，判断服务器端数据是否有更新。如果有更新，则对客户端进行响应，如果一直没有数据，则它会在长轮询超时时间之前一直hold住请求并检测是否有数据更新，直到有数据或者超时后才返回。</p>
</blockquote>
<h2 id="RocketMQ如何实现长轮询–客户端实现"><a href="#RocketMQ如何实现长轮询–客户端实现" class="headerlink" title="RocketMQ如何实现长轮询–客户端实现"></a>RocketMQ如何实现长轮询–客户端实现</h2><p>了解了长轮询机制的概念，我们就容易理解RocketMQ对长轮询机制的应用了。请跟随笔者的思路，进入到源码中一探究竟。</p>
<p>首先复习一下客户端如何进行消息拉取：</p>
<p>从上文中，我们已经得知，DefaultMQPushConsumer应用了长轮询机制，从之前的源码分析文章中，我们知道RocketMQ消息拉取是通过消息拉取线程PullMessageService实现的，关于这部分的逻辑可以移步 <a href="http://wuwenliang.net/2019/08/20/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ%E4%B9%8B%E6%B6%88%E6%81%AF%E6%8B%89%E5%8F%96%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/">跟我学RocketMQ之消息拉取源码解析</a>。</p>
<p>我们进入PullMessageService类，重点看它的 <strong>run()</strong> 方法。</p>
<pre><code>[PullMessageService.java]
@Override
public void run() {
    log.info(this.getServiceName() + &quot; service started&quot;);

    while (!this.isStopped()) {
        try {
            PullRequest pullRequest = this.pullRequestQueue.take();
            this.pullMessage(pullRequest);
        } catch (InterruptedException ignored) {
        } catch (Exception e) {
            log.error(&quot;Pull Message Service Run Method exception&quot;, e);
        }
    }

    log.info(this.getServiceName() + &quot; service end&quot;);
}
</code></pre><p>当broker启动后，会在启动MQClientInstance过程中启动PullMessageService，当PullMessageService启动后一直执行run方法进行消息拉取（只要stopped == false）。</p>
<p>回顾一下PullRequest的结构：</p>
<pre><code>public class PullRequest {
    // 消费者组
    private String consumerGroup;
    // 待拉取到消息队列
    private MessageQueue messageQueue;
    // 消息处理队列，消息从broker中拉取以后会先存到该ProcessQueue中，然后再提交给消费者线程池进行消费
    private ProcessQueue processQueue;
    // 带拉取消息的偏移量
    private long nextOffset;
    // 是否锁定
    private boolean lockedFirst = false;
</code></pre><p>对于每个MessageQueue，都有对应的一个pullRequest，每个MessageQueue还对应一个processQueue，保存该MessageQueue消息处理的快照；通过nextOffset来标识当前读取的位置。</p>
<p>消息拉取最终是由PullAPIWrapper.java执行的，在它的pullKernelImpl()方法中，真正的消息拉取逻辑如下：</p>
<pre><code>[PullAPIWrapper.java.pullKernelImpl()]

// 组装消息拉取请求头
PullMessageRequestHeader requestHeader = new PullMessageRequestHeader();
requestHeader.setConsumerGroup(this.consumerGroup);
requestHeader.setTopic(mq.getTopic());
requestHeader.setQueueId(mq.getQueueId());
requestHeader.setQueueOffset(offset);
requestHeader.setMaxMsgNums(maxNums);
requestHeader.setSysFlag(sysFlagInner);
requestHeader.setCommitOffset(commitOffset);
// 设置broker最大阻塞时间，默认为15秒，BROKER_SUSPEND_MAX_TIME_MILLIS = 1000 * 15;
requestHeader.setSuspendTimeoutMillis(brokerSuspendMaxTimeMillis);
requestHeader.setSubscription(subExpression);
requestHeader.setSubVersion(subVersion);
requestHeader.setExpressionType(expressionType);

// 获取拉取broker地址
String brokerAddr = findBrokerResult.getBrokerAddr();
if (PullSysFlag.hasClassFilterFlag(sysFlagInner)) {
    brokerAddr = computPullFromWhichFilterServer(mq.getTopic(), brokerAddr);
}

// 执行消息拉取
PullResult pullResult = this.mQClientFactory.getMQClientAPIImpl().pullMessage(
    brokerAddr,
    requestHeader,
    timeoutMillis,
    communicationMode,
    pullCallback);
return pullResult;
</code></pre><p>这里的参数brokerSuspendMaxTimeMillis（默认值为15s）代表进行消息拉取时，broker的最长阻塞时间。</p>
<p>当进行消息拉取时，如果broker端没有消息，则进行阻塞，否则会对消息体进行打包并直接返回。</p>
<h2 id="RocketMQ如何实现长轮询–服务端实现"><a href="#RocketMQ如何实现长轮询–服务端实现" class="headerlink" title="RocketMQ如何实现长轮询–服务端实现"></a>RocketMQ如何实现长轮询–服务端实现</h2><p>RocketMQ的长轮询是在broker上实现的，具体的代码实现在PullMessageProcessor中。我们进入代码中一窥芳容。</p>
<p>它的启动链路如下：</p>
<pre><code>BrokerStartup
    |-start()
        |-createBrokerController(String[] args) 
            |-BrokerController() // BrokerController构造方法
            |-new PullMessageProcessor(this);
</code></pre><p>当broker启动完成之后，PullMessageProcessor便能够被远程的消费者访问到，通过网络进行消息拉取调用操作。</p>
<p>我们重点看方法processRequest，它是消息拉取网络交互的核心方法。</p>
<h3 id="processRequest"><a href="#processRequest" class="headerlink" title="processRequest()"></a>processRequest()</h3><blockquote>
<p>processRequest为broker对外提供消息拉取的服务方法，它提供针对不同拉取结果的处理逻辑。</p>
</blockquote>
<pre><code>[PullMessageProcessor.java.processRequest]
// 根据客户端发送的拉取消息头，构建拉取结果响应体
RemotingCommand response = RemotingCommand.createResponseCommand(PullMessageResponseHeader.class);
...各种前置校验...
// 从请求头中取出消费者组、主题、队列id、offset、消息最大拉取条数、过滤条件等，去commitLog中查找对应的消息
switch (getMessageResult.getStatus()) {
        case FOUND:
            response.setCode(ResponseCode.SUCCESS);
            break;
        case MESSAGE_WAS_REMOVING:
            response.setCode(ResponseCode.PULL_RETRY_IMMEDIATELY);
            break;
...省略其他case分支...

// 根据上面拉取结果中设置的code进行处理           
switch (response.getCode()) {
    ...省略其他case分支...
    case ResponseCode.PULL_NOT_FOUND:

            if (brokerAllowSuspend &amp;&amp; hasSuspendFlag) {
                long pollingTimeMills = suspendTimeoutMillisLong;
                if (!this.brokerController.getBrokerConfig().isLongPollingEnable()) {
                    pollingTimeMills = this.brokerController.getBrokerConfig().getShortPollingTimeMills();
                }

                String topic = requestHeader.getTopic();
                long offset = requestHeader.getQueueOffset();
                int queueId = requestHeader.getQueueId();
                PullRequest pullRequest = new PullRequest(request, channel, pollingTimeMills,
                    this.brokerController.getMessageStore().now(), offset, subscriptionData, messageFilter);
                this.brokerController.getPullRequestHoldService().suspendPullRequest(topic, queueId, pullRequest);
                response = null;
                break;
            }
</code></pre><p>对于ResponseCode.SUCCESS的拉取响应码，RocektMQ将消息拉取结果以byte数组形式设置到拉取响应中，并会返回给客户端；我们重点关注 <strong>ResponseCode.PULL_NOT_FOUND</strong> 类型，即 <strong>当前未拉取到消息</strong>。</p>
<p>对于ResponseCode.PULL_NOT_FOUND类型，RocketMQ会调用PullRequestHoldService将请求holkd住，不会返回客户端响应，这里就是长轮询的核心逻辑，代码如下：</p>
<pre><code>case ResponseCode.PULL_NOT_FOUND:
    // 判断broker是否允许被挂起
    if (brokerAllowSuspend &amp;&amp; hasSuspendFlag) {
        // 获取长轮询超时时长
        long pollingTimeMills = suspendTimeoutMillisLong;
        // 如果长轮询支持未开启，则pollingTimeMills为短轮询时间，ShortPollingTimeMills默认为1秒
        if (!this.brokerController.getBrokerConfig().isLongPollingEnable()) {
            pollingTimeMills = this.brokerController.getBrokerConfig().getShortPollingTimeMills();
        }

        String topic = requestHeader.getTopic();
        long offset = requestHeader.getQueueOffset();
        int queueId = requestHeader.getQueueId();
        // 根据入参request，Nio的channel，轮询时间，当前消息存储时间戳，消息拉取offset，订阅信息，消息过滤表达式等信息构建长轮询拉取请求
        PullRequest pullRequest = new PullRequest(request, channel, pollingTimeMills,
            this.brokerController.getMessageStore().now(), offset, subscriptionData, messageFilter);
        // 通过PullRequestHoldService对拉取请求进行hold，使用pullRequest对指定topic、queueId的队列进行长轮询消息拉取
        this.brokerController.getPullRequestHoldService().suspendPullRequest(topic, queueId, pullRequest);
        // 设置拉取返回为null，不对客户端进行返回
        response = null;
        break;
    }
</code></pre><p>我们总结一下这里的逻辑：</p>
<ul>
<li>首先判断broker是否允许被hold，如果允许则执行长轮询业务逻辑</li>
<li>获取长轮询超时时长，该参数可配置，如果长轮询支持未开启则改用短轮询时间，默认为1s</li>
<li>从消息拉取请求头中获取topic、队列offset、队列id</li>
<li>构造长轮询消息拉取请求对象PullRequest</li>
<li>调用PullRequestHoldService进行长轮询操作</li>
<li>拉取返回为空，在超时之前不对客户端进行返回</li>
</ul>
<h2 id="PullRequestHoldService核心逻辑"><a href="#PullRequestHoldService核心逻辑" class="headerlink" title="PullRequestHoldService核心逻辑"></a>PullRequestHoldService核心逻辑</h2><p>从上面的分析我们得知，长轮询真正的执行者为PullRequestHoldService，我们看下这个类的代码，PullRequestHoldService继承了ServiceThread，我们重点关注其run方法。</p>
<pre><code>@Override
public void run() {
    log.info(&quot;{} service started&quot;, this.getServiceName());
    while (!this.isStopped()) {
        try {
            // 如果支持长轮询，则等待5秒
            if (this.brokerController.getBrokerConfig().isLongPollingEnable()) {
                this.waitForRunning(5 * 1000);
            } else {
                // 短轮询则默认等待1s
                this.waitForRunning(this.brokerController.getBrokerConfig().getShortPollingTimeMills());
            }

            long beginLockTimestamp = this.systemClock.now();
            // 检测hold请求
            this.checkHoldRequest();
            // 如果检测花费时间超过5s打印日志
            long costTime = this.systemClock.now() - beginLockTimestamp;
            if (costTime &gt; 5 * 1000) {
                log.info(&quot;[NOTIFYME] check hold request cost {} ms.&quot;, costTime);
            }
        } catch (Throwable e) {
            log.warn(this.getServiceName() + &quot; service has exception. &quot;, e);
        }
    }
    log.info(&quot;{} service end&quot;, this.getServiceName());
}
</code></pre><p>run方法不断检测被hold住的请求，它不断检查是否有消息获取成功。检测方法通过执行方法suspendPullRequest实现</p>
<pre><code>private ConcurrentMap&lt;String/* topic@queueId */, ManyPullRequest&gt; pullRequestTable =
    new ConcurrentHashMap&lt;String, ManyPullRequest&gt;(1024);

public void suspendPullRequest(final String topic, final int queueId, final PullRequest pullRequest) {
    String key = this.buildKey(topic, queueId);
    // 从pullRequestTable中获取对应topic+queueId下的拉取请求ManyPullRequest
    ManyPullRequest mpr = this.pullRequestTable.get(key);
    if (null == mpr) {
        mpr = new ManyPullRequest();
        ManyPullRequest prev = this.pullRequestTable.putIfAbsent(key, mpr);
        if (prev != null) {
            mpr = prev;
        }
    }
    // 将等待检测的pullRequest添加到ManyPullRequest中
    mpr.addPullRequest(pullRequest);
}
</code></pre><p>注意，这里的ManyPullRequest对象实际上是一组PullRequest的集合，它封装了一个topic+queueId下的一批消息。</p>
<p>具体的检测逻辑通过方法checkHoldRequest()实现。</p>
<pre><code>private void checkHoldRequest() {
    // 迭代PullRequest Map，key=topic@queueId
    for (String key : this.pullRequestTable.keySet()) {
        // 解析出topic  queueId
        String[] kArray = key.split(TOPIC_QUEUEID_SEPARATOR);
        if (2 == kArray.length) {
            String topic = kArray[0];
            int queueId = Integer.parseInt(kArray[1]);
            // 获取当前获取的数据的最大offset
            final long offset = this.brokerController.getMessageStore().getMaxOffsetInQueue(topic, queueId);
            try {
                // 通知消息到达
                this.notifyMessageArriving(topic, queueId, offset);
            } catch (Throwable e) {
                log.error(&quot;check hold request failed. topic={}, queueId={}&quot;, topic, queueId, e);
            }
        }
    }
}
</code></pre><p>checkHoldRequest()方法解析pullRequestTable的keySet，对key进行解析，取出topic及queueId，获取topic+queueId对应的当前MessageQueue的最大offset，并与当前的offset对比从而确定是否有新消息到达，具体逻辑在notifyMessageArriving(topic, queueId, offset);方法中实现</p>
<blockquote>
<p>这里的检测逻辑整体是异步的，后台检测线程PullRequestHoldService一直在运行；在PullMessageProcessor中提交待检测的PullRequest到PullRequestHoldService，将其放入pullRequestTable，等待被PullRequestHoldService进行处理。</p>
</blockquote>
<h3 id="notifyMessageArriving-topic-queueId-offset"><a href="#notifyMessageArriving-topic-queueId-offset" class="headerlink" title="notifyMessageArriving(topic, queueId, offset)"></a>notifyMessageArriving(topic, queueId, offset)</h3><pre><code>public void notifyMessageArriving(final String topic, final int queueId, final long maxOffset, final Long tagsCode,
    long msgStoreTime, byte[] filterBitMap, Map&lt;String, String&gt; properties) {
    String key = this.buildKey(topic, queueId);
    ManyPullRequest mpr = this.pullRequestTable.get(key);
    if (mpr != null) {
        // 根据key=topic@queueId从pullRequestTable获取ManyPullRequest
        // 如果ManyPullRequest不为空，拷贝ManyPullRequest中的List&lt;PullRequest&gt;
        List&lt;PullRequest&gt; requestList = mpr.cloneListAndClear();
        if (requestList != null) {
            // 构造响应list
            List&lt;PullRequest&gt; replayList = new ArrayList&lt;PullRequest&gt;();
            // 迭代请求list
            for (PullRequest request : requestList) {
                long newestOffset = maxOffset;
                // 如果当前最新的offset小于等于请求的offset
                if (newestOffset &lt;= request.getPullFromThisOffset()) {
                    // 当前最新的offset就是队列的最大offset
                    newestOffset = this.brokerController.getMessageStore().getMaxOffsetInQueue(topic, queueId);
                }
                // 如果当前最新offset大于请求offset，也就是有新消息到来
                if (newestOffset &gt; request.getPullFromThisOffset()) {
                    // 判断消息是否满足过滤表达式
                    boolean match = request.getMessageFilter().isMatchedByConsumeQueue(tagsCode,
                        new ConsumeQueueExt.CqExtUnit(tagsCode, msgStoreTime, filterBitMap));
                    // match by bit map, need eval again when properties is not null.
                    if (match &amp;&amp; properties != null) {
                        match = request.getMessageFilter().isMatchedByCommitLog(null, properties);
                    }
                    if (match) {
                        try {
                            // 消息匹配，则将消息返回客户端
                            this.brokerController.getPullMessageProcessor().executeRequestWhenWakeup(request.getClientChannel(),
                                request.getRequestCommand());
                        } catch (Throwable e) {
                            log.error(&quot;execute request when wakeup failed.&quot;, e);
                        }
                        continue;
                    }
                }
                // 判断是否超时
                if (System.currentTimeMillis() &gt;= (request.getSuspendTimestamp() + request.getTimeoutMillis())) {
                    try {
                        // 如果当前时间 &gt;= 请求超时时间+hold时间，则返回客户端消息未找到
                        this.brokerController.getPullMessageProcessor().executeRequestWhenWakeup(request.getClientChannel(),
                            request.getRequestCommand());
                    } catch (Throwable e) {
                        log.error(&quot;execute request when wakeup failed.&quot;, e);
                    }
                    continue;
                }
                replayList.add(request);
            }
            if (!replayList.isEmpty()) {
                mpr.addPullRequest(replayList);
            }
        }
    }
}
</code></pre><p>总结一下，notifyMessageArriving主要作用为判断消息是否到来，并根据判断结果对客户端进行相应。</p>
<ul>
<li>比较maxOffset与当前的offset，如果当前最新offset大于请求offset，也就是有新消息到来，则将新消息返回给客户端</li>
<li>校验是否超时，如果当前时间 &gt;= 请求超时时间+hold阻塞时间，则返回客户端消息未找到</li>
</ul>
<blockquote>
<p>该方法会在PullRequestHoldService中循环调用进行检查，也会在DefaultMessageStore中消息被存储的时候调用。这里体现了主动检查与被动通知共同作用的思路。</p>
</blockquote>
<p>当服务端处理完成之后，相应客户端，客户端会在消息处理完成之后再次将拉取请求pullRequest放到PullMessageService中，等待下次轮询。这样就能够一直进行消息拉取操作。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文对RocketMQ消息拉取的长轮询机制进行了分支，我们得知：</p>
<blockquote>
<p>RocektMQ并没有使用推模式或者拉模式，而是使用了结合两者优点的长轮询机制，它本质上还是拉模式，但服务端能够通过hold住请求的方式减少客户端对服务端的频繁访问，从而提高资源利用率及消息响应实时性。这种策略在服务端开发的其他方向如：IM等领域都有广泛的实践，因此了解它的原理是有必要的。</p>
</blockquote>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;RoceketMQ提供了两种消息消费者，DefaultMQPushConsumer、DefaultMQPullConsumer。我们都知道DefaultMQPullConsumer是基于拉模式的消费，而DefaultMQPushConsumer是基于推模式的消费。我们先简单复习一下推拉模式的概念。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;推模式：当服务端有数据立即通知客户端，这个策略依赖服务端与客户端之间的长连接，它具有高实时性、客户端开发简单等优点；同时缺点也很明显，比如：服务端需要感知与它建立链接的客户端，要实现客户端节点的发现，服务端本身主动推送，需要服务端对消息做额外的处理，以便能够及时将消息分发给客户端。&lt;/p&gt;
&lt;p&gt;拉模式：客户端主动对服务端的数据进行拉取。客户端拉取数据，拉取成功后处理数据，处理完成再次进行拉取，循环执行。缺点是如果不能很好的设置拉取的频率，时间间隔，过多的空轮询会对服务端造成较大的访问压力，数据的实时性也不能得到很好的保证。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;基于对上述两个策略的优缺点的综合考虑，RocketMQ的DefaultMQPushConsumer采用了结合了推拉模式两者优点的长轮询机制，对消息进行消费。这样，既能保证主动权在客户端，还能保证数据拉取的实时性。&lt;/p&gt;
&lt;p&gt;本文我们就对RocketMQ的长轮询机制进行分析讲解，从而更好的理解RocketMQ的设计精巧之处。&lt;/p&gt;
&lt;p&gt;首先了解一下什么是 &lt;strong&gt;长轮询&lt;/strong&gt; 机制：&lt;/p&gt;
    
    </summary>
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/categories/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/tags/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
  </entry>
  
  <entry>
    <title>跟我学RocketMQ之定时消息源码解析</title>
    <link href="http://wuwenliang.net/2019/09/15/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ%E4%B9%8B%E5%AE%9A%E6%97%B6%E6%B6%88%E6%81%AF%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"/>
    <id>http://wuwenliang.net/2019/09/15/跟我学RocketMQ之定时消息源码解析/</id>
    <published>2019-09-15T11:13:15.000Z</published>
    <updated>2019-09-16T09:34:44.924Z</updated>
    
    <content type="html"><![CDATA[<p>本文我们单独对RocketMQ的定时消息进行源码解析。</p>
<p>同事务消息类似，RocketMQ定时消息也是通过Topic替换，后台线程异步发送实现的。具体逻辑是通过org.apache.rocketmq.store.schedule.ScheduleMessageService实现的。</p>
<h2 id="定时消息原理概述"><a href="#定时消息原理概述" class="headerlink" title="定时消息原理概述"></a>定时消息原理概述</h2><p>在正式进行源码分析之前，我们先从概念上对定时消息做一个较为宏观的认知。</p>
<blockquote>
<p>RocketMQ支持指定级别的消息延迟，默认为1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h。</p>
<p>RocketMQ消息重试以及定时消息均是通过定时任务实现的。重试消息以及定时消息在存入commitLog之前会判断重试次数，如果大于0，则会将消息的topic设置为SCHEDULE_TOPIC_XXXX。</p>
<p>ScheduleMessageService在实例化之后会对SCHEDULE_TOPIC_XXXX主题下的消息进行定时调度，从而实现定时投递。</p>
</blockquote>
<a id="more"></a>
<h2 id="ScheduleMessageService源码解析"><a href="#ScheduleMessageService源码解析" class="headerlink" title="ScheduleMessageService源码解析"></a>ScheduleMessageService源码解析</h2><p>我们接着对ScheduleMessageService进行解析，了解RocketMQ具体是如何实现定时消息机制的。</p>
<h3 id="重要变量"><a href="#重要变量" class="headerlink" title="重要变量"></a>重要变量</h3><p>在正式分析之前，先对ScheduleMessageService的重要成员变量做一下了解：</p>
<blockquote>
<p>delayLevelTable,记录了对延迟级别的解析结果，key=延迟级别，value=对应延迟级别的毫秒数</p>
</blockquote>
<pre><code>private final ConcurrentMap&lt;Integer /* level */, Long/* delay timeMillis */&gt; delayLevelTable =
    new ConcurrentHashMap&lt;Integer, Long&gt;(32);
</code></pre><blockquote>
<p>offsetTable,延迟级别对应的消费进度，key=延迟级别，value=对应延迟级别下的消费进度</p>
</blockquote>
<pre><code>private final ConcurrentMap&lt;Integer /* level */, Long/* offset */&gt; offsetTable =
    new ConcurrentHashMap&lt;Integer, Long&gt;(32);
</code></pre><h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><p>ScheduleMessageService的初始化是在DefaultMessageStore实现的，具体的调用链如下：</p>
<pre><code>BrokerStartup
    |-main
        |-start
            |-createBrokerController
                |-BrokerController.initialize()    
                |-controller.start()
                    |-DefaultMessageStore.start()
                        |-new ScheduleMessageService(this)
                        |-scheduleMessageService.start()
</code></pre><p>从调用链可以看出，当broker启动完成，ScheduleMessageService就开始对定时消息进行调度。</p>
<p>对于ScheduleMessageService我们主要关注：</p>
<ul>
<li>load()方法</li>
<li>start()方法</li>
</ul>
<h3 id="ScheduleMessageService-load"><a href="#ScheduleMessageService-load" class="headerlink" title="ScheduleMessageService.load()"></a>ScheduleMessageService.load()</h3><p>首先关注一下load()方法逻辑。</p>
<pre><code>[ScheduleMessageService.java]
public boolean load() {
    boolean result = super.load();
    result = result &amp;&amp; this.parseDelayLevel();
    return result;
}
</code></pre><p>load()方法的逻辑比较清晰，它的主要职责为：</p>
<ol>
<li>通过super.load()方法获取配置文件,加载延迟消息的消费进度</li>
<li>初始化delayLevelTable</li>
</ol>
<blockquote>
<p>RocketMQ将延时消息的消费进度存储于 ${RocketMQ_Home}/store/config/delayOffset.json下。</p>
</blockquote>
<p>我们重点看一下parseDelayLevel();如何完成解析延时配置，并组装为delayLevelTable的。</p>
<pre><code>[ScheduleMessageService.java]
public boolean parseDelayLevel() {
    // 初始化一个时间单位map，key为秒、分、时、天；value为对应单位的毫秒数
    HashMap&lt;String, Long&gt; timeUnitTable = new HashMap&lt;String, Long&gt;();
    timeUnitTable.put(&quot;s&quot;, 1000L);
    timeUnitTable.put(&quot;m&quot;, 1000L * 60);
    timeUnitTable.put(&quot;h&quot;, 1000L * 60 * 60);
    timeUnitTable.put(&quot;d&quot;, 1000L * 60 * 60 * 24);

    // 从defaultMessageStore中获取配置文件，从配置文件中获取延迟级别配置串，即：messageDelayLevel
    String levelString = this.defaultMessageStore.getMessageStoreConfig().getMessageDelayLevel();
    try {

        // 根据空格进行拆分，分解为String数组
        String[] levelArray = levelString.split(&quot; &quot;);

        // 遍历String数组
        for (int i = 0; i &lt; levelArray.length; i++) {
            String value = levelArray[i];
            String ch = value.substring(value.length() - 1);
            Long tu = timeUnitTable.get(ch);

            // key=延迟级别，等于下标+1
            int level = i + 1;
            if (level &gt; this.maxDelayLevel) {
                this.maxDelayLevel = level;
            }
            long num = Long.parseLong(value.substring(0, value.length() - 1));
            // value=单位对应毫秒数 * 解析得到的时间单位
            long delayTimeMillis = tu * num;
            // 存放到delayLevelTable
            this.delayLevelTable.put(level, delayTimeMillis);
        }
    } catch (Exception e) {
        log.error(&quot;parseDelayLevel exception&quot;, e);
        log.info(&quot;levelString String = {}&quot;, levelString);
        return false;
    }
    return true;
}
</code></pre><p>这段代码很好理解，就是对配置中的延时串通过空格进行分割为数组，按照下标及单位，计算得到每个等级对应的毫秒数，最终存放在delayLevelTable中实现delayLevelTable的初始化，便于后续在代码逻辑中进行使用。</p>
<p>如果没有设置则使用代码中的默认值。</p>
<h3 id="ScheduleMessageService-start"><a href="#ScheduleMessageService-start" class="headerlink" title="ScheduleMessageService.start()"></a>ScheduleMessageService.start()</h3><p>我们接着看一下start()方法的逻辑，该方法是延迟消息(定时消息)调度的核心逻辑。</p>
<pre><code>[ScheduleMessageService.java]
public void start() {
    if (started.compareAndSet(false, true)) {
        this.timer = new Timer(&quot;ScheduleMessageTimerThread&quot;, true);
</code></pre><p>start方法的核心思想为</p>
<blockquote>
<p>对不同的延迟级别创建对应的定时任务，通过定时任务对持久化的消息队列的进度进行存储。</p>
</blockquote>
<pre><code>// 首先对delayLevelTable进行迭代，取出每一个级别及其对应的延时长度。
for (Map.Entry&lt;Integer, Long&gt; entry : this.delayLevelTable.entrySet()) {
    Integer level = entry.getKey();
    Long timeDelay = entry.getValue();
    Long offset = this.offsetTable.get(level);
    // 获取该级别对应的消费进度offset，如果不存在则设置为0
    if (null == offset) {
        offset = 0L;
    }

    // 如果延时不为空，则延迟1秒执行定时任务
    if (timeDelay != null) {
        this.timer.schedule(new DeliverDelayedMessageTimerTask(level, offset), FIRST_DELAY_TIME);
    }
}
</code></pre><p>这里简单总结一下，首先对delayLevelTable进行遍历，获取对应延迟级别level对应的消费进度，默认进度不存在，每个延迟级别对应的消费进度都从0开始。</p>
<p>创建定时任务开始进行调度，每个定时任务初始都延迟1秒开始进行调度。后续则使用对应的延迟级别进行调度。</p>
<blockquote>
<p>注意：延时级别与消费队列的关系为：消息队列id=延时级别-1，具体逻辑在queueId2DelayLevel方法中。</p>
</blockquote>
<pre><code>        this.timer.scheduleAtFixedRate(new TimerTask() {

            @Override
            public void run() {
                try {
                    if (started.get()) ScheduleMessageService.this.persist();
                } catch (Throwable e) {
                    log.error(&quot;scheduleAtFixedRate flush exception&quot;, e);
                }
            }
        }, 10000, this.defaultMessageStore.getMessageStoreConfig().getFlushDelayOffsetInterval());
    }
}
</code></pre><p>这段代码的核心逻辑为，执行定时任务，每隔10s进行一次消费进度的持久化操作。具体的持久化刷盘频率可以通过flushDelayOffsetInterval参数进行配置。</p>
<h3 id="定时任务实现：DeliverDelayedMessageTimerTask"><a href="#定时任务实现：DeliverDelayedMessageTimerTask" class="headerlink" title="定时任务实现：DeliverDelayedMessageTimerTask"></a>定时任务实现：DeliverDelayedMessageTimerTask</h3><p>上面的分析中我们得知，RocketMQ对定时消息的每一个延迟级别都设置了一个定时任务，这个定时任务识通过DeliverDelayedMessageTimerTask实现的。</p>
<p>DeliverDelayedMessageTimerTask继承了TimerTask，我们直接看它的run()方法实现。</p>
<pre><code>@Override
public void run() {
    try {
        if (isStarted()) {
            this.executeOnTimeup();
        }
    } catch (Exception e) {
        // XXX: warn and notify me
        log.error(&quot;ScheduleMessageService, executeOnTimeup exception&quot;, e);
        ScheduleMessageService.this.timer.schedule(new DeliverDelayedMessageTimerTask(
            this.delayLevel, this.offset), DELAY_FOR_A_PERIOD);
    }
}
</code></pre><p>可以看到，核心是executeOnTimeup()方法，当执行异常，延迟10s后继续执行调度。</p>
<p>我们进入executeOnTimeup()方法。</p>
<h4 id="executeOnTimeup"><a href="#executeOnTimeup" class="headerlink" title="executeOnTimeup()"></a>executeOnTimeup()</h4><p>首先根据topic=SCHEDULE_TOPIC_XXXX，延迟级别转换为队列id，查询到当前的消费队列。</p>
<pre><code>ConsumeQueue cq =
    ScheduleMessageService.this.defaultMessageStore.findConsumeQueue(SCHEDULE_TOPIC,
        delayLevel2QueueId(delayLevel));
</code></pre><p>根据当前的offset从消费队列中获取当前所有的有效消息，如果未能获取到则更新拉取进度，等待定时任务下次进行尝试。</p>
<pre><code>for (; i &lt; bufferCQ.getSize(); i += ConsumeQueue.CQ_STORE_UNIT_SIZE) {
    long offsetPy = bufferCQ.getByteBuffer().getLong();
    int sizePy = bufferCQ.getByteBuffer().getInt();
    long tagsCode = bufferCQ.getByteBuffer().getLong();

    if (cq.isExtAddr(tagsCode)) {
        if (cq.getExt(tagsCode, cqExtUnit)) {
            tagsCode = cqExtUnit.getTagsCode();
        } else {
            //can&apos;t find ext content.So re compute tags code.
            log.error(&quot;[BUG] can&apos;t find consume queue extend file content!addr={}, offsetPy={}, sizePy={}&quot;,
                tagsCode, offsetPy, sizePy);
            long msgStoreTime = defaultMessageStore.getCommitLog().pickupStoreTimestamp(offsetPy, sizePy);
            tagsCode = computeDeliverTimestamp(delayLevel, msgStoreTime);
        }
    }
</code></pre><p>定时任务每次执行到这里都进行时间比较，计算延迟时间与当前时间的差值，如果延迟时间-当前时间&lt;=0说明该延迟消息应当被处理，使其能够被消费者消费。</p>
<pre><code>long now = System.currentTimeMillis();
long deliverTimestamp = this.correctDeliverTimestamp(now, tagsCode);

nextOffset = offset + (i / ConsumeQueue.CQ_STORE_UNIT_SIZE);
</code></pre><p>根据消息偏移量及消息大小从commitLog中查询消息，如果查到，则开始执行正式的消息消费准备工作。</p>
<pre><code>if (countdown &lt;= 0) {
    MessageExt msgExt =
         ScheduleMessageService.
            this.defaultMessageStore.lookMessageByOffset(offsetPy, sizePy);
</code></pre><p>对消息执行重新存储操作，恢复原先的队列以及消息topic，再将消息重新持久化到commitLog中，此时的消息已经能够被消费者拉取到。</p>
<pre><code>if (msgExt != null) {
         try {
             MessageExtBrokerInner msgInner = this.messageTimeup(msgExt);

            PutMessageResult putMessageResult =
                ScheduleMessageService.this.writeMessageStore
                                    .putMessage(msgInner);
</code></pre><p>我们重点看一下messageTimeup(msgExt)方法是如何进行消息的恢复操作。</p>
<h4 id="messageTimeup-msgExt-恢复原消息主题及队列"><a href="#messageTimeup-msgExt-恢复原消息主题及队列" class="headerlink" title="messageTimeup(msgExt)恢复原消息主题及队列"></a>messageTimeup(msgExt)恢复原消息主题及队列</h4><pre><code>private MessageExtBrokerInner messageTimeup(MessageExt msgExt) {
        // 建立一个新的MessageExtBrokerInner实体
        MessageExtBrokerInner msgInner = new MessageExtBrokerInner();
        msgInner.setBody(msgExt.getBody());
        msgInner.setFlag(msgExt.getFlag());
        MessageAccessor.setProperties(msgInner, msgExt.getProperties());

        ...省略属性设置...

        msgInner.setWaitStoreMsgOK(false);
        // 清理消息延迟级别属性
        MessageAccessor.clearProperty(msgInner, MessageConst.PROPERTY_DELAY_TIME_LEVEL);

        // 恢复消息原主题
        msgInner.setTopic(msgInner.getProperty(MessageConst.PROPERTY_REAL_TOPIC));

        // 恢复消息原队列id
        String queueIdStr = msgInner.getProperty(MessageConst.PROPERTY_REAL_QUEUE_ID);
        int queueId = Integer.parseInt(queueIdStr);
        msgInner.setQueueId(queueId);

        return msgInner;
    }
</code></pre><p>经过上述操作，定时消息已经还原为普通消息。</p>
<p>我们继续回到 <strong>executeOnTimeup()</strong> 方法中，通过</p>
<pre><code>PutMessageResult putMessageResult = 
ScheduleMessageService.this.writeMessageStore.putMessage(msgInner);
</code></pre><p>将还原后的消息重新持久化到commitLog中。</p>
<pre><code>nextOffset = offset + (i / ConsumeQueue.CQ_STORE_UNIT_SIZE);
ScheduleMessageService.this.timer.schedule(new DeliverDelayedMessageTimerTask(
        this.delayLevel, nextOffset), DELAY_FOR_A_WHILE);
ScheduleMessageService.this.updateOffset(this.delayLevel, nextOffset);
</code></pre><p>更新当前延迟队列的消息拉取进度，继续处理后续的消息。</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>本文我们完整的对RocketMQ的定时消息实现方式进行了分析，我们总结一下它的完整流程：</p>
<ol>
<li>消息发送方发送消息，设置delayLevel。</li>
<li>如果delayLevel大于0，表明是一条延时消息，broker处理该消息，将消息的主题、队列id进行备份后，改变消息的主题为SCHEDULE_TOPIC_XXXX，队列id=延迟级别-1，将消息持久化。</li>
<li>通过定时任务ScheduleMessageService对定时消息进行处理，每隔1s从上次拉取偏移量取出所有的消息进行处理</li>
<li>从消费队列中解析出消息的物理偏移量，从而从commitLog中取出消息</li>
<li>根据消息的属性重建消息，恢复消息的topic、原队列id，将消息的延迟级别属性delayLevel清除掉，再次保存到commitLog中</li>
<li>将消息转发到原主题对应的消费队列中，此时消费者可以对该消息进行消费。</li>
</ol>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文我们单独对RocketMQ的定时消息进行源码解析。&lt;/p&gt;
&lt;p&gt;同事务消息类似，RocketMQ定时消息也是通过Topic替换，后台线程异步发送实现的。具体逻辑是通过org.apache.rocketmq.store.schedule.ScheduleMessageService实现的。&lt;/p&gt;
&lt;h2 id=&quot;定时消息原理概述&quot;&gt;&lt;a href=&quot;#定时消息原理概述&quot; class=&quot;headerlink&quot; title=&quot;定时消息原理概述&quot;&gt;&lt;/a&gt;定时消息原理概述&lt;/h2&gt;&lt;p&gt;在正式进行源码分析之前，我们先从概念上对定时消息做一个较为宏观的认知。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;RocketMQ支持指定级别的消息延迟，默认为1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h。&lt;/p&gt;
&lt;p&gt;RocketMQ消息重试以及定时消息均是通过定时任务实现的。重试消息以及定时消息在存入commitLog之前会判断重试次数，如果大于0，则会将消息的topic设置为SCHEDULE_TOPIC_XXXX。&lt;/p&gt;
&lt;p&gt;ScheduleMessageService在实例化之后会对SCHEDULE_TOPIC_XXXX主题下的消息进行定时调度，从而实现定时投递。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/categories/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/tags/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
  </entry>
  
  <entry>
    <title>TCC-Transaction源码解析之事务补偿</title>
    <link href="http://wuwenliang.net/2019/09/09/TCC-Transaction%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B9%8B%E4%BA%8B%E5%8A%A1%E8%A1%A5%E5%81%BF/"/>
    <id>http://wuwenliang.net/2019/09/09/TCC-Transaction源码解析之事务补偿/</id>
    <published>2019-09-09T08:57:02.000Z</published>
    <updated>2019-09-09T09:29:20.758Z</updated>
    
    <content type="html"><![CDATA[<p>上文中，我们对TCC-Transaction的事务提交阶段主流程进行了详细的解析。上文遗留了一个问题：</p>
<blockquote>
<p>如果在事务执行过程中出现了down机、停电、网络异常等情况，事务一致性就无法得到保证，此时应该怎么做？</p>
</blockquote>
<p>这个问题在TCC-Transaction框架中是通过定时任务+状态机方式实现的，这种方式也是我们日常开发中经常使用的一种策略。本文，我们对事务恢复主逻辑进行分析，使TCC-Transaction源码解析形成一个闭环。</p>
<a id="more"></a>
<h2 id="RecoverScheduledJob"><a href="#RecoverScheduledJob" class="headerlink" title="RecoverScheduledJob"></a>RecoverScheduledJob</h2><p>事务补偿定时任务的核心逻辑由tcc-transaction-spring模块下的RecoverScheduledJob.java完成，对失败的confirm、cancel操作进行失败补偿操作。代码逻辑如下：</p>
<pre><code>public class RecoverScheduledJob {

    private TransactionRecovery transactionRecovery;

    private TransactionConfigurator transactionConfigurator;

    private Scheduler scheduler;

    // 通过init方法启动quartz定时任务
    public void init() {

        try {
            MethodInvokingJobDetailFactoryBean jobDetail = new MethodInvokingJobDetailFactoryBean();
            jobDetail.setTargetObject(transactionRecovery);
            jobDetail.setTargetMethod(&quot;startRecover&quot;);
            jobDetail.setName(&quot;transactionRecoveryJob&quot;);
            jobDetail.setConcurrent(false);
            jobDetail.afterPropertiesSet();

            CronTriggerFactoryBean cronTrigger = new CronTriggerFactoryBean();
            cronTrigger.setBeanName(&quot;transactionRecoveryCronTrigger&quot;);
            cronTrigger.setCronExpression(transactionConfigurator.getRecoverConfig().getCronExpression());
            cronTrigger.setJobDetail(jobDetail.getObject());
            cronTrigger.afterPropertiesSet();

            scheduler.scheduleJob(jobDetail.getObject(), cronTrigger.getObject());
            scheduler.start();

        } catch (Exception e) {
            throw new SystemException(e);
        }
    }
    ...省略getter setter...
}
</code></pre><p>通过quartz进行任务调度，通过RecoverConfig中的配置初始化定时任务，通过MethodInvokingJobDetailFactoryBean的targetObject与targetMethod指定了定时任务具体执行类及具体方法。</p>
<p>我们注意以下代码，它将任务的核心逻辑设置到jobDetail中</p>
<pre><code>jobDetail.setTargetObject(transactionRecovery);
jobDetail.setTargetMethod(&quot;startRecover&quot;);
</code></pre><p>最终通过quartz的Scheduler对任务发起调度，这里通过cron表达式触发器进行调度。</p>
<h2 id="TransactionRecovery"><a href="#TransactionRecovery" class="headerlink" title="TransactionRecovery"></a>TransactionRecovery</h2><p>TransactionRecovery是TCC-Transaction框架中事务补偿的核心实现</p>
<pre><code>public class TransactionRecovery {

    ......

    private TransactionConfigurator transactionConfigurator;
</code></pre><p>通过startRecover开启事务补偿重试任务。</p>
<pre><code>public void startRecover() {
    // 获取待补偿的任务列表
    List&lt;Transaction&gt; transactions = loadErrorTransactions();
    // 对待补偿的任务列表执行补偿操作
    recoverErrorTransactions(transactions);
}
</code></pre><p>首先通过loadErrorTransactions()获取待补偿的任务列表：</p>
<pre><code>private List&lt;Transaction&gt; loadErrorTransactions() {

    long currentTimeInMillis = Calendar.getInstance().getTimeInMillis();
    // 获取配置的具体事务持久化策略，如：基于数据库、zk、redis等
    TransactionRepository transactionRepository = transactionConfigurator.getTransactionRepository();

    // 获取重试策略，包含：cron表达式，最大重试次数等
    RecoverConfig recoverConfig = transactionConfigurator.getRecoverConfig();

    // 获取在RecoverDuration间隔之前未完成的transaction列表，查询方式依具体的持久化策略而定
    return transactionRepository
        .findAllUnmodifiedSince(
            new Date(currentTimeInMillis 
                - recoverConfig.getRecoverDuration() * 1000));
}
</code></pre><p>接着看一下recoverErrorTransactions方法逻辑，对待补偿的任务列表进行补偿操作。</p>
<pre><code>    private void recoverErrorTransactions(List&lt;Transaction&gt; transactions) {
        // 对需要进行重试的事务列表进行迭代
        for (Transaction transaction : transactions) {

            // 如果重试次数超过配置的最大重试次数，则打印异常日志；跳过不再重试
            if (transaction.getRetriedCount() &gt; 
                transactionConfigurator.getRecoverConfig().getMaxRetryCount()) {
                ...省略异常日志...
                continue;
            }

            // 如果是分支事务，并且超过最长超时时间则忽略不再重试
            if (transaction.getTransactionType().equals(TransactionType.BRANCH)
            &amp;&amp; (transaction.getCreateTime().getTime() 
                  transactionConfigurator.getRecoverConfig().getMaxRetryCount()
                  *transactionConfigurator.getRecoverConfig().getRecoverDuration() 
                  * 1000
                  &gt; System.currentTimeMillis())) {
                continue;
            }

            try {
                // 增加重试次数
                transaction.addRetriedCount();
                // 如果当前事务状态为CONFIRMING
                if (transaction.getStatus().equals(TransactionStatus.CONFIRMING)) {
                    // 设置事务状态为CONFIRMING
                    transaction.changeStatus(TransactionStatus.CONFIRMING);
                    // 修改当前事务状态
                    transactionConfigurator.getTransactionRepository().update(transaction);
                    // 提交事务
                    transaction.commit();
                    // 删除事务记录（删除失败则不作处理）
                    transactionConfigurator.getTransactionRepository().delete(transaction);

                // 如果事务状态为CANCELLING或者事务为根事务（根事务没提交）
                } else if (transaction.getStatus().equals(TransactionStatus.CANCELLING)
                        || transaction.getTransactionType().equals(TransactionType.ROOT)) {

                    // 设置事务状态为CANCELLING
                    transaction.changeStatus(TransactionStatus.CANCELLING);
                    // 修改当前事务状态
                    transactionConfigurator.getTransactionRepository().update(transaction);
                    // 回滚事务
                    transaction.rollback();
                    // 删除事务记录（删除失败则不作处理）
                    transactionConfigurator.getTransactionRepository().delete(transaction);
                }

            } catch (Throwable throwable) {

                ...省略异常日志...
            }
        }
    }

    public void setTransactionConfigurator(TransactionConfigurator transactionConfigurator) {
        this.transactionConfigurator = transactionConfigurator;
    }
}
</code></pre><p>上述注释已经很明确的指出了事务补偿job的核心逻辑，就不再赘述。我们总结一下：</p>
<p>对于trying阶段的异常事务，不会进行重试；而是会触发canceling操作；</p>
<p>对于confirming、canceling阶段的异常事务，定时进行重试补偿，尽最大努力去尝试提交事务，如果达到了最大重试次数还是处理失败则不再处理。这种极端的情况需要人工进行介入。</p>
<p>TCC-Transaction提供的后台server模块允许我们对事务进行手工补偿操作，这极大的提高了框架的可靠性以及易用性。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文我们主要对TCC-Transaction的事务补偿阶段逻辑进行了分析。TCC-Transaction框架通过定时补偿，对异常事务进行处理，保证了分布式事务的最终一致性。</p>
<p>通过这一过程，我们能够看出，TCC-Transaction框架本质上也是柔性事务的一种解决方案，如果仔细分析，它也是满足BASE原则的。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;上文中，我们对TCC-Transaction的事务提交阶段主流程进行了详细的解析。上文遗留了一个问题：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;如果在事务执行过程中出现了down机、停电、网络异常等情况，事务一致性就无法得到保证，此时应该怎么做？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这个问题在TCC-Transaction框架中是通过定时任务+状态机方式实现的，这种方式也是我们日常开发中经常使用的一种策略。本文，我们对事务恢复主逻辑进行分析，使TCC-Transaction源码解析形成一个闭环。&lt;/p&gt;
    
    </summary>
    
      <category term="TCC-Transaction源码解析" scheme="http://wuwenliang.net/categories/TCC-Transaction%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"/>
    
    
      <category term="TCC-Transaction源码解析" scheme="http://wuwenliang.net/tags/TCC-Transaction%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>TCC-Transaction源码解析之事务执行</title>
    <link href="http://wuwenliang.net/2019/09/09/TCC-Transaction%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B9%8B%E4%BA%8B%E5%8A%A1%E6%89%A7%E8%A1%8C/"/>
    <id>http://wuwenliang.net/2019/09/09/TCC-Transaction源码解析之事务执行/</id>
    <published>2019-09-09T05:54:24.000Z</published>
    <updated>2019-09-09T08:55:02.348Z</updated>
    
    <content type="html"><![CDATA[<p>TCC分布式事务解决方案在开源界的主要实现为Byte-TCC、TCC-Transaction等。其中笔者了解较多并且业界使用率较高的为TCC-Transaction这一实现。</p>
<p>本文，我将带领读者对TCC-Transaction这一分布式事务框架进行一次源码解析，提高自己的阅读源码的能力，也希望能够对读者深入了解TCC-Transaction有所帮助。</p>
<h2 id="源码下载"><a href="#源码下载" class="headerlink" title="源码下载"></a>源码下载</h2><p>源码地址为 <a href="https://github.com/changmingxie/tcc-transaction" target="_blank" rel="external">https://github.com/changmingxie/tcc-transaction</a>，我们关注最新版本1.2.x。</p>
<p>源码下载后导入IDEA中，项目目录结构如下图：</p>
<p><img src="/2019/09/09/TCC-Transaction源码解析之事务执行/tcc0.png" alt="代码结构"></p>
<a id="more"></a>
<p>模块及其对应职责说明如下：</p>
<pre><code>tcc-transaction
    |-transaction-tcc-api                   框架API定义，公共类/核心实体定义/枚举/工具类等
    |-transaction-tcc-core                  框架核心逻辑
    |-transaction-tcc-dubbo                 框架整合Dubbo实现
    |-transaction-tcc-spring                框架Spring整合，包含获取数据库连接/切面获取等
    |-transaction-tcc-server                后台管理页面，对事务进行手工重试等
    |-transaction-tcc-unit-test             单元测试
    |-transaction-tcc-tutorial-sample       样例工程
        |-tcc-transaction-dubbo-sample
        |-tcc-transaction-http-sample
        |-tcc-transaction-sample-domain
        |-tcc-transaction-server-sample
</code></pre><p>项目核心模块为 <strong>tcc-transaction-core</strong>，它实现了TCC核心业务逻辑，也是本次源码解析的重点对象。</p>
<p>我们从Dubbo使用样例入手进行分析，关于如何使用TCC-Transaction的更多说明，请参照官方文档: <a href="https://github.com/changmingxie/tcc-transaction/wiki/%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%971.2.x" target="_blank" rel="external">使用指南1.2.x</a></p>
<h2 id="从一个简单的样例入手"><a href="#从一个简单的样例入手" class="headerlink" title="从一个简单的样例入手"></a>从一个简单的样例入手</h2><blockquote>
<p>我们从一个调用案例入手开始进行分析，样例路径为org.mengyun.tcctransaction.sample.dubbo.order.service.PaymentServiceImpl。</p>
</blockquote>
<pre><code>@Compensable(confirmMethod = &quot;confirmMakePayment&quot;, cancelMethod = &quot;cancelMakePayment&quot;, 
asyncConfirm = false, 
delayCancelExceptions = {SocketTimeoutException.class, com.alibaba.dubbo.remoting.TimeoutException.class})
public void makePayment(@UniqueIdentity String orderNo, Order order,
                 BigDecimal redPacketPayAmount, BigDecimal capitalPayAmount) {
    System.out.println(&quot;order try make payment called.time seq:&quot; + 
                DateFormatUtils.format(Calendar.getInstance(), &quot;yyyy-MM-dd HH:mm:ss&quot;));

    //check if the order status is DRAFT, if no, means that another call makePayment 
                for the same order happened, ignore this call makePayment.
    if (order.getStatus().equals(&quot;DRAFT&quot;)) {
        order.pay(redPacketPayAmount, capitalPayAmount);
        try {
            orderRepository.updateOrder(order);
        } catch (OptimisticLockingFailureException e) {
            //ignore the concurrently update order exception, ensure idempotency.
        }
    }

    String result = capitalTradeOrderService.record(buildCapitalTradeOrderDto(order));
    String result2 = redPacketTradeOrderService.record(buildRedPacketTradeOrderDto(order));
}
...省略confirmMakePayment实现...
...省略cancelMakePayment实现...
</code></pre><p>这段代码为模拟支付扣款操作，可以看到在方法上添加了@Compensable注解，它是TCC-Transaction框架的核心注解，作用为：<strong>开启tcc事务支持</strong>，注解可以设置一下参数</p>
<table>
<thead>
<tr>
<th style="text-align:left">参数名</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">propagation</td>
<td style="text-align:left">事务传播属性，REQUIRED（必须存在事务，不存在则进行创建），SUPPORTS（如果有事务则在事务内运行），MANDATORY（必须存在事务），REQUIRES_NEW（不管是否存在是否都创建新的事务）</td>
</tr>
<tr>
<td style="text-align:left">confirmMethod</td>
<td style="text-align:left">confirm阶段方法实现</td>
</tr>
<tr>
<td style="text-align:left">cancelMethod</td>
<td style="text-align:left">cancel阶段方法实现</td>
</tr>
<tr>
<td style="text-align:left">transactionContextEditor</td>
<td style="text-align:left">设置transactionContextEditor</td>
</tr>
<tr>
<td style="text-align:left">asyncConfirm</td>
<td style="text-align:left">是否使用异步confirm</td>
</tr>
<tr>
<td style="text-align:left">asyncCancel</td>
<td style="text-align:left">是否使用异步cancel</td>
</tr>
</tbody>
</table>
<h2 id="解析注解-Compensable"><a href="#解析注解-Compensable" class="headerlink" title="解析注解@Compensable"></a>解析注解@Compensable</h2><p>看到了@Compensable注解以及对应的confirm、cancle方法，处于技术敏感，我们可以猜测在框架中一定存在切面逻辑对@Compensable进行拦截并处理；在切面逻辑中一定有对confirm、cancel方法的调用。从这个猜想出发，我们通过阅读相关代码去验证自己的猜想。</p>
<blockquote>
<p>我们进入tcc-transaction-core模块的代码目录，目录结构如下：</p>
</blockquote>
<pre><code>org.mengyun.tcctransaction
    |-common
    |-context
    |-interceptor           TCC事务拦截器
    |-recover               TCC事务补偿
    |-repository            事务存储
    |-serializer
    |-support
    |-utils
</code></pre><p>我们主要关注interceptor目录，该目录下的interceptor实现了对注解@Compensable的解析以及对事务的代理逻辑。</p>
<h3 id="CompensableTransactionAspect"><a href="#CompensableTransactionAspect" class="headerlink" title="CompensableTransactionAspect"></a>CompensableTransactionAspect</h3><blockquote>
<p>CompensableTransactionAspect切面主要实现了对@Compensable的解析以及对事务的代理。</p>
</blockquote>
<pre><code>@Aspect
public abstract class CompensableTransactionAspect {

    private CompensableTransactionInterceptor compensableTransactionInterceptor;

    public void setCompensableTransactionInterceptor(
                CompensableTransactionInterceptor compensableTransactionInterceptor) {
        this.compensableTransactionInterceptor = compensableTransactionInterceptor;
    }

    @Pointcut(&quot;@annotation(org.mengyun.tcctransaction.api.Compensable)&quot;)
    public void compensableService() {

    }

    @Around(&quot;compensableService()&quot;)
    public Object interceptCompensableMethod(ProceedingJoinPoint pjp) throws Throwable {

        return compensableTransactionInterceptor.interceptCompensableMethod(pjp);
    }

    public abstract int getOrder();
}
</code></pre><p>CompensableTransactionAspect的实现类为ConfigurableTransactionAspect.java, 加载顺序order= Ordered.HIGHEST_PRECEDENCE（-2147483648）。</p>
<p>该切面对标注了@Compensable的方法进行拦截，通过@Around为业务方法添加环绕增强。可以看到具体的增强方法实现为CompensableTransactionInterceptor.interceptCompensableMethod(pjp);</p>
<h4 id="CompensableTransactionInterceptor-interceptCompensableMethod-pjp"><a href="#CompensableTransactionInterceptor-interceptCompensableMethod-pjp" class="headerlink" title="CompensableTransactionInterceptor.interceptCompensableMethod(pjp);"></a>CompensableTransactionInterceptor.interceptCompensableMethod(pjp);</h4><p>接着上述的分析，我们看一下CompensableTransactionInterceptor.interceptCompensableMethod(pjp)的逻辑。</p>
<pre><code>[CompensableTransactionInterceptor.java]
public Object interceptCompensableMethod(ProceedingJoinPoint pjp) throws Throwable {

    // 初始化一个TCC方法执行上下文
    CompensableMethodContext compensableMethodContext = new CompensableMethodContext(pjp);
    // 校验事务支持是否开启
    boolean isTransactionActive = transactionManager.isTransactionActive();
    // 校验事务隔离级别
    if (!TransactionUtils.isLegalTransactionContext(
                isTransactionActive, compensableMethodContext)) {
        throw new SystemException
            (&quot;no active compensable transaction while propagation is mandatory for method &quot; 
                    + compensableMethodContext.getMethod().getName());
    }
    // 根据事务方法类型判断执行哪个逻辑
    switch (compensableMethodContext.getMethodRole(isTransactionActive)) {
        case ROOT:
            return rootMethodProceed(compensableMethodContext);
        case PROVIDER:
            return providerMethodProceed(compensableMethodContext);
        default:
            return pjp.proceed();
    }
}
</code></pre><p>我们主要关注switch代码段</p>
<pre><code>switch (compensableMethodContext.getMethodRole(isTransactionActive)) {
    case ROOT:
        //处理主事务切面，即：本次事务的入口方法
        return rootMethodProceed(compensableMethodContext);
    case PROVIDER:
        //处理提供者事务切面
        return providerMethodProceed(compensableMethodContext);
    default:
        //消费者事务直接执行，会对应执行远端提供者事务切面
        return pjp.proceed();
}
</code></pre><p>当事务方法为ROOT方法（即分布式事务的主方法）时，执行rootMethodProceed(compensableMethodContext);方法为PROVIDER（提供者）方法时，执行providerMethodProceed(compensableMethodContext)。默认为消费者事务，则直接执行。</p>
<p>我们以此看一下这几种事务切面的执行逻辑。</p>
<h4 id="rootMethodProceed-compensableMethodContext"><a href="#rootMethodProceed-compensableMethodContext" class="headerlink" title="rootMethodProceed(compensableMethodContext)"></a>rootMethodProceed(compensableMethodContext)</h4><p>对于事务的Root方法，执行rootMethodProceed逻辑，代码逻辑：</p>
<pre><code>private Object rootMethodProceed(CompensableMethodContext compensableMethodContext) 
    throws Throwable {

    Object returnValue = null;

    Transaction transaction = null;

    boolean asyncConfirm = compensableMethodContext.getAnnotation().asyncConfirm();

    boolean asyncCancel = compensableMethodContext.getAnnotation().asyncCancel();

    Set&lt;Class&lt;? extends Exception&gt;&gt; allDelayCancelExceptions = new HashSet&lt;Class&lt;? extends Exception&gt;&gt;();
    allDelayCancelExceptions.addAll(this.delayCancelExceptions);
    allDelayCancelExceptions.addAll(Arrays.asList(compensableMethodContext.getAnnotation().delayCancelExceptions()));

    try {
        // 创建事务， 将主事务的信息写入db或者zk或者redis中去，事务信息写入具体方式可配置
        transaction = transactionManager.begin(compensableMethodContext.getUniqueIdentity());

        try {
            // 执行完成之后会马上进到另外一个切面中去
            returnValue = compensableMethodContext.proceed();
        } catch (Throwable tryingException) {
            // 如果try失败，则进行回滚
            if (!isDelayCancelException(tryingException, allDelayCancelExceptions)) {

                logger.warn(String.format(&quot;compensable transaction trying failed. transaction content:%s&quot;, JSON.toJSONString(transaction)), tryingException);
                // 回滚事务
                transactionManager.rollback(asyncCancel);
            }

            throw tryingException;
        }
        // 提交事务
        transactionManager.commit(asyncConfirm);

    } finally {
        // 最终如果执行成功，则删除之前的事务记录；如果执行失败则不作任何处理，等待job进行补偿操作
        transactionManager.cleanAfterCompletion(transaction);
    }
    return returnValue;
}
</code></pre><p>注意关注这段代码</p>
<pre><code>// 执行完成之后会马上进到另外一个切面中去
returnValue = compensableMethodContext.proceed();
</code></pre><p>当所有的切面都执行完成之后才会执行后续的逻辑，也就是真正执行业务方法。</p>
<p>该方法为一个典型的模板方法，对事务通过begin、commit、rollback进行了抽象。</p>
<p>我们进入三个方法详细的分析。</p>
<h5 id="begin"><a href="#begin" class="headerlink" title="begin()"></a>begin()</h5><p>首先进入begin方法</p>
<pre><code>[TransactionManager.java]
public Transaction begin(Object uniqueIdentify) {
    // 0
    Transaction transaction = new Transaction(uniqueIdentify,TransactionType.ROOT);
    // 1
    transactionRepository.create(transaction);
    // 2
    registerTransaction(transaction);
    return transaction;
}
</code></pre><p>0.首先声明并初始化一个分布式事务对象Transaction，标记为ROOT事务，事务初始状态为TRYING。这里采用了经典的状态机策略</p>
<pre><code>public Transaction(TransactionType transactionType) {
    this.xid = new TransactionXid();
    // 事务初始状态设置成TRYING
    this.status = TransactionStatus.TRYING;
    this.transactionType = transactionType;
}   
</code></pre><p>1.将事务信息存储到数据源中，数据源可以是数据库、redis、zk等，可配置；TransactionRepository是具体的持久化策略的抽象</p>
<p>2.注册事务，在TransactionManager中，通过双向队列（Deque<transaction>）实现事务栈功能，用来处理嵌套事务。通过对Deque<transaction>声明为为ThreadLocal，所以对每个线程而言，事务栈都都是独立的</transaction></transaction></p>
<blockquote>
<p>private static final ThreadLocal<deque<transaction>&gt; CURRENT = new ThreadLocal<deque<transaction>&gt;();</deque<transaction></deque<transaction></p>
</blockquote>
<h5 id="commit"><a href="#commit" class="headerlink" title="commit()"></a>commit()</h5><p>接着看一下commit()方法</p>
<pre><code>[TransactionManager.java]
public void commit(boolean asyncCommit) {

    // 从ThreadLocal中获取当前事务
    final Transaction transaction = getCurrentTransaction();
    // 设置事务状态为CONFIRMING
    transaction.changeStatus(TransactionStatus.CONFIRMING);
    // 更新存储中的事务信息
    transactionRepository.update(transaction);

    // 如果异步commit属性为true
    if (asyncCommit) {
        try {
            Long statTime = System.currentTimeMillis();
            // 通过本地线程池异步进行事务提交
            executorService.submit(new Runnable() {
                @Override
                public void run() {
                    commitTransaction(transaction);
                }
            });
            logger.debug(&quot;async submit cost time:&quot; + (System.currentTimeMillis() - statTime));
        } catch (Throwable commitException) {
            logger.warn(&quot;compensable transaction async submit confirm failed, recovery job will try to confirm later.&quot;, commitException);
            throw new ConfirmingException(commitException);
        }
    } else {
        // 否则同步进行事务提交
        commitTransaction(transaction);
    }
}
</code></pre><p>commit(boolean asyncCommit)方法执行事务的提交过程，具体提交逻辑在commitTransaction(transaction)中完成。</p>
<pre><code>[TransactionManager.java]
private void commitTransaction(Transaction transaction) {
    try {
        // 提交事务
        transaction.commit();
        // 删除本次提交的本地事务记录，如果commit异常，不会把数据库内事务记录删除，
        // 通过job重试进行补偿
        transactionRepository.delete(transaction);
    } catch (Throwable commitException) {
        logger.warn(&quot;compensable transaction confirm failed, recovery job will try to confirm later.&quot;, commitException);
        throw new ConfirmingException(commitException);
    }
}

[Transaction.java]
public void commit() {
    // 对每一个分支执行提交操作
    for (Participant participant : participants) {
        participant.commit();
    }
}
</code></pre><p>可以看到，在事务提交完成之后，对本地持久化的事务记录进行了物理删除，具体删除方式取决于持久化机制。感兴趣的同学可以自行查看 <strong>org.mengyun.tcctransaction.repository</strong> 目录下的实现。</p>
<h5 id="rollback"><a href="#rollback" class="headerlink" title="rollback()"></a>rollback()</h5><p>我们看一下方法rollback()是如何实现事务回滚逻辑的</p>
<pre><code>[TransactionManager.java]
public void rollback(boolean asyncRollback) {

    // 从ThreadLocal中获取当前事务    
    final Transaction transaction = getCurrentTransaction();
    transaction.changeStatus(TransactionStatus.CANCELLING);
    // 更新事务状态为CANCELLING
    transactionRepository.update(transaction);
    // 如果异步rollback属性为true
    if (asyncRollback) {
        try {
            executorService.submit(new Runnable() {
                @Override
                public void run() {
                    // 通过线程池执行回滚逻辑
                    rollbackTransaction(transaction);
                }
            });
        } catch (Throwable rollbackException) {
            logger.warn(&quot;compensable transaction async rollback failed, recovery job will try to rollback later.&quot;, rollbackException);
            throw new CancellingException(rollbackException);
        }
    } else {
        // 异步rollback设置为false，同步执行回滚
        rollbackTransaction(transaction);
    }
}
</code></pre><p>和commit方法类似，在rollback(boolean asyncRollback)执行事务的回滚操作，具体的操作在rollbackTransaction(transaction)中执行：</p>
<pre><code>private void rollbackTransaction(Transaction transaction) {
    try {
        // 事务回滚
        transaction.rollback();
        // 删除本次回滚的本地事务记录，如果rollback异常，不会把数据库内事务记录删除，
        // 通过job重试进行补偿
        transactionRepository.delete(transaction);
    } catch (Throwable rollbackException) {
        logger.warn(&quot;compensable transaction rollback failed, recovery job will try to rollback later.&quot;, rollbackException);
        throw new CancellingException(rollbackException);
    }
}
</code></pre><h5 id="cleanAfterCompletion-transaction"><a href="#cleanAfterCompletion-transaction" class="headerlink" title="cleanAfterCompletion(transaction)"></a>cleanAfterCompletion(transaction)</h5><p>无论是否提交/回滚，最终都会执行cleanAfterCompletion(transaction)方法进行现场清理操作。</p>
<pre><code>public void cleanAfterCompletion(Transaction transaction) {
    if (isTransactionActive() &amp;&amp; transaction != null) {
        // 从ThreadLocal中获取当前事务
        Transaction currentTransaction = getCurrentTransaction();‘
        // 弹出当前事务
        if (currentTransaction == transaction) {
            CURRENT.get().pop();
            if (CURRENT.get().size() == 0) {
                CURRENT.remove();
            }
        } else {
            throw new SystemException(&quot;Illegal transaction when clean after completion&quot;);
        }
    }
}
</code></pre><p>事务执行结束，从栈中弹出当前结束的事务。</p>
<h4 id="providerMethodProceed-compensableMethodContext"><a href="#providerMethodProceed-compensableMethodContext" class="headerlink" title="providerMethodProceed(compensableMethodContext)"></a>providerMethodProceed(compensableMethodContext)</h4><p>看完rootMethodProceed根事务切面逻辑，再来看提供者切面事务逻辑就好理解多了，方法逻辑如下：</p>
<pre><code>private Object providerMethodProceed(CompensableMethodContext compensableMethodContext) throws Throwable {

    // 获取异步回滚、异步提交标识
    Transaction transaction = null;
    boolean asyncConfirm = compensableMethodContext.getAnnotation().asyncConfirm();
    boolean asyncCancel = compensableMethodContext.getAnnotation().asyncCancel();

    try {
        // 判断当前事务状态
        switch (TransactionStatus.valueOf(compensableMethodContext.getTransactionContext().getStatus())) {
            // 如果事务状态为TRYING
            case TRYING:
                //  通过使用transactionContext创建分支事务
                transaction = transactionManager.propagationNewBegin(compensableMethodContext.getTransactionContext());
                // 执行被切方法逻辑
                return compensableMethodContext.proceed();

            // 如果事务状态为CONFIRMING
            case CONFIRMING:
                try {
                    // 对事务状态进行更新
                    transaction = transactionManager.propagationExistBegin(compensableMethodContext.getTransactionContext());
                    // 提交事务，不执行切面方法
                    transactionManager.commit(asyncConfirm);
                } catch (NoExistedTransactionException excepton) {
                    //the transaction has been commit,ignore it.
                }
                break;

            // 如果事务状态为CANCELLING
            case CANCELLING:
                try {
                    // 更新事务状态
                    transaction = transactionManager.propagationExistBegin(compensableMethodContext.getTransactionContext());
                    // 执行事务回滚，不执行切面方法
                    transactionManager.rollback(asyncCancel);
                } catch (NoExistedTransactionException exception) {
                    //the transaction has been rollback,ignore it.
                }
                break;
        }

    } finally {
        // 对现场进行清理
        transactionManager.cleanAfterCompletion(transaction);
    }

    Method method = compensableMethodContext.getMethod();
    // 处理原始类型返回值，返回原始类型的默认值，因为不能返回null
    return ReflectionUtils.getNullValue(method.getReturnType());
}

public Transaction propagationExistBegin(TransactionContext transactionContext) throws NoExistedTransactionException {

    // 根据事务id从事务持久化组件中查询到本事务
    Transaction transaction = transactionRepository.findByXid(transactionContext.getXid());
    // 不为空
    if (transaction != null) {
        // 对事务状态进行更新，根据传参不同，执行TRYING-&gt;CONFIRMING或者TRYING-&gt;CANCELING等操作
        transaction.changeStatus(TransactionStatus.valueOf(transactionContext.getStatus()));
        // 对事务栈进行操作，执行嵌套事务入栈
        registerTransaction(transaction);
        return transaction;
    } else {
        throw new NoExistedTransactionException();
    }
}
</code></pre><blockquote>
<p>这里进行小结，可以看到在provider类型的方法切面，对于远程的Participant，如果transaction的status为trying，则通过transactionManager.propagationNewBegin创建分支事务并执行被切方法逻辑；</p>
<p>如果是status为confirming或canceling，则会调用对应的confirm或cancel配置的方法，跳过被切方法</p>
<p>对于普通类型方法直接调用，normal类型的方法是封装了对远程dubbo接口方法调用逻辑的本地proxy方法，所以直接执行即可</p>
</blockquote>
<h3 id="ResourceCoordinatorAspect"><a href="#ResourceCoordinatorAspect" class="headerlink" title="ResourceCoordinatorAspect"></a>ResourceCoordinatorAspect</h3><blockquote>
<p>ResourceCoordinatorAspect切面主要是为了执行资源协调，它的实现为ConfigurableCoordinatorAspect</p>
</blockquote>
<pre><code>[ResourceCoordinatorAspect.java]
@Aspect
public abstract class ResourceCoordinatorAspect {

    private ResourceCoordinatorInterceptor resourceCoordinatorInterceptor;

    @Pointcut(&quot;@annotation(org.mengyun.tcctransaction.api.Compensable)&quot;)
    public void transactionContextCall() {
    }

    @Around(&quot;transactionContextCall()&quot;)
    public Object interceptTransactionContextMethod(ProceedingJoinPoint pjp) throws Throwable {
        return resourceCoordinatorInterceptor.interceptTransactionContextMethod(pjp);
    }

    public void setResourceCoordinatorInterceptor(ResourceCoordinatorInterceptor resourceCoordinatorInterceptor) {
        this.resourceCoordinatorInterceptor = resourceCoordinatorInterceptor;
    }

    public abstract int getOrder();
}

[ConfigurableCoordinatorAspect.java]
@Aspect
public class ConfigurableCoordinatorAspect extends ResourceCoordinatorAspect implements Ordered {

    private TransactionConfigurator transactionConfigurator;

    public void init() {
        ResourceCoordinatorInterceptor resourceCoordinatorInterceptor = new ResourceCoordinatorInterceptor();
        resourceCoordinatorInterceptor.setTransactionManager(transactionConfigurator.getTransactionManager());
        this.setResourceCoordinatorInterceptor(resourceCoordinatorInterceptor);
    }

    @Override
    public int getOrder() {
        return Ordered.HIGHEST_PRECEDENCE + 1;
    }

    public void setTransactionConfigurator(TransactionConfigurator transactionConfigurator) {
        this.transactionConfigurator = transactionConfigurator;
    }
}
</code></pre><p>ConfigurableCoordinatorAspect的职责为设置事务的参与者；在一个事务内，每个被@Compensable注解的方法都是事务参与者。</p>
<p>可以看到该切面的优先级为 Ordered.HIGHEST_PRECEDENCE + 1，order的数值大于CompensableTransactionAspect。由于 <strong>@Order中的值越小，优先级越高</strong>，因此切面ResourceCoordinatorAspect的优先级小于CompensableTransactionAspect。</p>
<p>从代码可以看出，设置事务参与者逻辑是通过ResourceCoordinatorInterceptor.interceptTransactionContextMethod方法执行的。</p>
<pre><code>[ResourceCoordinatorInterceptor.java]
public Object interceptTransactionContextMethod(ProceedingJoinPoint pjp) throws Throwable {

    // 从当前ThreadLocal中获取事务
    Transaction transaction = transactionManager.getCurrentTransaction();
    if (transaction != null) {
        switch (transaction.getStatus()) {
            case TRYING:
                // 只需要在TRYING阶段将参与者的信息提取出来设置到transaction中
                enlistParticipant(pjp);
                break;
            case CONFIRMING:
                break;
            case CANCELLING:
                break;
        }
    }
    // 执行目标方法
    return pjp.proceed(pjp.getArgs());
}
</code></pre><p>我们可以得知，在trying阶段，框架会把所有事务参与者加入到当前事务中去。</p>
<p>对于Root方法，先创建主事务，事务参与者包括Root方法对应的本地参与者及Normal方法对应的远程参与者；</p>
<p>对于Provider方法，首先通过主事务上下文创建分支事务，事务参与者包括Provider方法对应的本地参与者以及它所包含的Normal方法对应的远程参与者。而远程参与者又可以开启新的分支事务。</p>
<p>我们可以合理的猜想，如果事务嵌套的层级很多，一定会存在性能问题。</p>
<h4 id="enlistParticipant-pjp"><a href="#enlistParticipant-pjp" class="headerlink" title="enlistParticipant(pjp)"></a>enlistParticipant(pjp)</h4><p>我们详细看一下enlistParticipant(pjp)是如何生成的事务参与者对象。</p>
<pre><code>private void enlistParticipant(ProceedingJoinPoint pjp) throws IllegalAccessException, InstantiationException {

    // 首先获取@Compensable信息
    Method method = CompensableMethodUtils.getCompensableMethod(pjp);
    if (method == null) {
        // @Compensable标注的方法为空则抛出异常
        throw new RuntimeException(String.format(&quot;join point not found method, point is : %s&quot;, pjp.getSignature().getName()));
    }
    Compensable compensable = method.getAnnotation(Compensable.class);

    // 回去confirm和cancle方法名
    String confirmMethodName = compensable.confirmMethod();
    String cancelMethodName = compensable.cancelMethod();
    // 获取当前事务以及全局事务id
    Transaction transaction = transactionManager.getCurrentTransaction();
    TransactionXid xid = new TransactionXid(transaction.getXid().getGlobalTransactionId());

    // 设置事务上下文到Editor中
    // Editor用来统一提取事务上下文，如果是dubbo则对应设置dubbo的rpc上下文
    // 此处的上下文设置之后就会调用try逻辑
    if (FactoryBuilder.factoryOf(compensable.transactionContextEditor()).getInstance().get(pjp.getTarget(), method, pjp.getArgs()) == null) {
        FactoryBuilder.factoryOf(compensable.transactionContextEditor()).getInstance().set(new TransactionContext(xid, TransactionStatus.TRYING.getId()), pjp.getTarget(), ((MethodSignature) pjp.getSignature()).getMethod(), pjp.getArgs());
    }

    // 通过目标类名，方法名，参数类型获取目标类
    Class targetClass = ReflectionUtils.getDeclaringType(pjp.getTarget().getClass(), method.getName(), method.getParameterTypes());

    // confirm逻辑调用上下文
    InvocationContext confirmInvocation = new InvocationContext(targetClass,
            confirmMethodName,
            method.getParameterTypes(), pjp.getArgs());

    //cancel逻辑调用上下文
    InvocationContext cancelInvocation = new InvocationContext(targetClass,
            cancelMethodName,
            method.getParameterTypes(), pjp.getArgs());

    // 此处较为关键，confirm和cancle具有相同地位，都被抽象成InvocationContext
    Participant participant =
            new Participant(
                    xid,
                    confirmInvocation,
                    cancelInvocation,
                    compensable.transactionContextEditor());
    // 将participant设置到transaction中，并同步到持久化存储中
    transactionManager.enlistParticipant(participant);
}

[TransactionManager.java]
public void enlistParticipant(Participant participant) {
    Transaction transaction = this.getCurrentTransaction();
    transaction.enlistParticipant(participant);
    transactionRepository.update(transaction);
}

[Transaction.java]
public void enlistParticipant(Participant participant) {
    participants.add(participant);
}
</code></pre><blockquote>
<p>从上述的代码逻辑中，我们可以得到结论，CompensableTransactionAspect开启事务，ResourceCoordinatorAspect对注解@Compensable进行解析，将confirm与cancel的具体逻辑设置到事务管理器中。</p>
<p>当上述两个切面都执行完成之后，开始执行try中的方法。如果try成功则执行commit否则执行rollback。</p>
<p>每个分支事务最终被封装到Transaction的participants中，每个分布式事务都有一个自己的 <strong>ThreadLocal<deque＜transaction＞></deque＜transaction＞></strong></p>
</blockquote>
<p>我们再次回顾commit的逻辑，查看Transaction.commit()方法</p>
<pre><code>[Transaction.java]
public void commit() {
    // 对每一个分支执行提交操作
    for (Participant participant : participants) {
        participant.commit();
    }
}
</code></pre><p>participant就是切面ResourceCoordinatorAspect 添加的。我们再看一下participant.commit()的逻辑：</p>
<pre><code>[Transaction.java]
public void commit() {
    terminator.invoke(new TransactionContext(xid, TransactionStatus.CONFIRMING.getId()), confirmInvocationContext, transactionContextEditorClass);
}
</code></pre><p>可以看到最终事务提交是通过invoke反射实现的，我们进入invoke逻辑</p>
<pre><code>public Object invoke(TransactionContext transactionContext, 
                    InvocationContext invocationContext, 
                    Class&lt;? extends TransactionContextEditor&gt; transactionContextEditorClass) {
    // 如果事务执行上下文方法名不为空
    if (StringUtils.isNotEmpty(invocationContext.getMethodName())) {
        try {
            Object target = FactoryBuilder.factoryOf(invocationContext.getTargetClass()).getInstance();

            Method method = null;

            method = target.getClass().getMethod(invocationContext.getMethodName(), invocationContext.getParameterTypes());
            // 实例化原事务执行者的代理对象
            FactoryBuilder.factoryOf(transactionContextEditorClass).getInstance().set(transactionContext, target, method, invocationContext.getArgs());
            // 反射执行
            return method.invoke(target, invocationContext.getArgs());

        } catch (Exception e) {
            throw new SystemException(e);
        }
    }
    return null;
}
</code></pre><p>最终通过method.invoke(target, invocationContext.getArgs())方法完成了真实的事务提交操作。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>到此我们对TCC-TRANSACTION的事务提交主流程进行了完整的分析。</p>
<p>通过分析我们可以知道TCC-TRANSACTION的核心逻辑是通过两个切面CompensableTransactionAspect、ResourceCoordinatorAspect 实现的。通过对事务进行包装与代理，实现了类二阶段的分布式事务解决方案。</p>
<p>实际上，TCC-TRANSACTION还有一个重要的补偿逻辑我们还没有分析，它是基于定时调度实现的。</p>
<p>限于本文的篇幅，就不再继续展开。我将单独用一篇文章来对TCC-TRANSACTION的补偿过程进行分析，我们下文再会。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;TCC分布式事务解决方案在开源界的主要实现为Byte-TCC、TCC-Transaction等。其中笔者了解较多并且业界使用率较高的为TCC-Transaction这一实现。&lt;/p&gt;
&lt;p&gt;本文，我将带领读者对TCC-Transaction这一分布式事务框架进行一次源码解析，提高自己的阅读源码的能力，也希望能够对读者深入了解TCC-Transaction有所帮助。&lt;/p&gt;
&lt;h2 id=&quot;源码下载&quot;&gt;&lt;a href=&quot;#源码下载&quot; class=&quot;headerlink&quot; title=&quot;源码下载&quot;&gt;&lt;/a&gt;源码下载&lt;/h2&gt;&lt;p&gt;源码地址为 &lt;a href=&quot;https://github.com/changmingxie/tcc-transaction&quot;&gt;https://github.com/changmingxie/tcc-transaction&lt;/a&gt;，我们关注最新版本1.2.x。&lt;/p&gt;
&lt;p&gt;源码下载后导入IDEA中，项目目录结构如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/09/09/TCC-Transaction源码解析之事务执行/tcc0.png&quot; alt=&quot;代码结构&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="TCC-Transaction源码解析" scheme="http://wuwenliang.net/categories/TCC-Transaction%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"/>
    
    
      <category term="TCC-Transaction源码解析" scheme="http://wuwenliang.net/tags/TCC-Transaction%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>研磨Spring事件机制</title>
    <link href="http://wuwenliang.net/2019/09/08/%E7%A0%94%E7%A3%A8Spring%E4%BA%8B%E4%BB%B6%E6%9C%BA%E5%88%B6/"/>
    <id>http://wuwenliang.net/2019/09/08/研磨Spring事件机制/</id>
    <published>2019-09-08T08:41:09.000Z</published>
    <updated>2019-09-08T09:29:05.227Z</updated>
    
    <content type="html"><![CDATA[<p>Spring提供了应用程序事件特性为开发者提供了事件发布和接收事件的能力，它基于观察者模式实现，对于提升应用逻辑的松耦合很有意义。</p>
<p>本文就如何使用Spring事件机制进行较为详细的总结。</p>
<h2 id="Spring事件概述"><a href="#Spring事件概述" class="headerlink" title="Spring事件概述"></a>Spring事件概述</h2><ul>
<li>每一个Spring事件都需要继承ApplicationEvent的类，ApplicationEvent又继承自java.util.EventObject</li>
<li>Spring中的任何bean都能够通过实现ApplicationListener<t>接口来监听事件；这里的泛型T就是上面提到的继承了ApplicationEvent的类</t></li>
<li>SpringContext会对实现ApplicationListener接口的任意bean进行自动注册</li>
<li>发布事件是通过ApplicationEventPublisher.publishEvent方法实现的。应用中一般通过ApplicationContext进行事件发布，ApplicationContext实现了ApplicationEventPublisher接口</li>
<li>另一种发布事件的方式是bean实现ApplicationContextAware接口，拿到ApplicationContext实例从而实现事件发布</li>
</ul>
<a id="more"></a>
<h2 id="Spring事件机制实战"><a href="#Spring事件机制实战" class="headerlink" title="Spring事件机制实战"></a>Spring事件机制实战</h2><p>我们通过一个简单的案例对Spring事件机制使用进行总结。</p>
<h3 id="定义事件"><a href="#定义事件" class="headerlink" title="定义事件"></a>定义事件</h3><blockquote>
<p>首先需要对事件进行定义，事件可以理解为消息队列中的消息，即：当满足某个条件时候需要发布的一个实体，该实体中包含了我们需要事件监听器处理的内容。<br>比如：当数据库中的内容发生更新，我们需要同步对缓存中的数据进行更新，那么我们就可以在数据库更新成功之后发布一个缓存更新事件，将更新后的数据实体通过publishEvent发布出去，<br>在另一个监听器类中获取到该缓存更新事件对缓存进行更新即可。这是一个事件机制的典型应用。</p>
</blockquote>
<p>一个事件是一个javabean，它需要继承ApplicationEvent。</p>
<pre><code>public class DemoEvent extends ApplicationEvent {

    private String key;
    private String value;

    public DemoEvent(Object source) {
        super(source);
    }

    public String getKey() {
        return key;
    }

    public DemoEvent setKey(String key) {
        this.key = key;
        return this;
    }

    public String getValue() {
        return value;
    }

    public DemoEvent setValue(String value) {
        this.value = value;
        return this;
    }

    @Override
    public String toString() {
        return &quot;DemoEvent{&quot; +
                &quot;key=&apos;&quot; + key + &apos;\&apos;&apos; +
                &quot;, value=&apos;&quot; + value + &apos;\&apos;&apos; +
                &apos;}&apos;;
    }
}
</code></pre><p>上述这个类继承了ApplicationEvent，key、value是它的属性，在实际应用中，属性可以使任意的应用数据。</p>
<blockquote>
<p>需要注意的是，ApplicationEvent具有一个接受指向事件源的引用的构造函数，在DemoEvent的构造函数中，需要通过super(source);传入事件源的引用。</p>
</blockquote>
<h3 id="定义事件监听器"><a href="#定义事件监听器" class="headerlink" title="定义事件监听器"></a>定义事件监听器</h3><p>ApplicationListener接口定义了方法onApplicationEvent，当触发了一个事件的时候，Spring框架会回调onApplicationEvent方法。</p>
<p>通过实现ApplicationListener接口，应用事件监听器需要对接收到的事件类进行处理。</p>
<pre><code>@Component
public class DemoEventListener implements ApplicationListener&lt;DemoEvent&gt; {

    private static final Map&lt;String, String&gt; CONTAINER = new ConcurrentHashMap&lt;&gt;();

    @Override
    public void onApplicationEvent(DemoEvent demoEvent) {
        CONTAINER.put(demoEvent.getKey(), demoEvent.getValue());
        System.out.println(&quot;[DemoEventListener]接受事件--&quot; + demoEvent.toString());
        System.out.println(CONTAINER.toString());
    }
}
</code></pre><p>这里的逻辑是DemoEventListener实现了强类型的ApplicationListener接口，对我们发布的DemoEvent事件进行处理。</p>
<p>具体的处理逻辑为将DemoEvent的key、value属性添加到CONTAINER这个Map中，模拟缓存更新。</p>
<blockquote>
<p>另外一种创建事件监听器的方式为可以使用注解<strong>@EventListener</strong>：原理就是通过扫描这个注解，创建监听器并添加到ApplicationContext</p>
</blockquote>
<h3 id="发布事件"><a href="#发布事件" class="headerlink" title="发布事件"></a>发布事件</h3><p>通过接口ApplicationEventPublisher的publishEvent方法我们能够完成发布事件的目的，在Spring框架中AbstractApplicationContext实现了ApplicationEventPublisher接口。</p>
<p>因此我们能够在应用中通过获取ApplicationContext实例使用事件发布能力。</p>
<blockquote>
<p>也可以通过实现ApplicationEventPublisherAware接口来发布事件</p>
</blockquote>
<pre><code>@Component
public class DemoEventPublisher implements CommandLineRunner {

    ScheduledExecutorService executorService = Executors.newScheduledThreadPool(1);

    private static final AtomicInteger ATOMIC_INTEGER = new AtomicInteger(0);

    @Autowired
    ApplicationContext context;

    @Override
    public void run(String... args) throws Exception {
        executorService.scheduleAtFixedRate(new Runnable() {
            @Override
            public void run() {
                // 设置事件源
                DemoEvent demoEvent = new DemoEvent(this);
                demoEvent.setKey(String.valueOf(ATOMIC_INTEGER.getAndAdd(1))).setValue(&quot;snowalker&quot;);
                context.publishEvent(demoEvent);
                System.out.println(&quot;[DemoEventPublisher]发布事件：&quot; + demoEvent.toString());
            }
        }, 0, 3000, TimeUnit.MILLISECONDS);
    }
}
</code></pre><p>我们通过context.publishEvent(demoEvent);发布了缓存更新事件，每3秒发布一次。另一种写法为</p>
<pre><code>@Component
public class DemoEventPublisher2 implements CommandLineRunner, ApplicationEventPublisherAware {

    ScheduledExecutorService executorService = Executors.newScheduledThreadPool(1);

    private static final AtomicInteger ATOMIC_INTEGER = new AtomicInteger(0);

    ApplicationEventPublisher applicationEventPublisher;

    @Override
    public void run(String... args) throws Exception {
        executorService.scheduleAtFixedRate(new Runnable() {
            @Override
            public void run() {
                // 设置事件源
                DemoEvent demoEvent = new DemoEvent(this);
                demoEvent.setKey(String.valueOf(ATOMIC_INTEGER.getAndAdd(1))).setValue(&quot;snowalker&quot;);
                System.out.println(&quot;[DemoEventPublisher]发布事件：&quot; + demoEvent.toString());
                applicationEventPublisher.publishEvent(demoEvent);
            }
        }, 0, 3000, TimeUnit.MILLISECONDS);
    }

    @Override
    public void setApplicationEventPublisher(ApplicationEventPublisher applicationEventPublisher) {
        this.applicationEventPublisher = applicationEventPublisher;
    }
}
</code></pre><p>这两种写法效果一致，最终都是通过applicationEventPublisher进行了事件的发布。</p>
<h3 id="案例运行"><a href="#案例运行" class="headerlink" title="案例运行"></a>案例运行</h3><pre><code>[DemoEventPublisher]发布事件：DemoEvent{key=&apos;0&apos;, value=&apos;snowalker&apos;}
[DemoEventListener]接受事件--DemoEvent{key=&apos;0&apos;, value=&apos;snowalker&apos;}
{0=snowalker}
[DemoEventPublisher]发布事件：DemoEvent{key=&apos;1&apos;, value=&apos;snowalker&apos;}
[DemoEventListener]接受事件--DemoEvent{key=&apos;1&apos;, value=&apos;snowalker&apos;}
{0=snowalker, 1=snowalker}
[DemoEventPublisher]发布事件：DemoEvent{key=&apos;2&apos;, value=&apos;snowalker&apos;}
[DemoEventListener]接受事件--DemoEvent{key=&apos;2&apos;, value=&apos;snowalker&apos;}
{0=snowalker, 1=snowalker, 2=snowalker}
......
</code></pre><p>可以看到，通过事件机制，我们实现了进程内的事件通信，这种方式能够很好的对业务进行解耦合，更加灵活的进行业务处理。</p>
<h4 id="事务绑定事件"><a href="#事务绑定事件" class="headerlink" title="事务绑定事件"></a>事务绑定事件</h4><p>另外需要注意的是，某些场景下，我们需要在事务提交之后再发布事件，这里就涉及到了事务绑定事件能力。</p>
<p>具体的方式为使用 <strong>@TransactionalEventListener注解</strong> 或者 <strong>TransactionSynchronizationManager</strong> 类来解决此类问题，也就是：事务成功提交之后，再发布事件。</p>
<p>当然我们也可以在事件提交之后将结果返回给调用方然后发布事件，但是这种方式不够优雅，因此还是建议使用事务绑定事件的方式进行基于事务的事件发布。</p>
<h3 id="异步事件支持"><a href="#异步事件支持" class="headerlink" title="异步事件支持"></a>异步事件支持</h3><p>上述的方式为同步事件，我们可以通过配置开启异步事件支持。</p>
<p>通过使用@Async注解事件监听器开启异步支持，需要要开启对异步注解的支持.</p>
<ul>
<li>java配置通过@EnableAsync开启.</li>
<li>如果是xml配置文件则需要配置: <task:annotation-driven></task:annotation-driven></li>
</ul>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Spring提供了应用程序事件特性为开发者提供了事件发布和接收事件的能力，它基于观察者模式实现，对于提升应用逻辑的松耦合很有意义。&lt;/p&gt;
&lt;p&gt;本文就如何使用Spring事件机制进行较为详细的总结。&lt;/p&gt;
&lt;h2 id=&quot;Spring事件概述&quot;&gt;&lt;a href=&quot;#Spring事件概述&quot; class=&quot;headerlink&quot; title=&quot;Spring事件概述&quot;&gt;&lt;/a&gt;Spring事件概述&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;每一个Spring事件都需要继承ApplicationEvent的类，ApplicationEvent又继承自java.util.EventObject&lt;/li&gt;
&lt;li&gt;Spring中的任何bean都能够通过实现ApplicationListener&lt;T&gt;接口来监听事件；这里的泛型T就是上面提到的继承了ApplicationEvent的类&lt;/T&gt;&lt;/li&gt;
&lt;li&gt;SpringContext会对实现ApplicationListener接口的任意bean进行自动注册&lt;/li&gt;
&lt;li&gt;发布事件是通过ApplicationEventPublisher.publishEvent方法实现的。应用中一般通过ApplicationContext进行事件发布，ApplicationContext实现了ApplicationEventPublisher接口&lt;/li&gt;
&lt;li&gt;另一种发布事件的方式是bean实现ApplicationContextAware接口，拿到ApplicationContext实例从而实现事件发布&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="spring-boot" scheme="http://wuwenliang.net/categories/spring-boot/"/>
    
    
      <category term="spring-boot" scheme="http://wuwenliang.net/tags/spring-boot/"/>
    
  </entry>
  
  <entry>
    <title>跟我学RocektMQ之事务消息提交及回查源码解析</title>
    <link href="http://wuwenliang.net/2019/09/01/%E8%B7%9F%E6%88%91%E5%AD%A6RocektMQ%E4%B9%8B%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF%E6%8F%90%E4%BA%A4%E5%8F%8A%E5%9B%9E%E6%9F%A5%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"/>
    <id>http://wuwenliang.net/2019/09/01/跟我学RocektMQ之事务消息提交及回查源码解析/</id>
    <published>2019-09-01T03:11:36.000Z</published>
    <updated>2019-09-01T07:10:09.144Z</updated>
    
    <content type="html"><![CDATA[<p>本文进入了事务消息源码解析的最后部分，该部分是RocketMQ二阶段事务的第二阶段，即：提交/回滚事务以及事务回查。</p>
<h2 id="消息提交-回滚-客户端逻辑-：endTransaction"><a href="#消息提交-回滚-客户端逻辑-：endTransaction" class="headerlink" title="消息提交/回滚[客户端逻辑]：endTransaction"></a>消息提交/回滚[客户端逻辑]：endTransaction</h2><p>在事务消息源码解析的第一篇末尾，我们分析了DefaultMQProducerImpl.endTransaction的逻辑：</p>
<a id="more"></a>
<pre><code>[DefaultMQProducerImpl.endTransaction]
......
String transactionId = sendResult.getTransactionId();
// 获取broker地址
final String brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(sendResult.getMessageQueue().getBrokerName());
EndTransactionRequestHeader requestHeader = new EndTransactionRequestHeader();
requestHeader.setTransactionId(transactionId);
requestHeader.setCommitLogOffset(id.getOffset());
switch (localTransactionState) {
    case COMMIT_MESSAGE:
        requestHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_COMMIT_TYPE);
        break;
    case ROLLBACK_MESSAGE:
        requestHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_ROLLBACK_TYPE);
        break;
    case UNKNOW:
        requestHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_NOT_TYPE);
        break;
    default:
        break;
}
// 设置生产者组
requestHeader.setProducerGroup(this.defaultMQProducer.getProducerGroup());
// 设置队列offset
requestHeader.setTranStateTableOffset(sendResult.getQueueOffset());
// 设置消息id
requestHeader.setMsgId(sendResult.getMsgId());

String remark = localException != null ? 
        (&quot;executeLocalTransactionBranch exception: &quot; + localException.toString())
        : null;
// 发送事务结束请求
this.mQClientFactory.getMQClientAPIImpl().endTransactionOneway(brokerAddr, requestHeader, remark,
        this.defaultMQProducer.getSendMsgTimeout());
</code></pre><p>代码的主要逻辑概括如下：</p>
<ol>
<li>根据消息丛书的消息队列获取broker的ip及端口信息</li>
<li>构造事务结束请求头，设置事务id以及commit的offset</li>
<li>根据本地事务实际的执行状况，为事务结束请求头设置 <strong>提交/回滚/什么都不做</strong> 标记</li>
<li>通过当前客户端持有的MQClientInstance发送事务结束请求到broker</li>
</ol>
<h2 id="消息提交-回滚-服务端逻辑-：EndTransactionProcessor-processRequest"><a href="#消息提交-回滚-服务端逻辑-：EndTransactionProcessor-processRequest" class="headerlink" title="消息提交/回滚[服务端逻辑]：EndTransactionProcessor.processRequest"></a>消息提交/回滚[服务端逻辑]：EndTransactionProcessor.processRequest</h2><p>broker在启动时会加载EndTransactionProcessor，处理客户端发送的事务结束请求；调用链如下：</p>
<pre><code>BrokerStartup.main(String[] args)
    |-BrokerStartup.start(BrokerController controller)
    |-BrokerStartup.createBrokerController(String[] args) 返回BrokerController
        |-BrokerController.initialize()
            |-BrokerController.registerProcessor()
                |-RemotingServer.registerProcessor(
                        final int requestCode,                   (RequestCode.END_TRANSACTION,)
                        final NettyRequestProcessor processor,   (new EndTransactionProcessor(this))
                        final ExecutorService executor);         (this.endTransactionExecutor)
</code></pre><p>EndTransactionProcessor的核心逻辑如下：</p>
<pre><code>[EndTransactionProcessor.processRequest]
OperationResult result = new OperationResult();
// 如果MessageSysFlag为事务提交类型
if (MessageSysFlag.TRANSACTION_COMMIT_TYPE == requestHeader.getCommitOrRollback()) {
    // 执行消息提交
    result = this.brokerController.getTransactionalMessageService().commitMessage(requestHeader);
    if (result.getResponseCode() == ResponseCode.SUCCESS) {
        RemotingCommand res = checkPrepareMessage(result.getPrepareMessage(), requestHeader);
        if (res.getCode() == ResponseCode.SUCCESS) {
            // 结束消息事务
            MessageExtBrokerInner msgInner = endMessageTransaction(result.getPrepareMessage());
            msgInner.setSysFlag(MessageSysFlag.resetTransactionValue(msgInner.getSysFlag(), requestHeader.getCommitOrRollback()));
            msgInner.setQueueOffset(requestHeader.getTranStateTableOffset());
            msgInner.setPreparedTransactionOffset(requestHeader.getCommitLogOffset());
            msgInner.setStoreTimestamp(result.getPrepareMessage().getStoreTimestamp());
            RemotingCommand sendResult = sendFinalMessage(msgInner);
            // 删除半消息
            if (sendResult.getCode() == ResponseCode.SUCCESS) {
                this.brokerController.getTransactionalMessageService().deletePrepareMessage(result.getPrepareMessage());
            }
            return sendResult;
        }
        return res;
    }
} 
// 如果MessageSysFlag为事务回滚类型
else if (MessageSysFlag.TRANSACTION_ROLLBACK_TYPE == requestHeader.getCommitOrRollback()) {
    // 执行消息回滚
    result = this.brokerController.getTransactionalMessageService().rollbackMessage(requestHeader);
    if (result.getResponseCode() == ResponseCode.SUCCESS) {
        RemotingCommand res = checkPrepareMessage(result.getPrepareMessage(), requestHeader);
        if (res.getCode() == ResponseCode.SUCCESS) {
            // 删除半消息
            this.brokerController.getTransactionalMessageService().deletePrepareMessage(result.getPrepareMessage());
        }
        return res;
    }
}
// 组装返回体
response.setCode(result.getResponseCode());
response.setRemark(result.getResponseRemark());
return response;
</code></pre><p>总结一下EndTransactionProcessor逻辑：</p>
<ol>
<li>判断MessageSysFlag，如果MessageSysFlag为事务提交类型，则执行事务提交操作<ol>
<li>执行TransactionalMessageService.commitMessage进行半消息提交操作</li>
<li>执行endMessageTransaction，恢复消息原主题，原队列，恢复原消息</li>
<li>重新对消息进行持久化，存储到commitLog中，执行sendFinalMessage将原消息转发至实际的消息消费队列中，以便消费者进行消费</li>
<li>执行deletePrepareMessage方法删除prepare消息，内部实现为将prepare消息转储到RMQ_SYS_TRANS_OP_HALF TOPIC 主题中；标识该消息已被处理，为事务回查提供依据</li>
</ol>
</li>
<li>如果MessageSysFlag为事务回滚类型，则执行事务回滚操作<ol>
<li>执行TransactionalMessageService.rollbackMessage进行半消息回滚操作</li>
<li>通过deletePrepareMessage将prepare半消息进行删除，实现方式与事务提交相同，将prepare消息转储到RMQ_SYS_TRANS_OP_HALF TOPIC 主题中，标识该消息已被处理。</li>
</ol>
</li>
</ol>
<p>我们具体分析一下这个过程中涉及到的子流程：</p>
<h3 id="prepare消息提交：commitMessage"><a href="#prepare消息提交：commitMessage" class="headerlink" title="prepare消息提交：commitMessage"></a>prepare消息提交：commitMessage</h3><blockquote>
<p>首先是commitMessage，执行事务提交操作</p>
</blockquote>
<pre><code>[TransactionalMessageServiceImpl.commitMessage]
@Override
public OperationResult commitMessage(EndTransactionRequestHeader requestHeader) {
    return getHalfMessageByOffset(requestHeader.getCommitLogOffset());
}

private OperationResult getHalfMessageByOffset(long commitLogOffset) {
    OperationResult response = new OperationResult();
    // 根据消息的物理偏移commitLogOffset获取消息MessageExt
    MessageExt messageExt = this.transactionalMessageBridge.lookMessageByOffset(commitLogOffset);
    // 将消息设置到OperationResult返回体中
    if (messageExt != null) {
        response.setPrepareMessage(messageExt);
        response.setResponseCode(ResponseCode.SUCCESS);
    } 
    ...省略messageExt为空的逻辑...
    return response;
}
</code></pre><blockquote>
<p>endMessageTransaction，恢复消息原主题，原队列，恢复原消息</p>
</blockquote>
<pre><code>[EndTransactionProcessor.endMessageTransaction()]
private MessageExtBrokerInner endMessageTransaction(MessageExt msgExt) {
    // 初始化新的消息实体MessageExtBrokerInner
    MessageExtBrokerInner msgInner = new MessageExtBrokerInner();
    // 从属性中恢复消息的原topic
    msgInner.setTopic(msgExt.getUserProperty(MessageConst.PROPERTY_REAL_TOPIC));
    // 从属性中恢复消息的原队列id
    msgInner.setQueueId(Integer.parseInt(msgExt.getUserProperty(MessageConst.PROPERTY_REAL_QUEUE_ID)));
    // 复制消息体，消息属性
    msgInner.setBody(msgExt.getBody());
    msgInner.setFlag(msgExt.getFlag());
    msgInner.setBornTimestamp(msgExt.getBornTimestamp());
    msgInner.setBornHost(msgExt.getBornHost());
    msgInner.setStoreHost(msgExt.getStoreHost());
    msgInner.setReconsumeTimes(msgExt.getReconsumeTimes());
    msgInner.setWaitStoreMsgOK(false);
    msgInner.setTransactionId(msgExt.getUserProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX));
    msgInner.setSysFlag(msgExt.getSysFlag());
    TopicFilterType topicFilterType =
        (msgInner.getSysFlag() &amp; MessageSysFlag.MULTI_TAGS_FLAG) == MessageSysFlag.MULTI_TAGS_FLAG ? TopicFilterType.MULTI_TAG
            : TopicFilterType.SINGLE_TAG;
    long tagsCodeValue = MessageExtBrokerInner.tagsString2tagsCode(topicFilterType, msgInner.getTags());
    msgInner.setTagsCode(tagsCodeValue);
    MessageAccessor.setProperties(msgInner, msgExt.getProperties());
    msgInner.setPropertiesString(MessageDecoder.messageProperties2String(msgExt.getProperties()));
    MessageAccessor.clearProperty(msgInner, MessageConst.PROPERTY_REAL_TOPIC);
    MessageAccessor.clearProperty(msgInner, MessageConst.PROPERTY_REAL_QUEUE_ID);
    return msgInner;
}
</code></pre><blockquote>
<p>sendFinalMessage，将原消息转发至实际的消息消费队列中，以便消费者进行消费</p>
</blockquote>
<pre><code>[EndTransactionProcessor.sendFinalMessage]
final PutMessageResult putMessageResult =
        this.brokerController.getMessageStore().putMessage(msgInner);
...省略后续校验逻辑...
</code></pre><p>最终通过DefaultMessageStore.putMessage将恢复后的原消息再次持久化到commitLog中。</p>
<blockquote>
<p>deletePrepareMessage，删除prepare消息，非物理删除</p>
</blockquote>
<pre><code>[TransactionalMessageServiceImpl.deletePrepareMessage]
@Override
public boolean deletePrepareMessage(MessageExt msgExt) {
    if (this.transactionalMessageBridge.putOpMessage(msgExt, TransactionalMessageUtil.REMOVETAG)) {
        log.info(&quot;Transaction op message write successfully. messageId={}, queueId={} msgExt:{}&quot;, 
        msgExt.getMsgId(), msgExt.getQueueId(), msgExt);
        return true;
    } else {
        log.error(&quot;Transaction op message write failed. messageId is {}, queueId is {}&quot;, 
        msgExt.getMsgId(), msgExt.getQueueId());
        return false;
    }
}
</code></pre><p>可以看到是通过transactionalMessageBridge.putOpMessage实现的逻辑删除</p>
<pre><code>[TransactionalMessageBridge.putOpMessage]
public boolean putOpMessage(MessageExt messageExt, String opType) {
    MessageQueue messageQueue = new MessageQueue(messageExt.getTopic(),
        this.brokerController.getBrokerConfig().getBrokerName(), messageExt.getQueueId());
    if (TransactionalMessageUtil.REMOVETAG.equals(opType)) {
        // 将该prepare消息存储到RMQ_SYS_TRANS_OP_HALF TOPIC 主题中
        return addRemoveTagInTransactionOp(messageExt, messageQueue);
    }
    return true;
}
</code></pre><p>通过addRemoveTagInTransactionOp将prepare消息存储到RMQ_SYS_TRANS_OP_HALF TOPIC 主题</p>
<pre><code>[TransactionalMessageBridge.addRemoveTagInTransactionOp]
private boolean addRemoveTagInTransactionOp(MessageExt messageExt, MessageQueue messageQueue) {
    Message message = new Message(
        TransactionalMessageUtil.buildOpTopic(), 
        TransactionalMessageUtil.REMOVETAG,
        String.valueOf(messageExt.getQueueOffset()).getBytes(TransactionalMessageUtil.charset));
    writeOp(message, messageQueue);
    return true;
}
</code></pre><p>可以看到最终是通过writeOp实现的消息转储</p>
<pre><code>private void writeOp(Message message, MessageQueue mq) {
    MessageQueue opQueue;
    ...省略opQueue校验过程...
    if (opQueue == null) {
        opQueue = new MessageQueue(TransactionalMessageUtil.buildOpTopic(), mq.getBrokerName(), mq.getQueueId());
    }
    putMessage(makeOpMessageInner(message, opQueue));
}
</code></pre><p>通过putMessage将prepare消息持久化到commiLog。topic为RMQ_SYS_TRANS_OP_HALF_TOPIC；我们看一下topic的创建方法TransactionalMessageUtil.buildOpTopic()</p>
<pre><code>[TransactionalMessageUtil.buildOpTopic]
public static String buildOpTopic() {
    return MixAll.RMQ_SYS_TRANS_OP_HALF_TOPIC;
}
</code></pre><p>这里的写法可以参考，即通过一个静态方法将常量进行封装。到此我们对prepare消息提交的分析就告一段落。</p>
<p>最终半消息的删除已依靠文件删除机制实现的。</p>
<h3 id="prepare消息回滚：rollbackMessage"><a href="#prepare消息回滚：rollbackMessage" class="headerlink" title="prepare消息回滚：rollbackMessage"></a>prepare消息回滚：rollbackMessage</h3><p>接着看一下prepare消息的回滚逻辑。</p>
<blockquote>
<p>首先执行TransactionalMessageService.rollbackMessage进行半消息回滚操作</p>
</blockquote>
<pre><code>[TransactionalMessageServiceImpl.rollbackMessage]
@Override
public OperationResult rollbackMessage(EndTransactionRequestHeader requestHeader) {
    return getHalfMessageByOffset(requestHeader.getCommitLogOffset());
}
</code></pre><p>这里的逻辑同commitMessage相同，同样是根据消息的物理偏移commitLogOffset获取消息MessageExt；获取到消息之后执行deletePrepareMessage将prepare消息删除。实现方式与事务提交相同，这部分代码上文已经分析过就不再重复。</p>
<h2 id="事务消息回查逻辑"><a href="#事务消息回查逻辑" class="headerlink" title="事务消息回查逻辑"></a>事务消息回查逻辑</h2><p>我们最后分析一下二阶段中重要的一个流程，事务回查的实现。</p>
<h3 id="事务回查service初始化"><a href="#事务回查service初始化" class="headerlink" title="事务回查service初始化"></a>事务回查service初始化</h3><p>事务回查实现是通过线程TransactionalMessageCheckService实现的，它的初始化调用链如下：</p>
<pre><code>BrokerStartup.main(String[] args)
    |-BrokerStartup.start(BrokerController controller)
    |-BrokerStartup.createBrokerController(String[] args) 返回BrokerController
        |-BrokerController.initialize()
            |-BrokerController.initialTransaction();
                |-this.transactionalMessageCheckService = new TransactionalMessageCheckService(this);
</code></pre><p>RocketMQ的broker关键的异步逻辑基本上都是通过该调用链实现的，包括但不限于上文中提到的事务提交/回滚处理器EndTransactionProcessor的注册过程。</p>
<p>在broker启动完成之后事务回查线程TransactionalMessageCheckService也随之加载完毕。</p>
<h3 id="事务回查逻辑"><a href="#事务回查逻辑" class="headerlink" title="事务回查逻辑"></a>事务回查逻辑</h3><p>我们查看一下回查线程TransactionalMessageCheckService的run方法，核心的回查逻辑就在该方法中</p>
<pre><code>[TransactionalMessageCheckService.java]
@Override
public void run() {
    log.info(&quot;Start transaction check service thread!&quot;);
    long checkInterval = brokerController.getBrokerConfig().getTransactionCheckInterval();
    while (!this.isStopped()) {
        this.waitForRunning(checkInterval);
    }
    log.info(&quot;End transaction check service thread!&quot;);
}
</code></pre><p>checkInterval为回查任务的间隔时间，默认为60秒，</p>
<pre><code>[BrokerConfig.java]
@ImportantField
private long transactionCheckInterval = 60 * 1000;
</code></pre><p>checkInterval的值可通过在broker.conf文件中配置transactionChecklnterval来改变，单位为毫秒。</p>
<p>我们继续进入 waitForRunning方法中</p>
<pre><code>[TransactionalMessageCheckService.java]
protected void waitForRunning(long interval) {
    if (hasNotified.compareAndSet(true, false)) {
        this.onWaitEnd();
        return;
    }
    ......
}
</code></pre><p>进入onWaitEnd方法中；TransactionalMessageCheckService重写了父类ServiceThread的onWaitEnd方法，我们分析一下具体逻辑</p>
<pre><code>[TransactionalMessageCheckService.java]
@Override
protected void onWaitEnd() {
    // TransactionTimeOut默认值为5秒
    long timeout = brokerController.getBrokerConfig().getTransactionTimeOut();
    // 回查最大次数为15次；
    // 如果超过最大检测次数还是无法获得事务状态，RocketMQ将直接丢弃该消息即相当于回滚事务。
    int checkMax = brokerController.getBrokerConfig().getTransactionCheckMax();
    long begin = System.currentTimeMillis();
    log.info(&quot;Begin to check prepare message, begin time:{}&quot;, begin);
    // 回查逻辑
    this.brokerController.getTransactionalMessageService().check(timeout, checkMax, this.brokerController.getTransactionalMessageCheckListener());
    log.info(&quot;End to check prepare message, consumed time:{}&quot;, System.currentTimeMillis() - begin);
}
</code></pre><p>这里我们可以得出，事务回查操作周期默认为60s一次，每次执行的超时时间为5秒；最大回查次数为15次，超过最大回查次数则丢弃消息，相当有对事务进行了回滚。</p>
<h4 id="回查逻辑TransactionalMessageService-check"><a href="#回查逻辑TransactionalMessageService-check" class="headerlink" title="回查逻辑TransactionalMessageService.check"></a>回查逻辑TransactionalMessageService.check</h4><pre><code>[TransactionalMessageServiceImpl.check]
String topic = MixAll.RMQ_SYS_TRANS_HALF_TOPIC;
Set&lt;MessageQueue&gt; msgQueues = transactionalMessageBridge.fetchMessageQueues(topic);
if (msgQueues == null || msgQueues.size() == 0) {
    log.warn(&quot;The queue of topic is empty :&quot; + topic);
    return;
}
</code></pre><p>上述逻辑首先获取了RMQ_SYS_TRANS_HALF_TOPIC半消息中的所有队列。</p>
<pre><code>......
// 迭代队列
for (MessageQueue messageQueue : msgQueues) {
    long startTime = System.currentTimeMillis();
    MessageQueue opQueue = getOpQueue(messageQueue);
    // 获取半消息队列的消费偏移量
    long halfOffset = transactionalMessageBridge.fetchConsumeOffset(messageQueue);
    // 获取op队列已经删除消费队列的偏移量
    long opOffset = transactionalMessageBridge.fetchConsumeOffset(opQueue);
    log.info(&quot;Before check, the queue={} msgOffset={} opOffset={}&quot;, messageQueue, halfOffset, opOffset);
    if (halfOffset &lt; 0 || opOffset &lt; 0) {
        log.error(&quot;MessageQueue: {} illegal offset read: {}, op offset: {},skip this queue&quot;, messageQueue,
            halfOffset, opOffset);
        continue;
    }

    List&lt;Long&gt; doneOpOffset = new ArrayList&lt;&gt;();
    HashMap&lt;Long, Long&gt; removeMap = new HashMap&lt;&gt;();

    // 确认消息是否删除
    PullResult pullResult = fillOpRemoveMap(removeMap, opQueue, opOffset, halfOffset, doneOpOffset);
    if (null == pullResult) {
        log.error(&quot;The queue={} check msgOffset={} with opOffset={} failed, pullResult is null&quot;,
            messageQueue, halfOffset, opOffset);
        continue;
    }
</code></pre><p>根据方法fillOpRemoveMap确认半消息是否已经被删除，具体逻辑如下：</p>
<pre><code>[TransactionalMessageServiceImpl.fillOpRemoveMap]
......
List&lt;MessageExt&gt; opMsg = pullResult.getMsgFoundList();
if (opMsg == null) {
    log.warn(&quot;The miss op offset={} in queue={} is empty, pullResult={}&quot;, pullOffsetOfOp, opQueue, pullResult);
    return pullResult;
}
for (MessageExt opMessageExt : opMsg) {
    Long queueOffset = getLong(new String(opMessageExt.getBody(), TransactionalMessageUtil.charset));
    if (TransactionalMessageUtil.REMOVETAG.equals(opMessageExt.getTags())) {
        if (queueOffset &lt; miniOffset) {
            doneOpOffset.add(opMessageExt.getQueueOffset());
        } else {
            removeMap.put(queueOffset, opMessageExt.getQueueOffset());
        }
    } else {
        log.error(&quot;Found a illegal tag in opMessageExt= {} &quot;, opMessageExt);
    }
}
return pullResult;
</code></pre><p>比较半消息消费队列中的最大偏移量miniOffset 与 删除消费队列的消息偏移量queueOffset；</p>
<p>如果queueOffset &gt;= miniOffset,说明半消息已经删除过了，但是半消息还没有更新，将半消息存放在removeMap中。</p>
<blockquote>
<p>我们继续回到check方法中</p>
</blockquote>
<pre><code>while (true) {
        ......
    // 如果半消息已经被处理过，偏移量继续递增，往后处理
    if (removeMap.containsKey(i)) {
        log.info(&quot;Half offset {} has been committed/rolled back&quot;, i);
        removeMap.remove(i);
    } else {
        // 查找半消息
        GetResult getResult = getHalfMsg(messageQueue, i);
        MessageExt msgExt = getResult.getMsg();
        ...省略半消息不存在处理逻辑...
        // 如果超过存储时间needSkip（默认3天）或者 超过回查次数needDiscard（默认15次）
        // 继续往后执行
        if (needDiscard(msgExt, transactionCheckMax) || needSkip(msgExt)) {
            listener.resolveDiscardMsg(msgExt);
            newOffset = i + 1;
            i++;
            continue;
        }
        // 消息存储时间大于开始时间的不处理
        if (msgExt.getStoreTimestamp() &gt;= startTime) {
            log.debug(&quot;Fresh stored. the miss offset={}, check it later, store={}&quot;, i,
                new Date(msgExt.getStoreTimestamp()));
            break;
        }

        long valueOfCurrentMinusBorn = System.currentTimeMillis() - msgExt.getBornTimestamp();
        long checkImmunityTime = transactionTimeout;
        String checkImmunityTimeStr = msgExt.getUserProperty(MessageConst.PROPERTY_CHECK_IMMUNITY_TIME_IN_SECONDS);
        if (null != checkImmunityTimeStr) {
            checkImmunityTime = getImmunityTime(checkImmunityTimeStr, transactionTimeout);
            // 如果存储时间小于需要进行回查的时间，跳过继续下一个
            if (valueOfCurrentMinusBorn &lt; checkImmunityTime) {
                if (checkPrepareQueueOffset(removeMap, doneOpOffset, msgExt)) {
                    newOffset = i + 1;
                    i++;
                    continue;
                }
            }
        } 
</code></pre><p>这段代码的逻辑总结如下：</p>
<ol>
<li>判断removeMap中包含该消息，表明消息已经被处理过，只是半消息队列未更新；跳过这个消息不进行处理</li>
<li>如果消息回查次数大于15次或者消息已经超过了存储时间则不对消息进行处理</li>
<li><p>消息存储时间大于目前的回查程序开始时间的暂时不处理，等待后续进行回查</p>
<pre><code>        List&lt;MessageExt&gt; opMsg = pullResult.getMsgFoundList();
        boolean isNeedCheck = (opMsg == null &amp;&amp; valueOfCurrentMinusBorn &gt; checkImmunityTime)
            || (opMsg != null &amp;&amp; (opMsg.get(opMsg.size() - 1).getBornTimestamp() - startTime &gt; transactionTimeout))
            || (valueOfCurrentMinusBorn &lt;= -1);

        if (isNeedCheck) {
            // 将半消息重新存储在topic--RMQ_SYS_TRANS_HALF_TOPIC中
            if (!putBackHalfMsgQueue(msgExt, i)) {
                continue;
            }
            // 发给客户端选择一个producerGroup进行回查
            listener.resolveHalfMsg(msgExt);
        } else {
            pullResult = fillOpRemoveMap(removeMap, opQueue, pullResult.getNextBeginOffset(), halfOffset, doneOpOffset);
            log.info(&quot;The miss offset:{} in messageQueue:{} need to get more opMsg, result is:{}&quot;, i,
                messageQueue, pullResult);
            continue;
        }
    }
    newOffset = i + 1;
    i++;
}
// 保存op消费进度
if (newOffset != halfOffset) {
    transactionalMessageBridge.updateConsumeOffset(messageQueue, newOffset);
}
</code></pre></li>
</ol>
<p>这段逻辑对本次回查未能获取结果的消息重新存储到RMQ_SYS_TRANS_HALF_TOPIC中，等待下次回查的执行；否则发给客户端进行回查，最终保存已处理消息与半消息的消费进度。</p>
<h4 id="客户端进行事务回查"><a href="#客户端进行事务回查" class="headerlink" title="客户端进行事务回查"></a>客户端进行事务回查</h4><p>客户端ClientRemotingProcessor通过checkTransactionState方法响应事务回查请求</p>
<pre><code>[ClientRemotingProcessor.java]
public RemotingCommand checkTransactionState(ChannelHandlerContext ctx,
    RemotingCommand request) throws RemotingCommandException {

    // 请求头解码
    final CheckTransactionStateRequestHeader requestHeader =
        (CheckTransactionStateRequestHeader) request.decodeCommandCustomHeader(CheckTransactionStateRequestHeader.class);
    final ByteBuffer byteBuffer = ByteBuffer.wrap(request.getBody());
    final MessageExt messageExt = MessageDecoder.decode(byteBuffer);
    if (messageExt != null) {
        if (StringUtils.isNotEmpty(this.mqClientFactory.getClientConfig().getNamespace())) {
            messageExt.setTopic(NamespaceUtil
                .withoutNamespace(messageExt.getTopic(), this.mqClientFactory.getClientConfig().getNamespace()));
        }
        String transactionId = messageExt.getProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX);
        if (null != transactionId &amp;&amp; !&quot;&quot;.equals(transactionId)) {
            messageExt.setTransactionId(transactionId);
        }
        final String group = messageExt.getProperty(MessageConst.PROPERTY_PRODUCER_GROUP);
        if (group != null) {
            // 选择一个事务消息生产者实例
            MQProducerInner producer = this.mqClientFactory.selectProducer(group);
            if (producer != null) {
                final String addr = RemotingHelper.parseChannelRemoteAddr(ctx.channel());
                // 执行事务回查
                producer.checkTransactionState(addr, messageExt, requestHeader);
            } else {
                log.debug(&quot;checkTransactionState, pick producer by group[{}] failed&quot;, group);
            }
        ...省略异常日志打印...
    return null;
}
</code></pre><p>客户单选择一个生产者实例发起真正的事务回查操作，通过producer.checkTransactionState(addr, messageExt, requestHeader)执行回查</p>
<p>回查是在客户端中起线程异步执行的，通过异步回调客户端TransactionListener的checkLocalTransactionState方法实现。</p>
<pre><code>// 构造一个回查任务
Runnable request = new Runnable() {
    private final String brokerAddr = addr;
    private final MessageExt message = msg;
    private final CheckTransactionStateRequestHeader checkRequestHeader = header;
    private final String group = DefaultMQProducerImpl.this.defaultMQProducer.getProducerGroup();

    @Override
    public void run() {
</code></pre><blockquote>
<p>首先获取客户端设置的事务监听器</p>
</blockquote>
<pre><code>TransactionCheckListener transactionCheckListener = DefaultMQProducerImpl.this.checkListener();
TransactionListener transactionListener = getCheckListener();
if (transactionCheckListener != null || transactionListener != null) {
    LocalTransactionState localTransactionState = LocalTransactionState.UNKNOW;
    Throwable exception = null;
    try {
        if (transactionCheckListener != null) {
</code></pre><blockquote>
<p>通过transactionCheckListener.checkLocalTransactionState(message);执行回查操作</p>
</blockquote>
<pre><code>        localTransactionState = transactionCheckListener.checkLocalTransactionState(message);
    } else if (transactionListener != null) {
        log.debug(&quot;Used new check API in transaction message&quot;);
        localTransactionState = transactionListener.checkLocalTransaction(message);
    } else {
        log.warn(&quot;CheckTransactionState, pick transactionListener by group[{}] failed&quot;, group);
    }
} catch (Throwable e) {
    log.error(&quot;Broker call checkTransactionState, but checkLocalTransactionState exception&quot;, e);
    exception = e;
}
</code></pre><blockquote>
<p>将回查得到的本地事务执行结果发送给broker，以便broker对半消息进行回滚/提交等操作</p>
</blockquote>
<pre><code>        this.processTransactionState(
            localTransactionState,
            group,
            exception);
    } else {
        log.warn(&quot;CheckTransactionState, pick transactionCheckListener by group[{}] failed&quot;, group);
    }
}
</code></pre><p>通过processTransactionState方法将事务回查的结果提交给broker</p>
<pre><code>private void processTransactionState(
    // 本地事务执行状态
    final LocalTransactionState localTransactionState,
    final String producerGroup,
    final Throwable exception) {

    final EndTransactionRequestHeader thisHeader = new EndTransactionRequestHeader();
    thisHeader.setCommitLogOffset(checkRequestHeader.getCommitLogOffset());
    thisHeader.setProducerGroup(producerGroup);
    thisHeader.setTranStateTableOffset(checkRequestHeader.getTranStateTableOffset());
    thisHeader.setFromTransactionCheck(true);

    String uniqueKey = message.getProperties().get(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX);
    if (uniqueKey == null) {
        uniqueKey = message.getMsgId();
    }
    thisHeader.setMsgId(uniqueKey);
    thisHeader.setTransactionId(checkRequestHeader.getTransactionId());
</code></pre><p>构造事务结束请求实体EndTransactionRequestHeader，根据回查得到的本地事务执行结果，设置具体的消息执行状态MessageSysFlag。这里与半消息发送阶段对本地事务的处理是一致的。</p>
<pre><code>switch (localTransactionState) {
    case COMMIT_MESSAGE:
        thisHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_COMMIT_TYPE);
        break;
    case ROLLBACK_MESSAGE:
        thisHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_ROLLBACK_TYPE);
        log.warn(&quot;when broker check, client rollback this transaction, {}&quot;, thisHeader);
        break;
    case UNKNOW:
        thisHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_NOT_TYPE);
        log.warn(&quot;when broker check, client does not know this transaction state, {}&quot;, thisHeader);
        break;
    default:
        break;
}

String remark = null;
if (exception != null) {
    remark = &quot;checkLocalTransactionState Exception: &quot; + RemotingHelper.exceptionSimpleDesc(exception);
}

try {
</code></pre><blockquote>
<p>通过endTransactionOneway将事务回查状态发送给broker，具体的逻辑与本文开头一致。</p>
</blockquote>
<pre><code>            DefaultMQProducerImpl.this.mQClientFactory.getMQClientAPIImpl().endTransactionOneway(brokerAddr, thisHeader, remark,
                3000);
        } catch (Exception e) {
            log.error(&quot;endTransactionOneway exception&quot;, e);
        }
    }
};
</code></pre><blockquote>
<p>实际上回查的请求就是通过客户端设置的回查线程池提交的，这句代码可见端倪。</p>
</blockquote>
<pre><code>// 提交回查请求到事务回查线程池
this.checkExecutor.submit(request);
</code></pre><p>可以看到，回查任务最终提交到了TransactionMQProducer的事务回查线程池中执行，最终调用了应用程序实现的<br>TransactionListener 的checkLoca!Transaction 方法，根据执行结果返回真实的事务状态。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>我们最后再总结一下RocketMQ事务消息的实现思想：</p>
<blockquote>
<p>RocketMQ的事务消息是基于两阶段提交思想，并配合事务状态回查机制实现的。</p>
</blockquote>
<p>两阶段提交部分：首先发送prepare半消息，根据本地事务执行的提交或者回滚发送半消息commit/rollback命令给broker；</p>
<p>broker端通过定时任务，默认以1分钟为回查频率，对Prepare消息存储队列（topic=RMQ__SYS_TRANS _HALF_TOPIC）及半消息处理队列（topic=RMQ_SYS_TRANS_OP_HALF_TOPIC存储已经提交或者回滚的消息）中的消息进行比较，对需要进行回查的prepare消息发送给客户端进行回查；根据回查结果最终决定对半消息进行commit/rollback操作。</p>
<p>到此事务消息的提交/回滚及回查的解析就告一段落，事务消息部分的源码解析就到此结束。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文进入了事务消息源码解析的最后部分，该部分是RocketMQ二阶段事务的第二阶段，即：提交/回滚事务以及事务回查。&lt;/p&gt;
&lt;h2 id=&quot;消息提交-回滚-客户端逻辑-：endTransaction&quot;&gt;&lt;a href=&quot;#消息提交-回滚-客户端逻辑-：endTransaction&quot; class=&quot;headerlink&quot; title=&quot;消息提交/回滚[客户端逻辑]：endTransaction&quot;&gt;&lt;/a&gt;消息提交/回滚[客户端逻辑]：endTransaction&lt;/h2&gt;&lt;p&gt;在事务消息源码解析的第一篇末尾，我们分析了DefaultMQProducerImpl.endTransaction的逻辑：&lt;/p&gt;
    
    </summary>
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/categories/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/tags/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
  </entry>
  
  <entry>
    <title>跟我学RocketMQ之事务消息存储源码解析</title>
    <link href="http://wuwenliang.net/2019/08/31/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ%E4%B9%8B%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"/>
    <id>http://wuwenliang.net/2019/08/31/跟我学RocketMQ之事务消息存储源码解析/</id>
    <published>2019-08-31T12:13:24.000Z</published>
    <updated>2019-08-31T13:04:01.069Z</updated>
    
    <content type="html"><![CDATA[<p>我们接着对RocketMQ的事务消息的存储阶段源码进行解析。</p>
<h2 id="事务消息正式发送阶段"><a href="#事务消息正式发送阶段" class="headerlink" title="事务消息正式发送阶段"></a>事务消息正式发送阶段</h2><p>首先接着上文，介绍一下事务消息正式发送阶段。</p>
<p>在DefaultMQProducerlmpl.sendKernelImpl方法中设置消息类型为事务消息：</p>
<pre><code>final String tranMsg = msg.getProperty(MessageConst.PROPERTY_TRANSACTION_PREPARED);
if (tranMsg != null &amp;&amp; Boolean.parseBoolean(tranMsg)) {
    sysFlag |= MessageSysFlag.TRANSACTION_PREPARED_TYPE;
}
</code></pre><p>如果消息类型的确是事务消息，则设置sysFlag为事务消息标识== 0x1 &lt;&lt; 2。方便broker对消息进行识别。</p>
<a id="more"></a>
<h3 id="broker存储事务消息"><a href="#broker存储事务消息" class="headerlink" title="broker存储事务消息"></a>broker存储事务消息</h3><p>broker端收到消息后，对消息进行处理，如果消息类型为事务半消息 （prepare消息）则执行半消息存储方法prepareMessage，否则按照普通消息进行处理（普通消息存储执行putMessage方法）。</p>
<p>具体逻辑如下：</p>
<pre><code>[SendMessagePocessor.sendMessage]
// 解码消息发送请求头中属性为Map
Map&lt;String, String&gt; oriProps = MessageDecoder
    .string2messageProperties(requestHeader.getProperties());
// 获取属性PROPERTY_TRANSACTION_PREPARED（TRAN_MSG）的值，这个属性在客户端进行事务消息发送时设置
String traFlag = oriProps.get(MessageConst.PROPERTY_TRANSACTION_PREPARED);
// 如果traFlag不为空且true，说明是事务消息

if (traFlag != null &amp;&amp; Boolean.parseBoolean(traFlag)) {
    // 如果broker不允许接受事务消息则响应“broker拒绝接受事务消息”，默认为允许接受
    if (this.brokerController.getBrokerConfig().isRejectTransactionMessage()) {
        response.setCode(ResponseCode.NO_PERMISSION);
        response.setRemark(
            &quot;the broker[&quot; + this.brokerController.getBrokerConfig().getBrokerIP1()
                + &quot;] sending transaction message is forbidden&quot;);
        return response;
    }
    // 执行事务消息存储
    putMessageResult = this.brokerController.getTransactionalMessageService().prepareMessage(msgInner);
} else {
    // 执行普通消息存储
    putMessageResult = this.brokerController.getMessageStore().putMessage(msgInner);
}   
</code></pre><p>总结一下：</p>
<ol>
<li>对请求头requestHeader的属性值解码为Map，读取其中的事务消息属性，判断是否为true</li>
<li>如果是事务消息则判断broker是否能够接受事务消息。</li>
</ol>
<blockquote>
<p>broker可以通过配置属性rejectTransactionMessage为true/false来决定是否能够接受事务消息请求，默认为false即允许接受事务消息。</p>
</blockquote>
<h4 id="prepareMessage"><a href="#prepareMessage" class="headerlink" title="prepareMessage"></a>prepareMessage</h4><p>我们进入prepareMessage方法查询具体的事务消息存储逻辑。</p>
<pre><code>[TransactionalMessageServiceImpl.prepareMessage]
@Override
public PutMessageResult prepareMessage(MessageExtBrokerInner messageInner) {
    return transactionalMessageBridge.putHalfMessage(messageInner);
}
</code></pre><p>继续查看transactionalMessageBridge.putHalfMessage(messageInner);</p>
<blockquote>
<p>MessageExtBrokerInner对象为将请求RemotingCommand转换后的broker端对消息的封装实体。</p>
</blockquote>
<pre><code>[TransactionalMessageBridge.putHalfMessage]
public PutMessageResult putHalfMessage(MessageExtBrokerInner messageInner) {
    return store.putMessage(parseHalfMessageInner(messageInner));
}

private MessageExtBrokerInner parseHalfMessageInner(MessageExtBrokerInner msgInner) {
    // 备份消息原主题
    MessageAccessor.putProperty(msgInner, MessageConst.PROPERTY_REAL_TOPIC, msgInner.getTopic());
    // 备份消息原队列id
    MessageAccessor.putProperty(msgInner, MessageConst.PROPERTY_REAL_QUEUE_ID,
        String.valueOf(msgInner.getQueueId()));
    // 重置sysFlag值为
    msgInner.setSysFlag(
        MessageSysFlag.resetTransactionValue(msgInner.getSysFlag(), MessageSysFlag.TRANSACTION_NOT_TYPE));
    // 设置topic为RMQ_SYS_TRANS_HALF_TOPIC = &quot;RMQ_SYS_TRANS_HALF_TOPIC&quot;;
    msgInner.setTopic(TransactionalMessageUtil.buildHalfTopic());
    // 设置队列id为0
    msgInner.setQueueId(0);
    // 转存消息属性Map为字符串形式
    msgInner.setPropertiesString(MessageDecoder.messageProperties2String(msgInner.getProperties()));
    return msgInner;
}
</code></pre><p>这里是RocektMQ对事务消息处理过程的一个巧妙之处。</p>
<p>RocketMQ对事务消息进行了主题更换操作，备份了原先的topic、队列id之后，将事务消息的topic统一更换为 <strong>RMQ_SYS_TRANS_HALF_TOPIC</strong>，队列id统一更换为0。</p>
<p>通过<strong>store.putMessage(parseHalfMessageInner(messageInner));</strong> 对消息进行了存储，这里可以看到，对事务消息进行真正的存储的时候是按照普通消息进行的。但此时topic及队列id已经更换为事务消息的topic及队列id。</p>
<p>通过这个操作，使得事务消息在提交之前不会被消费者消费到。</p>
<p>RocektMQ会通过定时任务起线程去消费该事务topic下的消息，当消息满足提交条件，则将该消息的主题和队列id进行恢复（之前已经备份过），最终会被消息的消费者消费到，这个思路在定时消息的实现上也用到了。</p>
<blockquote>
<p>我们能够发现，事务消息最终落盘其实还是按照普通消息的方式落盘，区别只是对topic和队列id进行了变换，以便该事务消息在提交之前不会被消费者消费到，借此保证消息的提交与回滚与本地事务的提交与回滚是同时成功、同时失败的。</p>
</blockquote>
<p>关于消息的持久化（消息落盘）的具体过程我们在后续的消息存储源码分析中会专门说到，此处就简单的看一下，不进行展开了。</p>
<p>消息持久化是RocketMQ的store模块实现，具体的代码段如下：</p>
<pre><code>[DefaultMessageStore.java]
PutMessageResult result = this.commitLog.putMessage(msg);
</code></pre><p>最终是通过commitLog.putMessage(msg)实现了消息的最终持久化，我们后续会详细分析。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文我们对事务消息如何发送到broker，及broker如何对事务消息进行预处理并落盘的主要过程进行了分析。</p>
<p>事务消息发送的第一阶段就分析完毕了；事务消息系列的下一篇文章，我们将对事务消息的第二阶段：事务消息提交/回滚以及事务消息回查过程进行解析，我们下文见。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我们接着对RocketMQ的事务消息的存储阶段源码进行解析。&lt;/p&gt;
&lt;h2 id=&quot;事务消息正式发送阶段&quot;&gt;&lt;a href=&quot;#事务消息正式发送阶段&quot; class=&quot;headerlink&quot; title=&quot;事务消息正式发送阶段&quot;&gt;&lt;/a&gt;事务消息正式发送阶段&lt;/h2&gt;&lt;p&gt;首先接着上文，介绍一下事务消息正式发送阶段。&lt;/p&gt;
&lt;p&gt;在DefaultMQProducerlmpl.sendKernelImpl方法中设置消息类型为事务消息：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;final String tranMsg = msg.getProperty(MessageConst.PROPERTY_TRANSACTION_PREPARED);
if (tranMsg != null &amp;amp;&amp;amp; Boolean.parseBoolean(tranMsg)) {
    sysFlag |= MessageSysFlag.TRANSACTION_PREPARED_TYPE;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果消息类型的确是事务消息，则设置sysFlag为事务消息标识== 0x1 &amp;lt;&amp;lt; 2。方便broker对消息进行识别。&lt;/p&gt;
    
    </summary>
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/categories/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/tags/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
  </entry>
  
  <entry>
    <title>跟我学RocketMQ之事务消息发送源码解析</title>
    <link href="http://wuwenliang.net/2019/08/30/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ%E4%B9%8B%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"/>
    <id>http://wuwenliang.net/2019/08/30/跟我学RocketMQ之事务消息发送源码解析/</id>
    <published>2019-08-30T03:20:59.000Z</published>
    <updated>2019-08-31T12:42:56.059Z</updated>
    
    <content type="html"><![CDATA[<p>接下来我将通过一个小系列对RocketMQ事务消息进行一次较为全面的源码解析，本文主要对事务消息发送进行重点分析。</p>
<blockquote>
<p>RocketMQ从4.3.0版本重新开源了事务消息，通过基于两阶段提交方式+定时回查机制，为分布式事务问题提供了新的解决方案。</p>
</blockquote>
<a id="more"></a>
<h2 id="事务消息流程概述"><a href="#事务消息流程概述" class="headerlink" title="事务消息流程概述"></a>事务消息流程概述</h2><p>为了便于读者朋友理解，我们先对事务消息的流程进行概述。</p>
<ol>
<li>应用程序事务发起者发送事务半消息到MQ的broker端，发送成功后，服务端会同步回调事务监听器的本地事务执行方法执行本地事务</li>
<li>RocketMQ的broker收到半消息后，先对消息的topic与消费队列id进行备份，然后存储到主题为 <strong>RMQ_SYS_TRANS_HALF_TOPIC</strong> 的队列中</li>
<li>broker端开启一个定时任务，取出RMQ_SYS_TRANS_HALF_TOPIC中的消息向消息的发送者发起回查。发送端根据本地事务的具体执行状态返回 提交/回滚/事务未知 状态</li>
<li>如果返回 提交/回滚 则broker对事务消息进行提交或者回滚，如果返回了未知，则等待下次继续进行回查。消息的回查间隔与回查次数是可以进行配置的</li>
<li>对于达到回查次数依旧无法获取事务状态的消息，broker会对该事务消息做回滚操作</li>
</ol>
<p>通过上述的步骤，能够保证事务消息发起者的本地事务与消息发送同时成功，同时失败。即：</p>
<blockquote>
<p>当事务发起者本地事务提交，消息才会提交并能够被事务消息消费者消费到。如果事务发起者本地事务回滚，则事务消息也会回滚。保证了事务消息的发送与事务消息发送方本地事务是原子的。</p>
<p>而回查机制保证了对于异常/未知情况，能够最大努力得保证消息发送与事务消息发送方本地事务的原子性。</p>
</blockquote>
<p>对于事务消息的消费者，只需要通过重试机制就能够与事务消息发送方达到分布式事务的最终一致性。因此事务消息本质上也属于 柔性事务 的一种具体实现方式。</p>
<h2 id="事务消息发送"><a href="#事务消息发送" class="headerlink" title="事务消息发送"></a>事务消息发送</h2><p>首先看一段事务消息发送的代码样例，取自官方demo。</p>
<pre><code>public static void main(String[] args) throws MQClientException, InterruptedException {
    TransactionListener transactionListener = new TransactionListenerImpl();
    TransactionMQProducer producer = new TransactionMQProducer(&quot;please_rename_unique_group_name&quot;);
    ExecutorService executorService = 
        new ThreadPoolExecutor(2, 5, 
                        100, TimeUnit.SECONDS, 
                        new ArrayBlockingQueue&lt;Runnable&gt;(2000), new ThreadFactory() {
        @Override
        public Thread newThread(Runnable r) {
            Thread thread = new Thread(r);
            thread.setName(&quot;client-transaction-msg-check-thread&quot;);
            return thread;
        }
    });

    producer.setExecutorService(executorService);
    producer.setTransactionListener(transactionListener);
    producer.start();

    String[] tags = new String[] {&quot;TagA&quot;, &quot;TagB&quot;, &quot;TagC&quot;, &quot;TagD&quot;, &quot;TagE&quot;};
    for (int i = 0; i &lt; 10; i++) {
        try {
            Message msg =
                new Message(&quot;TopicTest1234&quot;, tags[i % tags.length], &quot;KEY&quot; + i,
                    (&quot;Hello RocketMQ &quot; + i).getBytes(RemotingHelper.DEFAULT_CHARSET));
            SendResult sendResult = producer.sendMessageInTransaction(msg, null);
            System.out.printf(&quot;%s%n&quot;, sendResult);

            Thread.sleep(10);
        } catch (MQClientException | UnsupportedEncodingException e) {
            e.printStackTrace();
        }
    }

    for (int i = 0; i &lt; 100000; i++) {
        Thread.sleep(1000);
    }
    producer.shutdown();
}
</code></pre><p>可以看到涉及到的主要类有：</p>
<ul>
<li>TransactionMQProducer – 事务消息生产者，主要实现事务消息发送</li>
<li>TransactionListener   – 事务监听器，主要实现本地事务执行及事务状态回查</li>
</ul>
<h3 id="TransactionMQProducer初始化"><a href="#TransactionMQProducer初始化" class="headerlink" title="TransactionMQProducer初始化"></a>TransactionMQProducer初始化</h3><p>TransactionMQProducer类声明如下：</p>
<pre><code>public class TransactionMQProducer extends DefaultMQProducer {
</code></pre><p>可以看到TransactionMQProducer继承自DefaultMQProducer，我们之前解析的DefaultMQProducer的特性，TransactionMQProducer都有。</p>
<p>上面的demo中，通过</p>
<pre><code>producer.setExecutorService(executorService);
</code></pre><p>设置了线程池executorService，它的作用在于提供异步执行事务状态回查能力。</p>
<p>通过下面的代码将本地事务执行逻辑、回查逻辑的实现设置给了TransactionMQProducer。</p>
<pre><code>producer.setTransactionListener(transactionListener);
</code></pre><p>通过 <strong>producer.start();</strong> 就启动了事务消息发送者的实例。start()方法与DefaultMQProducer的start()方法有所区别：</p>
<h4 id="TransactionMQProducer-start"><a href="#TransactionMQProducer-start" class="headerlink" title="TransactionMQProducer.start()"></a>TransactionMQProducer.start()</h4><pre><code>[TransactionMQProducer.java]
@Override
public void start() throws MQClientException {
    this.defaultMQProducerImpl.initTransactionEnv();
    super.start();
}
</code></pre><p>在真正启动客户端实例之前，通过initTransactionEnv()方法进行了事务消息相关的配置，具体逻辑如下</p>
<pre><code>[DefaultMQProducerImpl.java]
public void initTransactionEnv() {
    TransactionMQProducer producer = (TransactionMQProducer) this.defaultMQProducer;
    if (producer.getExecutorService() != null) {
        this.checkExecutor = producer.getExecutorService();
    } else {
        this.checkRequestQueue = new LinkedBlockingQueue&lt;Runnable&gt;(producer.getCheckRequestHoldMax());
        this.checkExecutor = new ThreadPoolExecutor(
            producer.getCheckThreadPoolMinSize(),
            producer.getCheckThreadPoolMaxSize(),
            1000 * 60,
            TimeUnit.MILLISECONDS,
            this.checkRequestQueue);
    }
}
</code></pre><p>这里对事务消息回查线程池checkExecutor进行了赋值。如果调用者设置了自定义的checkExecutor线程池实现，则使用客户端的实例；否则实例化一个ThreadPoolExecutor，设置回查任务阻塞队列大小为checkRequestHoldMax，默认值为2000。</p>
<p>事务消息发送的方法为 <strong>sendMessageInTransaction</strong>，我们从这里入手开始进行解析。</p>
<h3 id="sendMessageInTransaction"><a href="#sendMessageInTransaction" class="headerlink" title="sendMessageInTransaction"></a>sendMessageInTransaction</h3><pre><code>[TransactionMQProducer.java]
@Override
public TransactionSendResult sendMessageInTransaction(final Message msg,
    final Object arg) throws MQClientException {
    if (null == this.transactionListener) {
        throw new MQClientException(&quot;TransactionListener is null&quot;, null);
    }
    // 执行事务消息发送
    return this.defaultMQProducerImpl.sendMessageInTransaction(msg, null, arg);
}
</code></pre><p>在进行事务消息发送之前，校验transactionListener是否为null，如果为null则抛出异常。否则调用defaultMQProducerImpl的sendMessageInTransaction执行事务消息发送。</p>
<p>我们对defaultMQProducerImpl的sendMessageInTransaction方法做详细的分析。</p>
<h4 id="defaultMQProducerImpl-sendMessageInTransaction"><a href="#defaultMQProducerImpl-sendMessageInTransaction" class="headerlink" title="defaultMQProducerImpl.sendMessageInTransaction"></a>defaultMQProducerImpl.sendMessageInTransaction</h4><pre><code>public TransactionSendResult sendMessageInTransaction(final Message msg,
                                                      final LocalTransactionExecuter localTransactionExecuter,
                                                       final Object arg)
                                                throws MQClientException {
    TransactionListener transactionListener = getCheckListener();
    if (null == localTransactionExecuter &amp;&amp; null == transactionListener) {
        throw new MQClientException(&quot;tranExecutor is null&quot;, null);
    }
</code></pre><p>校验transactionListener或者localTransactionExecuter实例是否存在，如果两者都为null，则抛出异常。</p>
<pre><code>// 校验Message，对topic、body是否为null及body长度进行校验
Validators.checkMessage(msg, this.defaultMQProducer);

SendResult sendResult = null;
// prepare消息
MessageAccessor.putProperty(msg, MessageConst.PROPERTY_TRANSACTION_PREPARED, &quot;true&quot;);
// 设置生产者组。用于回查本地事务，从生产者组中选择随机选择一个生产者即可
MessageAccessor.putProperty(msg, MessageConst.PROPERTY_PRODUCER_GROUP, this.defaultMQProducer.getProducerGroup());
</code></pre><p>这里对消息添加事务消息属性， 添加PROPERTY_TRANSACTION_PREPARED（值为：TRAN_MSG）=true标识消息为事务消息；</p>
<p>添加PROPERTY_PRODUCER_GROUP（值为：PGROUP）=调用方设置的生产者组，代表事务消息所属消息生产者组。</p>
<pre><code>try {
    sendResult = this.send(msg);
} catch (Exception e) {
    throw new MQClientException(&quot;send message Exception&quot;, e);
}
</code></pre><p>发送事务消息，如果异常则进行抛出。具体的消息发送过程在之前的源码解析文章中已经有所涉及，这里就不再展开。读者可以前往 <a href="http://wuwenliang.net/2019/08/07/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ%E4%B9%8B%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/">跟我学RocketMQ之消息发送源码解析</a> 自行回顾。</p>
<pre><code>LocalTransactionState localTransactionState = LocalTransactionState.UNKNOW;
Throwable localException = null;
// 根据消息发送结果中的sendStatus属性选择对应的处理逻辑
switch (sendResult.getSendStatus()) {
    case SEND_OK: {
        try {
            if (sendResult.getTransactionId() != null) {
                // 设置事务消息id
                msg.putUserProperty(&quot;__transactionId__&quot;, sendResult.getTransactionId());
            }
            String transactionId = msg.getProperty(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX);
            if (null != transactionId &amp;&amp; !&quot;&quot;.equals(transactionId)) {
                msg.setTransactionId(transactionId);
            }
            if (null != localTransactionExecuter) {
                // 回调localTransactionExecuter执行本地事务
                localTransactionState = localTransactionExecuter.executeLocalTransactionBranch(msg, arg);
            } else if (transactionListener != null) {
                log.debug(&quot;Used new transaction API&quot;);
                // 回调transactionListener的executeLocalTransaction执行本地事务
                localTransactionState = transactionListener.executeLocalTransaction(msg, arg);
            }
            if (null == localTransactionState) {
                // 本地事务执行状态未知
                localTransactionState = LocalTransactionState.UNKNOW;
            }

            // 对于本地事务执行状态非 COMMIT_MESSAGE的情况进行日志打印
            if (localTransactionState != LocalTransactionState.COMMIT_MESSAGE) {
                log.info(&quot;executeLocalTransactionBranch return {}&quot;, localTransactionState);
                log.info(msg.toString());
            }
        } catch (Throwable e) {
            log.info(&quot;executeLocalTransactionBranch exception&quot;, e);
            log.info(msg.toString());
            localException = e;
        }
    }
    break;
    // 对非SEND_OK的情况，回滚事务消息。
    case FLUSH_DISK_TIMEOUT:
    case FLUSH_SLAVE_TIMEOUT:
    case SLAVE_NOT_AVAILABLE:
        localTransactionState = LocalTransactionState.ROLLBACK_MESSAGE;
        break;
    default:
        break;
}
</code></pre><p>根据消息发送结果执行对应的处理逻辑。</p>
<p>如果消息发送状态为 <strong>SEND_OK</strong>，则同步回调localTransactionExecuter执行本地事务或者回调transactionListener的executeLocalTransaction执行本地事务。这里推荐后者，源码中明确标识，通过localTransactionExecuter执行本地事务的方式将在RocketMQ5.0.0移除。</p>
<p>如果本地事务结果localTransactionState返回null，则localTransactionState设置为UNKNOW。</p>
<p>对于本地事务执行失败的情况，设置localTransactionState为ROLLBACK_MESSAGE，MQ broker会对localTransactionState==ROLLBACK_MESSAGE的消息进行删除处理。</p>
<p>通过这段逻辑就保证了本地事务与事务消息状态的一致性。这段代码我认为是事务消息中较为关键的一段代码。</p>
<pre><code>try {
    // 结束事务
    this.endTransaction(sendResult, localTransactionState, localException);
} catch (Exception e) {
    log.warn(&quot;local transaction execute &quot; + localTransactionState + &quot;, but end broker transaction failed&quot;, e);
}
...省略后续处理...
</code></pre><h3 id="endTransaction"><a href="#endTransaction" class="headerlink" title="endTransaction"></a>endTransaction</h3><p>这里通过endTransaction方法结束事务操作，我们进入endTransaction方法中查看如何对事务进行结束处理。</p>
<pre><code>[DefaultMQProducerImpl.endTransaction]
......
String transactionId = sendResult.getTransactionId();
// 获取broker地址
final String brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(sendResult.getMessageQueue().getBrokerName());
EndTransactionRequestHeader requestHeader = new EndTransactionRequestHeader();
requestHeader.setTransactionId(transactionId);
requestHeader.setCommitLogOffset(id.getOffset());
switch (localTransactionState) {
    case COMMIT_MESSAGE:
        requestHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_COMMIT_TYPE);
        break;
    case ROLLBACK_MESSAGE:
        requestHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_ROLLBACK_TYPE);
        break;
    case UNKNOW:
        requestHeader.setCommitOrRollback(MessageSysFlag.TRANSACTION_NOT_TYPE);
        break;
    default:
        break;
}
</code></pre><p>根据localTransactionState的具体类型为requestHeader设置消息提交或者回滚状态。</p>
<ol>
<li>如果localTransactionState==COMMIT_MESSAGE，设置为MessageSysFlag.TRANSACTION_COMMIT_TYPE</li>
<li>如果localTransactionState==ROLLBACK_MESSAGE，设置为MessageSysFlag.TRANSACTION_ROLLBACK_TYPE</li>
<li>如果localTransactionState==UNKNOW，设置为MessageSysFlag.TRANSACTION_NOT_TYPE</li>
</ol>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文主要对事务消息的发送主流程进行了解析，接下来我将对事务消息存储相关的逻辑进行分析。我们下篇文章再见。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;接下来我将通过一个小系列对RocketMQ事务消息进行一次较为全面的源码解析，本文主要对事务消息发送进行重点分析。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;RocketMQ从4.3.0版本重新开源了事务消息，通过基于两阶段提交方式+定时回查机制，为分布式事务问题提供了新的解决方案。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/categories/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/tags/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
  </entry>
  
  <entry>
    <title>跟我学RocketMQ之开源客户端混合云实践与案例解析</title>
    <link href="http://wuwenliang.net/2019/08/28/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ%E4%B9%8B%E5%BC%80%E6%BA%90%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%B7%B7%E5%90%88%E4%BA%91%E5%AE%9E%E8%B7%B5%E4%B8%8E%E6%A1%88%E4%BE%8B%E8%A7%A3%E6%9E%90/"/>
    <id>http://wuwenliang.net/2019/08/28/跟我学RocketMQ之开源客户端混合云实践与案例解析/</id>
    <published>2019-08-28T13:47:47.000Z</published>
    <updated>2019-08-28T13:48:38.346Z</updated>
    
    <content type="html"><![CDATA[<ul>
<li>开源rocketmq-java客户端sdk使用方法</li>
<li>开源rocketmq-java客户端sdk使用场景解读 </li>
<li>混合云场景案例解析  </li>
<li>下一站：测试／线上一体化</li>
</ul>
<h2 id="开源rocketmq-java客户端sdk使用方法"><a href="#开源rocketmq-java客户端sdk使用方法" class="headerlink" title="开源rocketmq-java客户端sdk使用方法"></a>开源rocketmq-java客户端sdk使用方法</h2><blockquote>
<p>目前通过RocketMQ开源客户端可以访问阿里云RocketMQ的 普通消息、顺序消息、延时／定时消息、事务消息，基本覆盖了云上MQ的主流场景。</p>
</blockquote>
<p>我们接着讲解一下如何通过开源SDK使用云上RocketMQ。</p>
<blockquote>
<p>本部分的配置项，生产者、消费者应用都需要添加。</p>
</blockquote>
<p>我们通过代码案例讲解一下如何使用RocketMQ开源客户端的访问云上的MQ，进行消息发送与消费。</p>
<a id="more"></a>
<p>使用4.5.1版本进行讲解，在项目中添加如下依赖</p>
<pre><code>&lt;!-- https://mvnrepository.com/artifact/org.apache.rocketmq/rocketmq-client --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt;
    &lt;artifactId&gt;rocketmq-client&lt;/artifactId&gt;
    &lt;version&gt;4.5.1&lt;/version&gt;
&lt;/dependency&gt;

&lt;!-- https://mvnrepository.com/artifact/org.apache.rocketmq/rocketmq-acl --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt;
    &lt;artifactId&gt;rocketmq-acl&lt;/artifactId&gt;
    &lt;version&gt;4.5.1&lt;/version&gt;
&lt;/dependency&gt;
</code></pre><p>在springboot项目的application.properties中添加rocketmq配置</p>
<pre><code>#nameServer地址
rocketmq.nameServer.offline=开源版本nameServer地址
rocketmq.nameServer.aliyun=阿里云接入点
rocketmq.acl.accesskey=云上accesskey
rocketmq.acl.accessSecret=云上accessSecret
</code></pre><blockquote>
<p>ak sk 写上对开源版本代码运行没有影响。换到开源版本，这部分代码保留即可，</p>
</blockquote>
<p>为了方便代码部署，编写一个配置读取类，根据环境变量设置的环境类型，选取不同的nameServer</p>
<pre><code>@Component
public class MQNamesrvConfig {

    // 线下开源rocketMQ
    @Value(&quot;${rocketmq.nameServer.offline}&quot;)
    String offlineNamesrv;

    // 阿里云RocketMQ接入点
    @Value(&quot;${rocketmq.nameServer.aliyun}&quot;)
    String aliyunNamesrv;

    /**
    * 根据环境选择nameServer地址
    * @return
    */
    public String nameSrvAddr() {
        String envType = System.getProperty(&quot;envType&quot;);
        if (StringUtils.isBlank(envType)) {
            throw new IllegalArgumentException(&quot;please insert envType&quot;);
        }
        switch (envType) {
            case &quot;offline&quot; : {
                return offlineNamesrv;
            }
            case &quot;aliyun&quot; : {
                return aliyunNamesrv;
            }
            default : {
                throw new IllegalArgumentException(&quot;please insert right envType, offline/aliyun&quot;);
            }
        }
    }
}
</code></pre><h3 id="生产者代码样例"><a href="#生产者代码样例" class="headerlink" title="生产者代码样例"></a>生产者代码样例</h3><p>为了支持代码访问云上MQ需要更改生产者构造方法，代码如下：</p>
<pre><code>@Autowired
MQNamesrvConfig namesrvConfig;

@Value(&quot;${rocketmq.acl.accesskey}&quot;)
String aclAccessKey;

@Value(&quot;${rocketmq.acl.accessSecret}&quot;)
String aclAccessSecret;

private DefaultMQProducer defaultMQProducer;

@PostConstruct
public void init() {
    defaultMQProducer =
            new DefaultMQProducer(&quot;GID_SNOWALKE_TEST&quot;,
            new AclClientRPCHook(new SessionCredentials(aclAccessKey, aclAccessSecret)));
    defaultMQProducer.setNamesrvAddr(namesrvConfig.nameSrvAddr());
    // 发送失败重试次数
    defaultMQProducer.setRetryTimesWhenSendFailed(3);
    try {
        defaultMQProducer.start();
    } catch (MQClientException e) {
        LOGGER.error(&quot;[秒杀订单生产者]--SecKillChargeOrderProducer加载异常!e={}&quot;, LogExceptionWapper.getStackTrace(e));
        throw new RuntimeException(&quot;[秒杀订单生产者]--SecKillChargeOrderProducer加载异常!&quot;, e);
    }
    LOGGER.info(&quot;[秒杀订单生产者]--SecKillChargeOrderProducer加载完成!&quot;);
}
</code></pre><p>关键点在于构造初始化的过程中，设置AclClientRPCHook，并将accesskey与secretKey设置进去。官方sample代码如下</p>
<pre><code>DefaultMQProducer producer = new DefaultMQProducer(&quot;ProducerGroupName&quot;, getAclRPCHook());
producer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;);
producer.start();

static RPCHook getAclRPCHook() {
    return new AclClientRPCHook(new SessionCredentials(ACL_ACCESS_KEY,ACL_SECRET_KEY));
}
</code></pre><h3 id="消费者代码样例"><a href="#消费者代码样例" class="headerlink" title="消费者代码样例"></a>消费者代码样例</h3><p>消费者初始化代码也需要稍作改造。</p>
<pre><code>@Autowired
MQNamesrvConfig namesrvConfig;

@Value(&quot;${rocketmq.acl.accesskey}&quot;)
String aclAccessKey;

@Value(&quot;${rocketmq.acl.accessSecret}&quot;)
String aclAccessSecret;

private DefaultMQPushConsumer defaultMQPushConsumer;

@Resource(name = &quot;secKillChargeOrderListenerImpl&quot;)
private MessageListenerConcurrently messageListener;

@PostConstruct
public void init() {
    defaultMQPushConsumer =
            new DefaultMQPushConsumer(&quot;GID_SNOWALKE_TEST&quot;,,
                    new AclClientRPCHook(new SessionCredentials(aclAccessKey, aclAccessSecret)),
                    // 平均分配队列算法，hash
                    new AllocateMessageQueueAveragely());
    defaultMQPushConsumer.setNamesrvAddr(namesrvConfig.nameSrvAddr());
    // 从头开始消费
    defaultMQPushConsumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);
    // 消费模式:集群模式
    defaultMQPushConsumer.setMessageModel(MessageModel.CLUSTERING);
    // 注册监听器
    defaultMQPushConsumer.registerMessageListener(messageListener);
    // 设置每次拉取的消息量，默认为1
    defaultMQPushConsumer.setConsumeMessageBatchMaxSize(1);
    // 订阅所有消息
    try {
        defaultMQPushConsumer.subscribe(MessageProtocolConst.SECKILL_CHARGE_ORDER_TOPIC.getTopic(), &quot;*&quot;);
        // 启动消费者
        defaultMQPushConsumer.start();
    } catch (MQClientException e) {
        LOGGER.error(&quot;[秒杀下单消费者]--SecKillChargeOrderConsumer加载异常!e={}&quot;, LogExceptionWapper.getStackTrace(e));
        throw new RuntimeException(&quot;[秒杀下单消费者]--SecKillChargeOrderConsumer加载异常!&quot;, e);
    }
    LOGGER.info(&quot;[秒杀下单消费者]--SecKillChargeOrderConsumer加载完成!&quot;);
}
</code></pre><p>同生产者初始化过程类似，关键点在于构造初始化的过程中，设置AclClientRPCHook，并将accesskey与secret设置进去。官方sample代码如下</p>
<blockquote>
<p>我们主要以PushConsumer为例，PullConsumer的使用可以自行前往官方sample目录下查看</p>
</blockquote>
<pre><code>DefaultMQPushConsumer consumer = 
new DefaultMQPushConsumer(&quot;ConsumerGroupName&quot;, 
                            getAclRPCHook(), 
                            new AllocateMessageQueueAveragely());
consumer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;);


static RPCHook getAclRPCHook() {
    return new AclClientRPCHook(new SessionCredentials(ACL_ACCESS_KEY,ACL_SECRET_KEY));
} 
</code></pre><h3 id="补充：其他改造方案简介"><a href="#补充：其他改造方案简介" class="headerlink" title="补充：其他改造方案简介"></a>补充：其他改造方案简介</h3><ol>
<li>通过java -D方式将ak sk及nameserver参数设置为环境变量</li>
<li>通过docker -e 方式将参数设置为环境变量</li>
<li>如果使用了K8S部署应用，则使用values.yaml或者configMap则更为方便</li>
</ol>
<p>这些方式几乎可以做到零改动升级。</p>
<h2 id="开源rocketmq-java客户端sdk使用场景解读"><a href="#开源rocketmq-java客户端sdk使用场景解读" class="headerlink" title="开源rocketmq-java客户端sdk使用场景解读"></a>开源rocketmq-java客户端sdk使用场景解读</h2><p>使用开源RocketMQ的java客户端能够满足多种需求，如：</p>
<ol>
<li>混合云场景</li>
<li>测试线上一体化</li>
<li>云迁移场景</li>
</ol>
<h2 id="混合云场景"><a href="#混合云场景" class="headerlink" title="混合云场景"></a>混合云场景</h2><blockquote>
<p>如果您的企业需要同时访问阿里云和其他公有云或者本地数据中心，开源客户端也可以支持多云环境的无缝切换。很好的支持分布式系统多云环境的数据同步、异地容灾等功能。</p>
</blockquote>
<p>我们常说，不能把鸡蛋放在一个篮子里。</p>
<p>这种思维恰恰就是多云环境的体现。对于某些核心业务，我们要满足HA，应用部署需要具备可迁移，多环境热备，抗不可抗力等的能力。</p>
<p>我们会选择打通多云环境，或者建立私有云平台，保证跨云数据同步。</p>
<p>本次分享主要就混合云场景做重要的分析，我们将采用一个电商秒杀业务场景的混合云场景改造进行案例分析。</p>
<h3 id="测试／线上一体化"><a href="#测试／线上一体化" class="headerlink" title="测试／线上一体化"></a>测试／线上一体化</h3><blockquote>
<p>鉴于开源客户端既可以访问开源RocketMQ集群又可以访问阿里云MQ，您的应用可以在开发、测试阶段使用开源RocketMQ集群，线上阶段使用阿里云RocketMQ，这将很大程度为您节约成本。切换过程无需修改一行代码。</p>
</blockquote>
<p>测试线上一体化的核心为 “一套代码，处处运行”，线上线下逻辑相同，不需要进行针对环境进行变更，使业务逻辑无状态化。</p>
<p>云上的MQ公网模式下按量收费，为了节省开发测试成本，因此在开发测试阶段选择使用线下的开源RocektMQ；正式上线再接入线上的云MQ。</p>
<p>客户端sdk支持一套代码访问开源、云上的MQ，从而降低开发成本。</p>
<p>示例图如下：</p>
<p><img src="/2019/08/28/跟我学RocketMQ之开源客户端混合云实践与案例解析/devprod.png" alt="测试线上一体化"></p>
<p>案例：我当前所在的业务线在生产环境主要使用了阿里云RocketMQ的铂金版，线下测试如果也使用铂金版成本较高，换成公网由于Topic数量有三十多个，测试开发两套环境每个月固定支出几千，因此对代码进行了升级。</p>
<p>测试和开发环境功能测试访问本地开源RocketMQ集群，线上使用阿里云铂金版RocketMQ，效果很稳定。</p>
<h3 id="云迁移场景"><a href="#云迁移场景" class="headerlink" title="云迁移场景"></a>云迁移场景</h3><blockquote>
<p>如果您正想从开源RocketMQ迁移到阿里云MQ，开源客户端是最好的选择，升级到开源客户端后，您可以在应用不停机的情况下无缝迁移到阿里云RocketMQ。</p>
</blockquote>
<p>商业版MQ具有完备的技术团队支撑，稳定性及可靠性表现优异，如果应用有上云需求，访问对应区域的阿里云RocketMQ是一个不错的选择。</p>
<p>尤其是之前已经基于开源版MQ部署过的应用，代码量可观，如果使用云上的客户端进行兼容，修改量比较大，因此通过ACL支持的开源版客户端，几乎零修改，便可以无缝上云。</p>
<p>推荐的迁移策略如下：</p>
<ol>
<li>对现有应用的客户端进行升级，加入ACL支持</li>
<li>进行线下的兼容性测试，保证原先业务不受影响</li>
<li>将配置信息剥离到环境变量中，如:<ol>
<li>通过java -D方式将参数设置为环境变量</li>
<li>通过docker -e 方式将参数设置为环境变量</li>
<li>如果使用了K8S部署应用，则使用values.yaml或者configMap则更为方便</li>
</ol>
</li>
<li>将应用打包后部署到云上环境即可完成迁移</li>
</ol>
<p>流程图如下：</p>
<p><img src="/2019/08/28/跟我学RocketMQ之开源客户端混合云实践与案例解析/exchange.png" alt="云迁移流程"></p>
<h2 id="混合云场景案例解析"><a href="#混合云场景案例解析" class="headerlink" title="混合云场景案例解析"></a>混合云场景案例解析</h2><p>混合云场景的案例分析基于一个简化的电商秒杀场景业务系统讲解，项目的代码地址为 <a href="https://github.com/TaXueWWL/seckill-rocketmq" target="_blank" rel="external">https://github.com/TaXueWWL/seckill-rocketmq</a></p>
<h3 id="项目简介："><a href="#项目简介：" class="headerlink" title="项目简介："></a>项目简介：</h3><blockquote>
<p>用户访问秒杀网关进行秒杀订单下单，平台通过RocketMQ对秒杀流量进行削峰填谷。用户通过主动查询订单 获取下单结果的完整业务流程</p>
</blockquote>
<h3 id="本地化部署架构解析"><a href="#本地化部署架构解析" class="headerlink" title="本地化部署架构解析"></a>本地化部署架构解析</h3><p>上述场景为非混合云平台部署方式，该方式的部署架构图如下：</p>
<p><img src="/2019/08/28/跟我学RocketMQ之开源客户端混合云实践与案例解析/idc-deploy.png" alt="非混合云部署方式"></p>
<p>秒杀网关服务、秒杀订单服务、开源MQ集群、缓存集群、DB集群都在一个环境进行部署。</p>
<h3 id="混合云平台部署解析"><a href="#混合云平台部署解析" class="headerlink" title="混合云平台部署解析"></a>混合云平台部署解析</h3><p>我们对上述部署方式进行混合云改造，将数据库、MQ等中间件更换为云上版本，订单收单业务模块部署到云上环境；将缓存、收单网关部署到本地环境（使用本地环境模拟IDC）。整个部署方式变成了混合云架构。</p>
<p>整个平台的部署架构图如下：</p>
<p><img src="/2019/08/28/跟我学RocketMQ之开源客户端混合云实践与案例解析/mix-deploy.png" alt="混合云部署方式"></p>
<h3 id="案例流程解析"><a href="#案例流程解析" class="headerlink" title="案例流程解析"></a>案例流程解析</h3><p>案例的流程图如下；</p>
<p><img src="/2019/08/28/跟我学RocketMQ之开源客户端混合云实践与案例解析/demo-seq.png" alt="案例流程图"></p>
<h3 id="demo演示及讲解"><a href="#demo演示及讲解" class="headerlink" title="demo演示及讲解"></a>demo演示及讲解</h3><p>我们对demo项目进行演示，主要演示通过访问阿里云云上MQ实现消息收发。</p>
<p>消息发送控制台截图：</p>
<p><img src="/2019/08/28/跟我学RocketMQ之开源客户端混合云实践与案例解析/aliyun-mq-send.png" alt="消息发送"></p>
<p>消息消费控制台截图：</p>
<p><img src="/2019/08/28/跟我学RocketMQ之开源客户端混合云实践与案例解析/aliyun-mq-consume.png" alt="消息发送"></p>
<h3 id="改造流程总结"><a href="#改造流程总结" class="headerlink" title="改造流程总结"></a>改造流程总结</h3><ol>
<li>代码支持云上MQ，具体方法参考第一章节 《开源rocketmq-java客户端sdk使用方法》</li>
<li>进行应用迁移部署</li>
<li>功能验证</li>
</ol>
<p>可以看到通过4.5.1以上的新版本RocketMQ客户端SDK，能够明显降低我们业务上云、混合云部署等的改造成本，提高业务部署的可靠性。</p>
<h2 id="下一站：测试／线上一体化"><a href="#下一站：测试／线上一体化" class="headerlink" title="下一站：测试／线上一体化"></a>下一站：测试／线上一体化</h2><p>进行混合云部署改造的过程其实就涉及到了另外的场景，即：测试／线上一体化。我们可以通过4.5.1以上的新版本RocketMQ客户端SDK达到该目的。</p>
<p>即：开发测试环境访问本地开源MQ集群，进行测试，节约成本。线上使用云上MQ，节约运维成本，更好的满足服务高可用。</p>
<h2 id="上云指导文档"><a href="#上云指导文档" class="headerlink" title="上云指导文档"></a>上云指导文档</h2><blockquote>
<p>如果有以下场景需求可以访问下列链接，获取更多的上云指导</p>
</blockquote>
<ul>
<li>云迁移场景：想从开源RocketMQ迁移到阿里云MQ</li>
<li>混合云场景：应用需要同时访问私有云的开源RocketMQ和阿里云tMQ。</li>
<li>测试环境访问开源RocketMQ，线上环境访问阿里云MQ。</li>
</ul>
<p><a href="http://rocketmq.cloud/zh-cn/blog/tocloud-catalog.html" target="_blank" rel="external">RocketMQ开源客户端访问阿里云MQ</a></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://github.com/apache/rocketmq/blob/master/example/src/main/java/org/apache/rocketmq/example/simple/AclClient.java" target="_blank" rel="external">RocketMQ 官方Sample</a></p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;开源rocketmq-java客户端sdk使用方法&lt;/li&gt;
&lt;li&gt;开源rocketmq-java客户端sdk使用场景解读 &lt;/li&gt;
&lt;li&gt;混合云场景案例解析  &lt;/li&gt;
&lt;li&gt;下一站：测试／线上一体化&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;开源rocketmq-java客户端sdk使用方法&quot;&gt;&lt;a href=&quot;#开源rocketmq-java客户端sdk使用方法&quot; class=&quot;headerlink&quot; title=&quot;开源rocketmq-java客户端sdk使用方法&quot;&gt;&lt;/a&gt;开源rocketmq-java客户端sdk使用方法&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;目前通过RocketMQ开源客户端可以访问阿里云RocketMQ的 普通消息、顺序消息、延时／定时消息、事务消息，基本覆盖了云上MQ的主流场景。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们接着讲解一下如何通过开源SDK使用云上RocketMQ。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;本部分的配置项，生产者、消费者应用都需要添加。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们通过代码案例讲解一下如何使用RocketMQ开源客户端的访问云上的MQ，进行消息发送与消费。&lt;/p&gt;
    
    </summary>
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/categories/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/tags/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
  </entry>
  
  <entry>
    <title>跟我学RocketMQ之消息拉取源码解析</title>
    <link href="http://wuwenliang.net/2019/08/20/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ%E4%B9%8B%E6%B6%88%E6%81%AF%E6%8B%89%E5%8F%96%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"/>
    <id>http://wuwenliang.net/2019/08/20/跟我学RocketMQ之消息拉取源码解析/</id>
    <published>2019-08-20T06:21:07.000Z</published>
    <updated>2019-08-20T09:30:10.148Z</updated>
    
    <content type="html"><![CDATA[<p>我们继续对消息消费流程的源码进行解析。</p>
<p>本文主要针对push模式下的消息拉取流程进行解析。我们重点分析集群消费模式，对于广播模式其实很好理解，每个消费者都需要拉取主题下面的所有消费队列的消息。</p>
<p>在集群消费模式下，同一个消费者组内包含了多个消费者实例，同一个topic下存在多个消费队列。对于单个消费者组，其内部维护了一个线程池进行消息消费，这部分内容可以移步 <a href="http://wuwenliang.net/2019/08/15/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ%E4%B9%8B%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-2/">跟我学RocketMQ之消息消费源码解析(2)</a>。</p>
<p>之前我们已经研究了消费者的初始化流程，在启动MQClientInstance过程中，启动了一个消息拉取线程PullMessageService进行消息拉取工作。</p>
<a id="more"></a>
<h2 id="PullMessageService启动"><a href="#PullMessageService启动" class="headerlink" title="PullMessageService启动"></a>PullMessageService启动</h2><pre><code>public MQClientInstance(ClientConfig clientConfig, int instanceIndex, String clientId, RPCHook rpcHook) {
    this.clientConfig = clientConfig;
    this.instanceIndex = instanceIndex;
    this.nettyClientConfig = new NettyClientConfig();
    this.nettyClientConfig.setClientCallbackExecutorThreads(clientConfig.getClientCallbackExecutorThreads());
    this.nettyClientConfig.setUseTLS(clientConfig.isUseTLS());
    this.clientRemotingProcessor = new ClientRemotingProcessor(this);
    this.mQClientAPIImpl = new MQClientAPIImpl(this.nettyClientConfig, this.clientRemotingProcessor, rpcHook, clientConfig);

    ...省略其他...
    this.pullMessageService = new PullMessageService(this);
    ...省略其他...
    this.rebalanceService = new RebalanceService(this);
}
</code></pre><p>可以看到在MQClientInstance的构造初始化过程中，启动了PullMessageService线程。</p>
<h2 id="PullMessageService启动-1"><a href="#PullMessageService启动-1" class="headerlink" title="PullMessageService启动"></a>PullMessageService启动</h2><p>从之前文章中对消息消费启动过程的分析中得知，在消费者启动过程defaultMQPushConsumerImpl.start()中，我们启动了MQClientInstance。</p>
<p>在启动MQClientInstance的过程中，对消息拉取线程进行了start()。消息拉取线程开始运行，看下代码实现</p>
<pre><code>public void start() throws MQClientException {

    synchronized (this) {
        switch (this.serviceState) {
            case CREATE_JUST:
                this.serviceState = ServiceState.START_FAILED;
                // If not specified,looking address from name server
                if (null == this.clientConfig.getNamesrvAddr()) {
                    this.mQClientAPIImpl.fetchNameServerAddr();
                }
                // Start request-response channel
                this.mQClientAPIImpl.start();
                // Start various schedule tasks
                this.startScheduledTask();
                // 启动消息拉取线程
                this.pullMessageService.start();
                // Start rebalance service
                this.rebalanceService.start();
                // Start push service
                this.defaultMQProducer.getDefaultMQProducerImpl().start(false);
                log.info(&quot;the client factory [{}] start OK&quot;, this.clientId);
                this.serviceState = ServiceState.RUNNING;
                break;
            case RUNNING:
                break;
            case SHUTDOWN_ALREADY:
                break;
            case START_FAILED:
                throw new MQClientException(&quot;The Factory object[&quot; + this.getClientId() + &quot;] has been created before, and failed.&quot;, null);
            default:
                break;
        }
    }
}
</code></pre><p>通过 <strong>this.pullMessageService.start()</strong> 启动了消息拉取线程。</p>
<h2 id="PullMessageService消息拉取流程分析"><a href="#PullMessageService消息拉取流程分析" class="headerlink" title="PullMessageService消息拉取流程分析"></a>PullMessageService消息拉取流程分析</h2><p>PullMessageService是ServiceThread的子类，ServiceThread是RocketMQ实现的具备启停能力的线程实现，它实现了Runnable接口。我们看一下PullMessageService的声明。</p>
<pre><code>public class PullMessageService extends ServiceThread {
</code></pre><p>当PullMessageService启动后，开始运行run方法，我们看一下run方法逻辑。</p>
<pre><code>@Override
public void run() {
    log.info(this.getServiceName() + &quot; service started&quot;);

    while (!this.isStopped()) {
        try {
            // step 1
            PullRequest pullRequest = this.pullRequestQueue.take();
            // step 2
            this.pullMessage(pullRequest);
        } catch (InterruptedException ignored) {
        } catch (Exception e) {
            log.error(&quot;Pull Message Service Run Method exception&quot;, e);
        }
    }

    log.info(this.getServiceName() + &quot; service end&quot;);
}
</code></pre><p><strong>while (!this.isStopped()) {</strong> 这个写法是一种通用的设计技巧，stopped是一个声明为volatile的boolean类型变量，保证多线程下的可见性；每次执行逻辑时判断stopped是否为false，如果是则执行循环体内逻辑。</p>
<p>其他线程能够通过设置stopped为true，导致此处判断结果为false从而终止拉取线程的运行。</p>
<ul>
<li>[step 1] 从pullRequestQueue（LinkedBlockingQueue无界队列）中通过take()获取一个PullRequest消息拉取任务；如果队列为空，则线程阻塞，等待新的PullRequest被放入恢复运行。</li>
<li>[step 2] 执行pullMessage方法进行真正的消息拉取操作。</li>
</ul>
<h2 id="PullRequest添加流程"><a href="#PullRequest添加流程" class="headerlink" title="PullRequest添加流程"></a>PullRequest添加流程</h2><p>在阅读pullMessage逻辑之前，我们先看一下PullRequest是从何添加的。</p>
<pre><code>public void executePullRequestLater(final PullRequest pullRequest, final long timeDelay) {
    if (!isStopped()) {
        this.scheduledExecutorService.schedule(new Runnable() {
            @Override
            public void run() {
                PullMessageService.this.executePullRequestImmediately(pullRequest);
            }
        }, timeDelay, TimeUnit.MILLISECONDS);
    } else {
        log.warn(&quot;PullMessageServiceScheduledThread has shutdown&quot;);
    }
}

public void executePullRequestImmediately(final PullRequest pullRequest) {
    try {
        this.pullRequestQueue.put(pullRequest);
    } catch (InterruptedException e) {
        log.error(&quot;executePullRequestImmediately pullRequestQueue.put&quot;, e);
    }
}
</code></pre><p>PullMessageService提供了即时添加与延时添加两种方式添加PullRequest，将其加入到pullRequestQueue阻塞队列中。PullRequest的创建过程是在RebalanceImpl中完成的，这个过程涉及到RocketMQ消息消费的重要过程 <strong>消息队列负载机制</strong>，这个过程我们会单独进行讲解。</p>
<h3 id="PullRequest简介"><a href="#PullRequest简介" class="headerlink" title="PullRequest简介"></a>PullRequest简介</h3><p>我们简单看一下PullRequest的结构：</p>
<pre><code>public class PullRequest {
    // 消费者组
    private String consumerGroup;
    // 待拉取到消息队列
    private MessageQueue messageQueue;
    // 消息处理队列，消息从broker中拉取以后会先存到该ProcessQueue中，然后再提交给消费者线程池进行消费
    private ProcessQueue processQueue;
    // 带拉取消息的偏移量
    private long nextOffset;
    // 是否锁定
    private boolean lockedFirst = false;
</code></pre><h2 id="PullRequest消息拉取流程"><a href="#PullRequest消息拉取流程" class="headerlink" title="PullRequest消息拉取流程"></a>PullRequest消息拉取流程</h2><p>我们继续回到PullRequest拉取流程中来，查看PullMessageService.pullMessage方法。</p>
<pre><code>private void pullMessage(final PullRequest pullRequest) {
    final MQConsumerInner consumer = this.mQClientFactory.selectConsumer(pullRequest.getConsumerGroup());
    if (consumer != null) {
        DefaultMQPushConsumerImpl impl = (DefaultMQPushConsumerImpl) consumer;
        impl.pullMessage(pullRequest);
    } else {
        log.warn(&quot;No matched consumer for the PullRequest {}, drop it&quot;, pullRequest);
    }
}
</code></pre><p>这是一个私有方法，可以看到</p>
<ol>
<li>首先从MQClientInstance中选择一个消费者，选取条件为当前拉取请求中的消费者组；</li>
<li>将该消费者实例强转为DefaultMQPushConsumerImpl</li>
<li>调用DefaultMQPushConsumerImpl的pullMessage方法进行消息拉取。</li>
</ol>
<p>我们接着进入DefaultMQPushConsumerImpl.java中查看其pullMessage的具体实现。</p>
<h2 id="DefaultMQPushConsumerImpl-pullMessage消息拉取逻辑"><a href="#DefaultMQPushConsumerImpl-pullMessage消息拉取逻辑" class="headerlink" title="DefaultMQPushConsumerImpl.pullMessage消息拉取逻辑"></a>DefaultMQPushConsumerImpl.pullMessage消息拉取逻辑</h2><p>前方大段代码预警……我会将这个大方法拆分成一段一段的细分逻辑进行分析。</p>
<pre><code>public void pullMessage(final PullRequest pullRequest) {
    final ProcessQueue processQueue = pullRequest.getProcessQueue();
    if (processQueue.isDropped()) {
        log.info(&quot;the pull request[{}] is dropped.&quot;, pullRequest.toString());
        return;
    }

    pullRequest.getProcessQueue().setLastPullTimestamp(System.currentTimeMillis());
</code></pre><p>首先从pullRequest请求中获取到处理队列processQueue，如果processQueue已经被丢弃则结束拉取流程；</p>
<p>如果processQueue未被丢弃，则更新LastPullTimestamp属性未当前时间戳。</p>
<pre><code>try {
    this.makeSureStateOK();
} catch (MQClientException e) {
    log.warn(&quot;pullMessage exception, consumer state not ok&quot;, e);
    this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_EXCEPTION);
    return;
}
</code></pre><p>判断当前线程状态是否为运行态，makeSureStateOK()方法会通过 <strong>this.serviceState != ServiceState.RUNNING</strong> 进行服务状态的判断； 如果不是RUNNING状态则抛出异常结束消息拉取流程。</p>
<pre><code>if (this.isPause()) {
    ...省略warn日志...
    // long PULL_TIME_DELAY_MILLS_WHEN_SUSPEND = 1000;单位毫秒
    this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_SUSPEND);
    return;
}
</code></pre><p>对消费者是否挂起进行判断，如果消费者状态为已挂起，则将拉取请求延迟1s后再次放到PullMessageService的消息拉取任务队列中。</p>
<pre><code>long cachedMessageCount = processQueue.getMsgCount().get();
long cachedMessageSizeInMiB = processQueue.getMsgSize().get() / (1024 * 1024);

if (cachedMessageCount &gt; this.defaultMQPushConsumer.getPullThresholdForQueue()) {
    this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL);
    if ((queueFlowControlTimes++ % 1000) == 0) {
        ...省略warn日志...
    }
    return;
}
</code></pre><p>此处进行消息拉取流控校验：</p>
<p>如果processQueue当前处理的消息条数超过了PullThresholdForQueue（消息拉取阈值=1000）触发流控，结束本次拉取任务，50毫秒之后将该拉取任务再次加入到消息拉取任务队列中。每触发1000次流控，打印warn日志；</p>
<pre><code>if (!this.consumeOrderly) {
    if (processQueue.getMaxSpan() &gt; this.defaultMQPushConsumer.getConsumeConcurrentlyMaxSpan()) {
        this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL);
        if ((queueMaxSpanFlowControlTimes++ % 1000) == 0) {
            ...省略warn日志...
        }
        return;
    }
</code></pre><p>如果不是顺序消费，判断processQueue中队列最大偏移量与最小偏移量之间的间隔，如果大于ConsumeConcurrentlyMaxSpan（拉取偏移量阈值==2000）触发流控，结束本次拉取；50毫秒之后将该拉取任务再次加入到消息拉取任务队列中。</p>
<p>每触发1000次流程，打印warn日志。</p>
<pre><code>} else {
    if (processQueue.isLocked()) {
        if (!pullRequest.isLockedFirst()) {
            final long offset = this.rebalanceImpl.computePullFromWhere(pullRequest.getMessageQueue());
            boolean brokerBusy = offset &lt; pullRequest.getNextOffset();
            log.info(&quot;the first time to pull message, so fix offset from broker. pullRequest: {} NewOffset: {} brokerBusy: {}&quot;,
                pullRequest, offset, brokerBusy);
            if (brokerBusy) {
                log.info(&quot;[NOTIFYME]the first time to pull message, but pull request offset larger than broker consume offset. pullRequest: {} NewOffset: {}&quot;,
                    pullRequest, offset);
            }

            pullRequest.setLockedFirst(true);
            pullRequest.setNextOffset(offset);
        }
    } else {
        this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_EXCEPTION);
        log.info(&quot;pull message later because not locked in broker, {}&quot;, pullRequest);
        return;
    }
}
</code></pre><p>如果消息处理队列锁定成功，判断消息拉取请求是否锁定，如果没有锁定则计算从何处开始拉取。</p>
<p>判断broker是否繁忙，如果当前拉取的进度小于拉取请求中要拉取到下一个进度，表明当前broker处理的拉取请求还没有执行完成，因此brokerBusy为true，表示broker处于繁忙状态。</p>
<p>更新拉取请求的锁定标记为已锁定，更新下一次拉取的offset为计算出的offset。</p>
<p>如果消息处理队列未锁定，则延迟3s之后将将该拉取任务再次加入到消息拉取任务队列。打印日志表明稍后再进行消息拉取，原因为broker未被锁定。结束本次拉取。</p>
<pre><code>final SubscriptionData subscriptionData = this.rebalanceImpl.getSubscriptionInner().get(pullRequest.getMessageQueue().getTopic());
if (null == subscriptionData) {
    this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_EXCEPTION);
    log.warn(&quot;find the consumer&apos;s subscription failed, {}&quot;, pullRequest);
    return;
}
</code></pre><p>获取当前topic的订阅消息，如果订阅消息不存在，则结束当前消息拉取；延迟三秒之后将拉取任务再次加入到消息拉取任务队列中。</p>
<pre><code>final long beginTimestamp = System.currentTimeMillis();

...省略pullCallback实现...

boolean commitOffsetEnable = false;
long commitOffsetValue = 0L;
if (MessageModel.CLUSTERING == this.defaultMQPushConsumer.getMessageModel()) {
    commitOffsetValue = this.offsetStore.readOffset(pullRequest.getMessageQueue(), ReadOffsetType.READ_FROM_MEMORY);
    if (commitOffsetValue &gt; 0) {
        commitOffsetEnable = true;
    }
}

String subExpression = null;
boolean classFilter = false;
SubscriptionData sd = this.rebalanceImpl.getSubscriptionInner().get(pullRequest.getMessageQueue().getTopic());
if (sd != null) {
    if (this.defaultMQPushConsumer.isPostSubscriptionWhenPull() &amp;&amp; !sd.isClassFilterMode()) {
        subExpression = sd.getSubString();
    }

    classFilter = sd.isClassFilterMode();
}
</code></pre><p>获取消息订阅信息，如果订阅信息存在则获取tag标识。</p>
<pre><code>int sysFlag = PullSysFlag.buildSysFlag(
    commitOffsetEnable, // commitOffset
    true, // suspend
    subExpression != null, // subscription
    classFilter // class filter
);
</code></pre><p>这里主要构造了消息拉取的系统标识；</p>
<pre><code>try {
    this.pullAPIWrapper.pullKernelImpl(
        pullRequest.getMessageQueue(),
        subExpression,
        subscriptionData.getExpressionType(),
        subscriptionData.getSubVersion(),
        pullRequest.getNextOffset(),
        this.defaultMQPushConsumer.getPullBatchSize(),
        sysFlag,
        commitOffsetValue,
        BROKER_SUSPEND_MAX_TIME_MILLIS,
        CONSUMER_TIMEOUT_MILLIS_WHEN_SUSPEND,
        CommunicationMode.ASYNC,
        pullCallback
    );
</code></pre><p>通过pullKernelImpl()方法发起真实的消息拉取请求，pullKernelImpl方法内部与服务端进行网络通信。底层调用了MQClientAPIImpl的pullMessage方法。此处涉及到网络通信，我们在后续的网络通讯代码部分进行分析。    </p>
<p>注意此处的pullKernelImpl方法中的最后一个参数为PullCallback，PullCallback为从Broker拉取消息之后的回调方法，它的初始化代码如下，我们单独拿出来进行解析。</p>
<h2 id="DefaultMQPushConsumerImpl-pullMessage-PullCallback实例化代码逻辑"><a href="#DefaultMQPushConsumerImpl-pullMessage-PullCallback实例化代码逻辑" class="headerlink" title="DefaultMQPushConsumerImpl.pullMessage.PullCallback实例化代码逻辑"></a>DefaultMQPushConsumerImpl.pullMessage.PullCallback实例化代码逻辑</h2><p>通过匿名内部类的方式初始化了PullCallback回调接口，需要实现其OnSuccess、onException方法。</p>
<pre><code>PullCallback pullCallback = new PullCallback() {
    @Override
    public void onSuccess(PullResult pullResult) {
        if (pullResult != null) {
            pullResult = DefaultMQPushConsumerImpl.this.pullAPIWrapper.processPullResult(pullRequest.getMessageQueue(), 
                            pullResult,
                            subscriptionData);
</code></pre><p>如果拉取结果不为空，表明拉取成功了，执行processPullResult对拉取结果进行解析。</p>
<pre><code>// 判断拉取状态
switch (pullResult.getPullStatus()) {
    case FOUND:
        long prevRequestOffset = pullRequest.getNextOffset();
        pullRequest.setNextOffset(pullResult.getNextBeginOffset());
        long pullRT = System.currentTimeMillis() - beginTimestamp;
        DefaultMQPushConsumerImpl.this.getConsumerStatsManager().incPullRT(pullRequest.getConsumerGroup(),
            pullRequest.getMessageQueue().getTopic(), pullRT);

        long firstMsgOffset = Long.MAX_VALUE;
        if (pullResult.getMsgFoundList() == null || pullResult.getMsgFoundList().isEmpty()) {
            DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest);
</code></pre><p>如果拉取结果响应中包含的消息列表为空，或者列表为空列表，则立即发起下一次拉取请求。以便唤醒PullMessageService再次执行拉取；之所以列表为空，是因为客户端通过TAG对消息进行了过滤，因此会出现过滤后列表为空的情况。</p>
<pre><code>} else {
    // 取出第一个消息的offset
    firstMsgOffset = pullResult.getMsgFoundList().get(0).getQueueOffset();

    DefaultMQPushConsumerImpl.this.getConsumerStatsManager().incPullTPS(pullRequest.getConsumerGroup(),
        pullRequest.getMessageQueue().getTopic(), pullResult.getMsgFoundList().size());

    boolean dispatchToConsume = processQueue.putMessage(pullResult.getMsgFoundList());
    DefaultMQPushConsumerImpl.this.consumeMessageService.submitConsumeRequest(
        pullResult.getMsgFoundList(),
        processQueue,
        pullRequest.getMessageQueue(),
        dispatchToConsume);
</code></pre><p>将拉取到的消息保存到processQueue中，通过submitConsumeRequest方法将拉取到的消息提交给ConsumeMessageService进行消息消费，这里是一个异步方法。</p>
<p>PullCallBack将消息提交给consumeMessageService之后就直接返回了，不关心消息具体是如何消费的。</p>
<pre><code>    if (DefaultMQPushConsumerImpl.this.defaultMQPushConsumer.getPullInterval() &gt; 0) {
        DefaultMQPushConsumerImpl.this.executePullRequestLater(pullRequest,
            DefaultMQPushConsumerImpl.this.defaultMQPushConsumer.getPullInterval());
    } else {
        DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest);
    }
}
</code></pre><blockquote>
<p>这里的逻辑比较重要，实现了消息的持续拉取。具体的逻辑为：</p>
</blockquote>
<p>将消息提交给消费者线程之后，PullCallBack立即返回，表明当前消息拉取已经完成。</p>
<p>判断PullInterval参数，如果PullInterval&gt;0，等待PullInterval毫秒之后将PullRequest对象放到PullMessageService的pullRequestQueue消息拉取队列中。</p>
<p>pullRequestQueue的下次拉取被激活，从而达到消息持续拉取的目的，拉取的频率几乎是准实时的。</p>
<pre><code>    if (pullResult.getNextBeginOffset() &lt; prevRequestOffset
        || firstMsgOffset &lt; prevRequestOffset) {
        log.warn(
            &quot;[BUG] pull message result maybe data wrong, nextBeginOffset: {} firstMsgOffset: {} prevRequestOffset: {}&quot;,
            pullResult.getNextBeginOffset(),
            firstMsgOffset,
            prevRequestOffset);
    }

    break;
case NO_NEW_MSG:
    pullRequest.setNextOffset(pullResult.getNextBeginOffset());

    DefaultMQPushConsumerImpl.this.correctTagsOffset(pullRequest);

    DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest);
    break;
case NO_MATCHED_MSG:
    pullRequest.setNextOffset(pullResult.getNextBeginOffset());

    DefaultMQPushConsumerImpl.this.correctTagsOffset(pullRequest);

    DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest);
    break;
</code></pre><p>如果返回的拉取结果为NO_NEW_MSG、NO_MATCHED_MSG，则使用服务端校准的offset发起下一次拉取请求。</p>
<pre><code>case OFFSET_ILLEGAL:
    log.warn(&quot;the pull request offset illegal, {} {}&quot;,
        pullRequest.toString(), pullResult.toString());
    pullRequest.setNextOffset(pullResult.getNextBeginOffset());

    pullRequest.getProcessQueue().setDropped(true);
    DefaultMQPushConsumerImpl.this.executeTaskLater(new Runnable() {
</code></pre><p>如果返回的拉取结果状态为OFFSET_ILLEGAL，即offset非法；首先设置ProcessQueue的Dropped为true，将该消息队列标记为丢弃。通过服务端下一次校准的offset尝试对当前消息的消费进度进行更新。</p>
<pre><code>@Override
public void run() {
    try {
        DefaultMQPushConsumerImpl.this.offsetStore.updateOffset(pullRequest.getMessageQueue(),
            pullRequest.getNextOffset(), false);
</code></pre><p>持久化当前消息的消费进度</p>
<pre><code>DefaultMQPushConsumerImpl.this.offsetStore.persist(pullRequest.getMessageQueue());

DefaultMQPushConsumerImpl.this.rebalanceImpl.removeProcessQueue(pullRequest.getMessageQueue());
</code></pre><p>将当前消息队列从rebalanceImpl的ProcessQueue中移除，对当前队列的消息拉取进行暂停处理，等待下一次rebalance。</p>
<pre><code>                            log.warn(&quot;fix the pull request offset, {}&quot;, pullRequest);
                        } catch (Throwable e) {
                            log.error(&quot;executeTaskLater Exception&quot;, e);
                        }
                    }
                }, 10000);
                break;
            default:
                break;
        }
    }
}
</code></pre><p>offset校准时，基本上使用原先的offset。</p>
<p>客户端进行消费进度，只有实际消费进度大于当前消费进度会会进行offset的覆盖操作，从而保证offset的准确性。</p>
<pre><code>    @Override
    public void onException(Throwable e) {
        if (!pullRequest.getMessageQueue().getTopic().startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) {
            log.warn(&quot;execute the pull request exception&quot;, e);
        }

        DefaultMQPushConsumerImpl.this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_EXCEPTION);
    }
};
</code></pre><p>如果拉取结果异常，则3s后将消息拉取请求重新将PullRequest对象放到PullMessageService的pullRequestQueue消息拉取队列中。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文主要对PullMessageService消息拉取逻辑进行了分析，整个流程还是比较复杂的。其中的一些编码套路在实战中也是能够借鉴的，希望本文能够对读者理解消息拉取有所帮助。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我们继续对消息消费流程的源码进行解析。&lt;/p&gt;
&lt;p&gt;本文主要针对push模式下的消息拉取流程进行解析。我们重点分析集群消费模式，对于广播模式其实很好理解，每个消费者都需要拉取主题下面的所有消费队列的消息。&lt;/p&gt;
&lt;p&gt;在集群消费模式下，同一个消费者组内包含了多个消费者实例，同一个topic下存在多个消费队列。对于单个消费者组，其内部维护了一个线程池进行消息消费，这部分内容可以移步 &lt;a href=&quot;http://wuwenliang.net/2019/08/15/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ%E4%B9%8B%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-2/&quot;&gt;跟我学RocketMQ之消息消费源码解析(2)&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;之前我们已经研究了消费者的初始化流程，在启动MQClientInstance过程中，启动了一个消息拉取线程PullMessageService进行消息拉取工作。&lt;/p&gt;
    
    </summary>
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/categories/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/tags/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
  </entry>
  
  <entry>
    <title>跟我学RocketMQ之订阅关系一致性源码讨论</title>
    <link href="http://wuwenliang.net/2019/08/20/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ%E4%B9%8B%E8%AE%A2%E9%98%85%E5%85%B3%E7%B3%BB%E4%B8%80%E8%87%B4%E6%80%A7%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
    <id>http://wuwenliang.net/2019/08/20/跟我学RocketMQ之订阅关系一致性源码分析/</id>
    <published>2019-08-19T18:04:49.000Z</published>
    <updated>2019-08-21T01:30:41.713Z</updated>
    
    <content type="html"><![CDATA[<p>RocketMQ消费者在进行消费时，需要遵循 “订阅关系一致” 原则，关于订阅关系一致，我引用阿里云RocketMQ页面的解释，如下图：</p>
<p><img src="/2019/08/20/跟我学RocketMQ之订阅关系一致性源码分析/./rmq0.png" alt="rmq0.png"></p>
<p>从图中可以提炼出关键词，即：</p>
<blockquote>
<p>同一个消费者组订阅的topic、topic中的tag必须保持一致，否则会出现消费不到消息的情况。</p>
</blockquote>
<p>举个例子：比如我们有个topic名为DEMO_TOPIC，它有两个tag，分别为tagA、tagB。用一个消费者组demo_group分别订阅tagA、tagB，这时就会出现某个tag对应的消费者消费不到消息的情况。</p>
<p>解决方法就是：针对不同的tag使用不同的消费者组，在上面的案例中的解决方法为：使用demo_group_A 订阅tagA，使用demo_group_B订阅tagB。</p>
<p>提供了解决方案，还是有些意犹未尽，那么我们就深入RocketMQ的源码，感受一下订阅关系一致的机理。</p>
<a id="more"></a>
<h2 id="心跳维持MQClientInstance-java"><a href="#心跳维持MQClientInstance-java" class="headerlink" title="心跳维持MQClientInstance.java"></a>心跳维持MQClientInstance.java</h2><p>在之前的源码解析中，我们已经讲到了消费者客户端实例MQClientInstance中启动了心跳维持线程，具体的代码如下：</p>
<pre><code>public void start() throws MQClientException {

    synchronized (this) {
        switch (this.serviceState) {
            case CREATE_JUST:
                this.serviceState = ServiceState.START_FAILED;
                // If not specified,looking address from name server
                if (null == this.clientConfig.getNamesrvAddr()) {
                    this.mQClientAPIImpl.fetchNameServerAddr();
                }
                // Start request-response channel
                this.mQClientAPIImpl.start();
                // Start various schedule tasks
                this.startScheduledTask();
</code></pre><p>我们进入方法startScheduledTask();</p>
<pre><code>this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() {

    @Override
    public void run() {
        try {
            MQClientInstance.this.cleanOfflineBroker();
            MQClientInstance.this.sendHeartbeatToAllBrokerWithLock();
        } catch (Exception e) {
            log.error(&quot;ScheduledTask sendHeartbeatToAllBroker exception&quot;, e);
        }
    }
}, 1000, this.clientConfig.getHeartbeatBrokerInterval(), TimeUnit.MILLISECONDS);
</code></pre><p>这段代码中，主要向定时任务调度线程池中提交了清理离线Broker、发送心跳包到所有broker这两个任务，我们重点看心跳包发送方法sendHeartbeatToAllBrokerWithLock();</p>
<pre><code>public void sendHeartbeatToAllBrokerWithLock() {
    if (this.lockHeartbeat.tryLock()) {
        try {
            this.sendHeartbeatToAllBroker();
            this.uploadFilterClassSource();
        } catch (final Exception e) {
            log.error(&quot;sendHeartbeatToAllBroker exception&quot;, e);
        } finally {
            this.lockHeartbeat.unlock();
        }
    } else {
        log.warn(&quot;lock heartBeat, but failed.&quot;);
    }
}
</code></pre><p>继续进入sendHeartbeatToAllBroker()方法查看逻辑。</p>
<pre><code>private void sendHeartbeatToAllBroker() {

    // 构造前置心跳包
    final HeartbeatData heartbeatData = this.prepareHeartbeatData();
    final boolean producerEmpty = heartbeatData.getProducerDataSet().isEmpty();
    final boolean consumerEmpty = heartbeatData.getConsumerDataSet().isEmpty();

    // 没有消费者或生产者
    if (producerEmpty &amp;&amp; consumerEmpty) {
        log.warn(&quot;sending heartbeat, but no consumer and no producer&quot;);
        return;
    }

    if (!this.brokerAddrTable.isEmpty()) {
        long times = this.sendHeartbeatTimesTotal.getAndIncrement();
        Iterator&lt;Entry&lt;String, HashMap&lt;Long, String&gt;&gt;&gt; it = this.brokerAddrTable.entrySet().iterator();
        while (it.hasNext()) {
            Entry&lt;String, HashMap&lt;Long, String&gt;&gt; entry = it.next();
            String brokerName = entry.getKey();
            HashMap&lt;Long, String&gt; oneTable = entry.getValue();
            if (oneTable != null) {
                for (Map.Entry&lt;Long, String&gt; entry1 : oneTable.entrySet()) {
                    Long id = entry1.getKey();
                    String addr = entry1.getValue();
                    if (addr != null) {
                        if (consumerEmpty) {
                            if (id != MixAll.MASTER_ID)
                                continue;
                        }

                        try {
                            // 真正发送心跳的逻辑
                            int version = this.mQClientAPIImpl.sendHearbeat(addr, heartbeatData, 3000);
                            if (!this.brokerVersionTable.containsKey(brokerName)) {
                                this.brokerVersionTable.put(brokerName, new HashMap&lt;String, Integer&gt;(4));
                            }
                            this.brokerVersionTable.get(brokerName).put(addr, version);
                            if (times % 20 == 0) {
                                log.info(&quot;send heart beat to broker[{} {} {}] success&quot;, brokerName, id, addr);
                                log.info(heartbeatData.toString());
                            }
                        } catch (Exception e) {
                            ...省略异常...
                        }
                    }
                }
            }
        }
    }
}
</code></pre><p>这个方法中向所有Broker发送心跳，心跳消息类型为是HEART_BEAT类型的消息，这类消息在broker中使用ClientManageProcessor处理，那么我们就进入ClientManageProcessor看下心跳处理逻辑:heartBeat()方法</p>
<h2 id="broker心跳处理逻辑"><a href="#broker心跳处理逻辑" class="headerlink" title="broker心跳处理逻辑"></a>broker心跳处理逻辑</h2><pre><code>[ClientManageProcessor.java]
public RemotingCommand heartBeat(ChannelHandlerContext ctx, RemotingCommand request) {
    RemotingCommand response = RemotingCommand.createResponseCommand(null);
    // 解码客户端的心跳请求体
    HeartbeatData heartbeatData = HeartbeatData.decode(request.getBody(), HeartbeatData.class);
    ClientChannelInfo clientChannelInfo = new ClientChannelInfo(
        ctx.channel(),
        heartbeatData.getClientID(),
        request.getLanguage(),
        request.getVersion()
    );

    for (ConsumerData data : heartbeatData.getConsumerDataSet()) {

        // 消息订阅组配置
        SubscriptionGroupConfig subscriptionGroupConfig =
            this.brokerController.getSubscriptionGroupManager().findSubscriptionGroupConfig(
                data.getGroupName());
        boolean isNotifyConsumerIdsChangedEnable = true;
        if (null != subscriptionGroupConfig) {
            isNotifyConsumerIdsChangedEnable = subscriptionGroupConfig.isNotifyConsumerIdsChangedEnable();
            int topicSysFlag = 0;
            if (data.isUnitMode()) {
                topicSysFlag = TopicSysFlag.buildSysFlag(false, true);
            }
            String newTopic = MixAll.getRetryTopic(data.getGroupName());
            this.brokerController.getTopicConfigManager().createTopicInSendMessageBackMethod(
                newTopic,
                subscriptionGroupConfig.getRetryQueueNums(),
                PermName.PERM_WRITE | PermName.PERM_READ, topicSysFlag);
        }

        // 注册消费者实例
        boolean changed = this.brokerController.getConsumerManager().registerConsumer(
            data.getGroupName(),
            clientChannelInfo,
            data.getConsumeType(),
            data.getMessageModel(),
            data.getConsumeFromWhere(),
            data.getSubscriptionDataSet(),
            isNotifyConsumerIdsChangedEnable
        );

        if (changed) {
            log.info(&quot;registerConsumer info changed {} {}&quot;,
                data.toString(),
                RemotingHelper.parseChannelRemoteAddr(ctx.channel())
            );
        }
    }

    for (ProducerData data : heartbeatData.getProducerDataSet()) {
        this.brokerController.getProducerManager().registerProducer(data.getGroupName(),
            clientChannelInfo);
    }
    response.setCode(ResponseCode.SUCCESS);
    response.setRemark(null);
    return response;
}
</code></pre><p>我们主要关注registerConsumer()方法，此处broker会根据consumer发送的消息，获取自身记录的消费者订阅信息，这个逻辑是按照消费组为单位获取的，我们进入registerConsumer方法体</p>
<pre><code>[ConsumerManager.java]
public boolean registerConsumer(final String group, 
final ClientChannelInfo clientChannelInfo,
    ConsumeType consumeType, 
    MessageModel messageModel, 
    ConsumeFromWhere consumeFromWhere,
    final Set&lt;SubscriptionData&gt; subList, boolean isNotifyConsumerIdsChangedEnable) {

    // 获取消费者组信息
    ConsumerGroupInfo consumerGroupInfo = this.consumerTable.get(group);

    // 不存在则根据心跳构造新的消费组信息
    if (null == consumerGroupInfo) {
        ConsumerGroupInfo tmp = new ConsumerGroupInfo(group, consumeType, messageModel, consumeFromWhere);
        ConsumerGroupInfo prev = this.consumerTable.putIfAbsent(group, tmp);
        consumerGroupInfo = prev != null ? prev : tmp;
    }

    // 更新ClientChannelInfo
    boolean r1 =
        consumerGroupInfo.updateChannel(clientChannelInfo, consumeType, messageModel,
            consumeFromWhere);

    // 更新订阅关系表
    boolean r2 = consumerGroupInfo.updateSubscription(subList);

    if (r1 || r2) {
        if (isNotifyConsumerIdsChangedEnable) {
            this.consumerIdsChangeListener.handle(ConsumerGroupEvent.CHANGE, group, consumerGroupInfo.getAllChannel());
        }
    }

    this.consumerIdsChangeListener.handle(ConsumerGroupEvent.REGISTER, group, subList);

    return r1 || r2;
}
</code></pre><p>我们仔细研究一下这段代码，首先</p>
<pre><code>ConsumerGroupInfo prev = this.consumerTable.putIfAbsent(group, tmp);
</code></pre><p>首次不存在订阅关系直接讲订阅关系放置到订阅关系表。</p>
<p>接着进入consumerGroupInfo.updateSubscription(subList);方法</p>
<pre><code>[ConsumerGroupInfo.java]
public boolean updateSubscription(final Set&lt;SubscriptionData&gt; subList) {
    boolean updated = false;

    // 遍历订阅关系列表
    for (SubscriptionData sub : subList) {
        SubscriptionData old = this.subscriptionTable.get(sub.getTopic());
        // 如果原先的订阅关系不存在
        if (old == null) {
            // 更新本订阅关系
            SubscriptionData prev = this.subscriptionTable.putIfAbsent(sub.getTopic(), sub);
            if (null == prev) {
                updated = true;
                log.info(&quot;subscription changed, add new topic, group: {} {}&quot;,
                    this.groupName,
                    sub.toString());
            }
        // 如果当前的version大于原有version，则更新订阅关系
        // version值为系统时间戳
        // (SubscriptionData.java)
        // private long subVersion = System.currentTimeMillis();
        } else if (sub.getSubVersion() &gt; old.getSubVersion()) {
            if (this.consumeType == ConsumeType.CONSUME_PASSIVELY) {
                log.info(&quot;subscription changed, group: {} OLD: {} NEW: {}&quot;,
                    this.groupName,
                    old.toString(),
                    sub.toString()
                );
            }

            this.subscriptionTable.put(sub.getTopic(), sub);
        }
    }
</code></pre><p>这里主要做订阅关系表更新逻辑，如果不存在订阅关系则直接更新；如果存在则比较哪一个更新，最新的会覆盖老的那一个。</p>
<pre><code>Iterator&lt;Entry&lt;String, SubscriptionData&gt;&gt; it = this.subscriptionTable.entrySet().iterator();
while (it.hasNext()) {
    Entry&lt;String, SubscriptionData&gt; next = it.next();
    String oldTopic = next.getKey();

    boolean exist = false;
    for (SubscriptionData sub : subList) {
        if (sub.getTopic().equals(oldTopic)) {
            exist = true;
            break;
        }
    }

    if (!exist) {
        log.warn(&quot;subscription changed, group: {} remove topic {} {}&quot;,
            this.groupName,
            oldTopic,
            next.getValue().toString()
        );

        it.remove();
        updated = true;
    }
}

this.lastUpdateTimestamp = System.currentTimeMillis();

return updated;
</code></pre><p>继续往下看，对订阅关系表进行迭代处理。</p>
<p>如果当前的订阅的topic与上次的topic不相等，则exist（topic存在标识）设置为true，进入if代码块，执行remove操作，将老的topic删掉，后续的topic就覆盖了老的topic。</p>
<p>consumerTable中存放按照消费者进行划分依据的消费者信息。如果一个组的消费信息不一样，在上文举的例子中，则订阅了topicA的消费者心跳信息首先通知broker自己组订阅了topicA/tagA，broker记录了该订阅关系并更新了本地的订阅关系表。当另外的心跳发送过来，通知broker当前组订阅的是topicB/tagB，后来的这一个的时间戳必然大于前一个，就会将前一个覆盖，导致订阅关系发生变化。</p>
<p>这样会导致了订阅消息相互覆盖，当拉取消息时，会存在一个消费者没法拉到消息，因为Broker上查询不到该订阅信息。</p>
<h2 id="其他原因"><a href="#其他原因" class="headerlink" title="其他原因"></a>其他原因</h2><p>除了上述原因外，还有一个更为重要的原因在于消息的Rebalance过程。我们看一下RebalanceImpl.java</p>
<pre><code>private void rebalanceByTopic(final String topic, final boolean isOrder) {
    switch (messageModel) {
        case BROADCASTING: {
            ...省略...
        case CLUSTERING: {
            Set&lt;MessageQueue&gt; mqSet = this.topicSubscribeInfoTable.get(topic);
            List&lt;String&gt; cidAll = this.mQClientFactory.findConsumerIdList(topic, consumerGroup);
            if (null == mqSet) {
                if (!topic.startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) {
                    log.warn(&quot;doRebalance, {}, but the topic[{}] not exist.&quot;, consumerGroup, topic);
                }
            }
</code></pre><p>这里对某个topic下消息的进行Rebalance，我们进入 this.mQClientFactory.findConsumerIdList(topic, consumerGroup);这一行</p>
<pre><code>[MQClientInstance.java]
public List&lt;String&gt; findConsumerIdList(final String topic, final String group) {
        String brokerAddr = this.findBrokerAddrByTopic(topic);
        if (null == brokerAddr) {
            this.updateTopicRouteInfoFromNameServer(topic);
            brokerAddr = this.findBrokerAddrByTopic(topic);
        }

        if (null != brokerAddr) {
            try {
                return this.mQClientAPIImpl.getConsumerIdListByGroup(brokerAddr, group, 3000);
            } catch (Exception e) {
                log.warn(&quot;getConsumerIdListByGroup exception, &quot; + brokerAddr + &quot; &quot; + group, e);
            }
        }

        return null;
    }
</code></pre><p>这里根据topic获取到broker地址，如果broker地址存在则获取消费者id列表。</p>
<p>这里是根据consumerGroup组来进行选择的，如果同一个group订阅了两个以上topic或者多个tag，则会把另外一个topic的消费者也取下来，导致Rebalance之后出现问题，这会导致每个topic下面的数据量少一半（如果是2个不同topic）</p>
<p>关于消息的Rebalance过程我们在后续的文章中会单独进行分析。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;RocketMQ消费者在进行消费时，需要遵循 “订阅关系一致” 原则，关于订阅关系一致，我引用阿里云RocketMQ页面的解释，如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/08/20/跟我学RocketMQ之订阅关系一致性源码分析/./rmq0.png&quot; alt=&quot;rmq0.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;从图中可以提炼出关键词，即：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;同一个消费者组订阅的topic、topic中的tag必须保持一致，否则会出现消费不到消息的情况。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;举个例子：比如我们有个topic名为DEMO_TOPIC，它有两个tag，分别为tagA、tagB。用一个消费者组demo_group分别订阅tagA、tagB，这时就会出现某个tag对应的消费者消费不到消息的情况。&lt;/p&gt;
&lt;p&gt;解决方法就是：针对不同的tag使用不同的消费者组，在上面的案例中的解决方法为：使用demo_group_A 订阅tagA，使用demo_group_B订阅tagB。&lt;/p&gt;
&lt;p&gt;提供了解决方案，还是有些意犹未尽，那么我们就深入RocketMQ的源码，感受一下订阅关系一致的机理。&lt;/p&gt;
    
    </summary>
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/categories/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/tags/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
  </entry>
  
</feed>
