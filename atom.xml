<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>朝·闻·道</title>
  <subtitle>SnoWalker&#39;s Blog</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://wuwenliang.net/"/>
  <updated>2020-11-01T15:06:25.085Z</updated>
  <id>http://wuwenliang.net/</id>
  
  <author>
    <name>SnoWalker</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Java后端研发套路之灰度策略</title>
    <link href="http://wuwenliang.net/2020/11/01/Java%E5%90%8E%E7%AB%AF%E7%A0%94%E5%8F%91%E5%A5%97%E8%B7%AF%E4%B9%8B%E7%81%B0%E5%BA%A6%E7%AD%96%E7%95%A5/"/>
    <id>http://wuwenliang.net/2020/11/01/Java后端研发套路之灰度策略/</id>
    <published>2020-11-01T14:58:00.000Z</published>
    <updated>2020-11-01T15:06:25.085Z</updated>
    
    <content type="html"><![CDATA[<p>日常开发中，对于遗留系统代码逻辑的改造，通常不会粗暴地采用停机更新方式直接迁移到新业务逻辑，往往需要通过灰度方式逐步迁移到新逻辑，最后再把老业务逻辑下线。</p>
<p>这个过程中就涉及到新老业务逻辑并存的问题，而这个问题是需要研发同学去通过工具、编码、配置等方式实现灰度策略，制定灰度计划，并付诸实施，保障系统能够平稳地从老业务逻辑迁移至新业务逻辑。</p>
<p>通常，如果是http网关类的接口灰度，我们可以利用网关，如nginx自身的能力，根据cookie中传递的唯一标识，进行百分比分流，通过免开发的方式进行灰度。</p>
<p>但实际开发中，我们面对的系统不只是网关类的系统，大部分情况下，分布式系统开发中面对的是RPC类接口或者异步消息逻辑，对于这种代码逻辑的灰度就需要研发同学通过编码方式，细粒度的进行灰度。</p>
<p>本文中，我们就后者展开代码级别的讨论和分享，向读者介绍笔者面对接口级别的灰度场景，是如何通过编码实现具体的灰度策略的。</p>
<a id="more"></a>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;日常开发中，对于遗留系统代码逻辑的改造，通常不会粗暴地采用停机更新方式直接迁移到新业务逻辑，往往需要通过灰度方式逐步迁移到新逻辑，最后再把老业务逻辑下线。&lt;/p&gt;
&lt;p&gt;这个过程中就涉及到新老业务逻辑并存的问题，而这个问题是需要研发同学去通过工具、编码、配置等方式实现灰度策略，制定灰度计划，并付诸实施，保障系统能够平稳地从老业务逻辑迁移至新业务逻辑。&lt;/p&gt;
&lt;p&gt;通常，如果是http网关类的接口灰度，我们可以利用网关，如nginx自身的能力，根据cookie中传递的唯一标识，进行百分比分流，通过免开发的方式进行灰度。&lt;/p&gt;
&lt;p&gt;但实际开发中，我们面对的系统不只是网关类的系统，大部分情况下，分布式系统开发中面对的是RPC类接口或者异步消息逻辑，对于这种代码逻辑的灰度就需要研发同学通过编码方式，细粒度的进行灰度。&lt;/p&gt;
&lt;p&gt;本文中，我们就后者展开代码级别的讨论和分享，向读者介绍笔者面对接口级别的灰度场景，是如何通过编码实现具体的灰度策略的。&lt;/p&gt;
    
    </summary>
    
      <category term="Java" scheme="http://wuwenliang.net/categories/Java/"/>
    
    
      <category term="Java" scheme="http://wuwenliang.net/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Java内存阻塞队列实例</title>
    <link href="http://wuwenliang.net/2020/10/20/Java%E5%86%85%E5%AD%98%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97%E5%AE%9E%E4%BE%8B/"/>
    <id>http://wuwenliang.net/2020/10/20/Java内存阻塞队列实例/</id>
    <published>2020-10-20T15:54:46.000Z</published>
    <updated>2020-10-20T16:40:32.323Z</updated>
    
    <content type="html"><![CDATA[<p>在之前的一篇文章 <a href="http://wuwenliang.net/2019/08/19/%E6%89%8B%E5%86%99JDK%E7%BB%84%E4%BB%B6%E4%B9%8B%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97BlockedQueue/">手写JDK组件之阻塞队列BlockedQueue</a> 中  ，我们模仿Java的ArrayBlockingQueue实现了一个阻塞队列。并通过该案例对阻塞队列的实现机制有了一个初步的认识。</p>
<p>实际上，Java中的阻塞队列用处还是比较广泛的，尤其是当我们不需要使用复杂的分布式消息队列，只是想要基于生产者-消费者模型，解耦业务逻辑，那么我们就可以借助内存队列实现。</p>
<p>这类型业务场景往往具备以下特点：</p>
<ul>
<li>消息发送量不多</li>
<li>消息的安全性不高，可以容忍丢失</li>
<li>不需要保证HA</li>
<li>不需要提供完备的failover机制</li>
</ul>
<p>举个例子，比如说当订单下单成功后我们想发送一个站内信，通知商户或者用户下单成功，仅仅作为一个提醒。类似这种场景，我们就可以借助内存队列实现。</p>
<p>基于我们刚提出的这个场景，编写一个demo进行验证。</p>
<a id="more"></a>
<h2 id="场景抽象"><a href="#场景抽象" class="headerlink" title="场景抽象"></a>场景抽象</h2><blockquote>
<p>我们为该场景划分几个部分</p>
</blockquote>
<h3 id="消息发送端"><a href="#消息发送端" class="headerlink" title="消息发送端"></a>消息发送端</h3><p>封装了消息发送、消息合法性校验、消息体转化、内容序列化以及入队逻辑，提供友好的api被业务代码所使用。</p>
<h3 id="阻塞队列"><a href="#阻塞队列" class="headerlink" title="阻塞队列"></a>阻塞队列</h3><p>基于Java的BlockQueue实现，在外层进行一定封装。</p>
<h3 id="消息消费端"><a href="#消息消费端" class="headerlink" title="消息消费端"></a>消息消费端</h3><p>负责读取、并对对列中消息进行消费，当没有消息时进行阻塞等待，遇到异常时会交给异常处理机制进行处理。</p>
<h3 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h3><p>负责在消费消息过程中，出现异常时的后续处理。</p>
<p>常见的处理方式如：</p>
<ul>
<li>对消息经过处理后重新丢回队列</li>
<li>对消息进行持久化，后续进行重发等处理方式。</li>
</ul>
<p>为了提升消息的处理效率，对消费任务通常会通过一个线程去监听队列并阻塞等待。并且这个线程一般都是随应用启动而启动，即：消费端的线程是随着应用初始化而创建，并且常驻内存。</p>
<h2 id="代码讲解"><a href="#代码讲解" class="headerlink" title="代码讲解"></a>代码讲解</h2><p>简单了解了原理和场景，我们直接看代码实现。</p>
<h3 id="核心队列逻辑MailSendQueue-java"><a href="#核心队列逻辑MailSendQueue-java" class="headerlink" title="核心队列逻辑MailSendQueue.java"></a>核心队列逻辑MailSendQueue.java</h3><pre><code>public class MailSendQueue {

    private Logger logger = LoggerFactory.getLogger(MailSendQueue.class);

    /**队列大小*/
    public static final int QUEUE_MAX_SIZE = 100;

    private static MailSendQueue mailSendQueue = new MailSendQueue();

    /**阻塞队列*/
    private BlockingQueue&lt;MailMessageVO&gt; blockingQueue = new LinkedBlockingQueue&lt;MailMessageVO&gt;(QUEUE_MAX_SIZE);

    public static MailSendQueue getInstance() {
        return mailSendQueue;
    }

    /**
    * 消息入队
    *
    * @param alarmMessageVO
    * @return
    */
    public boolean push(MailMessageVO alarmMessageVO) {
        return this.blockingQueue.offer(alarmMessageVO);
    }

    /**
    * 消息出队
    *
    * @return
    */
    public MailMessageVO poll() {
        MailMessageVO result = null;
        try {
            result = this.blockingQueue.take();
        } catch (InterruptedException e) {
            logger.error(&quot;message poll error.&quot;, e);
        }
        return result;
    }

    /**
    * 获取队列大小
    *
    * @return
    */
    public int size() {
        return this.blockingQueue.size();
    }
}
</code></pre><p>类MailSendQueue是我们的邮件发送阻塞队列核心逻辑，它的核心是LinkedBlockingQueue，接受的元素为业务定义的邮件发送对象MailMessageVO。</p>
<p>MailSendQueue提供方法 <strong>push(MailMessageVO alarmMessageVO)</strong> 供消息发送，提供方法 <strong>poll()</strong> 供消息消费。</p>
<p>其中push方法核心为调用BlockingQueue的offer方法，</p>
<p><strong>offer方法会将指定元素插入此队列中（如果立即可行且不会违反容量限制），当插入成功时返回 true，如果当前没有可用的空间，则返回 false，不会抛异常：</strong></p>
<p>出队方法poll()的核心逻辑为调用blockingQueue的take()方法，</p>
<p><strong>take方法会从队列头部获取元素，获取后此队列的头部，在元素变得可用之前一直等待 。queue的长度 == 0 的时候，一直阻塞</strong></p>
<h3 id="生产者逻辑"><a href="#生产者逻辑" class="headerlink" title="生产者逻辑"></a>生产者逻辑</h3><pre><code>public class MessageProducer {
    public void sendMessage(MailMessageVO mailMessageVO) {
        MailSendQueue.getInstance().push(mailMessageVO);
    }
}
</code></pre><p>生产者逻辑很简洁，就是获取MailSendQueue实例，将消息对象入队。</p>
<h3 id="消费者逻辑"><a href="#消费者逻辑" class="headerlink" title="消费者逻辑"></a>消费者逻辑</h3><pre><code>public class MessageConsumer implements Runnable {

    private static final Logger LOGGER = Logger.getLogger(&quot;MessageConsumer&quot;);

    private Thread thread;

    public void start() {
        Thread thread = new Thread(this);
        thread.start();
    }

    @Override
    public void run() {
        while (true) {
            try {
                MailMessageVO mailMessageVO = MailSendQueue.getInstance().poll();
                consume(mailMessageVO);
            } catch (Exception e) {
                LOGGER.warning(&quot;Poll AlarmMessageVO from AlarmMessageQueue error or send alarm mail error.&quot;);
            }
        }
    }

    private void consume(MailMessageVO mailMessageVO) {
        Thread.currentThread().setName(&quot;MessageConsumer-thread&quot;);
        System.out.println(Thread.currentThread().getName() + &quot;-消费消息: &quot; + JSON.toJSONString(mailMessageVO));
    }
}
</code></pre><p>消费者逻辑通过线程触发，通过while，无限循环阻塞等待及消费消息。</p>
<p>此处的业务场景不需要对消费异常的消息进行重试，但在实际工作中，需要根据具体的业务场景去决定是否需要在catch里面进行异常处理流程。</p>
<p>根据经验，实际开发中，我们尽量考虑异常的重试机制，尤其是异步的消息处理场景，尽量对异常流程增加重试操作。比如，常见的措施就是对异常消息进行持久化操作。</p>
<h3 id="调用逻辑"><a href="#调用逻辑" class="headerlink" title="调用逻辑"></a>调用逻辑</h3><p>接着看一下如何进行调用。</p>
<pre><code>public class Client {

    public static void main(String[] args) throws InterruptedException {
        MessageProducer producer = new MessageProducer();
        MessageConsumer consumer = new MessageConsumer();
        consumer.start();

        for (int i = 0; i &lt; 100; i++) {
            MailMessageVO message = new MailMessageVO();
            message.setId(i).setContent(&quot;消息发送,第&quot; + i + &quot;条&quot;);
            producer.sendMessage(message);
            Thread.sleep(1000);
        }

    }
}
</code></pre><p>我们的场景是，发送100条消息，观察消费者的消费情况，日志输出如下：</p>
<pre><code>MessageConsumer-thread-消费消息: {&quot;content&quot;:&quot;消息发送,第0条&quot;,&quot;id&quot;:0}
MessageConsumer-thread-消费消息: {&quot;content&quot;:&quot;消息发送,第1条&quot;,&quot;id&quot;:1}
MessageConsumer-thread-消费消息: {&quot;content&quot;:&quot;消息发送,第2条&quot;,&quot;id&quot;:2}
MessageConsumer-thread-消费消息: {&quot;content&quot;:&quot;消息发送,第3条&quot;,&quot;id&quot;:3}
MessageConsumer-thread-消费消息: {&quot;content&quot;:&quot;消息发送,第4条&quot;,&quot;id&quot;:4}
......
</code></pre><p>可以看到输出符合预期。</p>
<p>此处要注意的是，之所以在消费者内部通过异步线程进行消费处理，主要原因在于消费端是阻塞的，如果在主线程中直接执行，效率较低。</p>
<h3 id="MailMessageVO"><a href="#MailMessageVO" class="headerlink" title="MailMessageVO"></a>MailMessageVO</h3><p>最后贴一下消息体的代码，用于备份。</p>
<pre><code>public class MailMessageVO {

    private int id;
    private String content;
    ...省略get set...
</code></pre><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文我们通过一个案例，基于Java的阻塞队列实现了一个异步的生产-消费模型，提供了一种简单的内存队列的实现方式。</p>
<p>在后续的文章中，我将继续带领读者完善代码，对内存队列使用中的异常场景进行补充讲解，从而掌握到更加贴近生产的内存队列使用经验。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在之前的一篇文章 &lt;a href=&quot;http://wuwenliang.net/2019/08/19/%E6%89%8B%E5%86%99JDK%E7%BB%84%E4%BB%B6%E4%B9%8B%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97BlockedQueue/&quot;&gt;手写JDK组件之阻塞队列BlockedQueue&lt;/a&gt; 中  ，我们模仿Java的ArrayBlockingQueue实现了一个阻塞队列。并通过该案例对阻塞队列的实现机制有了一个初步的认识。&lt;/p&gt;
&lt;p&gt;实际上，Java中的阻塞队列用处还是比较广泛的，尤其是当我们不需要使用复杂的分布式消息队列，只是想要基于生产者-消费者模型，解耦业务逻辑，那么我们就可以借助内存队列实现。&lt;/p&gt;
&lt;p&gt;这类型业务场景往往具备以下特点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;消息发送量不多&lt;/li&gt;
&lt;li&gt;消息的安全性不高，可以容忍丢失&lt;/li&gt;
&lt;li&gt;不需要保证HA&lt;/li&gt;
&lt;li&gt;不需要提供完备的failover机制&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;举个例子，比如说当订单下单成功后我们想发送一个站内信，通知商户或者用户下单成功，仅仅作为一个提醒。类似这种场景，我们就可以借助内存队列实现。&lt;/p&gt;
&lt;p&gt;基于我们刚提出的这个场景，编写一个demo进行验证。&lt;/p&gt;
    
    </summary>
    
      <category term="Java" scheme="http://wuwenliang.net/categories/Java/"/>
    
    
      <category term="Java" scheme="http://wuwenliang.net/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>跟我学RocketMQ之多DC部署HA方案概论</title>
    <link href="http://wuwenliang.net/2020/08/09/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ%E4%B9%8B%E5%A4%9ADC%E9%83%A8%E7%BD%B2HA%E6%96%B9%E6%A1%88%E6%A6%82%E8%AE%BA/"/>
    <id>http://wuwenliang.net/2020/08/09/跟我学RocketMQ之多DC部署HA方案概论/</id>
    <published>2020-08-09T14:46:46.000Z</published>
    <updated>2020-08-09T15:23:51.454Z</updated>
    
    <content type="html"><![CDATA[<p>在企业级生产环境，我们处于高可用的考虑，常常会部署多套MQ集群，提供集群高可用，保证高SLA。</p>
<p>具体到RoceketMQ，在生产环境下我们也需要考虑高可用部署，尤其是跨机房（跨DC）情况下的高可用。</p>
<a id="more"></a>
<h3 id="方案介绍"><a href="#方案介绍" class="headerlink" title="方案介绍"></a>方案介绍</h3><p>我们提供两组RocketMQ集群，假设他们分布在北京电信与联通两处机房。</p>
<p>生产端生产时默认发往电信机房，在电信RocketMQ集群不可用时，切换到联通RocketMQ集群上，从而保证消息生产过程不被打断。</p>
<p>而在消费端，同时启用两个消费者分别消费电信RocketMQ集群与联通RocketMQ集群，保证一定能消费到全量的消息。</p>
<p><strong>整个部署方式的示意图如下</strong><br><img src="/2020/08/09/跟我学RocketMQ之多DC部署HA方案概论/2.png" alt="部署方式"></p>
<p>正常场景下数据流向是 <strong>1 -&gt; 2 -&gt; 4</strong></p>
<p>发生切换后数据流向是 <strong>1 -&gt; 3 -&gt; 5</strong></p>
<h3 id="优缺点分析"><a href="#优缺点分析" class="headerlink" title="优缺点分析"></a>优缺点分析</h3><p>该方案存在几个关键点：</p>
<ol>
<li>生产者何时切换，换言之如何判定RocketMQ集群状态为不可用？</li>
<li>发生切换后，是否需要切换回来，以及何时需要切换回来？</li>
<li>切换后是否会造成消息丢失，如何解决？</li>
<li>切换后是否会造成消息顺序错乱，如何解决？</li>
<li>该高可用方案可以Cover哪些场景，以及无法Cover哪些场景？</li>
</ol>
<p>我们在下文中具体分析以上问题：</p>
<p><strong>1. 生产者何时发生切换，换言之，如何判定北京电信RocketMQ集群状态为不可用？</strong></p>
<p>策略：生产端由生产者自行根据本地发送状况决定，例如连续发送失败N次，则在本地标记该集群A为不可用状态。切换到集群B进行生产。</p>
<p><strong>2. 发生切换后，是否需要以及何时切换回来？</strong></p>
<p>生产端的健康检查线程会周期性的检查两个集群的状态，集群A故障后，必定会通过运维操作恢复，然后健康检查后将集群A的状态恢复为可用状态。此时是否需要切换有业务自行决定。</p>
<p>生产端为RocketMQ集群A和RocketMQ集群B配置分别一个优先级，如果两个集群优先级相同，在RocketMQ集群A恢复后不需要切换回去。如果RocketMQ集群A的优先级高于RocketMQ集群B，则在RocketMQ集群A恢复后切换会A。这样可以提供足够的灵活性。</p>
<p>建议在两个RocketMQ集群的性能与质量没有显著差异时，故障集群恢复后，不要切换回去。减少一次切换的开销。</p>
<p><strong>3. 切换后是否会造成消息丢失如何解决？</strong></p>
<p>生产端一旦认定集群A不可用会立即不再往集群A进行生产，而转向B进行生产。此时的消费端的两个消费者则会被动的发现消费者A不再接收到消息，而消费者B转而开始接收消息。消费端并不关注集群究竟发生了什么。</p>
<p>如果集群A是真的宕机或者断网，那么在集群A内积压的消息，故障期间无法再被消费者获取。如果消息具有强时效性，这部分数据应当被认为丢失，如果不具有强时效性，那么切换回去后，能被继续消费掉，可以认为不会丢失消息。如果集群A并非真的宕机或者断网，其实能提供消费，只是生产端认为其不可用，那么集群A内的消息会被消费者消费完，不会丢失消息。</p>
<p>综上，对于具有强时效性的业务场景，可以认为切换时存在消息丢失。因此业务需要有额外补偿机制，保证在某些消息一直未被消费时，通知到生产端，并触发重新生产。</p>
<p>同时，消费端做好消息去重的准备，因为切换回去后，可能会产生重复消费。</p>
<p><strong>4. 切换后是否会造成消息乱序如何解决？</strong></p>
<p>对于有序消息，生产端一般会根据Hash把同Key的消息发送到同一个Partition，然后消费者顺序消费Partition，从而保证消息的有序性。</p>
<p>切换之前以及切换之后，消息生产和消费仍然满足上述规律，因此消息仍旧是有序的。</p>
<p>切换的那一刻，会出现部分消息在故障集群A中，后续消息在集群B中，此时消费端可能会出现两种情况：</p>
<p>情况1：消费者A无法再取得故障集群A中的消息，消费者B开始获取集群B中的消息。会出现部分消息丢失，但是没有出现消息乱序。</p>
<p>情况2：消费者A仍然能够取得故障集群A中的消息，且消费者B开始获取集群B中的消息。此时会出现消费者A和消费者B两者之间部分消息乱序。</p>
<p>对于情况2，业务可以根据需要对消息添加一些版本信息，也就是发送方对消息进行全局的排序，作为消息顺序依据。</p>
<p><strong>5. 该高可用方案可以Cover哪些场景，无法Cover哪些场景？</strong></p>
<p>可以Cover的场景：</p>
<ul>
<li>电信/联通一处的RocketMQ集群所在机房宕机</li>
<li>电信/联通一处的RocketMQ集群所在机房断网</li>
<li>电信/联通一处的RocketMQ集群本身不可用</li>
</ul>
<p>不能Cover的场景：</p>
<ul>
<li>电信/联通两处RocketMQ集群同时宕机、断网、不可用</li>
<li>消费者所在机房与正在服务的RocketMQ集群之间网络不通</li>
</ul>
<h3 id="方案缺点"><a href="#方案缺点" class="headerlink" title="方案缺点"></a>方案缺点</h3><ol>
<li>需要生产端实现状态判断与切换逻辑，存在一定的工作量。</li>
<li>正常情况下只有一个集群在提供服务，资源存在浪费。</li>
</ol>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>到此我们对跨机房的高可用RocketMQ集群的部署就有了一定的了解，可以看到还是有很多额外的工作要做。</p>
<p>如果业务量不需要，则不需要建设如此复杂的架构，毕竟架构是演进出来的而不仅仅是设计出来的。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在企业级生产环境，我们处于高可用的考虑，常常会部署多套MQ集群，提供集群高可用，保证高SLA。&lt;/p&gt;
&lt;p&gt;具体到RoceketMQ，在生产环境下我们也需要考虑高可用部署，尤其是跨机房（跨DC）情况下的高可用。&lt;/p&gt;
    
    </summary>
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/categories/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/tags/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
  </entry>
  
  <entry>
    <title>再谈RestTemplate实战应用</title>
    <link href="http://wuwenliang.net/2020/06/28/%E5%86%8D%E8%B0%88RestTemplate%E5%AE%9E%E6%88%98%E5%BA%94%E7%94%A8/"/>
    <id>http://wuwenliang.net/2020/06/28/再谈RestTemplate实战应用/</id>
    <published>2020-06-28T10:08:27.000Z</published>
    <updated>2020-06-28T11:27:11.703Z</updated>
    
    <content type="html"><![CDATA[<p>笔者在两年前写过一篇RestTemplate使用相关的文章，地址: <a href="http://wuwenliang.net/2018/07/23/springboot%E4%B8%AD%E4%BD%BF%E7%94%A8RestTemplate%E8%B0%83%E7%94%A8web%E6%9C%8D%E5%8A%A1%E5%B0%8F%E7%BB%93/">springboot中使用RestTemplate调用web服务小结</a>。</p>
<p>文章写作时SpringBoot版本尚在1.x徘徊，随着SpringBoot版本升级，有些用法在2.x版本中已经不适用。恰逢最近又用到了RestTemplate进行HTTP接口对接，<br>因此写作本文对最新的使用方法进行小结，方便后续参考，也希望能够帮到读者更好的使用RestTemplate在2.x的SpringBoot中进行HTTP接口的调用。</p>
<p>对于Get方式请求，2.x与1.x是兼容的，因此可以直接阅读上文中提到的链接，本文就不再重复赘述。</p>
<a id="more"></a>
<h2 id="配置RestTemplate"><a href="#配置RestTemplate" class="headerlink" title="配置RestTemplate"></a>配置RestTemplate</h2><p>首先需要配置RestTemplate，这是使用它的必要条件。</p>
<p>在项目中引入web依赖，maven坐标如下：</p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
    &lt;version&gt;2.1.3.RELEASE&lt;/version&gt;
&lt;/dependency&gt;
</code></pre><p>只需要这个依赖即可。接着在项目中添加一个配置类，引入RestTemplate的bean定义，你可以直接引入下面的类。</p>
<pre><code>@Configuration
public class RestTemplateConfig {

    @Bean
    public RestTemplate restTemplate(ClientHttpRequestFactory factory){
        return new RestTemplate(factory);
    }

    @Bean
    public ClientHttpRequestFactory simpleClientHttpRequestFactory(){
        SimpleClientHttpRequestFactory factory = new SimpleClientHttpRequestFactory();
        /**读超时单位为ms*/
        factory.setReadTimeout(10000);
        /**连接超时单位为ms*/
        factory.setConnectTimeout(10000);
        return factory;
    }
}
</code></pre><p>这里，我指定读取超时时间和连接超时时间为10s，读者朋友可以根据自己的具体情况灵活配置。</p>
<h2 id="POST请求之表单提交"><a href="#POST请求之表单提交" class="headerlink" title="POST请求之表单提交"></a>POST请求之表单提交</h2><p>使用POST请求方式最常见的就是表单提交，更加专业的说法就是：content-type为 <strong>application/x-www-form-urlencoded</strong>。</p>
<p>使用RestTemplate请求 content-type为 <strong>application/x-www-form-urlencoded</strong> 格式的步骤如下：</p>
<h3 id="设置请求头"><a href="#设置请求头" class="headerlink" title="设置请求头"></a>设置请求头</h3><pre><code>HttpHeaders headers = new HttpHeaders();
headers.setContentType(MediaType.APPLICATION_FORM_URLENCODED);
</code></pre><p>在请求头中设置请求的content-type为application/x-www-form-urlencoded </p>
<h3 id="设置请求参数"><a href="#设置请求参数" class="headerlink" title="设置请求参数"></a>设置请求参数</h3><pre><code>MultiValueMap&lt;String, String&gt; requestParam= new LinkedMultiValueMap&lt;&gt;();
requestParam.add(&quot;paramA&quot;, paramA);
requestParam.add(&quot;paramB&quot;, paramB);
</code></pre><p>这里通过MultiValueMap设置请求参数，如果用get方式展示的话，格式类似于paramA=paramA&amp;paramB=paramB</p>
<h3 id="发送请求"><a href="#发送请求" class="headerlink" title="发送请求"></a>发送请求</h3><pre><code>HttpEntity&lt;MultiValueMap&lt;String, String&gt;&gt; requestEntity =
        new HttpEntity&lt;&gt;(requestParam, headers);

ResponseEntity&lt;String&gt; responseEntity = restTemplate.exchange(
        requestUrl, HttpMethod.POST, requestEntity, String.class);
</code></pre><ol>
<li>通过HttpEntity封装请求参数与headers</li>
<li>通过restTemplate.exchange方法发送请求，请求地址为requestUrl；请求方法为POST，请求参数为requestEntity，请求体数据格式为String</li>
</ol>
<p>exchange的完整方法签名如下：</p>
<pre><code>/**
 * Execute the HTTP method to the given URI template, writing the given request entity to the request, and
 * returns the response as {@link ResponseEntity}.
 * &lt;p&gt;URI Template variables are expanded using the given URI variables, if any.
 * @param url the URL
 * @param method the HTTP method (GET, POST, etc)
 * @param requestEntity the entity (headers and/or body) to write to the request
 * may be {@code null})
 * @param responseType the type of the return value
 * @param uriVariables the variables to expand in the template
 * @return the response as entity
 * @since 3.0.2
 */
&lt;T&gt; ResponseEntity&lt;T&gt; exchange(String url, HttpMethod method, @Nullable HttpEntity&lt;?&gt; requestEntity,
        Class&lt;T&gt; responseType, Object... uriVariables) throws RestClientException;
</code></pre><p>我们直接引用注释的解释：</p>
<ol>
<li>对给定的URI模板执行HTTP方法，将给定的请求实体写入请求，然后将响应返回为{@link ResponseEntity}。</li>
<li>URI模板变量使用给定的URI变量（如果有的话）进行扩展<ol>
<li>url              —请求地址网址</li>
<li>method           —HTTP方法（GET、POST等）</li>
<li>requestEntity    —要写入请求的实体（头和/或正文），可能是{@code null}）</li>
<li>responseType     —返回值的类型</li>
<li>uriVariables     —要在模板中展开的变量</li>
</ol>
</li>
<li>最终以实体形式返回响应</li>
</ol>
<h3 id="解析返回参"><a href="#解析返回参" class="headerlink" title="解析返回参"></a>解析返回参</h3><pre><code>// 这是一段防御代码
if (responseEntity == null) {
    return null;
}

String checkResponseBody = responseEntity.getBody();

// 这是一段防御代码
if (StringUtils.isBlank(checkResponseBody)) {
    return null;
}
</code></pre><p>通过<strong>responseEntity.getBody()</strong> 获取响应体。</p>
<h3 id="反序列化响应体为业务参数"><a href="#反序列化响应体为业务参数" class="headerlink" title="反序列化响应体为业务参数"></a>反序列化响应体为业务参数</h3><p>通过上一步的代码，我们已经能够从响应中获取到responseBody。</p>
<p>接着就可以使用自己喜欢的方式将其反序列化为对象。我习惯使用jackson。</p>
<p>一段简单的反序列化代码如下：</p>
<pre><code>JsonNode responseNode = OBJECT_MAPPER.readTree(checkResponseBody);
String status = responseNode.get(&quot;paramA&quot;).asText();
String msg = responseNode.get(&quot;paramB&quot;).asText();
</code></pre><p>这里解析出来的结果用json方式展示就是如下的样式：</p>
<pre><code>{
    &quot;paramA&quot; : &quot;paramA_value&quot;,
    &quot;paramB&quot; : &quot;paramB_value&quot;,
}
</code></pre><h2 id="POST请求之发送json"><a href="#POST请求之发送json" class="headerlink" title="POST请求之发送json"></a>POST请求之发送json</h2><p>除了上述的常见方式（表单提交）外，当前有些较为前卫的单位热衷于在请求阶段也发送json格式的数据，</p>
<p>相当于直接提交一个json文档。服务端需要对该json文档进行解析，从而完成一定的工作。</p>
<p>json格式的content-type为 <strong>application/json</strong></p>
<p>这里直接引用之前笔者写的开源秒杀案例中的代码进行讲解。</p>
<h3 id="设置请求头-1"><a href="#设置请求头-1" class="headerlink" title="设置请求头"></a>设置请求头</h3><pre><code>// 构造要序列化为json的业务对象
QueryOrdersResponse queryOrdersResponse = new QueryOrdersResponse();
queryOrdersRequest.setSign(sign);
ObjectMapper objectMapper = new ObjectMapper();

// 组装请求头
HttpHeaders headers = new HttpHeaders();
headers.setContentType(org.springframework.http.MediaType.APPLICATION_JSON);

// 构造请求体
HttpEntity&lt;QueryOrdersRequest&gt; httpEntity = new HttpEntity&lt;&gt;(queryOrdersRequest, headers);
</code></pre><ol>
<li>构造待发送的业务实体，为其设置属性</li>
<li>组装请求头，设置content-type为 <strong>application/json</strong></li>
<li>初始化HttpEntity， 通过有参构造方法设置业务实体与headers】</li>
</ol>
<h3 id="发送请求-1"><a href="#发送请求-1" class="headerlink" title="发送请求"></a>发送请求</h3><pre><code>// 2.发送请求
ResponseEntity&lt;String&gt; responseEntity = null;

// 2.1 发起请求
responseEntity = restTemplate.postForEntity(queryOrdersUrl, httpEntity, String.class);
System.out.println(&quot;----&quot; + JSON.toJSONString(responseEntity));
</code></pre><p>json格式的请求可以直接通过restTemplate.postForEntity发送，它的完整方法签名如下</p>
<pre><code>&lt;T&gt; ResponseEntity&lt;T&gt; postForEntity(String url, @Nullable Object request, Class&lt;T&gt; responseType,
    Object... uriVariables) throws RestClientException;
</code></pre><h3 id="解析返回参数"><a href="#解析返回参数" class="headerlink" title="解析返回参数"></a>解析返回参数</h3><p> 接收到ResponseEntity之后，通过 responseEntity.getBody();获取到responseBody，解析方式就和上文中提到的一致了。</p>
<p> 我们可以使用jackson/gson（笔者就不推荐用fastJson了，因为众人皆知的原因，八阿哥有点多啊……）来进行解析了。</p>
<pre><code>// 2.2. 解析返回参数
String responseBody = responseEntity.getBody();
queryOrdersResponse = objectMapper.readValue(responseBody, QueryOrdersResponse.class);
LOGGER.info(&quot;解析订单状态查询接口出参:[{}]&quot;, queryOrdersResponse.toString());
</code></pre><p>到此我们就实现了通过RestTemplate发送JSON格式的POST请求。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文偏应用实战，重点讲解了SpringBoot2.x版本中整合RestTemplate，并使用POST方法发送 <strong>application/x-www-form-urlencoded</strong> 及 <strong>application/json</strong> 两种超媒体文本的步骤。</p>
<p>方便自己以后能够快速落地，并希望能够对读者有所帮助。</p>
<p>相关原理解析会在未来的文章中发布，敬请期待。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;笔者在两年前写过一篇RestTemplate使用相关的文章，地址: &lt;a href=&quot;http://wuwenliang.net/2018/07/23/springboot%E4%B8%AD%E4%BD%BF%E7%94%A8RestTemplate%E8%B0%83%E7%94%A8web%E6%9C%8D%E5%8A%A1%E5%B0%8F%E7%BB%93/&quot;&gt;springboot中使用RestTemplate调用web服务小结&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;文章写作时SpringBoot版本尚在1.x徘徊，随着SpringBoot版本升级，有些用法在2.x版本中已经不适用。恰逢最近又用到了RestTemplate进行HTTP接口对接，&lt;br&gt;因此写作本文对最新的使用方法进行小结，方便后续参考，也希望能够帮到读者更好的使用RestTemplate在2.x的SpringBoot中进行HTTP接口的调用。&lt;/p&gt;
&lt;p&gt;对于Get方式请求，2.x与1.x是兼容的，因此可以直接阅读上文中提到的链接，本文就不再重复赘述。&lt;/p&gt;
    
    </summary>
    
      <category term="spring-boot" scheme="http://wuwenliang.net/categories/spring-boot/"/>
    
    
      <category term="spring-boot" scheme="http://wuwenliang.net/tags/spring-boot/"/>
    
  </entry>
  
  <entry>
    <title>Java8函数式编程之Stream编程详解(4)收集器</title>
    <link href="http://wuwenliang.net/2020/05/17/Java8%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%E4%B9%8BStream%E7%BC%96%E7%A8%8B%E8%AF%A6%E8%A7%A3-4-%E6%94%B6%E9%9B%86%E5%99%A8/"/>
    <id>http://wuwenliang.net/2020/05/17/Java8函数式编程之Stream编程详解-4-收集器/</id>
    <published>2020-05-17T05:23:06.000Z</published>
    <updated>2020-05-17T05:27:07.272Z</updated>
    
    <content type="html"><![CDATA[<p>本文我们重点讲解一下Stream中收集器Collector的主要使用方式。</p>
<h2 id="收集器"><a href="#收集器" class="headerlink" title="收集器"></a>收集器</h2><p>收集器（Collector）的作用为：将流中元素累积成一个结果作用于终端操作collect()上</p>
<p>关于收集器，我们主要关注：</p>
<pre><code>collect()（操作实现Collector接口的集合）、

Collector（接口）

Collectors（工具类）
</code></pre><p>日常开发中，我们使用最多的是预定义收集器功能（Collectors）</p>
<p>它的作用主要是：</p>
<pre><code>将流元素规约和汇总为一个值

将流元素分组

将流元素分区
</code></pre><a id="more"></a>
<h3 id="Collect-方法解析"><a href="#Collect-方法解析" class="headerlink" title="Collect()方法解析"></a>Collect()方法解析</h3><pre><code>&lt;R&gt; R collect(Supplier&lt;R&gt; supplier,                      初始化结果容器
            BiConsumer&lt;R, ? super T&gt; accumulator,      添加元素到结果容器的逻辑
            BiConsumer&lt;R, R&gt; combiner);                并行执行时多个结果容器的合并方式
</code></pre><p>我们此处介绍几个常用的预定义收集器方法</p>
<h3 id="集合收集器"><a href="#集合收集器" class="headerlink" title="集合收集器"></a>集合收集器</h3><pre><code>@Test
public void toList() {
    List&lt;Sku&gt; list = CartService.getCartSkuList();
    List&lt;Sku&gt; result = list.stream()
            .filter(sku -&gt; sku.getTotalPrice() &gt; 100)

            .collect(Collectors.toList());
    System.out.println(JSON.toJSONString(result, true));
}
</code></pre><p>这个用例的目的是：选出总价大于100的商品并打印，也就是大于100的sku会被保留。</p>
<p>运行结果：</p>
<pre><code>[
    {
        &quot;skuCategory&quot;:&quot;ELECTRONICS&quot;,
        &quot;skuId&quot;:2,
        &quot;skuName&quot;:&quot;无人机&quot;,
        &quot;skuPrice&quot;:1000.0,
        &quot;totalNum&quot;:10,
        &quot;totalPrice&quot;:1000.0
    },
    {
        &quot;skuCategory&quot;:&quot;ELECTRONICS&quot;,
        &quot;skuId&quot;:1,
        &quot;skuName&quot;:&quot;VR一体机&quot;,
        &quot;skuPrice&quot;:2100.0,
        &quot;totalNum&quot;:10,
        &quot;totalPrice&quot;:2100.0
    },
    {
        &quot;skuCategory&quot;:&quot;CLOTHING&quot;,
        &quot;skuId&quot;:13,
        &quot;skuName&quot;:&quot;衬衫&quot;,
        &quot;skuPrice&quot;:120.0,
        &quot;totalNum&quot;:10,
        &quot;totalPrice&quot;:120.0
    }
]

Process finished with exit code 0
</code></pre><h3 id="集合分组"><a href="#集合分组" class="headerlink" title="集合分组"></a>集合分组</h3><pre><code>@Test
public void group() {
    List&lt;Sku&gt; list = CartService.getCartSkuList();
    // key=分组条件  value=元素集合  即Map&lt;分组条件，结果集合&gt;
    Map&lt;Enum, List&lt;Sku&gt;&gt; result = list.stream()
            .collect(Collectors.groupingBy(sku -&gt; sku.getSkuCategory()));
    System.out.println(JSON.toJSONString(result, true));
}
</code></pre><p>这个用例的目的是：根据sku类别对list进行分组，分组结束后返回一个Map&lt;分组条件，结果集合&gt;，即key=分组条件  value=元素集合</p>
<p>运行结果：</p>
<pre><code>{&quot;CLOTHING&quot;:[
        {
            &quot;skuCategory&quot;:&quot;CLOTHING&quot;,
            &quot;skuId&quot;:4,
            &quot;skuName&quot;:&quot;牛仔裤&quot;,
            &quot;skuPrice&quot;:60.0,
            &quot;totalNum&quot;:10,
            &quot;totalPrice&quot;:60.0
        },
        {
            &quot;skuCategory&quot;:&quot;CLOTHING&quot;,
            &quot;skuId&quot;:13,
            &quot;skuName&quot;:&quot;衬衫&quot;,
            &quot;skuPrice&quot;:120.0,
            &quot;totalNum&quot;:10,
            &quot;totalPrice&quot;:120.0
        }
    ],&quot;BOOKS&quot;:[
        {
            &quot;skuCategory&quot;:&quot;BOOKS&quot;,
            &quot;skuId&quot;:121,
            &quot;skuName&quot;:&quot;Java编程思想&quot;,
            &quot;skuPrice&quot;:100.0,
            &quot;totalNum&quot;:10,
            &quot;totalPrice&quot;:100.0
        },
        {
            &quot;skuCategory&quot;:&quot;BOOKS&quot;,
            &quot;skuId&quot;:3,
            &quot;skuName&quot;:&quot;程序化广告&quot;,
            &quot;skuPrice&quot;:80.0,
            &quot;totalNum&quot;:10,
            &quot;totalPrice&quot;:80.0
        }
    ],&quot;ELECTRONICS&quot;:[
        {
            &quot;skuCategory&quot;:&quot;ELECTRONICS&quot;,
            &quot;skuId&quot;:2,
            &quot;skuName&quot;:&quot;无人机&quot;,
            &quot;skuPrice&quot;:1000.0,
            &quot;totalNum&quot;:10,
            &quot;totalPrice&quot;:1000.0
        },
        {
            &quot;skuCategory&quot;:&quot;ELECTRONICS&quot;,
            &quot;skuId&quot;:1,
            &quot;skuName&quot;:&quot;VR一体机&quot;,
            &quot;skuPrice&quot;:2100.0,
            &quot;totalNum&quot;:10,
            &quot;totalPrice&quot;:2100.0
        }
    ]
}
</code></pre><p>从运行结果我们可以看出满足要求。</p>
<h3 id="集合分区"><a href="#集合分区" class="headerlink" title="集合分区"></a>集合分区</h3><p>集合分区是分组的一种特例：</p>
<p>分区是由一个谓词作为分区函数，分区函数返回一个boolean值最终将分区结果分为两组，一组为boolean=true的   一组为boolean=false的通俗的说也就是满足条件的分为一组，不满足条件的为一组</p>
<pre><code>@Test
public void partition() {
    List&lt;Sku&gt; list = CartService.getCartSkuList();
    Map&lt;Boolean, List&lt;Sku&gt;&gt; partition = list.stream()
            .collect(Collectors.partitioningBy(sku -&gt; sku.getTotalPrice() &gt; 100));
    System.out.println(JSON.toJSONString(partition, true));
}
</code></pre><p>运行结果：</p>
<pre><code>{
    false:[
        {
            &quot;skuCategory&quot;:&quot;CLOTHING&quot;,
            &quot;skuId&quot;:4,
            &quot;skuName&quot;:&quot;牛仔裤&quot;,
            &quot;skuPrice&quot;:60.0,
            &quot;totalNum&quot;:10,
            &quot;totalPrice&quot;:60.0
        },
        {
            &quot;skuCategory&quot;:&quot;BOOKS&quot;,
            &quot;skuId&quot;:121,
            &quot;skuName&quot;:&quot;Java编程思想&quot;,
            &quot;skuPrice&quot;:100.0,
            &quot;totalNum&quot;:10,
            &quot;totalPrice&quot;:100.0
        },
        {
            &quot;skuCategory&quot;:&quot;BOOKS&quot;,
            &quot;skuId&quot;:3,
            &quot;skuName&quot;:&quot;程序化广告&quot;,
            &quot;skuPrice&quot;:80.0,
            &quot;totalNum&quot;:10,
            &quot;totalPrice&quot;:80.0
        }
    ],
true:[
        {
            &quot;skuCategory&quot;:&quot;ELECTRONICS&quot;,
            &quot;skuId&quot;:2,
            &quot;skuName&quot;:&quot;无人机&quot;,
            &quot;skuPrice&quot;:1000.0,
            &quot;totalNum&quot;:10,
            &quot;totalPrice&quot;:1000.0
        },
        {
            &quot;skuCategory&quot;:&quot;ELECTRONICS&quot;,
            &quot;skuId&quot;:1,
            &quot;skuName&quot;:&quot;VR一体机&quot;,
            &quot;skuPrice&quot;:2100.0,
            &quot;totalNum&quot;:10,
            &quot;totalPrice&quot;:2100.0
        },
        {
            &quot;skuCategory&quot;:&quot;CLOTHING&quot;,
            &quot;skuId&quot;:13,
            &quot;skuName&quot;:&quot;衬衫&quot;,
            &quot;skuPrice&quot;:120.0,
            &quot;totalNum&quot;:10,
            &quot;totalPrice&quot;:120.0
        }
    ]
}

Process finished with exit code 0
</code></pre><p>通过日志打印我们能够看出，根据是否满足断言将集合分为两个组。结果与分组很像，只不过key变成了true/false。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文我们重点讲解一下Stream中收集器Collector的主要使用方式。&lt;/p&gt;
&lt;h2 id=&quot;收集器&quot;&gt;&lt;a href=&quot;#收集器&quot; class=&quot;headerlink&quot; title=&quot;收集器&quot;&gt;&lt;/a&gt;收集器&lt;/h2&gt;&lt;p&gt;收集器（Collector）的作用为：将流中元素累积成一个结果作用于终端操作collect()上&lt;/p&gt;
&lt;p&gt;关于收集器，我们主要关注：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;collect()（操作实现Collector接口的集合）、

Collector（接口）

Collectors（工具类）
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;日常开发中，我们使用最多的是预定义收集器功能（Collectors）&lt;/p&gt;
&lt;p&gt;它的作用主要是：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;将流元素规约和汇总为一个值

将流元素分组

将流元素分区
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
      <category term="Java" scheme="http://wuwenliang.net/categories/Java/"/>
    
    
      <category term="Java" scheme="http://wuwenliang.net/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Java8函数式编程之Stream编程详解(3)Stream的创建方式</title>
    <link href="http://wuwenliang.net/2020/05/17/Java8%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%E4%B9%8BStream%E7%BC%96%E7%A8%8B%E8%AF%A6%E8%A7%A3-3-Stream%E7%9A%84%E5%88%9B%E5%BB%BA%E6%96%B9%E5%BC%8F/"/>
    <id>http://wuwenliang.net/2020/05/17/Java8函数式编程之Stream编程详解-3-Stream的创建方式/</id>
    <published>2020-05-17T05:11:06.000Z</published>
    <updated>2020-05-17T05:37:49.866Z</updated>
    
    <content type="html"><![CDATA[<p>本文我们重点讲解一下Stream流的创建方式。</p>
<h3 id="4-6-流的创建"><a href="#4-6-流的创建" class="headerlink" title="4.6 流的创建"></a>4.6 流的创建</h3><p>流的创建方式一般有四种，分别是</p>
<pre><code>由值创建流

由数组创建流

由文件创建流

由函数生成流（无限流）
</code></pre><p>接下来我们通过代码直观感受下这四种方式</p>
<a id="more"></a>
<h4 id="4-6-1-由值创建流"><a href="#4-6-1-由值创建流" class="headerlink" title="4.6.1.由值创建流"></a>4.6.1.由值创建流</h4><pre><code>@Test
public void streamFromValue() {
    Stream&lt;Integer&gt; integerStream = Stream.of(1, 2, 3, 4, 5);
    integerStream.forEach(System.out::println);
}
</code></pre><p>我们通过Stream.of()方法构建了一个整型流，并进行打印（通过System.out方法引用），运行结果</p>
<pre><code>1
2
3
4
5
</code></pre><h4 id="4-6-2-由数组创建流"><a href="#4-6-2-由数组创建流" class="headerlink" title="4.6.2.由数组创建流"></a>4.6.2.由数组创建流</h4><pre><code>@Test
public void streamFromArray() {
    int[] numbers = {1, 2, 3, 4, 5};
    IntStream stream = Arrays.stream(numbers);
    stream.forEach(System.out::println);
}
</code></pre><p>这种方式其实和通过值类似，Arrays工具类的stream方法允许对传入的一个数组对象，并输出对应类型的流。</p>
<p>运行结果</p>
<pre><code>1
2
3
4
5
</code></pre><h3 id="4-6-3-由文件创建流"><a href="#4-6-3-由文件创建流" class="headerlink" title="4.6.3.由文件创建流"></a>4.6.3.由文件创建流</h3><pre><code>@Test
public void streamFromFile() throws IOException {
    // 返回指定路径下文件中每一行够成的字符串流
    Stream&lt;String&gt; stream = Files.lines(Paths.get(&quot;src/main/java/com/sankuai/meituan/waimai/bizad/jdk8/stream/package-info.java&quot;));
    stream.forEach(System.out::println);
}
</code></pre><p>我们可以通过文件生成字符串流，通过调用Files.lines(Path path)方法，生成一个字符串流。</p>
<p>运行结果</p>
<pre><code>...省略部分输出...

*      预定义收集器功能（Collectors）
*          1. 将流元素规约和汇总为一个值
*          2. 将流元素分组
*          3. 将流元素分区
* 1. 参考资料
* 区别peek与map https://blog.csdn.net/tckt75433/article/details/81510743
*
*/

Process finished with exit code 0
</code></pre><p>这里输出的是文件package-info.java中的内容，感兴趣的同学可以传入其他文件查看运行效果。</p>
<p>我们看一下Files.lines方法的声明</p>
<pre><code>public static Stream&lt;String&gt; lines(Path path) throws IOException {
</code></pre><p>可见是通过Stream，逐行返回文件的每一行字符串</p>
<h3 id="4-6-4-由函数生成流（无限流）"><a href="#4-6-4-由函数生成流（无限流）" class="headerlink" title="4.6.4.由函数生成流（无限流）"></a>4.6.4.由函数生成流（无限流）</h3><pre><code>@Test
public void streamFromFunction() {
    Stream&lt;Double&gt; generate = Stream.generate(Math::random);
    // 通过limit限制数量
    generate.limit(10)
            .forEach(System.out::println);
}
</code></pre><p>由函数生成的流为无限流，也就是如果我们没有做其他的限制（如：指定limit），对其做迭代操作，会一直运行。</p>
<p>这个案例中，我们通过 Math::random 生成随机数，限制生成十个并打印，运行结果</p>
<pre><code>0.8969250722445276
0.8285057001330353
0.2419437635017867
0.11082352196746204
0.8035381196761233
0.5600709938550267
0.21051515736759363
0.8671614956980346
0.8063736774791785
0.8656071095608636
</code></pre><p>如果去掉limit()会怎样？感兴趣的同学可以自行尝试，相信会加深你对“无限流”的认识。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文我们重点讲解一下Stream流的创建方式。&lt;/p&gt;
&lt;h3 id=&quot;4-6-流的创建&quot;&gt;&lt;a href=&quot;#4-6-流的创建&quot; class=&quot;headerlink&quot; title=&quot;4.6 流的创建&quot;&gt;&lt;/a&gt;4.6 流的创建&lt;/h3&gt;&lt;p&gt;流的创建方式一般有四种，分别是&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;由值创建流

由数组创建流

由文件创建流

由函数生成流（无限流）
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;接下来我们通过代码直观感受下这四种方式&lt;/p&gt;
    
    </summary>
    
      <category term="Java" scheme="http://wuwenliang.net/categories/Java/"/>
    
    
      <category term="Java" scheme="http://wuwenliang.net/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Java8函数式编程之Stream高阶编程</title>
    <link href="http://wuwenliang.net/2020/05/17/Java8%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%E4%B9%8BStream%E9%AB%98%E9%98%B6%E7%BC%96%E7%A8%8B/"/>
    <id>http://wuwenliang.net/2020/05/17/Java8函数式编程之Stream高阶编程/</id>
    <published>2020-05-17T05:05:12.000Z</published>
    <updated>2020-05-17T05:29:01.528Z</updated>
    
    <content type="html"><![CDATA[<p>本文是Java8函数式编程的最后一个章节，到此我们的Stream相关的讲解就暂时告一段落。</p>
<p>本文中我将带领读者朋友一起学习一下Stream高级编程相关的知识。</p>
<h2 id="规约与汇总"><a href="#规约与汇总" class="headerlink" title="规约与汇总"></a>规约与汇总</h2><p>Stream操作中有两个相对高阶的概念，分别为规约和汇总。</p>
<p>规约（reduce）</p>
<pre><code>将Stream流中元素转换成一个值
</code></pre><p>汇总（collect）</p>
<pre><code>将Stream流中的元素转换成一个容器，如Map 、List 、 Set
</code></pre><p>上文我们已经讲过了汇总操作Collect，此处我们重点讲讲规约操作（reduce）</p>
<a id="more"></a>
<p><strong>对reduce的理解</strong></p>
<p>reduce 操作可以实现从Stream中生成一个值，其生成的值不是随意的，是根据指定的计算模型。</p>
<p>比如，之前提到count、min和max方法，因为常用而被纳入标准库中。事实上，这些方法都是reduce操作。</p>
<p>我们看一个案例</p>
<pre><code>    /**
    * reduce 案例1：
    *      计算一批商品的总价格
    */
    @Test
    public void reduceTest() {

        /**
        * 准备一批订单数据
        */
        List&lt;Order&gt; list = Lists.newArrayList();
        list.add(new Order(1, 2, 15.12));
        list.add(new Order(2, 5, 257.23));
        list.add(new Order(3, 3, 23331.12));

        /**
        * 传统方式
        * 1. 计算商品数量
        * 2. 计算消费总金额
        *
        * 以下展示Stream的reduce方式
        * 思想：分治法
        *
        *     &lt;U&gt; U reduce(U identity,                                 初始基点,此处就是订单中属性都是0
        *                  BiFunction&lt;U, ? super T, U&gt; accumulator,    计算逻辑，定义两个元素如何进行操作
        *                  BinaryOperator&lt;U&gt; combiner);                并行执行时多个部分结果的合并方式
        *
        */

        /**
        * 汇总商品数量和总金额
        */
        Order order = list.stream()
                //.parallel()     // 并行方式
                .reduce(
                        // 参数1：初始化值
                        new Order(0, 0, 0.0),
                        // 参数2：Stream中两个元素的计算逻辑
                        (Order order1, Order order2) -&gt; {
                            System.out.println(&quot;执行 计算逻辑 方法！！！&quot;);
                            // 计算两个订单商品数量和，消费金额之和
                            int productCount = order1.getProductCount() + order2.getProductCount();
                            double totalAmount = order1.getTotalAmount() + order2.getTotalAmount();
                            // 返回计算结果
                            return new Order(0, productCount, totalAmount);
                        },
                        // 参数3：并行情况下，多个并行结果如何合并
                        (Order order1, Order order2) -&gt; {
                            System.out.println(&quot;执行 合并 方法！！！&quot;);
                            // 计算两个订单商品数量和，消费金额之和
                            int productCount = order1.getProductCount() + order2.getProductCount();
                            double totalAmount = order1.getTotalAmount() + order2.getTotalAmount();
                            // 返回计算结果
                            return new Order(0, productCount, totalAmount);
                        });
        System.out.println(JSON.toJSONString(order, true));
    }
}
</code></pre><p>运行结果：</p>
<pre><code>执行 计算逻辑 方法！！！
执行 计算逻辑 方法！！！
执行 计算逻辑 方法！！！
{
    &quot;id&quot;:0,
    &quot;productCount&quot;:10,
    &quot;totalAmount&quot;:23603.469999999998
}
</code></pre><p>可见通过reduce逻辑，我们能够很轻松实现注入复杂条件的累加，求最值等操作。</p>
<p>reduce规约操作，实际上采用了分治思想，提升了编码和执行效率。</p>
<p>更多关于reduce的解析可以参考   <a href="https://blog.csdn.net/weixin_41835612/article/details/83687078" target="_blank" rel="external">https://blog.csdn.net/weixin_41835612/article/details/83687078</a></p>
<h2 id="4-9-Stream特点："><a href="#4-9-Stream特点：" class="headerlink" title="4.9 Stream特点："></a>4.9 Stream特点：</h2><p>通过上述的介绍，我们能够总结出Stream的特点：</p>
<ul>
<li><p>无存储。stream不是一种数据结构，它只是某种数据源的一个视图，数据源可以是一个数组，Java容器或I/O channel等。</p>
</li>
<li><p>为函数式编程而生。对stream的任何修改都不会修改背后的数据源，比如对stream执行过滤操作并不会删除被过滤的元素，而是会产生一个不包含被过滤元素的新stream。</p>
</li>
<li><p>惰式执行。stream上的操作并不会立即执行，只有等到用户真正需要结果的时候才会执行。</p>
</li>
<li><p>可消费性。stream只能被“消费”一次，一旦遍历过就会失效，就像容器的迭代器那样，想要再次遍历必须重新生成。</p>
</li>
</ul>
<h2 id="更多Java8特性"><a href="#更多Java8特性" class="headerlink" title="更多Java8特性"></a>更多Java8特性</h2><p>由于篇幅及笔者个人能力有限，不能将Java8的所有特性都详细的呈现，感兴趣的同学可以自行学习。</p>
<pre><code>Optional

接口默认方法

新的日期和时间API

CompletableFuture:组合式异步编程

G1垃圾回收器
</code></pre><p>推荐阅读</p>
<pre><code>《Java8实战》Java8 In Action中文版

《深入理解JVM&amp;G1 GC》
</code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>到此，针对Java8的新特性Lambda表达式及stream流式编程的讲解就告一段落，希望本系列对读者朋友们有所帮助。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文是Java8函数式编程的最后一个章节，到此我们的Stream相关的讲解就暂时告一段落。&lt;/p&gt;
&lt;p&gt;本文中我将带领读者朋友一起学习一下Stream高级编程相关的知识。&lt;/p&gt;
&lt;h2 id=&quot;规约与汇总&quot;&gt;&lt;a href=&quot;#规约与汇总&quot; class=&quot;headerlink&quot; title=&quot;规约与汇总&quot;&gt;&lt;/a&gt;规约与汇总&lt;/h2&gt;&lt;p&gt;Stream操作中有两个相对高阶的概念，分别为规约和汇总。&lt;/p&gt;
&lt;p&gt;规约（reduce）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;将Stream流中元素转换成一个值
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;汇总（collect）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;将Stream流中的元素转换成一个容器，如Map 、List 、 Set
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;上文我们已经讲过了汇总操作Collect，此处我们重点讲讲规约操作（reduce）&lt;/p&gt;
    
    </summary>
    
      <category term="Java" scheme="http://wuwenliang.net/categories/Java/"/>
    
    
      <category term="Java" scheme="http://wuwenliang.net/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Java8函数式编程之Stream编程详解(2)终端操作</title>
    <link href="http://wuwenliang.net/2020/05/17/Java8%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%E4%B9%8BStream%E7%BC%96%E7%A8%8B%E8%AF%A6%E8%A7%A3-2-%E7%BB%88%E7%AB%AF%E6%93%8D%E4%BD%9C/"/>
    <id>http://wuwenliang.net/2020/05/17/Java8函数式编程之Stream编程详解-2-终端操作/</id>
    <published>2020-05-17T04:50:54.000Z</published>
    <updated>2020-05-17T05:26:27.710Z</updated>
    
    <content type="html"><![CDATA[<p>上文中主要学习了Stream编程中的中间操作，本文我们接着分析终端操作，它分为短路和非短路操作。</p>
<p><strong>我们提前明确一个原则</strong>：一个流一旦经过终端操作，就不能进行后续操作了。</p>
<h3 id="allMatch-检测所有元素是否满足断言，如果都满足返回true，有一个不满足返回false"><a href="#allMatch-检测所有元素是否满足断言，如果都满足返回true，有一个不满足返回false" class="headerlink" title="allMatch: 检测所有元素是否满足断言，如果都满足返回true，有一个不满足返回false"></a>allMatch: 检测所有元素是否满足断言，如果都满足返回true，有一个不满足返回false</h3><pre><code>@Test
public void allMatchTest() {
    boolean isMatch = list.stream()
            // 打印出部门商品名称即结束，参考打印结果
            .peek(sku -&gt; System.out.println(sku.getSkuName()))
            // allMatch是短路操作
            .allMatch(sku -&gt; sku.getTotalPrice() &gt; 100);
    System.out.println(isMatch);
}
</code></pre><p>运行结果：</p>
<pre><code>无人机
VR一体机
牛仔裤
false
</code></pre><a id="more"></a>
<p>我们知道list集合一共有6个元素，但是遍历了三个就结束遍历。这恰好印证了</p>
<p>allMatch操作是是短路操作，只要有不满足的就返回；只有所有元素匹配才返回true</p>
<h3 id="anyMatch-只有有元素满足断言判断就返回true，否则返回false-存在至少一个满足条件的元素即是true"><a href="#anyMatch-只有有元素满足断言判断就返回true，否则返回false-存在至少一个满足条件的元素即是true" class="headerlink" title="anyMatch: 只有有元素满足断言判断就返回true，否则返回false (存在至少一个满足条件的元素即是true)"></a>anyMatch: 只有有元素满足断言判断就返回true，否则返回false (存在至少一个满足条件的元素即是true)</h3><pre><code>@Test
public void anyMatchTest() {
    boolean isMatch = list.stream()
            .peek(sku -&gt; System.out.println(sku.getSkuName()))
            .anyMatch(sku -&gt; sku.getTotalPrice() &gt; 100);
    System.out.println(isMatch);
}
</code></pre><p>运行结果：</p>
<pre><code>无人机
true
</code></pre><p>无人机.getTotalPrice() &gt; 100 刚好满足，因此anyMatch直接返回true。可见anyMatch也是短路操作，任何元素匹配断言则返回true</p>
<h3 id="noneMatch-只有所有元素都不满足断言判断才返回true，否则返回false"><a href="#noneMatch-只有所有元素都不满足断言判断才返回true，否则返回false" class="headerlink" title="noneMatch: 只有所有元素都不满足断言判断才返回true，否则返回false"></a>noneMatch: 只有所有元素都不满足断言判断才返回true，否则返回false</h3><pre><code>@Test
public void noneMatchTest() {
    boolean isMatch = list.stream()
            .peek(sku -&gt; System.out.println(sku.getSkuName()))
            .noneMatch(sku -&gt; sku.getTotalPrice() &gt; 10_000);
    System.out.println(isMatch);
}
</code></pre><p>运行结果：</p>
<pre><code>无人机
VR一体机
牛仔裤
衬衫
Java编程思想
程序化广告
true
</code></pre><p>实例数据中的所有的数据价格都没有超过10000，因此noneMatch断言均满足，所以返回true。</p>
<p>noneMatch的含义就是全不匹配就是true</p>
<h3 id="findFirst：找到第一个元素"><a href="#findFirst：找到第一个元素" class="headerlink" title="findFirst：找到第一个元素"></a>findFirst：找到第一个元素</h3><pre><code>@Test
public void findFirstTest() {
    Optional&lt;Sku&gt; optional = list.stream()
            .peek(sku -&gt; System.out.println(sku.getSkuName()))
            .findFirst();
    System.out.println(JSON.toJSONString(optional.get()));
}
</code></pre><p>运行结果：</p>
<pre><code>无人机
{&quot;skuCategory&quot;:&quot;ELECTRONICS&quot;,&quot;skuId&quot;:2,&quot;skuName&quot;:&quot;无人机&quot;,&quot;skuPrice&quot;:1000.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:1000.0}
</code></pre><p>这个方法没什么特别注意的，我们只需要记住findFirst返回一个 Optional<t> 实例，需要调用get()获取实际的对象实例。</t></p>
<h3 id="findAny：找到任意一个元素，只要有元素就返回"><a href="#findAny：找到任意一个元素，只要有元素就返回" class="headerlink" title="findAny：找到任意一个元素，只要有元素就返回"></a>findAny：找到任意一个元素，只要有元素就返回</h3><pre><code>@Test
public void findAnyTest() {
    Optional&lt;Sku&gt; optional = list.stream()
            .peek(sku -&gt; System.out.println(sku.getSkuName()))
            .findAny();
    System.out.println(JSON.toJSONString(optional.get()));
}
</code></pre><p>运行结果：</p>
<pre><code>无人机
{&quot;skuCategory&quot;:&quot;ELECTRONICS&quot;,&quot;skuId&quot;:2,&quot;skuName&quot;:&quot;无人机&quot;,&quot;skuPrice&quot;:1000.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:1000.0}
</code></pre><p>findAny的语义是：</p>
<p>找到任意一个元素，只要有元素就返回；与findFirst相比，如果是并行操作，findAny更快，因为是随机匹配的；</p>
<p>如果是串行操作，则与findFirst花费时间相差无几</p>
<h3 id="max-获取流中某条件下最大值"><a href="#max-获取流中某条件下最大值" class="headerlink" title="max:获取流中某条件下最大值"></a>max:获取流中某条件下最大值</h3><pre><code>@Test
public void maxTest() {
    OptionalDouble optionalDouble = list.stream()
            // 提取出价格 数据类型为double  mapToDouble将元素映射为double元素，返回一个doubleStream流
            .mapToDouble(Sku::getTotalPrice)
            // 提取最大值
            .max();
    System.out.println(optionalDouble.getAsDouble());
}
</code></pre><p>运行结果：</p>
<pre><code>2100.0
</code></pre><p>max方法，字面意思就是获取流中的最大值。</p>
<p>在实例中，通过mapToDouble将元素映射为double元素，通过max方法获取其中的最大值。</p>
<h3 id="min：获取流中某条件下最小值"><a href="#min：获取流中某条件下最小值" class="headerlink" title="min：获取流中某条件下最小值"></a>min：获取流中某条件下最小值</h3><pre><code>@Test
public void minTest() {
    OptionalDouble optionalDouble = list.stream()
            // 提取出价格 数据类型为double  mapToDouble将元素映射为double元素，返回一个doubleStream流
            .mapToDouble(Sku::getTotalPrice)
            // 提取最小值
            .min();
    System.out.println(optionalDouble.getAsDouble());
}
</code></pre><p>运行结果：</p>
<pre><code>60.0
</code></pre><p>min与max 刚好相反，字面意思就是获取流中的最小值。</p>
<h3 id="count：获取流中元素的个数"><a href="#count：获取流中元素的个数" class="headerlink" title="count：获取流中元素的个数"></a>count：获取流中元素的个数</h3><pre><code>@Test
public void countTest() {
    long count = list.stream()
            // 提取出价格 数据类型为double  mapToDouble将元素映射为double元素，返回一个doubleStream流
            .mapToDouble(Sku::getTotalPrice)
            // 提取总数
            .count();
    System.out.println(count);
}
</code></pre><p>运行结果：</p>
<pre><code>6
</code></pre><p>count方法的目的为获取流中元素总数</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;上文中主要学习了Stream编程中的中间操作，本文我们接着分析终端操作，它分为短路和非短路操作。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我们提前明确一个原则&lt;/strong&gt;：一个流一旦经过终端操作，就不能进行后续操作了。&lt;/p&gt;
&lt;h3 id=&quot;allMatch-检测所有元素是否满足断言，如果都满足返回true，有一个不满足返回false&quot;&gt;&lt;a href=&quot;#allMatch-检测所有元素是否满足断言，如果都满足返回true，有一个不满足返回false&quot; class=&quot;headerlink&quot; title=&quot;allMatch: 检测所有元素是否满足断言，如果都满足返回true，有一个不满足返回false&quot;&gt;&lt;/a&gt;allMatch: 检测所有元素是否满足断言，如果都满足返回true，有一个不满足返回false&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;@Test
public void allMatchTest() {
    boolean isMatch = list.stream()
            // 打印出部门商品名称即结束，参考打印结果
            .peek(sku -&amp;gt; System.out.println(sku.getSkuName()))
            // allMatch是短路操作
            .allMatch(sku -&amp;gt; sku.getTotalPrice() &amp;gt; 100);
    System.out.println(isMatch);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;运行结果：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;无人机
VR一体机
牛仔裤
false
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
      <category term="Java" scheme="http://wuwenliang.net/categories/Java/"/>
    
    
      <category term="Java" scheme="http://wuwenliang.net/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Java8函数式编程之Stream编程详解(1)中间操作</title>
    <link href="http://wuwenliang.net/2020/05/17/Java8%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%E4%B9%8BStream%E7%BC%96%E7%A8%8B%E8%AF%A6%E8%A7%A3-1-%E4%B8%AD%E9%97%B4%E6%93%8D%E4%BD%9C/"/>
    <id>http://wuwenliang.net/2020/05/17/Java8函数式编程之Stream编程详解-1-中间操作/</id>
    <published>2020-05-17T04:05:05.000Z</published>
    <updated>2020-05-17T05:26:35.317Z</updated>
    
    <content type="html"><![CDATA[<p>我始终认为通过案例学习是最好的掌握一个技能的方式，因此我们还是通过之前文章中的案例，对Stream编程中涉及到的具体的方法进行详细的学习。</p>
<h3 id="初始化数据"><a href="#初始化数据" class="headerlink" title="初始化数据"></a>初始化数据</h3><p>首先初始化一个List集合，用于后续讲解所用。</p>
<pre><code>List&lt;Sku&gt; list;

@Before
public void init() {
    list = CartService.getCartSkuList();
}
</code></pre><p>我们仍旧使用之前的购物车数据</p>
<a id="more"></a>
<h3 id="中间操作实例"><a href="#中间操作实例" class="headerlink" title="中间操作实例"></a>中间操作实例</h3><p>首先讲解中间操作，它分为有状态和无状态两种形式</p>
<h4 id="filter使用：过滤不符合断言判断的数据"><a href="#filter使用：过滤不符合断言判断的数据" class="headerlink" title="filter使用：过滤不符合断言判断的数据"></a>filter使用：过滤不符合断言判断的数据</h4><pre><code>@Test
public void filterTest() {
    list.stream()
            // 判断是否符合一个断言（商品类型是否为书籍），不符合则过滤元素
            .filter(sku -&gt; SkuCategoryEnum.BOOKS.equals(sku.getSkuCategory()))
            // 打印终端操作结果
            .forEach(item -&gt; System.out.println(JSON.toJSONString(item, true)));
}
</code></pre><p>这个操作的目的是：从商品列表中选择所有的书籍类型，其余类型过滤</p>
<p>运行结果：</p>
<pre><code>{&quot;skuCategory&quot;:&quot;BOOKS&quot;,&quot;skuId&quot;:121,&quot;skuName&quot;:&quot;Java编程思想&quot;,&quot;skuPrice&quot;:100.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:100.0}
{&quot;skuCategory&quot;:&quot;BOOKS&quot;,&quot;skuId&quot;:3,&quot;skuName&quot;:&quot;程序化广告&quot;,&quot;skuPrice&quot;:80.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:80.0}
</code></pre><p><strong>总结</strong>：filter用于判断集合数据是否符合一个断言，不符合则过滤掉元素</p>
<p>filter结果为TRUE，表示通过测试，数据不过滤；结果为FALSE，表示未通过测试，数据被过滤</p>
<h4 id="map使用：将一个元素转换为另一个元素"><a href="#map使用：将一个元素转换为另一个元素" class="headerlink" title="map使用：将一个元素转换为另一个元素"></a>map使用：将一个元素转换为另一个元素</h4><pre><code>@Test
public void mapTest() {
    list.stream()
            // 将一个元素转换为另一个数据类型的元素
            .map(sku -&gt; sku.getSkuName())
            // 打印终端操作结果
            .forEach(item -&gt; System.out.println(JSON.toJSONString(item, true)));
}
</code></pre><p>这个操作的目的是：从商品列表中获取每个商品的名称，并打印</p>
<p>运行结果：</p>
<pre><code>&quot;无人机&quot;
&quot;VR一体机&quot;
&quot;牛仔裤&quot;
&quot;衬衫&quot;
&quot;Java编程思想&quot;
&quot;程序化广告&quot;
</code></pre><p>总结：map用于将一个元素转换为另一个(类型的)元素</p>
<h4 id="flatMap（扁平化）使用：将一个对象转换为一个流的操作"><a href="#flatMap（扁平化）使用：将一个对象转换为一个流的操作" class="headerlink" title="flatMap（扁平化）使用：将一个对象转换为一个流的操作"></a>flatMap（扁平化）使用：将一个对象转换为一个流的操作</h4><pre><code>@Test
public void flatMap() {
    list.stream()
            // 这里将商品名称切分为一个字符流，最终输出
            .flatMap(sku -&gt; Arrays.stream(sku.getSkuName().split(&quot;&quot;)))
            // 打印终端操作结果
            .forEach(item -&gt; System.out.println(JSON.toJSONString(item, true)));
}
</code></pre><p>这个操作的目的是：将商品名称逐字进行拆分</p>
<p>运行结果：</p>
<pre><code>&quot;无&quot;
&quot;人&quot;
&quot;机&quot;
&quot;V&quot;
&quot;R&quot;
&quot;一&quot;
&quot;体&quot;
&quot;机&quot;
&quot;牛&quot;
&quot;仔&quot;
&quot;裤&quot;
&quot;衬&quot;
&quot;衫&quot;
&quot;J&quot;
&quot;a&quot;
&quot;v&quot;
&quot;a&quot;
&quot;编&quot;
&quot;程&quot;
&quot;思&quot;
&quot;想&quot;
&quot;程&quot;
&quot;序&quot;
&quot;化&quot;
&quot;广&quot;
&quot;告&quot;
</code></pre><p>从运行结果可以直观看出：flatMap接收一个流 并返回一个新的流 ，且这个新的流能够与其他的流进行合并</p>
<p>我们看下flatMap方法的声明</p>
<pre><code>&lt;R&gt; Stream&lt;R&gt; flatMap(Function&lt;? super T, ? extends Stream&lt;? extends R&gt;&gt; mapper);
</code></pre><p>我们可以清楚的看到，flatMap接受一个流，并返回一个新流</p>
<p><strong>总结一下</strong>，flatMap 是获取了对象中集合类属性，组成一个新的流供我们使用。可以用在Map类数据的去重场景。</p>
<p>比如：key=商户 value=商户分类，我们要统计所有商户的类别，就可以将商户分类扁平化为一个流，进行distinct操作。</p>
<h4 id="peek-对流中元素进行遍历操作，与forEach类似，但不会销毁流元素"><a href="#peek-对流中元素进行遍历操作，与forEach类似，但不会销毁流元素" class="headerlink" title="peek: 对流中元素进行遍历操作，与forEach类似，但不会销毁流元素"></a>peek: 对流中元素进行遍历操作，与forEach类似，但不会销毁流元素</h4><pre><code>@Test
public void peekTest() {
    list.stream()
            // 对一个流中的所有元素进行处理，但与forEach不同之处在于，peek是一个中间操作，
            // 操作完成还能被后续使用。forEach是一个终端操作，处理完之后流就不能被操作了。
            .peek(sku -&gt; System.out.println(sku.getSkuName()))
            // 打印终端操作结果
            .forEach(item -&gt; System.out.println(JSON.toJSONString(item, true)));
}
</code></pre><p>这个操作的目的为：迭代商品列表，逐个输出商品名，并最终通过forEach迭代一次。</p>
<p>运行结果：</p>
<pre><code>无人机
{&quot;skuCategory&quot;:&quot;ELECTRONICS&quot;,&quot;skuId&quot;:2,&quot;skuName&quot;:&quot;无人机&quot;,&quot;skuPrice&quot;:1000.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:1000.0}
VR一体机
{&quot;skuCategory&quot;:&quot;ELECTRONICS&quot;,&quot;skuId&quot;:1,&quot;skuName&quot;:&quot;VR一体机&quot;,&quot;skuPrice&quot;:2100.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:2100.0}
牛仔裤
{&quot;skuCategory&quot;:&quot;CLOTHING&quot;,&quot;skuId&quot;:4,&quot;skuName&quot;:&quot;牛仔裤&quot;,&quot;skuPrice&quot;:60.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:60.0}
衬衫
{&quot;skuCategory&quot;:&quot;CLOTHING&quot;,&quot;skuId&quot;:13,&quot;skuName&quot;:&quot;衬衫&quot;,&quot;skuPrice&quot;:120.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:120.0}
Java编程思想
{&quot;skuCategory&quot;:&quot;BOOKS&quot;,&quot;skuId&quot;:121,&quot;skuName&quot;:&quot;Java编程思想&quot;,&quot;skuPrice&quot;:100.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:100.0}
程序化广告
{&quot;skuCategory&quot;:&quot;BOOKS&quot;,&quot;skuId&quot;:3,&quot;skuName&quot;:&quot;程序化广告&quot;,&quot;skuPrice&quot;:80.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:80.0}
</code></pre><p>看输出效果，peek与forEach是交替执行的，并不是先执行完peek之后才执行forEach</p>
<p>可以看到，流是惰性执行的 先执行中间操作，再执行终端操作，交替打印（peek是无状态的）</p>
<h4 id="sort：对流中元素进行排序，可选择自然排序或指定排序规则"><a href="#sort：对流中元素进行排序，可选择自然排序或指定排序规则" class="headerlink" title="sort：对流中元素进行排序，可选择自然排序或指定排序规则"></a>sort：对流中元素进行排序，可选择自然排序或指定排序规则</h4><pre><code>@Test
public void sortTest() {
    list.stream()
            .peek(sku -&gt; System.out.println(sku.getSkuName()))
            // 根据Sku的价格进行升序排列
            .sorted(Comparator.comparing(Sku::getTotalPrice))
            // 打印终端操作结果
            .forEach(item -&gt; System.out.println(JSON.toJSONString(item, true)));
}
</code></pre><p>运行结果：</p>
<pre><code>无人机
VR一体机
牛仔裤
衬衫
Java编程思想
程序化广告
{&quot;skuCategory&quot;:&quot;CLOTHING&quot;,&quot;skuId&quot;:4,&quot;skuName&quot;:&quot;牛仔裤&quot;,&quot;skuPrice&quot;:60.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:60.0}
{&quot;skuCategory&quot;:&quot;BOOKS&quot;,&quot;skuId&quot;:3,&quot;skuName&quot;:&quot;程序化广告&quot;,&quot;skuPrice&quot;:80.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:80.0}
{&quot;skuCategory&quot;:&quot;BOOKS&quot;,&quot;skuId&quot;:121,&quot;skuName&quot;:&quot;Java编程思想&quot;,&quot;skuPrice&quot;:100.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:100.0}
{&quot;skuCategory&quot;:&quot;CLOTHING&quot;,&quot;skuId&quot;:13,&quot;skuName&quot;:&quot;衬衫&quot;,&quot;skuPrice&quot;:120.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:120.0}
{&quot;skuCategory&quot;:&quot;ELECTRONICS&quot;,&quot;skuId&quot;:2,&quot;skuName&quot;:&quot;无人机&quot;,&quot;skuPrice&quot;:1000.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:1000.0}
{&quot;skuCategory&quot;:&quot;ELECTRONICS&quot;,&quot;skuId&quot;:1,&quot;skuName&quot;:&quot;VR一体机&quot;,&quot;skuPrice&quot;:2100.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:2100.0}
</code></pre><p>和上述案例对比，这个案例在于增加了sorted排序操作。</p>
<p>执行完成，可以看到，peek与forEach并不是交替打印的，这是因为增加了sorted操作（sorted是有状态的）之后，必须要sort完成，才进行后续操作</p>
<h5 id="补充：看一个较为复杂的排序案例"><a href="#补充：看一个较为复杂的排序案例" class="headerlink" title="补充：看一个较为复杂的排序案例"></a>补充：看一个较为复杂的排序案例</h5><pre><code>public void sortTrade() {
    List&lt;Sku&gt; collect = list.stream()
            .sorted(// 逆序
                    Comparator
                            // 排序条件1：总价逆序
                            .comparing(Sku::getTotalPrice,
                                    Comparator.reverseOrder())
                            // 排序条件2：skuId升序(自然排序)
                            .thenComparing(Sku::getSkuId)
                            // 排序条件3：商品单价逆序
                            .thenComparing(Sku::getSkuPrice, Comparator.reverseOrder())
                            // 自定义排序条件：根据类别 
                            .thenComparing(
                                    // 排序字段值
                                    Sku::getSkuCategory,
                                    // 排序规则
                                    (type1, type2) -&gt; {
                                        if (SkuCategoryEnum.BOOKS.equals(type1)) {
                                            // 标识type1在先，type2在后
                                            return -1;
                                        }
                                        if (SkuCategoryEnum.CLOTHING.equals(type2)) {
                                            // 标识type1在后，type2在先
                                            return 1;
                                        }
                                        // 两者相等
                                        return 0;
                                    })).collect(Collectors.toList());

    ;
}
</code></pre><p>我们分析一下这段代码，可以看到它是根据一定的排序规则，链式地进行编码。如果掌握了Stream编程，那么这段代码写起来会很顺手，读起来也赏心悦目。</p>
<p>但是另一方面，这点代码由于采用了链式编程方式，每个操作都依赖之前操作的结果，对于不了解Stream编程的同学讲就比较痛苦了。</p>
<p>我的建议是，stream编程我们要学，对于复杂的流程如果要采用stream实现，那么请把注释写清楚，方便后续维护。</p>
<p>毕竟Stream被人诟病较多的地方就是：复杂逻辑下不好理解，不易测试。</p>
<p>我个人的建议是，注释在精不在多，关键逻辑，复杂逻辑要有注释，对自己对别人都有好处。</p>
<h4 id="distinct：对流元素进行去重，有状态操作（针对所有元素进行排序）"><a href="#distinct：对流元素进行去重，有状态操作（针对所有元素进行排序）" class="headerlink" title="distinct：对流元素进行去重，有状态操作（针对所有元素进行排序）"></a>distinct：对流元素进行去重，有状态操作（针对所有元素进行排序）</h4><pre><code>@Test
public void distinctTest() {
    list.stream()
            .map(sku -&gt; sku.getSkuCategory())
            .distinct()
            // 打印终端操作结果
            .forEach(item -&gt; System.out.println(JSON.toJSONString(item, true)));
}
</code></pre><p>运行结果：</p>
<pre><code>&quot;ELECTRONICS&quot;
&quot;CLOTHING&quot;
&quot;BOOKS&quot;
</code></pre><p>distinct()操作的目的为对流元素进行去重操作。原集合共6个元素，通过distinct()操作将重复的类别进行去除，最终保留不重复的类别结果。</p>
<h4 id="skip：跳过前N条记录，有状态操作"><a href="#skip：跳过前N条记录，有状态操作" class="headerlink" title="skip：跳过前N条记录，有状态操作"></a>skip：跳过前N条记录，有状态操作</h4><pre><code>@Test
public void skipTest() {
    list.stream()
            .sorted(Comparator.comparing(Sku::getTotalPrice))
            // 对价格排序之后跳过前三条
            .skip(3)
            // 打印终端操作结果
            .forEach(item -&gt; System.out.println(JSON.toJSONString(item, true)));
}
</code></pre><p>这段代码的意图为：对商品的价格进行排序，跳过前三个（从小到大排序，跳过最小的三个）</p>
<p>运行结果：</p>
<pre><code>{&quot;skuCategory&quot;:&quot;CLOTHING&quot;,&quot;skuId&quot;:13,&quot;skuName&quot;:&quot;衬衫&quot;,&quot;skuPrice&quot;:120.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:120.0}
{&quot;skuCategory&quot;:&quot;ELECTRONICS&quot;,&quot;skuId&quot;:2,&quot;skuName&quot;:&quot;无人机&quot;,&quot;skuPrice&quot;:1000.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:1000.0}
{&quot;skuCategory&quot;:&quot;ELECTRONICS&quot;,&quot;skuId&quot;:1,&quot;skuName&quot;:&quot;VR一体机&quot;,&quot;skuPrice&quot;:2100.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:2100.0}
</code></pre><h4 id="limit：截断前N条记录，有状态操作"><a href="#limit：截断前N条记录，有状态操作" class="headerlink" title="limit：截断前N条记录，有状态操作"></a>limit：截断前N条记录，有状态操作</h4><pre><code>@Test
public void limitTests() {
    list.stream()
            .sorted(Comparator.comparing(Sku::getTotalPrice))
            // 对价格排序之后取前三条
            .limit(3)
            // 打印终端操作结果
            .forEach(item -&gt; System.out.println(JSON.toJSONString(item, true)));
}
</code></pre><p>这段代码的意图与skip刚好相反：对商品价格进行排序，取前三个（从小到大，取top3）</p>
<p>运行结果：</p>
<pre><code>{&quot;skuCategory&quot;:&quot;CLOTHING&quot;,&quot;skuId&quot;:4,&quot;skuName&quot;:&quot;牛仔裤&quot;,&quot;skuPrice&quot;:60.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:60.0}
{&quot;skuCategory&quot;:&quot;BOOKS&quot;,&quot;skuId&quot;:3,&quot;skuName&quot;:&quot;程序化广告&quot;,&quot;skuPrice&quot;:80.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:80.0}
{&quot;skuCategory&quot;:&quot;BOOKS&quot;,&quot;skuId&quot;:121,&quot;skuName&quot;:&quot;Java编程思想&quot;,&quot;skuPrice&quot;:100.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:100.0}
</code></pre><p>结果和上面的运行结果刚好互为补集。由此我们可以猜测是否可以通过skip + limit实现内存分页？</p>
<p>答案是肯定的，具体的方法为</p>
<p>通过skip 和 limit 实现一个假分页如：3条一页</p>
<pre><code>第一页 skip(0 * 3).limit(3)
第二页 skip(1 * 3).limit(3)
...
第N页 skip((n - 1) * 3).limit(3)
</code></pre><p>总结为公式就是：</p>
<pre><code>skip((pageNum - 1) * pageSize).limit(pageSize)
</code></pre><p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我始终认为通过案例学习是最好的掌握一个技能的方式，因此我们还是通过之前文章中的案例，对Stream编程中涉及到的具体的方法进行详细的学习。&lt;/p&gt;
&lt;h3 id=&quot;初始化数据&quot;&gt;&lt;a href=&quot;#初始化数据&quot; class=&quot;headerlink&quot; title=&quot;初始化数据&quot;&gt;&lt;/a&gt;初始化数据&lt;/h3&gt;&lt;p&gt;首先初始化一个List集合，用于后续讲解所用。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;List&amp;lt;Sku&amp;gt; list;

@Before
public void init() {
    list = CartService.getCartSkuList();
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;我们仍旧使用之前的购物车数据&lt;/p&gt;
    
    </summary>
    
      <category term="Java" scheme="http://wuwenliang.net/categories/Java/"/>
    
    
      <category term="Java" scheme="http://wuwenliang.net/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Java8函数式编程之Stream概述</title>
    <link href="http://wuwenliang.net/2020/05/17/Java8%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%E4%B9%8BStream%E6%A6%82%E8%BF%B0/"/>
    <id>http://wuwenliang.net/2020/05/17/Java8函数式编程之Stream概述/</id>
    <published>2020-05-17T02:04:03.000Z</published>
    <updated>2020-05-17T05:26:42.014Z</updated>
    
    <content type="html"><![CDATA[<p>本文，我们开始进入到Java8的Stream流编程概念及实际使用方式的学习。</p>
<h2 id="什么是流（Stream）"><a href="#什么是流（Stream）" class="headerlink" title="什么是流（Stream）?"></a>什么是流（Stream）?</h2><blockquote>
<p>Stream流是jdk1.8引入的新成员，通过声明式的方式处理集合数据（多通过lambda表达式方式进行展示）</p>
<p>它能够将基础操作链接起来，从而完成复杂的数据处理流水线</p>
<p>它也为开发者提供了透明的并行处理</p>
</blockquote>
<p>《Java8实战》一书的解释为</p>
<blockquote>
<p>流，是从支持 数据处理操作 的 源 生成的元素序列</p>
</blockquote>
<a id="more"></a>
<h2 id="流与集合的区别"><a href="#流与集合的区别" class="headerlink" title="流与集合的区别"></a>流与集合的区别</h2><ol>
<li>时间与空间的区别</li>
</ol>
<p>集合是静态的概念，流是动态的概念。eg: DVD碟片是集合，播放中的一段视频是流集合面向的是存储，而流面向的计算</p>
<p>eg: 构造一个质数集合，这是做不到的，因为这个集合是无穷的      但是构造一个质数流是可以的，我们只需要不断的构造就可以了。</p>
<pre><code>也就是说，集合在时间维度看是无穷的，而流在时间维度上看是有穷的。
</code></pre><ol>
<li>集合可以遍历多次，但流只能遍历一次</li>
</ol>
<p>流是动态概念，遍历之后就不存在了，再次遍历会出现异常</p>
<ol>
<li>集合的迭代是外部迭代，如:foreach ； 流的迭代是内部迭代，我们只需要定义操作，流会帮我们在内部进行迭代操作</li>
</ol>
<h2 id="流的组成"><a href="#流的组成" class="headerlink" title="流的组成"></a>流的组成</h2><p>流由       </p>
<pre><code>数据源          中间操作(业务处理)               终端操作(将结果进行收集) 组成

如：           cart（SkuList）    -&gt;     [filter -&gt; sorted -&gt; map]  -&gt;    collect
</code></pre><h2 id="流操作的分类"><a href="#流操作的分类" class="headerlink" title="流操作的分类"></a>流操作的分类</h2><ol>
<li><p>中间操作</p>
<p> 1.1 无状态操作</p>
<pre><code>(不需要建立在所有的数据上，只需要针对单个数据进行判断即可)： filter、map、peek等,  具有局部性
</code></pre><p> 1.2 有状态操作</p>
<pre><code>(需要针对所有数据基础上)： distinct、sorted、limit等，具有全局性
</code></pre></li>
<li><p>终端操作</p>
<p> 1.1 非短路操作</p>
<pre><code>(所有数据均执行)： forEach、collect、count等
</code></pre><p> 1.2 短路操作</p>
<pre><code>(只要找到符合要求的就不需要继续执行了)：anyMatch、findFirst、findAny
</code></pre></li>
</ol>
<h2 id="流的使用"><a href="#流的使用" class="headerlink" title="流的使用"></a>流的使用</h2><p>这里我们对常见的流的使用方法进行详细分类，承接上方 流操作的分类 </p>
<ol>
<li><p>中间操作(无状态)</p>
<pre><code>过滤      filter
映射      map
扁平化    flatMap
遍历      peek
</code></pre></li>
<li><p>中间操作(有状态)</p>
<pre><code>去重     distinct
跳过     skip
截断     limit
排序     sorted
</code></pre></li>
<li><p>终端操作(非短路)</p>
<pre><code>遍历       forEach
规约       reduce
最大值     max
聚合       collect
最小值     min
计数       count
</code></pre></li>
<li><p>终端操作(短路)</p>
<pre><code>所有匹配    allMatch
任意匹配    anyMatch
不匹配      noneMatch
查找首个    findFirst
查找任意    findAny
</code></pre></li>
</ol>
<p>接下来，我们通过代码实例，挨个讲解一下这些方法的使用</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文，我们开始进入到Java8的Stream流编程概念及实际使用方式的学习。&lt;/p&gt;
&lt;h2 id=&quot;什么是流（Stream）&quot;&gt;&lt;a href=&quot;#什么是流（Stream）&quot; class=&quot;headerlink&quot; title=&quot;什么是流（Stream）?&quot;&gt;&lt;/a&gt;什么是流（Stream）?&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;Stream流是jdk1.8引入的新成员，通过声明式的方式处理集合数据（多通过lambda表达式方式进行展示）&lt;/p&gt;
&lt;p&gt;它能够将基础操作链接起来，从而完成复杂的数据处理流水线&lt;/p&gt;
&lt;p&gt;它也为开发者提供了透明的并行处理&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;《Java8实战》一书的解释为&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;流，是从支持 数据处理操作 的 源 生成的元素序列&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Java8函数式编程之Lambda与传统方式对集合操作的案例对比</title>
    <link href="http://wuwenliang.net/2020/05/16/Java8%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%E4%B9%8BLambda%E4%B8%8E%E4%BC%A0%E7%BB%9F%E6%96%B9%E5%BC%8F%E5%AF%B9%E9%9B%86%E5%90%88%E6%93%8D%E4%BD%9C%E7%9A%84%E6%A1%88%E4%BE%8B%E5%AF%B9%E6%AF%94/"/>
    <id>http://wuwenliang.net/2020/05/16/Java8函数式编程之Lambda与传统方式对集合操作的案例对比/</id>
    <published>2020-05-16T15:08:24.000Z</published>
    <updated>2020-05-17T05:11:03.976Z</updated>
    
    <content type="html"><![CDATA[<p>本章节中，我们通过一个实战案例对比原始集合操作与Stream集合操作具体有哪些不同，直观地展示Stream集合操作对编程效率的提升。</p>
<h2 id="案例：对比原始集合操作与Stream集合操作"><a href="#案例：对比原始集合操作与Stream集合操作" class="headerlink" title="案例：对比原始集合操作与Stream集合操作"></a>案例：对比原始集合操作与Stream集合操作</h2><h3 id="需求场景："><a href="#需求场景：" class="headerlink" title="需求场景："></a>需求场景：</h3><p>针对上面的购物车，我们想要</p>
<ol>
<li>全局查看购物车中都有哪些商品</li>
<li>将购物车中的图书类商品进行过滤（删除图书类商品）</li>
<li>在其余商品中挑选两件最贵的</li>
<li>打印出上述两件商品的名称和总价</li>
</ol>
<a id="more"></a>
<h3 id="原始集合操作："><a href="#原始集合操作：" class="headerlink" title="原始集合操作："></a>原始集合操作：</h3><pre><code>@Test
public void traditionalWay() {
    // 1. 打印所有商品
    List&lt;Sku&gt; skus = CartService.getCartSkuList();
    for (Sku sku : skus) {
        System.out.println(JSON.toJSONString(sku, true));
    }
    // 2. 过滤图书类商品
    List&lt;Sku&gt; notIncludeBooksList = new ArrayList&lt;&gt;();
    for (Sku sku : skus) {
        if (!sku.getSkuCategory().equals(SkuCategoryEnum.BOOKS)) {
            notIncludeBooksList.add(sku);
        }
    }
    // 3. 其余商品中挑选两件最贵的 价格倒排序，取top2
    // 3.1 先排序
    notIncludeBooksList.sort(new Comparator&lt;Sku&gt;() {
        @Override
        public int compare(Sku sku0, Sku sku1) {
            if (sku0.getTotalPrice() &gt; sku1.getTotalPrice()) {
                return -1;
            }
            if (sku0.getTotalPrice() &lt; sku1.getTotalPrice()) {
                return 1;
            }
            return 0;
        }
    });

    // 3.2 取top2
    List&lt;Sku&gt; top2SkuList = new ArrayList&lt;&gt;();
    for (int i = 0; i &lt; 2; i++) {
        top2SkuList.add(notIncludeBooksList.get(i));
    }
    // 4. 打印出上述两件商品的名称和总价
    // 4.1 求两件商品总价
    double totalMoney = 0.0;
    for (Sku sku : top2SkuList) {
        totalMoney += sku.getTotalPrice();
    }
    // 4.2 获取两件商品名称
    List&lt;String&gt; resultSkuNameList = new ArrayList&lt;&gt;();
    for (Sku sku : top2SkuList) {
        resultSkuNameList.add(sku.getSkuName());
    }
    // 打印输出结果
    System.out.println(&quot;结果商品名称: &quot; + JSON.toJSONString(resultSkuNameList, true));
    System.out.println(&quot;商品总价:&quot; + totalMoney);
}
</code></pre><p>运行结果：</p>
<pre><code>{&quot;skuCategory&quot;:&quot;ELECTRONICS&quot;,&quot;skuId&quot;:2,&quot;skuName&quot;:&quot;无人机&quot;,&quot;skuPrice&quot;:1000.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:1000.0}
{&quot;skuCategory&quot;:&quot;ELECTRONICS&quot;,&quot;skuId&quot;:1,&quot;skuName&quot;:&quot;VR一体机&quot;,&quot;skuPrice&quot;:2100.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:2100.0}
{&quot;skuCategory&quot;:&quot;CLOTHING&quot;,&quot;skuId&quot;:4,&quot;skuName&quot;:&quot;牛仔裤&quot;,&quot;skuPrice&quot;:60.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:60.0}
{&quot;skuCategory&quot;:&quot;CLOTHING&quot;,&quot;skuId&quot;:13,&quot;skuName&quot;:&quot;衬衫&quot;,&quot;skuPrice&quot;:120.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:120.0}
{&quot;skuCategory&quot;:&quot;BOOKS&quot;,&quot;skuId&quot;:121,&quot;skuName&quot;:&quot;Java编程思想&quot;,&quot;skuPrice&quot;:100.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:100.0}
{&quot;skuCategory&quot;:&quot;BOOKS&quot;,&quot;skuId&quot;:3,&quot;skuName&quot;:&quot;程序化广告&quot;,&quot;skuPrice&quot;:80.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:80.0}
结果商品名称: [
    &quot;VR一体机&quot;,
    &quot;无人机&quot;
]
商品总价:3100.0
</code></pre><p>我们可以看到传统的集合操作还是写了比较多的代码，而且在编码过程中为了满足各种要求，我们通过声明新的容器来接受过程中的操作结果，这带来了内存使用量的增加。</p>
<p>接下来看一下Stream方式下如何编码实现我们的需求：</p>
<h3 id="Stream集合操作："><a href="#Stream集合操作：" class="headerlink" title="Stream集合操作："></a>Stream集合操作：</h3><pre><code>@Test
public void streamWay() {
    AtomicReference&lt;Double&gt; money = new AtomicReference&lt;&gt;(Double.valueOf(0.0));
    List&lt;String&gt; resultSkuNameList = CartService.getCartSkuList()
                    // 获取集合流
            .stream()
            /**1. 打印商品信息*/
            .peek(sku -&gt; System.out.println(JSON.toJSONString(sku)))
            /**2. 过滤掉所有的图书类商品*/
            .filter(sku -&gt; !SkuCategoryEnum.BOOKS.equals(sku.getSkuCategory()))
            /**3. 价格进行排序，默认是从小到大，调用reversed进行翻转排序即从大到小*/
            .sorted(Comparator.comparing(Sku::getTotalPrice).reversed())
            /**4. 取top2*/
            .limit(2)
            /**累加金额*/
            .peek(sku -&gt; money.set(money.get() + sku.getTotalPrice()))
            /**获取商品名称*/
            .map(sku -&gt; sku.getSkuName())
            .collect(Collectors.toList());
    System.out.println(&quot;商品总价:&quot; + money.get());
    System.out.println(&quot;商品名列表:&quot; + JSON.toJSONString(resultSkuNameList));
}
</code></pre><p>运行结果：</p>
<pre><code>{&quot;skuCategory&quot;:&quot;ELECTRONICS&quot;,&quot;skuId&quot;:2,&quot;skuName&quot;:&quot;无人机&quot;,&quot;skuPrice&quot;:1000.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:1000.0}
{&quot;skuCategory&quot;:&quot;ELECTRONICS&quot;,&quot;skuId&quot;:1,&quot;skuName&quot;:&quot;VR一体机&quot;,&quot;skuPrice&quot;:2100.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:2100.0}
{&quot;skuCategory&quot;:&quot;CLOTHING&quot;,&quot;skuId&quot;:4,&quot;skuName&quot;:&quot;牛仔裤&quot;,&quot;skuPrice&quot;:60.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:60.0}
{&quot;skuCategory&quot;:&quot;CLOTHING&quot;,&quot;skuId&quot;:13,&quot;skuName&quot;:&quot;衬衫&quot;,&quot;skuPrice&quot;:120.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:120.0}
{&quot;skuCategory&quot;:&quot;BOOKS&quot;,&quot;skuId&quot;:121,&quot;skuName&quot;:&quot;Java编程思想&quot;,&quot;skuPrice&quot;:100.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:100.0}
{&quot;skuCategory&quot;:&quot;BOOKS&quot;,&quot;skuId&quot;:3,&quot;skuName&quot;:&quot;程序化广告&quot;,&quot;skuPrice&quot;:80.0,&quot;totalNum&quot;:10,&quot;totalPrice&quot;:80.0}
商品总价:3100.0
商品名列表:[&quot;VR一体机&quot;,&quot;无人机&quot;]
</code></pre><p>我们可以看到，通过Stream集合操作，运行结果与传统集合操作完全一致。但是编码量却能够显著减少。</p>
<p><strong>辩证的分析一下</strong>，如果对Stream操作没有一个较为明确的了解，阅读这段代码确实有些难度，但是只要有一点了解，Stream集合操作代码带来的无论是编码量显著降低还是可读性提升，亦或是内存空间的节约都是可观的。</p>
<h2 id="阶段小结"><a href="#阶段小结" class="headerlink" title="阶段小结"></a>阶段小结</h2><p>可见，学习并运用Lambda及Stream编程，对于提升我们的编码效率以及提升代码可读性都有着明显的收益。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本章节中，我们通过一个实战案例对比原始集合操作与Stream集合操作具体有哪些不同，直观地展示Stream集合操作对编程效率的提升。&lt;/p&gt;
&lt;h2 id=&quot;案例：对比原始集合操作与Stream集合操作&quot;&gt;&lt;a href=&quot;#案例：对比原始集合操作与Stream集合操作&quot; class=&quot;headerlink&quot; title=&quot;案例：对比原始集合操作与Stream集合操作&quot;&gt;&lt;/a&gt;案例：对比原始集合操作与Stream集合操作&lt;/h2&gt;&lt;h3 id=&quot;需求场景：&quot;&gt;&lt;a href=&quot;#需求场景：&quot; class=&quot;headerlink&quot; title=&quot;需求场景：&quot;&gt;&lt;/a&gt;需求场景：&lt;/h3&gt;&lt;p&gt;针对上面的购物车，我们想要&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;全局查看购物车中都有哪些商品&lt;/li&gt;
&lt;li&gt;将购物车中的图书类商品进行过滤（删除图书类商品）&lt;/li&gt;
&lt;li&gt;在其余商品中挑选两件最贵的&lt;/li&gt;
&lt;li&gt;打印出上述两件商品的名称和总价&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="Java" scheme="http://wuwenliang.net/categories/Java/"/>
    
    
      <category term="Java" scheme="http://wuwenliang.net/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Java8函数式编程之Lambda入门及案例解析</title>
    <link href="http://wuwenliang.net/2020/05/16/Java8%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%E4%B9%8BLambda%E5%85%A5%E9%97%A8%E5%8F%8A%E6%A1%88%E4%BE%8B%E8%A7%A3%E6%9E%90/"/>
    <id>http://wuwenliang.net/2020/05/16/Java8函数式编程之Lambda入门及案例解析/</id>
    <published>2020-05-16T02:03:50.000Z</published>
    <updated>2020-05-17T05:52:10.315Z</updated>
    
    <content type="html"><![CDATA[<p>这是一个新的系列，主要讲Java8的lambda编程以及Stream流式编程相关的用法和案例。</p>
<p>这个系列脱胎于一个内部的分享，由于篇幅较长，内容较多，因此拆分成多篇文章进行发布，方便自己后续参考，也希望能够帮到读者朋友。</p>
<p>在这里重点感谢慕课网的 <strong>《告别996，开启Java高效编程之门》</strong> 课程。</p>
<p>本文是Java8函数式编程系列的第一篇，我们一起学习一下Java8函数式编程的基本概念及操作。</p>
<h2 id="1-概述Lambda表达式"><a href="#1-概述Lambda表达式" class="headerlink" title="1.概述Lambda表达式"></a>1.概述Lambda表达式</h2><blockquote>
<p>Lambda 表达式，也可称为闭包，它是推动 Java 8 发布的最重要新特性。</p>
<p>Lambda 允许把函数作为一个方法的参数（函数作为参数传递进方法中）。</p>
</blockquote>
<p>使用 Lambda 表达式可以使代码变的更加简洁紧凑。</p>
<a id="more"></a>
<h3 id="1-1-lambda表达式语法"><a href="#1-1-lambda表达式语法" class="headerlink" title="1.1 lambda表达式语法"></a>1.1 lambda表达式语法</h3><pre><code>(parameters) -&gt; expression
或
(parameters) -&gt; {statement};
</code></pre><ol>
<li><p>我们可以将lambda表达式理解为一种代替原先匿名函数的新的编程方式</p>
</li>
<li><p>通过使用lambda表达式替换匿名函数的形式，将lambda表达式作为方法参数，实现判断逻辑参数化传递的目的。</p>
</li>
</ol>
<h3 id="1-2-lambda表达式形式"><a href="#1-2-lambda表达式形式" class="headerlink" title="1.2 lambda表达式形式"></a>1.2 lambda表达式形式</h3><p>无参数</p>
<pre><code>() -&gt; System.out.println(&quot;code&quot;);
</code></pre><p>只有一个参数</p>
<pre><code>name -&gt; System.out.println(&quot;hello:&quot; + name + &quot;!&quot;);
</code></pre><p>没有参数，且逻辑复杂，需要通过大括号将多个语句括起来</p>
<pre><code>() -&gt; {    
    System.out.println(&quot;hello&quot;);    
    System.out.println(&quot;lambda&quot;);
}
</code></pre><p>包含两个参数的方法</p>
<pre><code>BinaryOperator&lt;Long&gt; functionAdd = (x, y) -&gt; x + y;
Long result = functionAdd.apply(1L, 2L);
</code></pre><p>包含两个参数且对参数显式声明</p>
<pre><code>BinaryOperator&lt;Long&gt; functionAdd = (Long x, Long y) -&gt; x + y;
Long result = functionAdd.apply(1L, 2L);
</code></pre><h3 id="1-3-函数式接口"><a href="#1-3-函数式接口" class="headerlink" title="1.3 函数式接口"></a>1.3 函数式接口</h3><p>定义:</p>
<blockquote>
<p>一个接口有且只有一个抽象方法;</p>
</blockquote>
<p>函数式接口的实例可以通过 lambda 表达式、方法引用或者构造方法引用来创建;</p>
<p><strong>注意</strong>：</p>
<p>如果一个接口只有一个抽象方法，那么该接口就是一个函数式接口</p>
<p>如果我们在某个接口上声明了 <strong>@FunctionalInterface</strong> 注解，那么编译器就会按照函数式接口的定义来要求该接口</p>
<p>@FunctionInterface是Java8函数式接口注解，属于声明式注解，帮助编译器校验被标注的接口是否符合函数式接口定义</p>
<h3 id="1-4-方法引用"><a href="#1-4-方法引用" class="headerlink" title="1.4 方法引用"></a>1.4 方法引用</h3><p>我们通过Lambda表达式来实现匿名方法。</p>
<p>有些情况下，使用Lambda表达式仅仅是调用一些已经存在的方法；除了调用动作外，没有其他任何多余的动作，在这种情况下我们倾向于通过方法名来调用它，而Lambda表达式可以帮助我们实现这一要求。它使得Lambda在调用那些已经拥有方法名的方法的代码更简洁、更容易理解。</p>
<p>方法引用可以理解为Lambda表达式的另外一种表现形式。</p>
<p>方法引用是调用特定方法的lambda表达式的一种快捷写法，可以让你重复使用现有的方法定义，并像lambda表达式一样传递他们。</p>
<p>注意:</p>
<p>使用方法引用时，只写方法名，不写括号</p>
<h4 id="1-4-1-方法引用格式"><a href="#1-4-1-方法引用格式" class="headerlink" title="1.4.1 方法引用格式:"></a>1.4.1 方法引用格式:</h4><pre><code>格式: 目标引用    双冒号分隔符   方法名

eg:  String       ::        valueOf
</code></pre><h4 id="1-4-2-方法引用分类"><a href="#1-4-2-方法引用分类" class="headerlink" title="1.4.2 方法引用分类:"></a>1.4.2 方法引用分类:</h4><p>1.指向静态方法的方法引用：当Lambda表达式的结构体是一个对象，并且调用其静态方法时，使用如下方式</p>
<pre><code>表达式:
    (args) -&gt; ClassName::staticMethod(args);
格式:    ClassName :: staticMethodName
eg:     Integer   :: valueOf
</code></pre><p>2.指向任意类型实例方法的方法引用：当直接调用对象的实例方法，则使用如下方式进行调用</p>
<pre><code>表达式:
        (args) -&gt; args.instanceMethod();
格式:  ClassName::instanceMethod;
eg:   String::indexOf  
            String::toString
</code></pre><p>3.指向现有对象的实例方法的方法引用：通过对象实例，方法引用实例方法</p>
<pre><code>表达式:
    (args) -&gt; object.instanceMethod(args);
    改写为
    (args) -&gt;  object::instanceMethod;
eg:
    StringBuilder sb = new StringBuilder();
    Consumer&lt;String&gt; consumer = (String str) -&gt; stringBuilder.append(str);
就可以改写为

Consumer&lt;String&gt; consumer = (String str) -&gt; stringBuilder::append;
</code></pre><h2 id="2-从一个案例入手"><a href="#2-从一个案例入手" class="headerlink" title="2.从一个案例入手"></a>2.从一个案例入手</h2><p>我们先看一个例子，宏观感受一下Java8 Lambda编程带来的便利（后续讲解Stream同样使用该案例）</p>
<h3 id="2-1-案例：直观体验Java8Stream操作"><a href="#2-1-案例：直观体验Java8Stream操作" class="headerlink" title="2.1 案例：直观体验Java8Stream操作"></a>2.1 案例：直观体验Java8Stream操作</h3><p>Sku实体类:  标识一个电商下单商品信息对象</p>
<pre><code>public class Sku {
    // 商品编号
    private Integer skuId;
    // 商品名称
    private String skuName;
    // 单价
    private Double skuPrice;
    // 购买个数
    private Integer totalNum;
    // 总价
    private Double totalPrice;
    // 商品类型
    private Enum skuCategory;

    public Sku() {
    }

    public Sku(Integer skuId, String skuName, Double skuPrice, Integer totalNum, Double totalPrice, Enum skuCategory) {
        this.skuId = skuId;
        this.skuName = skuName;
        this.skuPrice = skuPrice;
        this.totalNum = totalNum;
        this.totalPrice = totalPrice;
        this.skuCategory = skuCategory;
    }
        ...省略getter  setter...
}
</code></pre><p>SkuCategoryEnum枚举类: 商品类型枚举</p>
<pre><code>public enum SkuCategoryEnum {
    CLOTHING(10, &quot;服务类&quot;),
    ELECTRONICS(20, &quot;数码产品类&quot;),
    SPORTS(30, &quot;运动类&quot;),
    BOOKS(40, &quot;图书类&quot;)
    ;

    // 商品类型编号
    private Integer code;
    // 商品名称
    private String name;

    SkuCategoryEnum(Integer code, String name) {
        this.code = code;
        this.name = name;
    }
    ...省略getter...
}
</code></pre><p>CartService类: 初始化一批数据，模拟购物车</p>
<pre><code>public class CartService {
    // 初始化购物车
    private static List&lt;Sku&gt; cartSkuList = new ArrayList&lt;&gt;();

    static {
        cartSkuList.add(new Sku(2, &quot;无人机&quot;, 1000.00, 10, 1000.00, SkuCategoryEnum.ELECTRONICS));
        cartSkuList.add(new Sku(1, &quot;VR一体机&quot;, 2100.00, 10, 2100.00, SkuCategoryEnum.ELECTRONICS));
        cartSkuList.add(new Sku(4, &quot;牛仔裤&quot;, 60.00, 10, 60.00, SkuCategoryEnum.CLOTHING));
        cartSkuList.add(new Sku(13, &quot;衬衫&quot;, 120.00, 10, 120.00, SkuCategoryEnum.CLOTHING));
        cartSkuList.add(new Sku(121, &quot;Java编程思想&quot;, 100.00, 10, 100.00, SkuCategoryEnum.BOOKS));
        cartSkuList.add(new Sku(3, &quot;程序化广告&quot;, 80.00, 10, 80.00, SkuCategoryEnum.BOOKS));
    }

    public static List&lt;Sku&gt; getCartSkuList() {
        return cartSkuList;
    }
}
</code></pre><p>我们直接看这个案例</p>
<pre><code>private static List&lt;Sku&gt; cartSkuList = CartService.getCartSkuList();

@Test
public void show() {
    List&lt;Integer&gt; collect = cartSkuList.stream()
            // 方法引用
            .map(Sku::getSkuId)
            .distinct()
            .sorted()
            .collect(Collectors.toList());
    collect.stream().forEach(skuId -&gt; {
        System.out.println(skuId.toString());
    });
}
</code></pre><p>简单解释下这段代码的意图：</p>
<p>首先获取购物车中商品列表，将该列表转换为流；收集商品列表中的所有商品编号（skuId），对商品编号进行去重，并进行自然排序（升序排列），最后收集为一个商品编号集合，并对该集合进行遍历打印。</p>
<p>我并没有加注释，但是相信聪明的你也一定能读懂上面这段代码，这正是Stream编程的特点：方法名见名知意，流式编程方式符合人类思考逻辑</p>
<p>运行该用例，打印如下：</p>
<pre><code>1
2
3
4
13
121
</code></pre><p>打印结果符合我们的预期意图。</p>
<p>想象一下，如果不使用lambda+Stream方式，而是使用java7及之前的传统集合操作，实现上述操作我们的代码量有多少？保守估计至少是上述代码段的1.5倍。</p>
<p>这个案例可能还不具备说服力，接下来的文章中，我将通过一个对比案例来比较lambda编程与传统方式对集合操作的效率提升。</p>
<p>我们下文继续。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这是一个新的系列，主要讲Java8的lambda编程以及Stream流式编程相关的用法和案例。&lt;/p&gt;
&lt;p&gt;这个系列脱胎于一个内部的分享，由于篇幅较长，内容较多，因此拆分成多篇文章进行发布，方便自己后续参考，也希望能够帮到读者朋友。&lt;/p&gt;
&lt;p&gt;在这里重点感谢慕课网的 &lt;strong&gt;《告别996，开启Java高效编程之门》&lt;/strong&gt; 课程。&lt;/p&gt;
&lt;p&gt;本文是Java8函数式编程系列的第一篇，我们一起学习一下Java8函数式编程的基本概念及操作。&lt;/p&gt;
&lt;h2 id=&quot;1-概述Lambda表达式&quot;&gt;&lt;a href=&quot;#1-概述Lambda表达式&quot; class=&quot;headerlink&quot; title=&quot;1.概述Lambda表达式&quot;&gt;&lt;/a&gt;1.概述Lambda表达式&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;Lambda 表达式，也可称为闭包，它是推动 Java 8 发布的最重要新特性。&lt;/p&gt;
&lt;p&gt;Lambda 允许把函数作为一个方法的参数（函数作为参数传递进方法中）。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;使用 Lambda 表达式可以使代码变的更加简洁紧凑。&lt;/p&gt;
    
    </summary>
    
      <category term="Java" scheme="http://wuwenliang.net/categories/Java/"/>
    
    
      <category term="Java" scheme="http://wuwenliang.net/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>跟我学zookeeper之curator客户端入门及集群选主</title>
    <link href="http://wuwenliang.net/2020/05/05/%E8%B7%9F%E6%88%91%E5%AD%A6zookeeper%E4%B9%8Bcurator%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%85%A5%E9%97%A8%E5%8F%8A%E9%9B%86%E7%BE%A4%E9%80%89%E4%B8%BB/"/>
    <id>http://wuwenliang.net/2020/05/05/跟我学zookeeper之curator客户端入门及集群选主/</id>
    <published>2020-05-05T15:29:41.000Z</published>
    <updated>2020-05-10T13:14:46.151Z</updated>
    
    <content type="html"><![CDATA[<p>zookeeper作为分布式系统中重要的协调组件，在后端开发中是难以绕开的一个重要知识领域。</p>
<p>可以说，只要在后端领域，比如说Java开发、大数据开发中呆过三年及以上的工程师，或多或少都接触过或者直接使用过zookeeper。</p>
<p>因此笔者开启本系列，作为自己学习zookeeper（后文均称为zk）的记录，如果能够启发读者那就更好不过了。</p>
<h2 id="zookeeper概述"><a href="#zookeeper概述" class="headerlink" title="zookeeper概述"></a>zookeeper概述</h2><blockquote>
<p>ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。</p>
<p>它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。</p>
</blockquote>
<p>度娘如是说。</p>
<p>zookeeper，直译过来就是动物园管理员，之所以这么说，主要是因为它在大数据技术栈中扮演了重要的协调角色。</p>
<p>在hadoop技术栈中，各种技术的logo都是小动物，而zookeeper的官方logo也是一位园丁模样的男士。这也直观的告诉了使用者，zk的用途和角色。</p>
<p>一言蔽之，zk就是在分布式系统中，对应用提供一致性保证，分布式选主，通过各种机制，对应用进行协调，从而使分布式系统对外提供某种特定的服务。</p>
<p><img src="/2020/05/05/跟我学zookeeper之curator客户端入门及集群选主/1.png" alt="zookeeper官方形象"></p>
<a id="more"></a>
<p>关于如何搭建zookeeper，网络上文章有很多，本文就不进行展开，感兴趣的可以自行查找相关资料。</p>
<p><a href="https://zookeeper.apache.org/" target="_blank" rel="external">zookeeper官网</a></p>
<h2 id="curator概述"><a href="#curator概述" class="headerlink" title="curator概述"></a>curator概述</h2><blockquote>
<p>Apache Curator是Netflix公司开源的一套zookeeper客户端框架，并贡献给了apache社区。</p>
<p>它封装了Zookeeper客户端底层的api，提供了流式风格的api，提供了很多开箱即用的高级特性，如：分布式选主、分布式锁、path监控、node监控、更加易用的节点CRUD操作、分布式队列等。</p>
<p>Patrixck Hunt（Zookeeper的commiter）以一句“Guava is to Java that Curator to Zookeeper”给予Curator高度评价。</p>
</blockquote>
<p>目前主流的zookeeper客户端共有三种：</p>
<ul>
<li>官方zookeeper客户端</li>
<li>zkClient</li>
<li>curator</li>
</ul>
<p>其中，官方的客户端提供的api都比较底层，开发者直接拿来用需要进行一定的封装，否则直接使用会显得过于复杂和繁琐；zkclient虽然使用起来比较方便，但是文档较少，社区也不太活跃；而curator则是apache顶级项目，拥有活跃的开源社区，且拥有较多的成熟api和高级特性。</p>
<p>因此在zk的客户端这个领域，curator大受推崇。</p>
<p><a href="http://curator.apache.org/index.html" target="_blank" rel="external">Apache curator官网</a></p>
<p><img src="/2020/05/05/跟我学zookeeper之curator客户端入门及集群选主/2.png" alt="2.png"></p>
<h2 id="curator基础操作"><a href="#curator基础操作" class="headerlink" title="curator基础操作"></a>curator基础操作</h2><p>我们通过代码来直接感受一下curator操作的快捷。</p>
<p>首先需要在工程中引入curator的依赖：</p>
<pre><code>&lt;!-- https://mvnrepository.com/artifact/org.apache.curator/curator-framework --&gt;
&lt;dependency&gt;
  &lt;groupId&gt;org.apache.curator&lt;/groupId&gt;
  &lt;artifactId&gt;curator-framework&lt;/artifactId&gt;
  &lt;version&gt;4.3.0&lt;/version&gt;
&lt;/dependency&gt;
&lt;!-- https://mvnrepository.com/artifact/org.apache.curator/curator-recipes --&gt;
&lt;dependency&gt;
  &lt;groupId&gt;org.apache.curator&lt;/groupId&gt;
  &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt;
  &lt;version&gt;4.3.0&lt;/version&gt;
&lt;/dependency&gt;
</code></pre><p><strong>注意</strong> 笔者使用的zookeeper服务端版本为3.5.6，因此使用4.0.0以上版本的curator是兼容的。</p>
<p>对于较低版本的zookeeper服务端，如3.4.x，则需要依赖curator2.x版本，如：2.12.0。如果使用高版本的curator，需要将curator自身依赖的ZooKeeper在maven中exclude掉。 并引入对应的低版本zookeeper客户端。</p>
<p>关于curator与zookeeper具体的版本依赖，请参考官方的说明 <a href="http://curator.apache.org/zk-compatibility.html" target="_blank" rel="external">ZooKeeper Version Compatibility</a></p>
<h3 id="创建客户端实例"><a href="#创建客户端实例" class="headerlink" title="创建客户端实例"></a>创建客户端实例</h3><p>使用Curator第一步是要创建一个客户端实例，代码如下：(后续的操作中，第一步均是创建客户端实例。后续讲解过程中只粘贴关键代码，在文章的末尾会粘贴本文中所有的代码案例的完整代码)。</p>
<pre><code>RetryPolicy retry = new ExponentialBackoffRetry(1000, 3);
CuratorFramework client =
        CuratorFrameworkFactory.newClient(&quot;127.0.0.1:2181&quot;, retry);
client.start();
System.out.println(&quot;启动curator客户端&quot;);
</code></pre><p>简单解释下这段代码的含义：</p>
<ol>
<li>首先创建一个重试策略实例RetryPolicy，当客户端与zk服务端连接失败或者超时，curator会使用我们指定的<br>重试策略进行重试。RetryPolicy有多个实现，这里使用ExponentialBackoffRetry策略，重试三次，每次间隔1秒钟。</li>
<li><p>通过CuratorFrameworkFactory创建一个CuratorFramework实例，传入zk连接地址以及重试策略。<br>示例代码中为单机方式连接串，如果是多节点方式只需要通过半角逗号分割的方式进行连接即可。</p>
<pre><code>多节点连接串
ip0:port0,ip1:port1,ip2:port2
</code></pre></li>
<li><p>调用CuratorFramework.start()方法，与zk服务端建立连接。</p>
</li>
</ol>
<p>如此，我们的客户端便能够与zk服务端建立起长连接，从而为各种交互做准备。</p>
<h3 id="节点操作"><a href="#节点操作" class="headerlink" title="节点操作"></a>节点操作</h3><p>连接建立好后，我们来学习一下curator如何对zk节点进行操作。通俗地说就是通过curator对zk的node做增删改查操作。</p>
<pre><code>try {
    // 增加
    client.create()
            .creatingParentsIfNeeded()
            .withMode(CreateMode.PERSISTENT)
            .forPath(&quot;/snowalker/path&quot;, &quot;100&quot;.getBytes());

    // 读取node的值
    byte[] dataBytes = client.getData().forPath(&quot;/snowalker/path&quot;);

    System.out.println(new String(dataBytes));
    // 修改node对应的值
    client.setData().forPath(&quot;/snowalker/path&quot;, &quot;120&quot;.getBytes());
    byte[] dataBytes1 = client.getData().forPath(&quot;/snowalker/path&quot;);

    System.out.println(new String(dataBytes1));
    // 获取子节点
    List&lt;String&gt; children = client.getChildren().forPath(&quot;/snowalker&quot;);
    System.out.println(children);

    // 删除节点
    client.delete().forPath(&quot;/snowalker/path&quot;);
} catch (Exception e) {
    e.printStackTrace();
} finally {
    client.close();
}
</code></pre><p>这段代码基本上就涵盖了curator对zk的node进行增删改查的主流操作了。介绍下代码含义：</p>
<ol>
<li>[增]首先，通过create方法在zk上创建了 ”/snowalker/path“ 这样一个持久化节点。方法 creatingParentsIfNeeded() 表示 <strong>如果有必要则创建父节点</strong>，也就是递归地创建多个节点。</li>
<li>节点建立后，写入value；value在zk的node上以字节形式进行存储；初始值为100，并进行打印</li>
<li>[查]通过CuratorFramework.getData().forPath(“/snowalker/path”)  可以读取对应节点的value</li>
<li>[改]接着我们通过CuratorFramework.setData() 修改”/snowalker/path“ 对应的value为120，并进行打印</li>
<li>如果想要获取某个子节点，我们可以通过CuratorFramework.getChildren().forPath(path) 方法获取，返回一个list；也就是说，zk的子节点是一对多的（zk文件系统是树形结构）</li>
<li>[删]通过执行CuratorFramework.delete().forPath(path) 能够将指定path进行删除</li>
</ol>
<p>运行代码，观察到日志打印如下：</p>
<pre><code>启动curator客户端
100
120
[path]
</code></pre><p>使用zkcli连接zookeeper服务端，ls看一下 /snowalker 目录下的节点：</p>
<pre><code>[zk: localhost:2181(CONNECTED) 6] ls /
[snowalker]
[zk: localhost:2181(CONNECTED) 7] ls /snowalker
[]
[zk: localhost:2181(CONNECTED) 8]
</code></pre><p>当前只有 /snowalker 节点存在，子节点已经被删除。</p>
<p>可以看到，通过curator，我们通过几行代码便实现了对zk node的增删改查</p>
<h2 id="curator进阶操作"><a href="#curator进阶操作" class="headerlink" title="curator进阶操作"></a>curator进阶操作</h2><p>zk提供了分布式选主、watcher动态监听等机制，能够为分布式系统提供分布式协调，配置实时变更通知等能力。Curator当然也提供了对应的API供我们进行调用。</p>
<p>接下来我们就分别看一下如何使用Curator来使用这些能力。</p>
<h3 id="集群选主"><a href="#集群选主" class="headerlink" title="集群选主"></a>集群选主</h3><p>首先看一下如何利用Curator实现集群选主。</p>
<p>Curator提供两种方式进行集群选主，分别为：</p>
<ul>
<li>LeaderLatch方式</li>
<li>LeaderElection方式</li>
</ul>
<h4 id="LeaderLatch方式"><a href="#LeaderLatch方式" class="headerlink" title="LeaderLatch方式"></a>LeaderLatch方式</h4><p>首先观察一下leaderLatch选主方式调用方式：</p>
<pre><code>public class LeaderLatchDemo {

    public static void main(String[] args) throws Exception {
        new LeaderLatchDemo().leaderLatch();
    }

    public void leaderLatch() throws Exception {
</code></pre><p>首先我们还是要实例化一个CuratorFramework客户端，与zk服务端建立连接</p>
<pre><code>RetryPolicy retry = new ExponentialBackoffRetry(1000, 3);
CuratorFramework client =
        CuratorFrameworkFactory.newClient(
                &quot;127.0.0.1:2181&quot;,
                5000,
                3000,
                retry);
client.start();
System.out.println(&quot;启动curator客户端&quot;);
</code></pre><p>接着注册一个连接状态监听器，在回调方法中根据返回的连接状态进行对应操作。</p>
<p>当连接状态ConnectionState为LOST时，表明客户端到服务端的连接已经断开，如果当前节点已经是leader，那么我们就需要暂停leader身份下的一切事情。</p>
<p>如果我们查看源码的话，会发现curator内部会将是否为leader的状态设置为false（已经不是leader了）</p>
<pre><code>client.getConnectionStateListenable().addListener(new ConnectionStateListener() {
    @Override
    public void stateChanged(CuratorFramework client, ConnectionState newState) {
        switch (newState) {
            case LOST: {
                break;
            }
        }
    }
});
</code></pre><p>我们声明一个路径作为选主的依据。</p>
<p>通过 <strong>LeaderLatch leaderLatch = new LeaderLatch(client, latchPath);</strong> 实例化一个LeaderLatch实例，通过它进行leader选举操作。</p>
<pre><code>// latch
String latchPath = &quot;/snowalker/leader_latch&quot;;
LeaderLatch leaderLatch = new LeaderLatch(client, latchPath);
// 开启leader选举过程
leaderLatch.start();
// 判断当前节点是否为leader
boolean hasLeadershipBefore = leaderLatch.hasLeadership();
System.out.println(&quot;是否成为leader:&quot; + hasLeadershipBefore);

leaderLatch.await();    
</code></pre><p>当通过 <strong>leaderLatch.start()</strong> 开启leader选举之后，我们需要调用  <strong>leaderLatch.await()</strong> 。</p>
<p>如果当前的客户端未成为leader，则会进行等待，（内部源码实现是通过Object.wait()进行阻塞） 直到成为leader后，当前客户端线程会被唤醒，继续执行后续逻辑。</p>
<p>这里说的后续逻辑，实际上就是客户端作为leader节点需要执行的业务逻辑。比如：hdfs中两台机器，当其中一台机器成为主节点就会以主节点的身份对外提供文件相关服务，而另外一台非leader机器则会await在这里，直到它成为leader才会作为主节点提供服务。（也就是说，只有被选为leader的节点才会真正的提供服务，否则它看起来就好像 “假死” 了）</p>
<pre><code>        boolean hasLeadershipAfter = leaderLatch.hasLeadership();
        System.out.println(&quot;是否成为leader:&quot; + hasLeadershipAfter);
        Thread.sleep(100000);
    }
}
</code></pre><p>最后我们再打印一下节点的状态，看当前节点是否成为leader。</p>
<h5 id="运行效果"><a href="#运行效果" class="headerlink" title="运行效果"></a>运行效果</h5><p>我们同时启动两个LeaderLatchDemo主进程，模拟双节点下的leader选举过程。</p>
<p>两个客户端控制台打印如下：</p>
<blockquote>
<p>客户端A</p>
</blockquote>
<pre><code>启动curator客户端
是否成为leader:false
</code></pre><blockquote>
<p>客户端B</p>
</blockquote>
<pre><code>启动curator客户端
是否成为leader:false
是否成为leader:true
</code></pre><p>上述日志打印，表明开始阶段，两个客户端均非leader。</p>
<p>当经过竞争之后，客户端B成为leader，而客户端A则阻塞。我们尝试关闭客户端B进程，观察客户端A的控制台日志打印：</p>
<blockquote>
<p>客户端A</p>
</blockquote>
<pre><code>启动curator客户端
是否成为leader:false
是否成为leader:true
</code></pre><p>我们发现，客户端A成为了leader，从阻塞中唤醒。</p>
<p>这个小demo直观的为我们展现了通过leaderLatch进行leader选举的场景。</p>
<h4 id="LeaderElection方式"><a href="#LeaderElection方式" class="headerlink" title="LeaderElection方式"></a>LeaderElection方式</h4><p>curator为我们提供了一种更为简洁的leader选举方式，它就是 <strong>LeaderElection</strong> 方式。（<strong>实际上</strong>，LeaderElection与LeaderLatch在原理上几乎没有差别，他们的原理都是基于分布式锁实现的，只不过LeaderElection方式在使用上更加简洁，开发效率更高）</p>
<p>话不多说，直接上代码：</p>
<pre><code>public class LeaderElectionDemo {

    public static void main(String[] args) throws InterruptedException {
</code></pre><p>首先还是实例化一个CuratorFramework建立到zk服务端的连接。</p>
<pre><code>RetryPolicy retry = new ExponentialBackoffRetry(1000, 3);
CuratorFramework client =
        CuratorFrameworkFactory.newClient(
                &quot;127.0.0.1:2181&quot;,
                5000,
                3000,
                retry);
client.start();
System.out.println(&quot;启动curator客户端&quot;);
</code></pre><p>接着定义一个leader选举节点，这个操作和LeaderLatch相似。</p>
<pre><code>String election = &quot;/leader/election&quot;;
</code></pre><p>这里就不同了，我们需要建立一个LeaderSelector实例，它接收CuratorFramework实例、选举节点、以及一个LeaderSelectorListener  Leader选举监听器。</p>
<p>我们需要实现LeaderSelectorListener的回调方法：</p>
<ul>
<li>takeLeadership回调中需要开发者实现当成为leader之后的业务逻辑。当一个客户端成为leader之后，便会回调takeLeadership方法，执行leader角色的业务逻辑</li>
<li><p>stateChanged方法需要开发者实现当连接状态发生变化之后的业务逻辑。比如：我们可以直接抛出异常，阻止leader业务逻辑继续进行。待另外的节点成为leader后执行takeLeadership方法</p>
<pre><code>LeaderSelector leaderSelector = new LeaderSelector(
        client,
        election,
        new LeaderSelectorListener() {
            @Override
            public void takeLeadership(CuratorFramework curatorFramework) throws Exception {
                System.out.println(&quot;你已经成为leader&quot;);
                // 在 这里干leader的所有事情，此时方法不能退出
                Thread.sleep(Integer.MAX_VALUE);
            }

            @Override
            public void stateChanged(CuratorFramework curatorFramework, ConnectionState connectionState) {
                System.out.println(&quot;你已经不是leader，链接状态发生变化，connectionState&quot; + connectionState);
                if (connectionState.equals(ConnectionState.LOST)) {
                    throw new CancelLeadershipException();
                }
            }
        });
</code></pre></li>
</ul>
<p>通过调用LeaderSelector.start之后，多个客户端会在election节点下竞争leader角色。当某个客户端竞争leader成功，就会执行takeLeadership回调方法通知当前应用节点已经成为leader。接着执行leader角色的逻辑即可</p>
<pre><code>        leaderSelector.start();
        Thread.sleep(Integer.MAX_VALUE);
    }
}
</code></pre><h5 id="运行代码"><a href="#运行代码" class="headerlink" title="运行代码"></a>运行代码</h5><p>我们启动两个LeaderElectionDemo客户端，让他们进行leader角色的选举操作，观察控制台输出：</p>
<p>客户端A打印如下：</p>
<pre><code>启动curator客户端
你已经成为leader
</code></pre><p>客户单B打印如下：</p>
<pre><code>启动curator客户端
</code></pre><p>这表明，客户端A竞争leader成功，并成功执行了回调方法takeLeadership。客户端B竞争leader失败，进程阻塞。</p>
<p>我们强制关闭客户端A，此时客户端B控制台输出如下：</p>
<pre><code>启动curator客户端
你已经成为leader
</code></pre><p>这表明，客户端A释放了leader角色，客户端B竞争成功，并开始执行leader角色的方法。</p>
<p><strong>事实上</strong> LeaderElection方式内部实现机制几乎与LeaderLatch方式一模一样，它本质上也是通过分布式锁竞争成为leader的。</p>
<p>具体到细节就是，LeaderElection是通过使用curator实现的mutex锁进行leader竞争。如果获取到的锁就是leader。<br>如果竞争leader的时候竞争锁失败，则会阻塞，并为上个节点添加watcher。</p>
<p>当上个节点对应的客户端down机或者长时间断开连接，则顺序临时节点就消失了，此时watcher会通知后一个节点进行加锁。后面的节点加锁成功便会成为leader角色。</p>
<p>我们发现，这其实就是Curator的分布式锁实现机制啊。</p>
<p>后续我们会对LeaderElection具体的代码实现进行展开讲解。敬请期待。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文到此就告一段落了，我们对curator的基本使用以及重要的leader选举特性进行了全方位的讲解和展示。</p>
<p>这里做个预告，接下来我会带领读者朋友们继续学习curator对zookeeper的watcher机制的封装和增强。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;zookeeper作为分布式系统中重要的协调组件，在后端开发中是难以绕开的一个重要知识领域。&lt;/p&gt;
&lt;p&gt;可以说，只要在后端领域，比如说Java开发、大数据开发中呆过三年及以上的工程师，或多或少都接触过或者直接使用过zookeeper。&lt;/p&gt;
&lt;p&gt;因此笔者开启本系列，作为自己学习zookeeper（后文均称为zk）的记录，如果能够启发读者那就更好不过了。&lt;/p&gt;
&lt;h2 id=&quot;zookeeper概述&quot;&gt;&lt;a href=&quot;#zookeeper概述&quot; class=&quot;headerlink&quot; title=&quot;zookeeper概述&quot;&gt;&lt;/a&gt;zookeeper概述&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。&lt;/p&gt;
&lt;p&gt;它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;度娘如是说。&lt;/p&gt;
&lt;p&gt;zookeeper，直译过来就是动物园管理员，之所以这么说，主要是因为它在大数据技术栈中扮演了重要的协调角色。&lt;/p&gt;
&lt;p&gt;在hadoop技术栈中，各种技术的logo都是小动物，而zookeeper的官方logo也是一位园丁模样的男士。这也直观的告诉了使用者，zk的用途和角色。&lt;/p&gt;
&lt;p&gt;一言蔽之，zk就是在分布式系统中，对应用提供一致性保证，分布式选主，通过各种机制，对应用进行协调，从而使分布式系统对外提供某种特定的服务。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/05/05/跟我学zookeeper之curator客户端入门及集群选主/1.png&quot; alt=&quot;zookeeper官方形象&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="跟我学zookeeper" scheme="http://wuwenliang.net/categories/%E8%B7%9F%E6%88%91%E5%AD%A6zookeeper/"/>
    
    
      <category term="跟我学zookeeper" scheme="http://wuwenliang.net/tags/%E8%B7%9F%E6%88%91%E5%AD%A6zookeeper/"/>
    
  </entry>
  
  <entry>
    <title>基于Centos7.6搭建Java微服务基础环境[持续更新]</title>
    <link href="http://wuwenliang.net/2020/05/01/%E5%9F%BA%E4%BA%8ECentos7-6%E6%90%AD%E5%BB%BAJava%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83-%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0/"/>
    <id>http://wuwenliang.net/2020/05/01/基于Centos7-6搭建Java微服务基础环境-持续更新/</id>
    <published>2020-05-01T13:31:02.000Z</published>
    <updated>2020-07-19T10:27:54.818Z</updated>
    
    <content type="html"><![CDATA[<p>作为开发者，除了能够实现书写代码实现产品需求外，还应当具备一定的运维能力。</p>
<p>这其中就包含了环境搭建能力，能够在一台只装有操作系统的服务器上，搭建起应用的基础运行时环境，搭建并运维中间件。</p>
<p>本文持续更新，将介绍基于centos7.6环境，从零搭建Java微服务运行时环境及搭建并运维相关中间件。</p>
<a id="more"></a>
<h2 id="安装jdk1-8"><a href="#安装jdk1-8" class="headerlink" title="安装jdk1.8"></a>安装jdk1.8</h2><p>首先介绍如何安装jdk1.8。</p>
<h3 id="下载jdk1-8"><a href="#下载jdk1-8" class="headerlink" title="下载jdk1.8"></a>下载jdk1.8</h3><p>前往oracle官网下载页面，选取文件名类似 “jdk-8u251-linux-x64.tar.gz” 的tar.gz文件进行下载。  </p>
<p><a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html" target="_blank" rel="external">jdk官方下载地址</a></p>
<p>往下来拉找到jdk1.8版本的下载地址，点击下载对应的tar.gz文件进行下载。</p>
<p>当前，下载低于1.8版本的jdk需要登录，这篇文章 <a href="https://blog.csdn.net/WNsshssm/article/details/84315519" target="_blank" rel="external">https://blog.csdn.net/WNsshssm/article/details/84315519</a> 给出了一个账号，亲测可用，账号 <strong>2696671285@qq.com</strong> ，密码 <strong>Oracle123</strong></p>
<p>输入账号密码后，会弹出下载框，点击保存文件。</p>
<h3 id="文件上传"><a href="#文件上传" class="headerlink" title="文件上传"></a>文件上传</h3><p>将下载好的文件上传到服务器上，通过rz -y 进行上传。如果命令不可用，执行</p>
<blockquote>
<p>yum -y install lrzsz </p>
</blockquote>
<p>进行安装。</p>
<p>上传完成之后，键入命令</p>
<blockquote>
<p>cp jdk-8u211-linux-x64.tar.gz /usr/java1.8 </p>
</blockquote>
<p>将文件复制到/usr 下重命名为java1.8。该步骤需要root权限，没有权限需要先键入命令su root 获取权限</p>
<h3 id="解压并安装JDK"><a href="#解压并安装JDK" class="headerlink" title="解压并安装JDK"></a>解压并安装JDK</h3><p>键入命令 cd /usr 来到刚才的复制文件处，键入命令</p>
<blockquote>
<p>tar -zxvf java1.8 </p>
</blockquote>
<p>进行解压。</p>
<h3 id="配置JDK环境变量"><a href="#配置JDK环境变量" class="headerlink" title="配置JDK环境变量"></a>配置JDK环境变量</h3><p>键入命令 <strong>vim /etc/profile</strong> 修改配置文件，记得要在root权限下修改。</p>
<p>输入i进入编辑状态，然后将光标移到最后一行，粘贴如下内容，JAVA_HOME 根据自己的解压目录设置即可。</p>
<pre><code>#java environment
export JAVA_HOME=/usr/jdk1.8.0_211
export CLASSPATH=.:${JAVA_HOME}/jre/lib/rt.jar:${JAVA_HOME}/lib/dt.jar:${JAVA_HOME}/lib/tools.jar
export PATH=$PATH:${JAVA_HOME}/bin
</code></pre><h4 id="保存配置"><a href="#保存配置" class="headerlink" title="保存配置"></a>保存配置</h4><p>编辑完成之后，点击esc 进入命令模式 输入：<strong>wq!</strong> 保存修改信息</p>
<p>然后键入如下命令使配置文件生效</p>
<blockquote>
<p>source /etc/profile</p>
</blockquote>
<h3 id="测试安装效果"><a href="#测试安装效果" class="headerlink" title="测试安装效果"></a>测试安装效果</h3><p>键入命令 <strong>java -version</strong> 查看安装结果，打印如下表明安装成功：</p>
<pre><code>java version &quot;1.8.0_251&quot;
Java(TM) SE Runtime Environment (build 1.8.0_251-b08)
Java HotSpot(TM) 64-Bit Server VM (build 25.251-b08, mixed mode)
</code></pre><h2 id="安装Redis"><a href="#安装Redis" class="headerlink" title="安装Redis"></a>安装Redis</h2><p>安装Redis过程较为繁琐，因此从精炼角度出发， 我们只贴出步骤与操作指令，不解释具体原理。</p>
<ul>
<li>1.获取redis资源</li>
</ul>
<blockquote>
<p>wget <a href="http://download.redis.io/releases/redis-4.0.8.tar.gz" target="_blank" rel="external">http://download.redis.io/releases/redis-4.0.8.tar.gz</a></p>
</blockquote>
<ul>
<li>2.解压</li>
</ul>
<blockquote>
<p>tar xzvf redis-4.0.8.tar.gz</p>
</blockquote>
<ul>
<li><p>3.安装</p>
<pre><code>  　cd redis-4.0.8
  　make
  　cd src
  　make install PREFIX=/usr/local/redis
</code></pre></li>
<li><p>4.移动配置文件到安装目录下</p>
<pre><code>  　cd ../
  　mkdir /usr/local/redis/etc
  　mv redis.conf /usr/local/redis/etc
</code></pre><ul>
<li>5.配置redis为后台启动</li>
</ul>
</li>
</ul>
<blockquote>
<p>vi /usr/local/redis/etc/redis.conf //将daemonize no 改成daemonize yes</p>
</blockquote>
<ul>
<li>6.将redis加入到开机启动</li>
</ul>
<blockquote>
<p>vi /etc/rc.local </p>
</blockquote>
<p>在里面添加内容：</p>
<blockquote>
<p>/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf </p>
</blockquote>
<p>意思就是开机调用这段开启redis的命令</p>
<ul>
<li><p>7.开启redis</p>
<blockquote>
<p>/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf </p>
</blockquote>
</li>
<li><p>8.将redis-cli,redis-server拷贝到bin下，让redis-cli指令可以在任意目录下直接使用</p>
<pre><code>cp /usr/local/redis/bin/redis-server /usr/local/bin/
cp /usr/local/redis/bin/redis-cli /usr/local/bin/
</code></pre></li>
<li><p>9.设置redis密码</p>
<pre><code>a.运行命令：redis-cli
b.查看现有的redis密码(可选操作，可以没有)
　　　　运行命令：config get requirepass 如果没有设置过密码的话运行结果会如下图所示
c.设置redis密码
　　　　运行命令：config set requirepass ****(****为你要设置的密码)，设置成功的话会返回‘OK’字样
d.测试连接
　　重启redis服务
　　//（redis-cli -h 127.0.0.1 -p 6379 -a ****（****为你设置的密码））
　　输入 redis-cli 进入命令模式，使用 auth &apos;*****&apos; （****为你设置的密码）登陆　　　　　 
</code></pre></li>
<li><p>10.启动redis有两种方式：</p>
</li>
</ul>
<blockquote>
<p>redis-server &amp;</p>
<p>加上<code>&amp;</code>号使redis以后台程序方式运行</p>
</blockquote>
<p>或者是</p>
<blockquote>
<p>redis-server</p>
</blockquote>
<ul>
<li><p>11.检测后台进程是否存在</p>
<blockquote>
<p>ps -ef |grep redis</p>
</blockquote>
</li>
<li><p>12.检测6379端口是否在监听</p>
<blockquote>
<p>netstat -lntp | grep 6379</p>
</blockquote>
</li>
<li><p>13.停止redis</p>
<blockquote>
<p>redis-cli shutdown</p>
</blockquote>
</li>
</ul>
<p>因为Redis可以妥善处理SIGTERM信号，所以直接kill -9也是可以的</p>
<blockquote>
<p>kill -9 PID</p>
</blockquote>
<p>附录：配置防火墙</p>
<blockquote>
<p>firewall-cmd –zone=public –add-port=6379/tcp –permanent（开放6379端口）</p>
<p>systemctl restart firewalld（重启防火墙以使配置即时生效）</p>
</blockquote>
<p>查看系统所有开放的端口</p>
<blockquote>
<p>firewall-cmd –zone=public –list-ports</p>
</blockquote>
<p>开放Redis外网访问一般不需要，且有安全隐患，因此本文不讲解，想要了解的朋友可以移步</p>
<p><a href="https://www.cnblogs.com/happywish/p/10944253.html" target="_blank" rel="external">https://www.cnblogs.com/happywish/p/10944253.html</a></p>
<h2 id="安装MySQL"><a href="#安装MySQL" class="headerlink" title="安装MySQL"></a>安装MySQL</h2><p>安装MySQL过程较为复杂， 此处尽量展示命令:</p>
<ul>
<li>下载MySQL源安装包<blockquote>
<p>wget <a href="http://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm" target="_blank" rel="external">http://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm</a></p>
</blockquote>
</li>
</ul>
<ul>
<li><p>安装MySql源</p>
<blockquote>
<p>yum -y install mysql57-community-release-el7-11.noarch.rpm</p>
</blockquote>
</li>
<li><p>查看安装效果</p>
<blockquote>
<p>yum repolist enabled | grep mysql.*</p>
</blockquote>
</li>
<li><p>安装MySQL服务器</p>
<blockquote>
<p>yum install mysql-community-server</p>
</blockquote>
</li>
</ul>
<p><strong>中间会弹出是与否的选择，选择y即可</strong></p>
<ul>
<li><p>启动MySQL服务</p>
<blockquote>
<p>systemctl start mysqld.service</p>
</blockquote>
</li>
<li><p>运行一下命令查看运行状态 </p>
<blockquote>
<p>systemctl status mysqld.service</p>
</blockquote>
</li>
<li><p>初始化数据库密码, 查看一下初始密码</p>
<blockquote>
<p>grep “password” /var/log/mysqld.log</p>
</blockquote>
</li>
<li><p>使用初始密码登录</p>
<blockquote>
<p>mysql -uroot -p (输出初始密码)</p>
</blockquote>
</li>
<li><p>修改密码</p>
<blockquote>
<p>ALTER USER ‘root’@’localhost’ IDENTIFIED BY ‘<strong><strong><strong><em>**</em></strong></strong></strong>‘;</p>
</blockquote>
<p>  mysql默认安装了密码安全检查插件（validate_password），<br>  默认密码检查策略要求密码必须包含：大小写字母、数字和特殊符号，并且长度不能少于8位。<br>  否则会提示ERROR 1819 (HY000): </p>
<pre><code>Your password does not satisfy the current policy requirements错误
</code></pre></li>
<li><p>数据库授权</p>
</li>
</ul>
<blockquote>
<p>数据库没有授权，只支持localhost本地访问</p>
<p>mysql&gt;GRANT ALL PRIVILEGES ON <em>.</em> TO ‘root’@’%’ IDENTIFIED BY ‘123456’ WITH GRANT OPTION;</p>
</blockquote>
<p>远程连接数据库的时候需要输入用户名和密码, 比如：</p>
<pre><code>用户名：root

密码:123456
</code></pre><p>指点ip:%代表所有Ip,此处也可以输入Ip来指定Ip</p>
<p>输入后使修改生效还需要下面的语句</p>
<blockquote>
<p>mysql&gt;FLUSH PRIVILEGES;</p>
</blockquote>
<p>也可以通过修改表来实现远程：</p>
<pre><code>mysql -u root -p

mysql&gt; use mysql; 
mysql&gt; update user set host = &apos;%&apos; where user = &apos;root&apos;; 
mysql&gt; select host, user from user;
</code></pre><ul>
<li>设置自动启动<blockquote>
<p>  systemctl enable mysqld</p>
<p>   systemctl daemon-reload</p>
</blockquote>
</li>
</ul>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文主要从实操角度出发，不介绍原理，只介绍安装过程，帮助读者快速从零搭建一套Java微服务运行环境。</p>
<p>文章中提到的方法也可以通过编写docker打包脚本实现自定义镜像。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作为开发者，除了能够实现书写代码实现产品需求外，还应当具备一定的运维能力。&lt;/p&gt;
&lt;p&gt;这其中就包含了环境搭建能力，能够在一台只装有操作系统的服务器上，搭建起应用的基础运行时环境，搭建并运维中间件。&lt;/p&gt;
&lt;p&gt;本文持续更新，将介绍基于centos7.6环境，从零搭建Java微服务运行时环境及搭建并运维相关中间件。&lt;/p&gt;
    
    </summary>
    
      <category term="专题-分布式" scheme="http://wuwenliang.net/categories/%E4%B8%93%E9%A2%98-%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="专题-分布式" scheme="http://wuwenliang.net/tags/%E4%B8%93%E9%A2%98-%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>跟我学RocketMQ之聊聊死信队列</title>
    <link href="http://wuwenliang.net/2020/04/11/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ%E4%B9%8B%E8%81%8A%E8%81%8A%E6%AD%BB%E4%BF%A1%E9%98%9F%E5%88%97/"/>
    <id>http://wuwenliang.net/2020/04/11/跟我学RocketMQ之聊聊死信队列/</id>
    <published>2020-04-11T11:55:48.000Z</published>
    <updated>2020-04-11T12:31:45.364Z</updated>
    
    <content type="html"><![CDATA[<p>有段时间没写东西了，再不写就有点说不过去了。</p>
<p>今天我们讨论一个轻松的话题，来聊聊RocketMQ中的死信队列</p>
<h2 id="是什么是死信队列"><a href="#是什么是死信队列" class="headerlink" title="是什么是死信队列"></a>是什么是死信队列</h2><p>在之前的文章中，我们聊过RocketMQ的消息重试机制。</p>
<p>如果消息消费失败，消费者返回Reconsume_later给RocketMQ broker，队列会按照重试时间窗口对消息进行重试。</p>
<p>当达到最大重试次数（默认16次），消息还是消费失败，RocketMQ不会将该消息丢弃而是会把它保存到私信队列中。</p>
<p>这种不能被消费者正常处理的消息我们一般称之为 <strong>死信消息（Dead-Letter Message）</strong>，将存储死信消息的队列称之为 <strong>死信队列（Dead-Letter Queue，DLQ）</strong></p>
<a id="more"></a>
<h2 id="死信消息-队列特点"><a href="#死信消息-队列特点" class="headerlink" title="死信消息/队列特点"></a>死信消息/队列特点</h2><p>首先看下死信消息具备的特点：</p>
<ul>
<li>私信队列中的消息不会再被消费者正常消费，也就是一般情况下DLQ是消费者不可见的</li>
<li>死信存储有效期与正常消息相同，均为 3 天，3 天后会被自动删除。因此，我们要保证在死信消息产生后的 3 天内对其进行及时处理</li>
</ul>
<p>而死信队列则具有以下特性：</p>
<ul>
<li>每个死信队列对应一个 Group ID，也就是每个消费者组都有一个私信队列； 而不是对应单个消费者实例</li>
<li>如果一个 Group ID 未产生死信消息，消息队列 RocketMQ 不会为其创建相应的死信队列</li>
<li>一个死信队列包含了对应 Group ID 下产生的所有死信消息，不论该消息属于哪个 Topic，也就是对于某个消费者组，它的所有的死信共享一个死信队列</li>
</ul>
<h2 id="使用console查看死信消息"><a href="#使用console查看死信消息" class="headerlink" title="使用console查看死信消息"></a>使用console查看死信消息</h2><p>我们可以通过console应用直观的查看死信队列中的消息。关于如何搭建console，请移步 <a href="http://wuwenliang.net/2019/01/09/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ-1-2-%E4%B9%8B%E5%AE%89%E8%A3%85RocketMQ-Console%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0/">安装RocketMQ-Console管理平台</a></p>
<ol>
<li>在cnosole中查询出现死信队列的主题</li>
</ol>
<p><img src="/2020/04/11/跟我学RocketMQ之聊聊死信队列/dlq.png" alt=""></p>
<ol>
<li>在消息界面根据主题查询死信消息</li>
</ol>
<p><img src="/2020/04/11/跟我学RocketMQ之聊聊死信队列/dlq1.png" alt=""></p>
<h2 id="如何处理死信"><a href="#如何处理死信" class="headerlink" title="如何处理死信"></a>如何处理死信</h2><p>了解了什么是死信，以及如何在console中查看死信。接下来我们看一下开发最关心的问题，如何处理死信？</p>
<p>实际上，当一条消息进入死信队列，就意味着某些因素导致消费者无法正常消费该消息（比如，代码中存在bug/数据库宕机等）。</p>
<p>因此，对于死信消息，通常需要开发进行特殊处理。</p>
<p>最关键的步骤是要排查可疑因素并解决代码中存在的bug。然后我们通过：</p>
<ul>
<li><p>控制台重新发送该消息，让消费者对该消息重新消费一次。</p>
</li>
<li><p>除了通过console手动推送消息进行消费，我们也可以查询死信中消息，将消息重新投递到原topic进行重新消费。</p>
</li>
</ul>
<p>死信Topic的命名为：<strong>%DLQ% + Consumer组名</strong>，如：%DLQ%online-tst。</p>
<p>举个例子，我们想要重新消费 %DLQ%online-tst 中的一条死信消息，就可以先通过mqadmin命令查询到该消息，然后将消息重新投递到原topic中，等待业务逻辑进行消费处理即可。前提是消费过程中要保证消费幂等。关于消费幂等，请移步 <a href="http://wuwenliang.net/2019/03/28/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ%E4%B9%8B%E6%B6%88%E6%81%AF%E5%B9%82%E7%AD%89/">跟我学RocketMQ之消息幂等</a></p>
<h2 id="附录：mqadmin死信相关指令"><a href="#附录：mqadmin死信相关指令" class="headerlink" title="附录：mqadmin死信相关指令"></a>附录：mqadmin死信相关指令</h2><blockquote>
<p>常见的mqadmin操作死信队列的命令如下：</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align:center">操作</th>
<th style="text-align:center">命令样例</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">更改死信队列权限</td>
<td style="text-align:center">将死信队列只写权限更改为读写权限: bin/mqadmin updateTopicPerm -c ClusterB -t %DLQ%online-tst -p 6 -n 192.168.1.x:9876  </td>
</tr>
<tr>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">查询死信队列状态</td>
<td style="text-align:center">bin/mqadmin topicStatus -n 192.168.1.x:9876 -t %DLQ%online-tst</td>
</tr>
<tr>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">根据offset查询消息内容</td>
<td style="text-align:center">bin/mqadmin  queryMsgByOffset -n localhost:9876 -t %DLQ%online-tst -b broker-a -i 0 -o 108</td>
</tr>
<tr>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;有段时间没写东西了，再不写就有点说不过去了。&lt;/p&gt;
&lt;p&gt;今天我们讨论一个轻松的话题，来聊聊RocketMQ中的死信队列&lt;/p&gt;
&lt;h2 id=&quot;是什么是死信队列&quot;&gt;&lt;a href=&quot;#是什么是死信队列&quot; class=&quot;headerlink&quot; title=&quot;是什么是死信队列&quot;&gt;&lt;/a&gt;是什么是死信队列&lt;/h2&gt;&lt;p&gt;在之前的文章中，我们聊过RocketMQ的消息重试机制。&lt;/p&gt;
&lt;p&gt;如果消息消费失败，消费者返回Reconsume_later给RocketMQ broker，队列会按照重试时间窗口对消息进行重试。&lt;/p&gt;
&lt;p&gt;当达到最大重试次数（默认16次），消息还是消费失败，RocketMQ不会将该消息丢弃而是会把它保存到私信队列中。&lt;/p&gt;
&lt;p&gt;这种不能被消费者正常处理的消息我们一般称之为 &lt;strong&gt;死信消息（Dead-Letter Message）&lt;/strong&gt;，将存储死信消息的队列称之为 &lt;strong&gt;死信队列（Dead-Letter Queue，DLQ）&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/categories/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/tags/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
  </entry>
  
  <entry>
    <title>跟我学Spring之运行时动态注册bean</title>
    <link href="http://wuwenliang.net/2020/03/11/%E8%B7%9F%E6%88%91%E5%AD%A6Spring%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%97%B6%E5%8A%A8%E6%80%81%E6%B3%A8%E5%86%8Cbean/"/>
    <id>http://wuwenliang.net/2020/03/11/跟我学Spring之运行时动态注册bean/</id>
    <published>2020-03-11T05:25:51.000Z</published>
    <updated>2020-03-11T06:38:49.494Z</updated>
    
    <content type="html"><![CDATA[<p>上文 <a href="http://wuwenliang.net/2020/03/08/%E8%B7%9F%E6%88%91%E5%AD%A6Spring%E4%B9%8BBean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F-BeanDefinition%E5%85%83%E4%BF%A1%E6%81%AF%E8%A7%A3%E6%9E%90/">跟我学Spring之Bean生命周期-BeanDefinition元信息解析</a> 中，我们了解了Spring中Bean生命周期的BeanDefinition元信息解析原理。</p>
<p>本文就利用该部分的原理，实战一把运行时动态注册Bean的黑科技玩法。</p>
<a id="more"></a>
<h2 id="需求场景"><a href="#需求场景" class="headerlink" title="需求场景"></a>需求场景</h2><p>首先我们要明确，什么情况会使用到运行期动态注册Bean。</p>
<p>通常情况下，我们对Bean的操作都是在容器初始化完成，bean装载之后发生的。一般也用不到运行时动态注册。</p>
<p>但是在某些特殊场景下，就不得不使用了。</p>
<p>比如，有个遗留项目中依赖了一个三方类库，其中有一个Spring Bean，比如叫QueryService是用来做数据库操作的，它依赖了一个数据源，这里就假设它用的是JdbcTemplate，当然其他的JPA，MyBatis也都可以。</p>
<p>在项目启动时候会默认加载这个QueryService，然后QueryService会依赖JdbcTemplate。</p>
<p>此时，产品提出一个需求，要我们整合多数据源，但是不能对三方库做修改。</p>
<p>抽象一下就是，我们要在容器中针对多个数据源，加载多个QueryService，并且每个QueryService都需要依赖对应的数据源，也就是特定的JdbcTemplate实例。</p>
<p>需求不复杂，但难就难在我们如何才能动态的为QueryService设置特定的JdbcTemplate，因为在Spring初始化之后，JdbcTemplate实例已经注入完成了，就是默认的数据源。</p>
<p>我们编码的核心就是要在运行时初始化特定的JdbcTemplate替换掉默认JdbcTemplate，并且将bean重新注册到Spring容器中。</p>
<p>提到Bean注册，你想到了什么？</p>
<p>没错，就是我们在上文中分析的DefaultListableBeanFactory，而本文的核心操作，也是围绕DefaultListableBeanFactory展开的。话不多说，我们进入实际操作。</p>
<h2 id="代码实操"><a href="#代码实操" class="headerlink" title="代码实操"></a>代码实操</h2><blockquote>
<p>为了方便理解，我们定义一个模拟的DBTemplate替代JdbcTemplate。实际开发中，根据具体依赖的Bean灵活替换即可。</p>
</blockquote>
<h3 id="DbTemplate"><a href="#DbTemplate" class="headerlink" title="DbTemplate"></a>DbTemplate</h3><blockquote>
<p>DbTemplate是一个模拟JdbcTemplate的实体</p>
</blockquote>
<pre><code>public class DbTemplate {

    private String dbName;
    private String userName;

    public DbTemplate(String dbName, String userName) {
        this.dbName = dbName;
        this.userName = userName;
    }

    public DbTemplate() {
    }

    public String getDbName() {
        return dbName;
    }

    public DbTemplate setDbName(String dbName) {
        this.dbName = dbName;
        return this;
    }

    public String getUserName() {
        return userName;
    }

    public DbTemplate setUserName(String userName) {
        this.userName = userName;
        return this;
    }

    @Override
    public String toString() {
        return &quot;DbTemplate{&quot; +
                &quot;dbName=&apos;&quot; + dbName + &apos;\&apos;&apos; +
                &quot;, userName=&apos;&quot; + userName + &apos;\&apos;&apos; +
                &apos;}&apos;;
    }
}
</code></pre><p>就是一个POJO，实现了toString方法便于观察日志。</p>
<h3 id="QueryService"><a href="#QueryService" class="headerlink" title="QueryService"></a>QueryService</h3><blockquote>
<p>QueryService是我们在需求阶段提到的三方库中的一个类，它被声明为一个Spring Bean注入容器中，实现InitializingBean接口，便于传递引用。</p>
</blockquote>
<p><strong>注意</strong>  我们要注意的是，这里的QueryService在实际编码中是不可修改的，这里的代码可以认为是反编译Jar中的class得到的，便于我们观察类定义。</p>
<pre><code>public class QueryService implements InitializingBean {

    @Autowired(required = false)
    DbTemplate defaultDbTemplate;

    private String name;

    public QueryService(String name) {
        this.name = name;
    }

    private static QueryService instance;

    public static QueryService instance() {
        return instance;
    }

    @Override
    public void afterPropertiesSet() throws Exception {
        instance = this;
        System.out.println(&quot;QueryService 初始化完成, name=&quot; + name + &quot;,dbTemplate： &quot; + defaultDbTemplate.toString());
    }

    public QueryService() {
    }

    public String getName() {
        return name;
    }

    public QueryService setName(String name) {
        this.name = name;
        return this;
    }

    public DbTemplate getDefaultDbTemplate() {
        return defaultDbTemplate;
    }

    public QueryService setDefaultDbTemplate(DbTemplate defaultDbTemplate) {
        this.defaultDbTemplate = defaultDbTemplate;
        return this;
    }
}
</code></pre><p>可以看到，在QueryService中注入了DbTemplate，它的beanName=defaultDbTemplate</p>
<h3 id="BeanConfig-注册类"><a href="#BeanConfig-注册类" class="headerlink" title="BeanConfig 注册类"></a>BeanConfig 注册类</h3><blockquote>
<p>我们编写一个BeanConfig注册类，声明要注入的Bean。使用XML配置文件能够达到同样的效果。</p>
</blockquote>
<pre><code>@Configuration
public class BeanConfig {

    /**
    * 用户库QueryService
    * @return
    */
    @Bean
    public QueryService userQueryService() {
        QueryService userQueryService = new QueryService(&quot;userQueryService&quot;);
        return userQueryService;
    }

    /**
    * 订单库QueryService
    * @return
    */
    @Bean
    public QueryService orderQueryService() {
        QueryService orderQueryService = new QueryService(&quot;orderQueryService&quot;);
        return orderQueryService;
    }


    /**
    * 默认的DbTemplate， 也是初始化注入到QueryService里的
    * @return
    */
    @Primary
    @Bean
    public DbTemplate defaultDbTemplate() {
        DbTemplate dbTemplate = new DbTemplate();
        dbTemplate.setDbName(&quot;default-db&quot;).setUserName(&quot;admin&quot;);
        return dbTemplate;
    }

    /**
    * DynamicQueryServiceHandler  更换QueryService中的DbTemplate引用
    * @return
    */
    @Bean
    public DynamicQueryServiceHandler dynamicQueryServiceHandler() {
        DynamicQueryServiceHandler dynamicQueryServiceHandler = new DynamicQueryServiceHandler();
        return dynamicQueryServiceHandler;
    }
}
</code></pre><p>BeanConfig是一个Bean的配置类，声明了QueryService的两个实例，</p>
<ul>
<li>userQueryService-表示用户库QueryService实例</li>
<li>orderQueryService-表示订单库QueryService实例</li>
</ul>
<p>声明了DbTemplate的默认实现，也就是QueryService依赖的DbTemplate实例；</p>
<p>我们还声明了一个dynamicQueryServiceHandler的bean，它就是本次文章说明的核心，主要作用为在运行期替换具体QueryService依赖的DbTemplate实例；我们在后面会详细分析。</p>
<h3 id="客户端类Client"><a href="#客户端类Client" class="headerlink" title="客户端类Client"></a>客户端类Client</h3><blockquote>
<p>编写一个Client类用于验证我们编写的代码逻辑。</p>
</blockquote>
<pre><code>public class Client {
    public static void main(String[] args) {
        ApplicationContext applicationContext = new AnnotationConfigApplicationContext(BeanConfig.class);
        // 获取DynamicQueryServiceHandler
        DynamicQueryServiceHandler dynamicQueryServiceHandler = applicationContext.getBean(&quot;dynamicQueryServiceHandler&quot;, DynamicQueryServiceHandler.class);

        // 初始化要替换的dbTemplate实例
        DbTemplate userDbTemplate = new DbTemplate(&quot;user-db&quot;, &quot;userAdmin&quot;);
        DbTemplate orderDbTemplate = new DbTemplate(&quot;order-db&quot;, &quot;orderAdmin&quot;);

        // 进行替换
        dynamicQueryServiceHandler.changeDbTemplate(&quot;userQueryService&quot;, &quot;userDbTemplate&quot;, userDbTemplate);
        dynamicQueryServiceHandler.changeDbTemplate(&quot;orderQueryService&quot;, &quot;orderDbTemplate&quot;, orderDbTemplate);

        // 打印更新之后的bean
        QueryService updatedUserQueryService = applicationContext.getBean(&quot;userQueryService&quot;, QueryService.class);
        QueryService updateOrderQueryService = applicationContext.getBean(&quot;orderQueryService&quot;, QueryService.class);
        System.out.println(&quot;updatedUserQueryService 更新完成, name=&quot; + updatedUserQueryService.getName() + &quot;,dbTemplate：&quot; +
                updatedUserQueryService.getDefaultDbTemplate().toString());
        System.out.println(&quot;updateOrderQueryService 更新完成, name=&quot; + updateOrderQueryService.getName() + &quot;,dbTemplate：&quot; +
                updateOrderQueryService.getDefaultDbTemplate().toString());
    }
}
</code></pre><p>这里先卖个关子，我们先不看DynamicQueryServiceHandler具体的代码实现，只需要知道定义了DynamicQueryServiceHandler这个bean，注入到Spring容器中的beanName是dynamicQueryServiceHandler。</p>
<p>main方法主要做了如下几件事</p>
<ol>
<li>定义并初始化了AnnotationConfigApplicationContext，通过构造方法注入BeanConfig配置类，用于加载并初始化我们声明的bean；同时返回ApplicationContext上下文</li>
<li>从ApplicationContext中根据beanName获取DynamicQueryServiceHandler实例</li>
<li>此时容器初始化完成，如果bean实现了InitializingBean接口，在容器加载过程中，会以此回调afterPropertiesSet()方法，有日志则打印日志</li>
<li>由于QueryService实现了InitializingBean接口，因此我们能在控制台看到QueryService打印出初始化日志</li>
<li>我们接着构造了两个具体的DbTemplate对象，类比到实际开发中，就是我们根据具体数据源的配置，创建出对应的数据源，并初始化对应的JdbcTemplate对象</li>
<li>接着调用 dynamicQueryServiceHandler.changeDbTemplate方法，传入要替换DBTemplate的具体QueryService实例的beanName，以及我们创建的DBTemplate实例引用，以及对应的beanName（根据业务灵活指定即可，不要同名）；dynamicQueryServiceHandler.changeDbTemplate方法会将替换好的QueryService实例重新注册到Spring容器上下文中</li>
<li>替换完成之后，我们重新获取一下beanName为userQueryService，orderQueryService的两个bean，并打印一下其中的属性（包含依赖的DBTemplate）是否已经变更。</li>
</ol>
<p>到此就是Client类的完整逻辑。我们先运行一下看看效果</p>
<h4 id="控制台打印"><a href="#控制台打印" class="headerlink" title="控制台打印"></a>控制台打印</h4><pre><code>...省略部分debug日志...
QueryService 初始化完成, name=userQueryService,dbTemplate： DbTemplate{dbName=&apos;default-db&apos;, userName=&apos;admin&apos;}
QueryService 初始化完成, name=orderQueryService,dbTemplate： DbTemplate{dbName=&apos;default-db&apos;, userName=&apos;admin&apos;}
finished  class com.dynamic.bean.DbTemplate
finished  class java.lang.String
finished  class com.dynamic.bean.QueryService
13:45:22.995 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - 
        Overriding bean definition for bean &apos;userQueryService&apos; with a different definition: 
finished  class com.dynamic.bean.DbTemplate
finished  class java.lang.String
finished  class com.dynamic.bean.QueryService
13:45:22.995 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - 
        Overriding bean definition for bean &apos;orderQueryService&apos; with a different definition: 
</code></pre><p>这部分是Spring容器加载阶段的日志，可以看到在Spring容器初始化过程中，注入了userQueryService,orderQueryService两个QueryService实例，并分别注入了默认的DbTemplate实例。</p>
<pre><code>13:45:22.995 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean &apos;userQueryService&apos;
13:45:23.002 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean &apos;userDbTemplate&apos;
QueryService 初始化完成, name=userQueryService,dbTemplate： DbTemplate{dbName=&apos;user-db&apos;, userName=&apos;user-db&apos;}
</code></pre><p>这里就是执行dynamicQueryServiceHandler.changeDbTemplate替换了DBTemplate之后重新注册userQueryService的日志打印</p>
<pre><code>13:45:23.016 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean &apos;orderQueryService&apos;
13:45:23.016 [main] DEBUG org.springframework.beans.factory.support.DefaultListableBeanFactory - Creating shared instance of singleton bean &apos;orderDbTemplate&apos;
QueryService 初始化完成, name=orderQueryService,dbTemplate： DbTemplate{dbName=&apos;order-db&apos;, userName=&apos;order-db&apos;}
</code></pre><p>这里逻辑同上，是执行dynamicQueryServiceHandler.changeDbTemplate替换了DBTemplate之后重新注册orderQueryService的日志打印</p>
<pre><code>updatedUserQueryService 更新完成, name=userQueryService,dbTemplate：DbTemplate{dbName=&apos;user-db&apos;, userName=&apos;user-db&apos;}
updateOrderQueryService 更新完成, name=orderQueryService,dbTemplate：DbTemplate{dbName=&apos;order-db&apos;, userName=&apos;order-db&apos;}
</code></pre><p>这里是我们在main方法中打印的日志，输出表明我们已经将默认的DBTemplate成功替换为对应的userDbTemplate和orderDbTemplate。</p>
<p>之后我们就可以使用userQueryService操作user数据源，使用orderQueryService操作order数据源了。</p>
<h3 id="分析DynamicQueryServiceHandler实现"><a href="#分析DynamicQueryServiceHandler实现" class="headerlink" title="分析DynamicQueryServiceHandler实现"></a>分析DynamicQueryServiceHandler实现</h3><p>到此，流程就梳理完成了。我们还有一个悬念没有解开，就是DynamicQueryServiceHandler具体是如何实现的？</p>
<p>接下来就详细分析一下DynamicQueryServiceHandler的代码逻辑。</p>
<p>首先声明DynamicQueryServiceHandler为一个Spring的Component，将其注册到Spring上下文中。</p>
<pre><code>@Component
public class DynamicQueryServiceHandler implements ApplicationContextAware {

    private ApplicationContext applicationContext;

    @Override
    public void setApplicationContext(ApplicationContext applicationContext) throws BeansException {
        this.applicationContext = applicationContext;
    }
</code></pre><p>通过实现ApplicationContextAware接口，使DynamicQueryServiceHandler能够获取到ApplicationContext上下文的引用，便于操作。</p>
<p>changeDbTemplate方法是核心替换逻辑，它接受三个参数</p>
<ul>
<li>queryServiceName， 要进行替换操作的QueryService引用</li>
<li>dbTemplateBeanName，实际替换的DbTemplate的BeanName</li>
<li><p>dbTemplate，实际替换的DbTemplate实例引用。（实例化之后传入即可）</p>
<pre><code>public void changeDbTemplate(String queryServiceName, String dbTemplateBeanName, DbTemplate dbTemplate) {
    QueryService queryService = applicationContext.getBean(queryServiceName, QueryService.class);
    if (queryService == null) {
        return;
    }
</code></pre></li>
</ul>
<p>step0：首先通过queryServiceName获取到容器中已经注册的具体的QueryService实例</p>
<pre><code>// 更新QueryService中的dbTemplate引用然后重新注册回去
Class&lt;?&gt; beanType = applicationContext.getType(queryServiceName);
if (beanType == null) {
    return;
}

Field[] declaredFields = beanType.getDeclaredFields();
for (Field field : declaredFields) {
    // 从spring容器中拿到这个具体的bean对象
    Object bean = queryService;
    // 当前字段设置新的值
    try {
        field.setAccessible(true);
        Class&lt;?&gt; type = field.getType();
        if (type == DbTemplate.class) {
            field.set(bean, dbTemplate);
        }
        System.out.println(&quot;finished  &quot; + type);
    } catch (Exception e) {
        e.printStackTrace();
    }
}
</code></pre><p>这段代码逻辑用到了反射，概括起来解释就是，我们取得了queryServiceName对应的Class，也就是QueryService.class。</p>
<p>然后获得QueryService.class的属性，并进行遍历，通过反射设置属性为可访问的，重点在于if逻辑：</p>
<p>如果判断属性的类型为DbTemplate.class，则将我们传入的dbTemplate实例设置给queryService实例。</p>
<p>这段逻辑完成之后，我们就获得了一个具备特定DBTemplate引用的QueryService实例。只不过它还是游离于Spring容器的，需要我们再将其注册回Spring上下文。</p>
<pre><code>// 刷新容器中的bean,获取bean工厂并转换为DefaultListableBeanFactory
defaultListableBeanFactory defaultListableBeanFactory = (DefaultListableBeanFactory) applicationContext.getAutowireCapableBeanFactory();
</code></pre><p>重头戏来了，通过applicationContext，我们获取到了DefaultListableBeanFactory实例，也就是BeanDefinitionRegistry实例。这部分不理解的一定要回过头去看 <a href="http://wuwenliang.net/2020/03/08/%E8%B7%9F%E6%88%91%E5%AD%A6Spring%E4%B9%8BBean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F-BeanDefinition%E5%85%83%E4%BF%A1%E6%81%AF%E8%A7%A3%E6%9E%90/">上一篇文章</a> ！</p>
<pre><code>// 刷新DbTemplate的bean定义
BeanDefinitionBuilder dbTemplatebeanDefinitionBuilder = BeanDefinitionBuilder.genericBeanDefinition(DbTemplate.class);
dbTemplatebeanDefinitionBuilder.addPropertyValue(&quot;dbName&quot;, dbTemplate.getDbName());
dbTemplatebeanDefinitionBuilder.addPropertyValue(&quot;userName&quot;, dbTemplate.getDbName());
</code></pre><p>这里的核心是通过BeanDefinitionBuilder为传入的DbTemplate引用，创建Bean定义，设置BeanDefinition的属性为传入的DbTemplate引用的具体属性值。</p>
<pre><code>// 通过BeanDefinitionBuilder创建bean定义
BeanDefinitionBuilder beanDefinitionBuilder = BeanDefinitionBuilder.genericBeanDefinition(QueryService.class);
// 设置属性defaultDbTemplate,此属性引用已经定义的bean,这里defaultDbTemplate已经被spring容器管理了.
beanDefinitionBuilder.addPropertyReference(&quot;defaultDbTemplate&quot;, dbTemplateBeanName);
// 刷新QueryService的DbTemplate引用
beanDefinitionBuilder.addPropertyValue(&quot;name&quot;, queryServiceName);
</code></pre><p>这里就和上面大同小异，我们还需要刷新QueryService实例的BeanDefinition，因此通过BeanDefinitionBuilder为QueryService创建Bean定义，并将defaultDbTemplate引用指向我们传入的待替换的dbTemplateBeanName，（举个例子，比如给userQueryService的defaultDbTemplate引用设置成userDbTemplate）。</p>
<p>最后通过beanDefinitionBuilder.addPropertyValue(“name”, queryServiceName);刷新其他属性，这里的name属性是为了打印日志方便增加的一个名称属性。可以根据需要灵活添加。</p>
<pre><code>// 重新注册bean
defaultListableBeanFactory.registerBeanDefinition(dbTemplateBeanName, dbTemplatebeanDefinitionBuilder.getRawBeanDefinition());
defaultListableBeanFactory.registerBeanDefinition(queryServiceName, beanDefinitionBuilder.getRawBeanDefinition());
</code></pre><p>最后，调用 <strong>defaultListableBeanFactory.registerBeanDefinition(String beanName, BeanDefinition beanDefinition)</strong> 方法，将更新之后的dbTemplate，queryService的beanDefinition注册回Spring容器中。</p>
<p>之后我们就可以使用刷新后的QueryService引用操作具体的DbTemplate对应的数据源了。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>到此，我们就通过一个完整的实战案例，从实操到分析，全方位的实践了 “运行时动态注册bean” 的黑科技操作。</p>
<p>Spring框架中这类特性还有很多，他们无一例外都以IOC、AOP为核心构建。</p>
<p>我们一直说IOC、AOP，但是真正能够灵活运用的却少之又少，这给我的启示就是一定不能空谈，要以实践结合理论。</p>
<p>追根溯源，唯有掌握Spring框架的核心机理，对于重点代码和原理熟练掌握，才能在错综复杂的需求中提炼出解决方案，并且优雅的解决问题。</p>
<p>希望本文能够对聪明的你有所启发。</p>
<p>更多Spring源码解析，请拭目以待。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;上文 &lt;a href=&quot;http://wuwenliang.net/2020/03/08/%E8%B7%9F%E6%88%91%E5%AD%A6Spring%E4%B9%8BBean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F-BeanDefinition%E5%85%83%E4%BF%A1%E6%81%AF%E8%A7%A3%E6%9E%90/&quot;&gt;跟我学Spring之Bean生命周期-BeanDefinition元信息解析&lt;/a&gt; 中，我们了解了Spring中Bean生命周期的BeanDefinition元信息解析原理。&lt;/p&gt;
&lt;p&gt;本文就利用该部分的原理，实战一把运行时动态注册Bean的黑科技玩法。&lt;/p&gt;
    
    </summary>
    
      <category term="spring-boot" scheme="http://wuwenliang.net/categories/spring-boot/"/>
    
    
      <category term="spring-boot" scheme="http://wuwenliang.net/tags/spring-boot/"/>
    
  </entry>
  
  <entry>
    <title>跟我学Spring之Bean生命周期-BeanDefinition元信息解析</title>
    <link href="http://wuwenliang.net/2020/03/08/%E8%B7%9F%E6%88%91%E5%AD%A6Spring%E4%B9%8BBean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F-BeanDefinition%E5%85%83%E4%BF%A1%E6%81%AF%E8%A7%A3%E6%9E%90/"/>
    <id>http://wuwenliang.net/2020/03/08/跟我学Spring之Bean生命周期-BeanDefinition元信息解析/</id>
    <published>2020-03-08T13:44:34.000Z</published>
    <updated>2020-03-11T06:38:56.850Z</updated>
    
    <content type="html"><![CDATA[<p>接下来，我将对Spring Bean的生命周期进行较为详细的整理和总结。 本文是该部分的第一篇， 我们重点分析一下BeanDefinition元信息解析是如何进行的。</p>
<p>BeanDefinition主要用来描述Spring的Bean定义，它是一个接口，声明如下：</p>
<pre><code>public interface BeanDefinition extends AttributeAccessor, BeanMetadataElement {
</code></pre><p>AbstractBeanDefinition这个抽象实现实现了BeanDefinitio接口，它包含了一个Bean定义的主要属性，这里挑选几个重要的进行注释：</p>
<a id="more"></a>
<pre><code>// Bean的Class对象
private volatile Object beanClass;
// Bean的作用域
private String scope = SCOPE_DEFAULT;
// 注入方式
private int autowireMode = AUTOWIRE_NO;
// 工厂Bean名称
private String factoryBeanName;
// 工厂Bean方法名
private String factoryMethodName;
// 属性
private MutablePropertyValues propertyValues;
// 初始化方法名
private String initMethodName;
// 销毁方法名
private String destroyMethodName;
</code></pre><p>BeanDefinition加载通常有两种方式, 基于XML/Properties配置文件的方式, 基于注解的方式。我们分别讲解</p>
<h2 id="基于配置文件方式解析BeanDefinition"><a href="#基于配置文件方式解析BeanDefinition" class="headerlink" title="基于配置文件方式解析BeanDefinition"></a>基于配置文件方式解析BeanDefinition</h2><p>首先编写一个User.java类，用于测试</p>
<pre><code>public class User {

    private String name;

    private int id;
</code></pre><p>省略getter setter，没什么特殊的地方， 就是一个普通的JavaBean</p>
<p>接着，在src/main/resources/META-INF/目录下建立bean.properties配置文件，我们在bean.properties中声明一个User对象的属性</p>
<pre><code># 使用半角括号作为占位符 参考文档 org.springframework.beans.factory.support.PropertiesBeanDefinitionReader
user.(class)=com.snowalker.spring.bean.User
user.id=2333
user.name=踏雪无痕SnoWalker
</code></pre><p>这里注意，根据PropertiesBeanDefinitionReader的javadoc，对象的class需要通过 <strong>对象名.(class)</strong> 进行定义，否则不生效。</p>
<p>熟悉XML方式定义Bean的同学应当能够很轻松的理解我们的意图，定义一个name=user的对象，指明User类的全限定名，设置id=233， name=踏雪无痕SnoWalker</p>
<p>接着编写测试类BeanMetadataConfigurationDemo.java:</p>
<pre><code>public class BeanMetadataConfigurationDemo {

    public static void main(String[] args) {

        //step0
        DefaultListableBeanFactory beanFactory = new DefaultListableBeanFactory();
        //step1
        PropertiesBeanDefinitionReader beanDefinitionReader = new PropertiesBeanDefinitionReader(beanFactory);

        String locations = &quot;META-INF/bean.properties&quot;;

        //step2
        Resource resource = new ClassPathResource(locations);
        EncodedResource encodedResource = new EncodedResource(resource, &quot;UTF-8&quot;);

        int beanNumbers = beanDefinitionReader.loadBeanDefinitions(encodedResource);
        System.out.println(&quot;已加载的BeanDefinition数量:&quot; + beanNumbers);

        // step3
        User user = beanFactory.getBean(&quot;user&quot;, User.class);
        System.out.println(user.toString());
    }
}
</code></pre><p>分析如下：</p>
<ul>
<li><p>step0： 声明并初始化一个DefaultListableBeanFactory对象，DefaultListableBeanFactory的类定义如下</p>
<pre><code>public class DefaultListableBeanFactory extends AbstractAutowireCapableBeanFactory
    implements ConfigurableListableBeanFactory, BeanDefinitionRegistry, Serializable {
</code></pre><p>  我们能够发现，DefaultListableBeanFactory实现了BeanDefinitionRegistry接口，这就是说，它是一个Bean定义的注册中心，事实上也是BeanDefinitionRegistry接口的唯一实现。可以这么认为 ： <strong>当我们说BeanDefinitionRegistry就是指DefaultListableBeanFactory</strong></p>
</li>
<li><p>step1：实例化基于Properties资源的beanDefinitionReader，它接受一个BeanDefinitionRegistry实例，根据上述的分析，我们知道这里的BeanDefinitionRegistry实例就是step0中定义的DefaultListableBeanFactory对象</p>
</li>
<li>step2：声明了bean的定义配置文件路径为classpath下的META-INF/bean.properties；我们通过ClassPathResource加载Properties资源。并通过EncodedResource包装了ClassPathResource，目的就是为了制定编码级，防止出现中文乱码</li>
<li>step3：通过beanDefinitionReader.loadBeanDefinitions(encodedResource)能够获取bean加载的数量；最终我们通过DefaultListableBeanFactory（它也是一个BeanFactory实例）的getBean获取到了name=user的User对象并将其打印出来。</li>
</ul>
<p>运行一下这个测试类，控制台打印情况：</p>
<pre><code>已加载的BeanDefinition数量:1
User{name=&apos;踏雪无痕SnoWalker&apos;, id=2333}
</code></pre><p>打印的结果证明我们成功的加载User的bean定义，并且从DefaultListableBeanFactory中获取到了User对象。</p>
<h2 id="基于注解的方式解析BeanDefinition"><a href="#基于注解的方式解析BeanDefinition" class="headerlink" title="基于注解的方式解析BeanDefinition"></a>基于注解的方式解析BeanDefinition</h2><p>接着我们介绍基于注解的方式解析BeanDefinition。</p>
<p>直接上测试用例，然后我们对其进行分析：</p>
<pre><code>public class AnnotatedBeanDefinitionParsingDemo {

    public static void main(String[] args) {

        DefaultListableBeanFactory beanFactory = new DefaultListableBeanFactory();
        // step0
        AnnotatedBeanDefinitionReader beanDefinitionReader = new AnnotatedBeanDefinitionReader(beanFactory);

        int beanDefinitionCounterBefore = beanFactory.getBeanDefinitionCount();

        // step1
        beanDefinitionReader.register(AnnotatedBeanDefinitionParsingDemo.class);
        beanDefinitionReader.register(User.class);

        int beanDefinitionCounterAfter = beanFactory.getBeanDefinitionCount();
        System.out.println(&quot;注册的总的bean数量:&quot; + (beanDefinitionCounterAfter - beanDefinitionCounterBefore));

        // step2
        AnnotatedBeanDefinitionParsingDemo demo = beanFactory.getBean(&quot;annotatedBeanDefinitionParsingDemo&quot;,
                AnnotatedBeanDefinitionParsingDemo.class);
        System.out.println(demo);
    }
}
</code></pre><p>运行该测试，控制台打印如下：</p>
<pre><code>注册的总的bean数量:2
com.snowalker.spring.lifecycle.AnnotatedBeanDefinitionParsingDemo@4cdbe50f
</code></pre><p>之所以注册总的bean数量为2，是因为在 <strong>step1</strong> 标注的位置，我们通过AnnotatedBeanDefinitionReader.register方法注册了两个bean，一个是User对象，一个是AnnotatedBeanDefinitionParsingDemo测试用例本身。</p>
<p>接下来，就详细的讲解一下基于注解解析BeanDefinition的逻辑：</p>
<ul>
<li>step0：声明并初始化一个DefaultListableBeanFactory对象；同时声明并初始化一个AnnotatedBeanDefinitionReader对象。<strong>AnnotatedBeanDefinitionReader</strong> 是基于Java注解的BeanDefinitionReader的实现</li>
<li>step1：将AnnotatedBeanDefinitionParsingDemo、User类注册到注册当前AnnotatedBeanDefinitionReader之中。这里 <strong>注意</strong> (非@Component标注的类也可以继续宁注册) 也就是说，AnnotatedBeanDefinitionReader中注册的可以是任意的Java类  不一定要Spring的Component及其派生注解标注</li>
<li>step2：通过annotatedBeanDefinitionParsingDemo名字获取到注册的AnnotatedBeanDefinitionParsingDemo对象，并进行打印。</li>
</ul>
<p>主要的逻辑就这些，并不复杂。</p>
<p>这里我们说一下beanName是如何生成的，为何默认首字母是当前类小写？</p>
<blockquote>
<p>实际上，Bean的名称来源于 BeanNameGenerator；它是一个接口，对于注解Bean的实现为 <strong>AnnotationBeanNameGenerator</strong></p>
</blockquote>
<p>我们观察一下 <strong>AnnotationBeanNameGenerator.buildDefaultBeanName(BeanDefinition definition)</strong> 这个方法。</p>
<pre><code>protected String buildDefaultBeanName(BeanDefinition definition) {
    // 获取BeanDefinition中存放的bean的全限定类名
    String beanClassName = definition.getBeanClassName();
    // 判断bean全限定类名是否为null
    Assert.state(beanClassName != null, &quot;No bean class name set&quot;);
    // 获取短类名，及去除包名后的类名，如User.java
    String shortClassName = ClassUtils.getShortName(beanClassName);
    // 返回首字母小写后的段类名
    return Introspector.decapitalize(shortClassName);
}
</code></pre><p>可以看出，实际上默认的bean名称是对全限定类名截取包名之后，将首字母进行小写处理的。</p>
<p>我们打开getShortName这个方法，重点看下面一行</p>
<pre><code>int lastDotIndex = className.lastIndexOf(PACKAGE_SEPARATOR);
int nameEndIndex = className.indexOf(CGLIB_CLASS_SEPARATOR);
......
String shortName = className.substring(lastDotIndex + 1, nameEndIndex);
shortName = shortName.replace(INNER_CLASS_SEPARATOR, PACKAGE_SEPARATOR);
return shortName;
</code></pre><p>PACKAGE_SEPARATOR其实就是 “.” ; 举个例子，如果类的全限定名为 a.b.c.User</p>
<p>则获取最后一个 “.” 所在下标， 截取 (最后一个 “.”下标 + 1, 最后一个字符下标) 就获取到了 User这个短类名。</p>
<p>最后调用 Introspector.decapitalize(shortClassName) 方法将首字母转换为小写。</p>
<pre><code>[java.beans.Introspector.decapitalize]
public static String decapitalize(String name) {
    if (name == null || name.length() == 0) {
        return name;
    }
    if (name.length() &gt; 1 &amp;&amp; Character.isUpperCase(name.charAt(1)) &amp;&amp;
                    Character.isUpperCase(name.charAt(0))){
        return name;
    }
    char chars[] = name.toCharArray();
    chars[0] = Character.toLowerCase(chars[0]);
    return new String(chars);
}
</code></pre><p>方法中判断name如果首字母和第二个字母都是大写则原样返回，如果只有首字母是大写，则将首字母转换为小写之后返回。返回的是不同于本体的一个新的String对象。</p>
<h2 id="DefaultListableBeanFactory如何注册BeanDefinition？"><a href="#DefaultListableBeanFactory如何注册BeanDefinition？" class="headerlink" title="DefaultListableBeanFactory如何注册BeanDefinition？"></a>DefaultListableBeanFactory如何注册BeanDefinition？</h2><p>讲完两种方式加载beanDefinition，我们趁热打铁，聊聊 <strong>DefaultListableBeanFactory是如何注册BeanDefinition的。</strong></p>
<p>从上文我们已经知道 DefaultListableBeanFactory 实际上也是一个 BeanDefinitionRegistry的唯一实现。</p>
<p>这让DefaultListableBeanFactory具备注册Bean定义,也就是BeanDefinition的能力。</p>
<p>在DefaultListableBeanFactory中，持有一个Map, 它装载注解的Bean定义。源码为：</p>
<pre><code>/** Map of bean definition objects, keyed by bean name. */
private final Map&lt;String, BeanDefinition&gt; beanDefinitionMap = new ConcurrentHashMap&lt;&gt;(256);
</code></pre><p>根据英文注释，我们得知，beanDefinitionMap是一个存放bean定义对象的Map集合，它的key是bean名称，value是BeanDefinition对象，也就是bean的定义。</p>
<p>这里还要说一下另一个集合 beanDefinitionNames， 它在源码中定义如下：</p>
<pre><code>/** List of bean definition names, in registration order. */
private volatile List&lt;String&gt; beanDefinitionNames = new ArrayList&lt;&gt;(256);
</code></pre><p>它是一个ArrayList，根据注释以及源码逻辑分析，我们知道beanDefinitionNames这个list按照bean定义的注册顺序存放了bean的定义名称。</p>
<p>之所以特地拿出beanDefinitionMap和beanDefinitionNames单独说明，主要原因就是他们两个在bean注册的过程中是互相协作共同起作用的。通过beanDefinitionMap存放bean名称与BeanDefinition的映射关系，而beanDefinitionNames用于标记BeanDefinition注册的顺序。</p>
<p>那么他们具体是如何作用的呢？接下来就让我们在代码逻辑中一睹为快吧。</p>
<pre><code>// 实现了BeanDefinitionRegistry中的registerBeanDefinition方法，也是目前默认的bean注册实现
@Override
public void registerBeanDefinition(String beanName, BeanDefinition beanDefinition)
        throws BeanDefinitionStoreException {

    // 对beanName，beanDefinition预检验
    Assert.hasText(beanName, &quot;Bean name must not be empty&quot;);
    Assert.notNull(beanDefinition, &quot;BeanDefinition must not be null&quot;);

    // 进行校验，如果校验异常则抛出
    if (beanDefinition instanceof AbstractBeanDefinition) {
        try {
            ((AbstractBeanDefinition) beanDefinition).validate();
        }
        catch (BeanDefinitionValidationException ex) {
            throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName,
                    &quot;Validation of bean definition failed&quot;, ex);
        }
    }

    // 尝试通过beanName获取存在的BeanDefinition
    BeanDefinition existingDefinition = this.beanDefinitionMap.get(beanName);
    if (existingDefinition != null) {

        // 如果不允许不同BeanDefinition实例使用相同beanName注册，则抛出异常，默认为允许
        if (!isAllowBeanDefinitionOverriding()) {
            throw new BeanDefinitionOverrideException(beanName, beanDefinition, existingDefinition);
        }
        ......
        // 存在相同beanName的不同BeanDefinition则打印一个日志，一般是看不到了
        else if (!beanDefinition.equals(existingDefinition)) {
            if (logger.isDebugEnabled()) {
                logger.debug(&quot;Overriding bean definition for bean &apos;&quot; + beanName +
                        &quot;&apos; with a different definition: replacing [&quot; + existingDefinition +
                        &quot;] with [&quot; + beanDefinition + &quot;]&quot;);
            }
        }
        else {
            if (logger.isTraceEnabled()) {
                logger.trace(&quot;Overriding bean definition for bean &apos;&quot; + beanName +
                        &quot;&apos; with an equivalent definition: replacing [&quot; + existingDefinition +
                        &quot;] with [&quot; + beanDefinition + &quot;]&quot;);
            }
        }
        // 使用当前的beanDefinition覆盖已有的beanDefinition（同名）
        this.beanDefinitionMap.put(beanName, beanDefinition);
    }
</code></pre><p>这里主要是将当前要注册的beanDefinition覆盖了已有的同名的beanDefinition。由于存在相同beanName处的校验只是打印了一个debug日志，所以一般来说，我们能看到的表现就是新来的BeanDefinition覆盖了原有的同名的BeanDefinition。这是允许的。</p>
<pre><code>    else {
        // 如果Bean初始化已经开始，则需要加锁，否则会存在并发问题
        if (hasBeanCreationStarted()) {
            // Cannot modify startup-time collection elements anymore (for stable iteration)
            // 给当前的beanDefinitionMap加锁
            synchronized (this.beanDefinitionMap) {
                // 这段代码主要就是使用新建的updatedDefinitions列表新增新的BeanDefinition名称之后，将引用指向beanDefinitionNames
                this.beanDefinitionMap.put(beanName, beanDefinition);
                List&lt;String&gt; updatedDefinitions = new ArrayList&lt;&gt;(this.beanDefinitionNames.size() + 1);
                updatedDefinitions.addAll(this.beanDefinitionNames);
                updatedDefinitions.add(beanName);
                this.beanDefinitionNames = updatedDefinitions;
                removeManualSingletonName(beanName);
            }
        }
        else {
            // Bean的初始化没有开始，则同步更新beanDefinitionMap与beanDefinitionNames
            // Still in startup registration phase
            this.beanDefinitionMap.put(beanName, beanDefinition);
            this.beanDefinitionNames.add(beanName);
            removeManualSingletonName(beanName);
        }
        this.frozenBeanDefinitionNames = null;
    }
    ......
}
</code></pre><p>这段的核心在于判断Bean的初始化是否开始，如果开始，则需要锁定当前的beanDefinitionMap，防止并发操作beanDefinitionMap产生问题。同时更新beanDefinitionNames。将当前BeanDefinition的name添加进去。</p>
<p>否则说明Bean初始化未开始，则可以放心的直接更新beanDefinitionMap与beanDefinitionNames。将beanName按照注册顺序加载到beanDefinitionNames（List）中，同时将beanDefinition注册到beanDefinitionMap里。以便后续初始化bean使用。</p>
<h2 id="annotatedBeanDefinitionReader-register-AnnotatedBeanDefinitionParsingDemo-class-机理"><a href="#annotatedBeanDefinitionReader-register-AnnotatedBeanDefinitionParsingDemo-class-机理" class="headerlink" title="annotatedBeanDefinitionReader.register(AnnotatedBeanDefinitionParsingDemo.class)机理"></a>annotatedBeanDefinitionReader.register(AnnotatedBeanDefinitionParsingDemo.class)机理</h2><p>既然beanDefinition的注册是在DefaultListableBeanFactory中实现的，可是我们在上面的demo中并没有调用这个方法啊？</p>
<p>的确，我们没有直接调用DefaultListableBeanFactory.registerBeanDefinition方法，但是我们通过</p>
<pre><code>beanDefinitionReader.register(AnnotatedBeanDefinitionParsingDemo.class)
</code></pre><p>进行了BeanDefinition的注册工作。</p>
<p>那么我们看一下AnnotatedBeanDefinitionReader构造方法：</p>
<pre><code>public AnnotatedBeanDefinitionReader(BeanDefinitionRegistry registry) {
    this(registry, getOrCreateEnvironment(registry));
}
</code></pre><p>它接受一个BeanDefinitionRegistry实例，我们将初始化好的DefaultListableBeanFactory实例设置给了该构造方法（<strong>DefaultListableBeanFactory实现了BeanDefinitionRegistry接口！</strong>）</p>
<p>接下来我们看一下AnnotatedBeanDefinitionReader.register方法实现：</p>
<pre><code>public void register(Class&lt;?&gt;... componentClasses) {
    for (Class&lt;?&gt; componentClass : componentClasses) {
        registerBean(componentClass);
    }
}
</code></pre><p>可见是对componentClasses可变参进行遍历，调用registerBean(componentClass)进行注册。我们每次只注册一个bean所以只迭代一次。继续看registerBean方法：</p>
<pre><code>...省略部分代码...

BeanDefinitionHolder definitionHolder = new BeanDefinitionHolder(abd, beanName);
definitionHolder = AnnotationConfigUtils.applyScopedProxyMode(scopeMetadata, definitionHolder, this.registry);
BeanDefinitionReaderUtils.registerBeanDefinition(definitionHolder, this.registry);
</code></pre><p>前面的校验我们先省略，重点看最后一行</p>
<pre><code>BeanDefinitionReaderUtils.registerBeanDefinition(definitionHolder, this.registry);
</code></pre><p>这里才是真正的bean注册逻辑，首先定义了BeanDefinitionHolder包装了BeanName以及AnnotatedGenericBeanDefinition。我们看一下BeanDefinitionReaderUtils.registerBeanDefinition是如何实现的</p>
<pre><code>public static void registerBeanDefinition(
        BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry)
        throws BeanDefinitionStoreException {

    // Register bean definition under primary name.
    String beanName = definitionHolder.getBeanName();
    registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition());

    ...省略部分代码...
}
</code></pre><p>好了，真相大白，在BeanDefinitionReaderUtils.registerBeanDefinition中，通过传入的BeanDefinitionRegistry引用的registerBeanDefinition方法对BeanDefinition进行了注册。</p>
<p><strong>而此处的BeanDefinitionRegistry实际上就是我们在外部初始化好的DefaultListableBeanFactory对象！</strong></p>
<p>是不是有一种豁然开朗的感觉。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>那么我们就小结一下，在本文中，我们了解总结了Spring Bean生命周期的开始阶段：BeanDefinition元信息是如何被解析并注册的。重点学习了BeanDefinitionRegistry接口的实现DefaultListableBeanFactory类。</p>
<p>对DefaultListableBeanFactory类如何进行BeanDefinition注册展开了详细的分析，从而了解到，一个Spring Bean是如何开始它的生命周期。</p>
<p>之前笔者只关注了Bean实例化之后的过程，对Bean定义，以及定义的解析过程漠不关心，随着学习的深入，不免心生疑惑：</p>
<blockquote>
<p>到底一个Bean的完整生命周期是怎样的？</p>
</blockquote>
<p>因此有了这个新的子系列，我希望能够把它写完。</p>
<p>写毕文章，不禁有种</p>
<pre><code>众里寻他千百度，蓦然回首，那人却在，灯火阑珊处。
</code></pre><p>之感。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://time.geekbang.org/course/intro/100042601" target="_blank" rel="external">极客时间-小马哥讲Spring核心编程思想</a></p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;接下来，我将对Spring Bean的生命周期进行较为详细的整理和总结。 本文是该部分的第一篇， 我们重点分析一下BeanDefinition元信息解析是如何进行的。&lt;/p&gt;
&lt;p&gt;BeanDefinition主要用来描述Spring的Bean定义，它是一个接口，声明如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public interface BeanDefinition extends AttributeAccessor, BeanMetadataElement {
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;AbstractBeanDefinition这个抽象实现实现了BeanDefinitio接口，它包含了一个Bean定义的主要属性，这里挑选几个重要的进行注释：&lt;/p&gt;
    
    </summary>
    
      <category term="spring-boot" scheme="http://wuwenliang.net/categories/spring-boot/"/>
    
    
      <category term="spring-boot" scheme="http://wuwenliang.net/tags/spring-boot/"/>
    
  </entry>
  
  <entry>
    <title>跟我学Spring之自定义bean容器提升代码可读性</title>
    <link href="http://wuwenliang.net/2020/02/28/%E8%B7%9F%E6%88%91%E5%AD%A6Spring%E4%B9%8B%E8%87%AA%E5%AE%9A%E4%B9%89bean%E5%AE%B9%E5%99%A8%E6%8F%90%E5%8D%87%E4%BB%A3%E7%A0%81%E5%8F%AF%E8%AF%BB%E6%80%A7/"/>
    <id>http://wuwenliang.net/2020/02/28/跟我学Spring之自定义bean容器提升代码可读性/</id>
    <published>2020-02-28T11:41:21.000Z</published>
    <updated>2020-02-28T14:43:36.085Z</updated>
    
    <content type="html"><![CDATA[<p>开发中经常有这样的场景：</p>
<p><strong>根据某个类型标识走不同的业务逻辑</strong>，通常我们会使用if(type.equals(xxxxx)) 或者 switch语句来进行逻辑处理。</p>
<p>这样做当然是没什么问题的。</p>
<p>当业务逻辑变得越来越复杂，类型标识增多之后，难免会出现if判断增加，或者switch case分支变多，这样的代码往往会过于冗长，代码重复性较大，或者说逼格不够高。</p>
<p>本文介绍一种基于自定义Bean容器的开发方式，消除代码中的判断分支，提升代码可读性。</p>
<a id="more"></a>
<p>我们通过一个demo来看如何实现这种编码方式。</p>
<h2 id="定义接口"><a href="#定义接口" class="headerlink" title="定义接口"></a>定义接口</h2><p>首先定义一个接口，主要有两个方法：</p>
<pre><code>public interface AbstractService&lt;T&gt; {

    /**
    * 返回serviceName
    * 作为bean选择标识
    * @return
    */
    String serviceName();

    /**
    * 具体的service方法
    * @param parm
    * @return
    */
    T execute(Object parm);
}
</code></pre><p>实现类需要实现serviceName，返回具体的类型，注意不同的bean实现类该返回值不能重复</p>
<p>execute方法为业务方法，这里只是做个示范，实际开发中可以是任意的通用业务方法。</p>
<h2 id="实现接口"><a href="#实现接口" class="headerlink" title="实现接口"></a>实现接口</h2><p>接着编写实现类，实现接口</p>
<blockquote>
<p>ServiceAImpl标记类型为 ServiceA</p>
</blockquote>
<pre><code>@Component
public class ServiceAImpl implements AbstractService&lt;DemoA&gt; {

    @Override
    public String serviceName() {
        return &quot;ServiceA&quot;;
    }

    @Override
    public DemoA execute(Object parm) {
        System.out.println(&quot;ServiceAImpl execute&quot;);
        return new DemoA().setName(&quot;DemoA&quot;);
    }
}
</code></pre><blockquote>
<p>ServiceBImpl标记类型为 ServiceB</p>
</blockquote>
<pre><code>@Component
public class ServiceBImpl implements AbstractService&lt;DemoB&gt; {

    @Override
    public String serviceName() {
        return &quot;ServiceB&quot;;
    }

    @Override
    public DemoB execute(Object parm) {
        System.out.println(&quot;ServiceBImpl execute&quot;);
        return new DemoB().setName(&quot;DemoB&quot;);
    }
}
</code></pre><h2 id="编写自定义Bean上下文"><a href="#编写自定义Bean上下文" class="headerlink" title="编写自定义Bean上下文"></a>编写自定义Bean上下文</h2><p>这里是重头戏，我们需要编写一个Bean上下文，并注入AbstractService集合。</p>
<pre><code>@Component
public class ServiceContext {

    // IService容器，key=serviceName，velue=实例
    private static Map&lt;String, AbstractService&gt; SERVICE_CONTEXT;

    @Autowired
    List&lt;AbstractService&gt; services;

    @PostConstruct
    void init() {
        SERVICE_CONTEXT = new ConcurrentHashMap&lt;&gt; ();
        if (services == null) {
            return;
        }
        // 将IService所有的实现类注册到serviceContext
        for(AbstractService service : services) {
            SERVICE_CONTEXT.put(service.serviceName(), service);
        }
        System.out.println(JSON.toJSONString(SERVICE_CONTEXT));
    }

    /**
    * 根据serviceName获取实例
    * @param serviceName
    * @return
    */
    public AbstractService getServiceImpl(String serviceName) {
        return SERVICE_CONTEXT.get(serviceName);
    }
}
</code></pre><p>其实注释已经很清楚了，首先定义一个Map，key为String，代表我们上文中接口返回的serviceName。</p>
<p>value为接口实现类bean实例。</p>
<p>接着通过@Autowired注入AbstractService集合，这里是一个List。当Spring容器初始化完成，会将AbstractService的实现类都加载到List中。</p>
<p>在@PostConstruct标记的初始化方法中，遍历 <strong>List＜AbstractService＞</strong>，并依次加载到我们初始化好的Map中。key=AbstractService.serviceName()的返回值，value为AbstractService实例。</p>
<p>定义一个getServiceImpl(String serviceName)提供给业务使用，能够让我们通过具体的serviceName标识获取到Bean实例。这也是为何serviceName不能重复的原因。</p>
<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>到此主要的逻辑编写就完成了，我们编写一个测试类测试一下具体如何使用。</p>
<pre><code>public static void main(String[] args) {
    ConfigurableApplicationContext applicationContext = SpringApplication.run(DemoApplication.class, args);
    // 获取bean Context
    ServiceContext serviceContext = applicationContext.getBean(&quot;serviceContext&quot;, ServiceContext.class);
    // 根据serviceName获取具体的接口实现类
    AbstractService serviceA = serviceContext.getServiceImpl(&quot;ServiceA&quot;);
    AbstractService serviceB = serviceContext.getServiceImpl(&quot;ServiceB&quot;);
    // 调用service方法
    serviceA.execute(null);
    serviceB.execute(null);
}
</code></pre><p>这里从Spring上下文中获取到ServiceContext，并通过具体的serviceName获取到对应的Bean实例，并调用实例的execute方法。执行结果如下：</p>
<pre><code>ServiceAImpl execute
ServiceBImpl execute
</code></pre><p>可能这还不算很直观，我们模拟一个业务场景。</p>
<p>业务需要先判断serviceName，再根据具体的值选择不同的执行逻辑。</p>
<p>正常情况下，我们会这样编写业务代码：</p>
<pre><code>if (&quot;ServiceA&quot;.equals(serviceName)) {
    serviceA.execute()
    return;
}

if (&quot;ServiceB&quot;.equals(serviceName)) {
    serviceB.execute()
    return;
}

...
</code></pre><p>如果有一百个serviceName，那么这里就要有100个if分支，switch也同理。</p>
<p>但是采取本文中的编码方式则只需要这么写：</p>
<pre><code>...省略获取serviceContext过程，最简单的方法是通过@Autowired/@Resource注入...
AbstractService service = serviceContext.getServiceImpl(serviceName);
service.execute()
</code></pre><p>这样我们就只需要在新增serviceName类型后，开发一个对应的实现类即可。</p>
<p>如果是传统的编码方式，则除了新增service实现，还需要修改if/switch判断逻辑，不够灵活且容易出错。</p>
<p>这里其实就是开放封闭原则的体现。传统的方式对修改和扩展都是开放的，而这种方式则是对扩展开发，对修改封闭的。尤其适用于复杂业务场景的开发。</p>
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>简单讲一下原理。</p>
<p>Spring框架支持对集合类型进行依赖注入，对于集合类型依赖注入与查找起作用的ApplicationContext实现类为 <strong>ListableBeanFactory</strong>。</p>
<p>我们看下源码是如何实现该特性的：</p>
<p>具体的逻辑在 <strong>org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency</strong> 这个方法中</p>
<p>打开该方法，重点关注下面这行</p>
<pre><code>Object arg = beanFactory.resolveDependency(currDesc, beanName, autowiredBeans, typeConverter);
</code></pre><p>进入resolveDependency方法，看到下面这一行，跳入doResolveDependency方法</p>
<pre><code>result = doResolveDependency(descriptor, requestingBeanName, 
autowiredBeanNames, typeConverter);
</code></pre><p>重点关注下面的逻辑</p>
<pre><code>Object multipleBeans = resolveMultipleBeans(descriptor, beanName, autowiredBeanNames, typeConverter);
if (multipleBeans != null) {
    return multipleBeans;
}
</code></pre><p>此处的resolveMultipleBeans方法逻辑为，如果解析到了多个匹配条件的Bean，就直接返回解析结果。</p>
<p>那具体的解析结果又是什么呢？我们进入resolveMultipleBeans方法</p>
<pre><code>private Object resolveMultipleBeans(DependencyDescriptor descriptor, @Nullable String beanName,
            @Nullable Set&lt;String&gt; autowiredBeanNames, @Nullable TypeConverter typeConverter) {

    Class&lt;?&gt; type = descriptor.getDependencyType();
    // 数组类型
    if (type.isArray()) {
        Class&lt;?&gt; componentType = type.getComponentType();
        ResolvableType resolvableType = descriptor.getResolvableType();
        Class&lt;?&gt; resolvedArrayType = resolvableType.resolve();
        if (resolvedArrayType != null &amp;&amp; resolvedArrayType != type) {
            type = resolvedArrayType;
            componentType = resolvableType.getComponentType().resolve();
        }
        if (componentType == null) {
            return null;
        }
        Map&lt;String, Object&gt; matchingBeans = findAutowireCandidates(beanName, componentType,
                new MultiElementDescriptor(descriptor));
        if (matchingBeans.isEmpty()) {
            return null;
        }
        if (autowiredBeanNames != null) {
            autowiredBeanNames.addAll(matchingBeans.keySet());
        }
        TypeConverter converter = (typeConverter != null ? typeConverter : getTypeConverter());
        Object result = converter.convertIfNecessary(matchingBeans.values(), type);
        if (getDependencyComparator() != null &amp;&amp; result instanceof Object[]) {
            Arrays.sort((Object[]) result, adaptDependencyComparator(matchingBeans));
        }
        return result;
    }
    // 集合类型，如List set
    else if (Collection.class.isAssignableFrom(type) &amp;&amp; type.isInterface()) {
        Class&lt;?&gt; elementType = descriptor.getResolvableType().asCollection().resolveGeneric();
        if (elementType == null) {
            return null;
        }
        Map&lt;String, Object&gt; matchingBeans = findAutowireCandidates(beanName, elementType,
                new MultiElementDescriptor(descriptor));
        if (matchingBeans.isEmpty()) {
            return null;
        }
        if (autowiredBeanNames != null) {
            autowiredBeanNames.addAll(matchingBeans.keySet());
        }
        TypeConverter converter = (typeConverter != null ? typeConverter : getTypeConverter());
        Object result = converter.convertIfNecessary(matchingBeans.values(), type);
        if (getDependencyComparator() != null &amp;&amp; result instanceof List) {
            ((List&lt;?&gt;) result).sort(adaptDependencyComparator(matchingBeans));
        }
        return result;
    }
    // Map类型
    else if (Map.class == type) {
        ResolvableType mapType = descriptor.getResolvableType().asMap();
        Class&lt;?&gt; keyType = mapType.resolveGeneric(0);
        if (String.class != keyType) {
            return null;
        }
        Class&lt;?&gt; valueType = mapType.resolveGeneric(1);
        if (valueType == null) {
            return null;
        }
        Map&lt;String, Object&gt; matchingBeans = findAutowireCandidates(beanName, valueType,
                new MultiElementDescriptor(descriptor));
        if (matchingBeans.isEmpty()) {
            return null;
        }
        if (autowiredBeanNames != null) {
            autowiredBeanNames.addAll(matchingBeans.keySet());
        }
        return matchingBeans;
    }
    else {
        return null;
    }
}
</code></pre><p>这里便是@Autowired注入集合类型的核心。</p>
<ul>
<li>首先判断注入类型，如果是数组、Collection、Map等类型，则注入元素数据，即查找与元素类型相同的Bean，并注入到集合中。</li>
<li><p>这里重点强调下Map类型，我们能够看出，Map的 key 为Bean的 name，value 为 与定义的元素类型相同的Bean。</p>
<pre><code>// Map的key
Class&lt;?&gt; keyType = mapType.resolveGeneric(0);
if (String.class != keyType) {
    return null;
}
// Map的value
Class&lt;?&gt; valueType = mapType.resolveGeneric(1);
if (valueType == null) {
    return null;
}
</code></pre></li>
</ul>
<p>也就是说，如果业务上不依赖外部的type，那么我们可以直接注入一个Map集合，比如：</p>
<pre><code>@Autowired
private Map&lt;String, BeanInterface&gt; map;
</code></pre><p>这样就能够将接口BeanInterface的实现都注入到Map中，key的值为具体Bean的name，value为Bean实例。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文中，我们通过案例与源码，全方位呈现了Spring对集合类型的注入方式。总结一下：</p>
<ol>
<li><p><strong>Spring在注入集合类的同时，会将集合泛型类的实例填入集合中，作为集合的初始值。</strong></p>
</li>
<li><p>对于list、set填入的是注入类型Spring管理的实例，对于map，Spring会将service的名字作为key，对象作为value封装进入Map。</p>
</li>
<li><p>对于List类型，可以通过@Order指定加入List的顺序。只需要在实现类中加入@Order(value) 注解即可 ，值越小越先被初始化越先被放入List</p>
</li>
</ol>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;开发中经常有这样的场景：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;根据某个类型标识走不同的业务逻辑&lt;/strong&gt;，通常我们会使用if(type.equals(xxxxx)) 或者 switch语句来进行逻辑处理。&lt;/p&gt;
&lt;p&gt;这样做当然是没什么问题的。&lt;/p&gt;
&lt;p&gt;当业务逻辑变得越来越复杂，类型标识增多之后，难免会出现if判断增加，或者switch case分支变多，这样的代码往往会过于冗长，代码重复性较大，或者说逼格不够高。&lt;/p&gt;
&lt;p&gt;本文介绍一种基于自定义Bean容器的开发方式，消除代码中的判断分支，提升代码可读性。&lt;/p&gt;
    
    </summary>
    
      <category term="spring-boot" scheme="http://wuwenliang.net/categories/spring-boot/"/>
    
    
      <category term="spring-boot" scheme="http://wuwenliang.net/tags/spring-boot/"/>
    
  </entry>
  
  <entry>
    <title>跟我学RocketMQ之拉模式消费的两种方式</title>
    <link href="http://wuwenliang.net/2020/02/20/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ%E4%B9%8B%E6%8B%89%E6%A8%A1%E5%BC%8F%E6%B6%88%E8%B4%B9%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F/"/>
    <id>http://wuwenliang.net/2020/02/20/跟我学RocketMQ之拉模式消费的两种方式/</id>
    <published>2020-02-20T09:02:18.000Z</published>
    <updated>2020-02-20T10:19:04.076Z</updated>
    
    <content type="html"><![CDATA[<p>今天我们聊聊RocketMQ基于拉模式的两种消费方式。</p>
<p>对于消费而言，RocketMQ提供了推拉两种方式，我们常用的是基于长轮询的DefaultPushConsumer，它具有实时性好，易开发等特点。</p>
<p>但同时由于是长轮询，因此在大量消息消费的场景下，可能导致broker端CPU负载较大等情况，因此我们会在这种情况下选择使用拉模式的</p>
<p>PullConsumer或者MQPullConsumerScheduleService+PullTaskCallback这两种方式进行更为灵活的消费。</p>
<a id="more"></a>
<h2 id="PullConsumer消费示例代码"><a href="#PullConsumer消费示例代码" class="headerlink" title="PullConsumer消费示例代码"></a>PullConsumer消费示例代码</h2><p>首先我们看下基于PullConsumer方式如何进行消费。这里引用官方的样例代码进行说明：</p>
<pre><code>public class PullConsumer {
</code></pre><p>我们定义了一个Map，key为指定的队列，value为这个队列拉取数据的最后位置，保存每个对列的拉取进度（offset），这里只是用作示例。实际开发中，这里需要基于持久化到Redis或者MySQL等外部存储设施中。</p>
<pre><code>//Map&lt;key, value&gt;  key为指定的队列，value为这个队列拉取数据的最后位置
private static final Map&lt;MessageQueue, Long&gt; offseTable = new HashMap&lt;MessageQueue, Long&gt;();

public static void main(String[] args) throws MQClientException {
</code></pre><p>首先需要定义消费者组，实例化一个DefaultMQPullConsumer消费者对象，标记消费者组。</p>
<p>为消费者设置NameServer地址，保证消费者客户端能够从NameServer获取到broker地址，从而执行消息消费流程。</p>
<pre><code>String group_name = &quot;test_pull_consumer_name&quot;;
DefaultMQPullConsumer consumer = new DefaultMQPullConsumer(group_name);
consumer.setNamesrvAddr(Const.NAMESRV_ADDR_MASTER_SLAVE);
consumer.start();
System.err.println(&quot;consumer start&quot;);
</code></pre><p>通过consumer.fetchSubscribeMessageQueues(TOPIC)方法获取指定TOPIC下的所有队列，默认有4个。</p>
<pre><code>//    从TopicTest这个主题去获取所有的队列（默认会有4个队列）
Set&lt;MessageQueue&gt; mqs = consumer.fetchSubscribeMessageQueues(&quot;test_pull_topic&quot;);
</code></pre><p>对获取到MessageQueue集合进行遍历，拉取数据并执行具体的消费过程。</p>
<pre><code>//    遍历每一个队列，进行拉取数据
for (MessageQueue mq : mqs) {
    System.out.println(&quot;Consume from the queue: &quot; + mq);
</code></pre><p>通过while(true) 不间断地从队列中拉取数据。默认情况下，每次拉取32条，这里需要显式地传入拉取开始offset，通过getMessageQueueOffset(mq)方法获取，从我们持久化的设施中得到对应MessageQueue的拉取进度(可以认为是消费进度)。</p>
<p>拉取结束后，在持久化设施(这里是一个Map)保存下次拉取的开始offset，也就是本次拉取结束的下一个offset。（通过pullResult.getNextBeginOffset()获取）</p>
<pre><code>while (true) {
    try {
        //    从queue中获取数据，从什么位置开始拉取数据 单次对多拉取32条记录
        PullResult pullResult = consumer.pullBlockIfNotFound(mq, null, getMessageQueueOffset(mq), 32);
        System.out.println(pullResult);
        System.out.println(pullResult.getPullStatus());
        System.out.println();
        putMessageQueueOffset(mq, pullResult.getNextBeginOffset());
</code></pre><p>从pullResult拉取结果中获取拉取状态，如果是FOUND则表明消息拉取成功；获取消息列表，并循环进行消费。其余均认为未拉取到消息，不做处理。</p>
<pre><code>                switch (pullResult.getPullStatus()) {
                    case FOUND:
                        List&lt;MessageExt&gt; list = pullResult.getMsgFoundList();
                        for(MessageExt msg : list){
                            System.out.println(new String(msg.getBody()));
                        }
                        break;
                    case NO_MATCHED_MSG:
                        break;
                    case NO_NEW_MSG:
                        System.out.println(&quot;没有新的数据啦...&quot;);
                        break SINGLE_MQ;
                    case OFFSET_ILLEGAL:
                        break;
                    default:
                        break;
                }
            }
            catch (Exception e) {
                e.printStackTrace();
            }
        }
    }
    consumer.shutdown();
}
</code></pre><p> 拉取结束之后，手动显式调用该方法，刷新对应队列MessageQueue的拉取进度；</p>
<pre><code>private static void putMessageQueueOffset(MessageQueue mq, long offset) {
    offseTable.put(mq, offset);
}
</code></pre><p>获取对应MessageQueue的消息消费进度Offset</p>
<pre><code>    private static long getMessageQueueOffset(MessageQueue mq) {
        Long offset = offseTable.get(mq);
        if (offset != null)
            return offset;
        return 0;
    }

}
</code></pre><h3 id="小结PullConsumer消费方式"><a href="#小结PullConsumer消费方式" class="headerlink" title="小结PullConsumer消费方式"></a>小结PullConsumer消费方式</h3><p>从上述代码样例中可以看出，PullConsumer方式需要我们显式地存储消费进度，并且在消费过程中要根据情况进行消费进度的更新与存储。</p>
<p>如果开发者稍有不慎，忘记保存offset，则每次都会从第一条进行拉取，这样很容易造成消息重复。如果是生产环境，则后果不忍想象。</p>
<p>另外，我们还需要通过额外的存储手段对offset进行保存，并且尽量保证该设施的稳定可靠，否则还是会引起重复消费的问题。</p>
<p>基于此，我建议使用MQPullConsumerScheduleService+PullTaskCallback这种消费方式，那它具体如何使用呢？</p>
<h2 id="MQPullConsumerScheduleService-PullTaskCallback消费方式"><a href="#MQPullConsumerScheduleService-PullTaskCallback消费方式" class="headerlink" title="MQPullConsumerScheduleService+PullTaskCallback消费方式"></a>MQPullConsumerScheduleService+PullTaskCallback消费方式</h2><p>基于上述分析的PullConsumer使用一些不便之处，我这里建议使用MQPullConsumerScheduleService+PullTaskCallback方式进行消费。我们还是按照习惯方式，直接上代码。</p>
<p> <strong>step1:</strong> 声明并实例化一个MQPullConsumerScheduleService对象，通过构造方法传递消费者组；           </p>
<pre><code>String group_name = &quot;test_pull_consumer_name&quot;;

final MQPullConsumerScheduleService scheduleService = new MQPullConsumerScheduleService(group_name);
</code></pre><p>为消费者设置NameServer地址，以便能够获取broker地址，开启消费过程。</p>
<pre><code>scheduleService.getDefaultMQPullConsumer().setNamesrvAddr(Const.NAMESRV_ADDR_MASTER_SLAVE);
</code></pre><p>设置消费方式为集群模式；</p>
<pre><code>scheduleService.setMessageModel(MessageModel.CLUSTERING);
</code></pre><p><strong>step2：</strong> 调用registerPullTaskCallback(topic, pullTaskCallback) ,将开发者实现的PullTaskCallback消息拉取实现类注册给MQPullConsumerScheduleService。并绑定到指定的topic下；</p>
<pre><code>scheduleService.registerPullTaskCallback(&quot;test_pull_topic&quot;, new PullTaskCallback() {
</code></pre><p> <strong>step3:</strong> 开发者需要实现PullTaskCallback的doPullTask消息拉取回调方法，这里使用匿名内部类的方式。如果是Spring项目，我们可以定义一个Bean实现PullTaskCallback接口，并将该Bean的引用设置到一个实例化好的MQPullConsumerScheduleService对象中。</p>
<pre><code>@Override
public void doPullTask(MessageQueue mq, PullTaskContext context) {
</code></pre><p>通过 PullTaskContext上下文获取到消息拉取实例对象MQPullConsumer；</p>
<pre><code>MQPullConsumer consumer = context.getPullConsumer();
System.err.println(&quot;-------------- queueId: &quot; + mq.getQueueId()  + &quot;-------------&quot;);
try {
</code></pre><p>获取当前的消费进度，即：从哪儿开始消费，如果offset小于0则指定从0开始。</p>
<pre><code>// 获取从哪里拉取
long offset = consumer.fetchConsumeOffset(mq, false);
if (offset &lt; 0)
    offset = 0;
</code></pre><p>从对应的offset拉取指定数量的消息，默认32条，返回结果为PullResult。</p>
<p>通过pullResult.getPullStatus()判断拉取结果，如果为FOUND，则开始消费流程；其他状态不做处理。</p>
<pre><code>PullResult pullResult = consumer.pull(mq, &quot;*&quot;, offset, 32);
switch (pullResult.getPullStatus()) {
    case FOUND:
        List&lt;MessageExt&gt; list = pullResult.getMsgFoundList();
        for(MessageExt msg : list){
            //消费数据...
            ystem.out.println(new String(msg.getBody()));
        }
        break;
    case NO_MATCHED_MSG:
        break;
    case NO_NEW_MSG:
    case OFFSET_ILLEGAL:
        break;
    default:
        break;
}
</code></pre><p><strong>step4：</strong> 重点来了，这里通过调用updateConsumeOffset，更新消费进度，将下次消费开始时的offset更新到broker。并不需要客户端本地保存消费进度。</p>
<p>设置下次拉取时间，定时进行拉取调度。</p>
<pre><code>    consumer.updateConsumeOffset(mq, pullResult.getNextBeginOffset());
    // 设置再过3000ms后重新拉取
    context.setPullNextDelayTimeMillis(3000);

}
...省略catch块...
</code></pre><p>启动拉取过程。 </p>
<pre><code>        scheduleService.start();
    }
}
</code></pre><h3 id="小结MQPullConsumerScheduleService消费方式"><a href="#小结MQPullConsumerScheduleService消费方式" class="headerlink" title="小结MQPullConsumerScheduleService消费方式"></a>小结MQPullConsumerScheduleService消费方式</h3><p>从代码中我们能够清晰的看出，MQPullConsumerScheduleService的优势：</p>
<ol>
<li>MQPullConsumerScheduleService基于定时任务，消费端能够灵活控制拉取频率</li>
<li>MQPullConsumerScheduleService支持提交消费进度到broker，不需要消费端进行保存</li>
<li>MQPullConsumerScheduleService本身基于PullConsumer，定制化程度高，使用起来不易出错</li>
</ol>
<p>可以说，MQPullConsumerScheduleService既保留了PullConsumer的优势，还对其进行了一定程序的增强；通过直接提交消费offset到broker，降低了客户端的开发量，较少了消费重复的风险。</p>
<p>因此笔者提倡在实际开发中，使用MQPullConsumerScheduleService进行拉模式的消息消费。</p>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><p>这里做个小预告，在后续的文章中，笔者将对MQPullConsumerScheduleService消费方式源码实现进行解析，请拭目以待。</p>
<p>为了方便读者和笔者后续开发，这里贴出两种方式的完整源码实现，以略去重读文章的繁琐：</p>
<h3 id="PullConsumer样例"><a href="#PullConsumer样例" class="headerlink" title="PullConsumer样例"></a>PullConsumer样例</h3><pre><code>public class PullConsumer {
    //Map&lt;key, value&gt;  key为指定的队列，value为这个队列拉取数据的最后位置
    private static final Map&lt;MessageQueue, Long&gt; offseTable = new HashMap&lt;MessageQueue, Long&gt;();

    public static void main(String[] args) throws MQClientException {

        String group_name = &quot;test_pull_consumer_name&quot;;
        DefaultMQPullConsumer consumer = new DefaultMQPullConsumer(group_name);
        consumer.setNamesrvAddr(Const.NAMESRV_ADDR_MASTER_SLAVE);
        consumer.start();
        System.err.println(&quot;consumer start&quot;);
        //    从TopicTest这个主题去获取所有的队列（默认会有4个队列）
        Set&lt;MessageQueue&gt; mqs = consumer.fetchSubscribeMessageQueues(&quot;test_pull_topic&quot;);
        //    遍历每一个队列，进行拉取数据
        for (MessageQueue mq : mqs) {
            System.out.println(&quot;Consume from the queue: &quot; + mq);

            SINGLE_MQ: while (true) {
                try {
                    //    从queue中获取数据，从什么位置开始拉取数据 单次对多拉取32条记录
                    PullResult pullResult = consumer.pullBlockIfNotFound(mq, null, getMessageQueueOffset(mq), 32);
                    System.out.println(pullResult);
                    System.out.println(pullResult.getPullStatus());
                    System.out.println();
                    putMessageQueueOffset(mq, pullResult.getNextBeginOffset());
                    switch (pullResult.getPullStatus()) {
                        case FOUND:
                            List&lt;MessageExt&gt; list = pullResult.getMsgFoundList();
                            for(MessageExt msg : list){
                                System.out.println(new String(msg.getBody()));
                            }
                            break;
                        case NO_MATCHED_MSG:
                            break;
                        case NO_NEW_MSG:
                            System.out.println(&quot;没有新的数据啦...&quot;);
                            break SINGLE_MQ;
                        case OFFSET_ILLEGAL:
                            break;
                        default:
                            break;
                    }
                }
                catch (Exception e) {
                    e.printStackTrace();
                }
            }
        }
        consumer.shutdown();
    }


    private static void putMessageQueueOffset(MessageQueue mq, long offset) {
        offseTable.put(mq, offset);
    }


    private static long getMessageQueueOffset(MessageQueue mq) {
        Long offset = offseTable.get(mq);
        if (offset != null)
            return offset;
        return 0;
    }

}
</code></pre><h3 id="MQPullConsumerScheduleService代码样例"><a href="#MQPullConsumerScheduleService代码样例" class="headerlink" title="MQPullConsumerScheduleService代码样例"></a>MQPullConsumerScheduleService代码样例</h3><pre><code>public class PullScheduleService {

    public static void main(String[] args) throws MQClientException {

        String group_name = &quot;test_pull_consumer_name&quot;;

        final MQPullConsumerScheduleService scheduleService = new MQPullConsumerScheduleService(group_name);

        scheduleService.getDefaultMQPullConsumer().setNamesrvAddr(Const.NAMESRV_ADDR_MASTER_SLAVE);

        scheduleService.setMessageModel(MessageModel.CLUSTERING);

        scheduleService.registerPullTaskCallback(&quot;test_pull_topic&quot;, new PullTaskCallback() {

            @Override
            public void doPullTask(MessageQueue mq, PullTaskContext context) {
                MQPullConsumer consumer = context.getPullConsumer();
                System.err.println(&quot;-------------- queueId: &quot; + mq.getQueueId()  + &quot;-------------&quot;);
                try {
                    // 从哪里拉取
                    long offset = consumer.fetchConsumeOffset(mq, false);
                    if (offset &lt; 0)
                        offset = 0;

                    PullResult pullResult = consumer.pull(mq, &quot;*&quot;, offset, 32);
                    switch (pullResult.getPullStatus()) {
                    case FOUND:
                        List&lt;MessageExt&gt; list = pullResult.getMsgFoundList();
                        for(MessageExt msg : list){
                            //消费数据
                            System.out.println(new String(msg.getBody()));
                        }
                        break;
                    case NO_MATCHED_MSG:
                        break;
                    case NO_NEW_MSG:
                    case OFFSET_ILLEGAL:
                        break;
                    default:
                        break;
                    }
                    consumer.updateConsumeOffset(mq, pullResult.getNextBeginOffset());
                    // 设置再过3000ms后重新拉取
                    context.setPullNextDelayTimeMillis(3000);

                }
                catch (Exception e) {
                    e.printStackTrace();
                }
            }
        });

        scheduleService.start();
    }
}
</code></pre><p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天我们聊聊RocketMQ基于拉模式的两种消费方式。&lt;/p&gt;
&lt;p&gt;对于消费而言，RocketMQ提供了推拉两种方式，我们常用的是基于长轮询的DefaultPushConsumer，它具有实时性好，易开发等特点。&lt;/p&gt;
&lt;p&gt;但同时由于是长轮询，因此在大量消息消费的场景下，可能导致broker端CPU负载较大等情况，因此我们会在这种情况下选择使用拉模式的&lt;/p&gt;
&lt;p&gt;PullConsumer或者MQPullConsumerScheduleService+PullTaskCallback这两种方式进行更为灵活的消费。&lt;/p&gt;
    
    </summary>
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/categories/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/tags/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
  </entry>
  
  <entry>
    <title>跟我学RocketMQ之消息持久化原理与Mmap</title>
    <link href="http://wuwenliang.net/2020/02/11/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ%E4%B9%8B%E6%B6%88%E6%81%AF%E6%8C%81%E4%B9%85%E5%8C%96%E5%8E%9F%E7%90%86%E4%B8%8EMmap/"/>
    <id>http://wuwenliang.net/2020/02/11/跟我学RocketMQ之消息持久化原理与Mmap/</id>
    <published>2020-02-11T15:35:37.000Z</published>
    <updated>2020-02-12T14:43:38.032Z</updated>
    
    <content type="html"><![CDATA[<p>大家好，跟我学RocketMQ系列并没有结束。随着笔者对RocketMQ的学习与感悟不断深入，我们的旅程也在继续。</p>
<p>本文我将带领读者朋友们一睹RocketMQ实现高性能消息存储的原理，以及它背后的核心Mmap的风采。</p>
<h2 id="RocketMQ消息持久化-消息不丢失-原理"><a href="#RocketMQ消息持久化-消息不丢失-原理" class="headerlink" title="RocketMQ消息持久化(消息不丢失)原理"></a>RocketMQ消息持久化(消息不丢失)原理</h2><p>在之前的文章中我们已经得知，broker通过调用以下代码实现消息持久化</p>
<pre><code>putMessageResult = this.brokerController.getMessageStore().putMessage(msgInner);
</code></pre><p>我们先不深入putMessage方法的内部实现，单说它背后的原理：<strong>CommitLog的顺序写入机制</strong>。</p>
<p>CommitLog顺序写，其实就是一个WAL，即write ahead log。</p>
<a id="more"></a>
<blockquote>
<p>Write Ahead Log（WAL），即：预写式日志。是关系数据库系统中用于提供原子性和持久性（ACID属性中的两个）的一系列技术。在使用WAL的系统中，所有的修改在提交之前都要先写入log文件中，log文件中通常包括redo和undo信息，通过日志记录描述好数据的改变后(redo和undo)，再写入缓存，等缓存区写满后，最后再往持久层修改数据。</p>
</blockquote>
<p>其实不单单数据库会使用，RocketMQ的commitLog也是WAL的一种，通过对文件的顺序追加写入，提高了文件的写入性能。</p>
<p>我们在RocketMQ的broker端文件系统中，能够看到如下的文件</p>
<pre><code>$HOME/store/consumequeue/{topic}/{queueId}/{fileName}
</code></pre><p>由于我们在broker上设置的每个Topic下都会存在一些MessageQueue，这里的{topic}指代的就是具体的Topic，而{queueId}指代的就是该Topic下某个MessageQueue。</p>
<p>fileName就是MessageQueue中消息在CommitLog中的偏移量，通过这个offset偏移量保证消息读取阶段能够定位到消息的物理位置。</p>
<blockquote>
<p>这个offset可以理解为对CommitLog文件中一个消息的引用。</p>
</blockquote>
<p>除了offset，在ConsumeQueue中还存储了消息的其他属性如，消息长度、消息tag等。单条数据大小为20字节，单个ConsumeQueue文件能够保存30万条数据，每个文件大约占用5.7MB。</p>
<p>也就是说Topic下每个MessageQueue对应了Broker上多个ConsumeQueue文件，这些ConsumeQueue文件保存了该MessageQueue的所有消息在CommitLog文件中的物理位置，即offset偏移量。</p>
<blockquote>
<p>事实上，ConsumeQueue的作用类似索引文件。</p>
</blockquote>
<p>它能够区分不同Topic下的不同MessageQueue的消息，同时能够为消费消息起到一定的<strong>缓冲作用</strong>（当只有ReputMessageService异步服务线程通过doDispatch异步生成了ConsumeQueue队列的元素后，Consumer端才能进行消费）。</p>
<p>这样，只要消息写入成功，并刷盘至CommitLog文件后，<strong>消息就不会丢失</strong>，即使ConsumeQueue中的数据丢失，也可以通过CommitLog来恢复。</p>
<h3 id="如何保证消息写入CommitLog文件性能接近内存写入性能？"><a href="#如何保证消息写入CommitLog文件性能接近内存写入性能？" class="headerlink" title="如何保证消息写入CommitLog文件性能接近内存写入性能？"></a>如何保证消息写入CommitLog文件性能接近内存写入性能？</h3><p>我们都知道的一点是，文件随机写入磁盘的性能是远低于随机写内存的性能。两者性能差距很大。</p>
<p>举个例子：</p>
<pre><code>我们对机械硬盘在随机写入情况下进行性能测试。
测试显示在数据块为512字节时平均写入速度仅为0.083MB/s，
当数据块大小为4KB时，平均写入速度仅为0.576MB/s

当对同样的机械硬盘顺序写情况下进行测试，
测试显示平均写入速度能达到79.0MB/s。
</code></pre><p>可以看到两者相差两个数量级。</p>
<p>说一个结论，顺序写文件的性能约等于随机写内存的性能。这也是RocketMQ为何选择对commitLog进行顺序写的原因。</p>
<p>提升写入性能的核心方法为：</p>
<ul>
<li>基于操作系统的PageCache</li>
<li>顺序写机制</li>
</ul>
<p>他们两者共同提升了commitLog写入性能。</p>
<p>这里重点说一下PageCache。</p>
<h3 id="RocketMQ对PageCache的使用（Mmap）"><a href="#RocketMQ对PageCache的使用（Mmap）" class="headerlink" title="RocketMQ对PageCache的使用（Mmap）"></a>RocketMQ对PageCache的使用（Mmap）</h3><p>PageCache是操作系统对文件的缓存，用于加速对文件的读写。</p>
<blockquote>
<p>一般来说，程序对文件进行顺序读写的速度几乎接近于内存的读写访问，这里的主要原因就是在于OS使用PageCache机制对读写访问操作进行了性能优化，将一部分的内存用作PageCache。</p>
</blockquote>
<p>对于数据文件的读取而言，如果一次读取文件时出现未命中PageCache的情况，OS从物理磁盘上访问读取文件的同时，会顺序对其他相邻块的数据文件进行预读取，即：顺序读入紧随其后的少数几个页面。</p>
<p>这样，只要下次访问的文件已经被加载至PageCache时，读取操作的速度就基本等于访问内存。</p>
<p>而对于数据文件的写入，OS会先写入至Cache内，随后通过异步的方式由<strong>pdflush内核线程</strong>将PageCache内的数据刷盘至物理磁盘上。</p>
<p>RocketMQ对消息的读写的大致做法是：</p>
<ol>
<li>首先将数据文件映射到OS的虚拟内存中，通过JDK NIO的MappedByteBuffer实现，即Mmap，我们后面细讲</li>
<li>当消息写入时，首先写PageCache，并通过异步刷盘的方式将消息批量持久化（同时也支持同步刷盘）</li>
<li>当消息消费者订阅消息时，此时对CommitLog是随机读取。由于PageCache的局部性热点原理，并且整体对消息的读取还是从旧到新的有序读，因此大部分情况下消息还是可以直接从Page Cache中读取，不会产生太多的缺页中断（Page Fault）而从磁盘读取</li>
</ol>
<p>读写速度快，是PageCache的优点，当然它也存在一定问题。</p>
<blockquote>
<p>PageCache的不足</p>
</blockquote>
<p>当OS进行脏页回写、内存回收、内存交换（swap）时，会引起较大的消息读写延迟。</p>
<p>对这些情况，RocketMQ采用多种优化技术，如内存预分配，文件预热，mlock系统调用等，保证了在尽可能地发挥PageCache机制优点的同时，尽力减少其缺点带来的消息读写延迟。</p>
<p>上文提到了RocketMQ消息刷盘，这里进行较为详细的讲解。</p>
<h3 id="RocketMQ消息刷盘"><a href="#RocketMQ消息刷盘" class="headerlink" title="RocketMQ消息刷盘"></a>RocketMQ消息刷盘</h3><p>消息刷盘主要有同步刷盘和异步刷盘两种方式。</p>
<p>先上图：</p>
<p><img src="/2020/02/11/跟我学RocketMQ之消息持久化原理与Mmap/./flush.png" alt="刷盘模式"></p>
<h4 id="同步刷盘"><a href="#同步刷盘" class="headerlink" title="同步刷盘"></a>同步刷盘</h4><p>对于同步刷盘模式，当生产者发送消息到broker，broker收到该消息，会对消息进行刷盘操作，只有消息刷盘成功才会返回ACK到生产者，保证消息写入一定能够成功。</p>
<p>同步刷盘保证了消息的可靠性，但对性能有较大影响，因为这个过程是完全同步的，应用场景主要适用于金融、支付、物流等对消息可靠性要求高的领域。</p>
<p>RocketMQ同步刷盘的大致做法如下：</p>
<ol>
<li>基于生产者消费者模型，主线程创建刷盘请求实例GroupCommitRequest</li>
<li>将请求实例GroupCommitRequest放入刷盘写队列后唤醒同步刷盘线程GroupCommitService执行刷盘动作（通过CAS变量和CountDownLatch来保证线程间的同步）</li>
<li>RocketMQ源码中用读写双缓存队列（requestsWrite/requestsRead）来实现读写分离，好处在于内部消费生成的同步刷盘请求可以不用加锁，提高并发度</li>
</ol>
<h4 id="异步刷盘"><a href="#异步刷盘" class="headerlink" title="异步刷盘"></a>异步刷盘</h4><p>默认情况下，broker采用异步刷盘策略。</p>
<p>异步刷盘，顾名思义，当broker收到消息时，并不会直接将消息刷盘，而是先写入PageCache，写入过程是很快的，这里完全是一个内存写操作。</p>
<p>写入成功后，直接返回ACK给生产者。然后在后台通过异步刷盘线程将消息异步写入commitLog，降低了读写延迟，提高了MQ的性能和吞吐量。</p>
<p>不同于同步刷盘，异步过程下，主线程不会阻塞，主线程唤醒刷盘线程后就会继续执行后续操作，提升了吞吐量。</p>
<p>当系统对消息的可靠性要求较低，可以通过异步刷盘策略提升消息吞吐量及读写性能。</p>
<p>原因在于，PageCache本质上还是内存，当出现掉电等情况，os cache中的消息就会丢失。这种情况在极端条件会出现，因此做好异地容灾及跨域同步等高可用策略后，基本上可以降低掉电造成的影响。</p>
<h2 id="Mmap内存映射及RocketMQ中的应用"><a href="#Mmap内存映射及RocketMQ中的应用" class="headerlink" title="Mmap内存映射及RocketMQ中的应用"></a>Mmap内存映射及RocketMQ中的应用</h2><p>首先我们来复习一下Mmap内存映射（零拷贝 zero copy）机制。</p>
<p>首先我们复习一下传统的io操作。传统io分为缓冲io和直接io，如下图所示</p>
<p><img src="/2020/02/11/跟我学RocketMQ之消息持久化原理与Mmap/./zhijie-io.png" alt="直接IO"></p>
<p><img src="/2020/02/11/跟我学RocketMQ之消息持久化原理与Mmap/./huanchong-io.png" alt="缓冲IO"></p>
<p>内核缓冲区为OS的pageCache，为了加快磁盘IO，Linux将磁盘上的数据以Page为单位缓存在系统的内存中，这里的Page是Linux系统定义的一个逻辑概念，一个Page大小一般为4KB。</p>
<p>对于缓冲IO，对操作有三次数据拷贝，写操作则为反向的三次数据拷贝。</p>
<blockquote>
<p>读操作：</p>
</blockquote>
<pre><code>磁盘-&gt;内核缓冲区-&gt;用户缓冲区-&gt;应用程序内存
</code></pre><blockquote>
<p>写操作：</p>
</blockquote>
<pre><code>应用程序内存-&gt;用户缓冲区-&gt;内核缓冲区-&gt;磁盘
</code></pre><p>对于直接IO，少了用户缓冲区，因此对于读操作会有两次数据拷贝，对于写操作，会有反向的两次数据拷贝。</p>
<p>直接IO的意思就是没有了用户级别的缓冲，操作系统内核态的缓冲还是存在的。</p>
<blockquote>
<p>读操作：</p>
</blockquote>
<pre><code>磁盘-&gt;内核缓冲区-&gt;应用程序内存
</code></pre><blockquote>
<p>写操作：</p>
</blockquote>
<pre><code>应用程序内存-&gt;内核缓冲区-&gt;磁盘
</code></pre><p>如果RocketMQ采用传统的直接IO或者缓冲IO，则文件拷贝次数就会大大增加，降低读写效率， 因此引入了零拷贝策略。</p>
<p>零拷贝在Java中的实现是MappedByteBuffer，它的核心原理是内存映射文件，如图所示：</p>
<p><img src="/2020/02/11/跟我学RocketMQ之消息持久化原理与Mmap/neicun-yingshe.png" alt="内存映射文件"></p>
<p>通过将应用程序的逻辑内存地址直接映射到Linux操作系统的内核缓冲区，应用程序通过读写自己的逻辑内存，达到实际操作操作系统内核缓冲区的效果，减少了用户态与内核态之间的数据拷贝次数。</p>
<p>由于内核态与用户态之间没有数据拷贝，因此叫零拷贝。</p>
<p>这里我们要区分“拷贝”和“映射”两个概念：</p>
<blockquote>
<p>拷贝是将数据从一块内存复制到另一块内存中；而映射只是持有了数据的一个引用(即地址)，数据本身只有一个副本。</p>
</blockquote>
<p>在Linux中，零拷贝通过sendFile实现，在Java中，通过FileChannel.transferTo实现。</p>
<p>那么，<strong>RocketMQ具体是如何基于MappedByteBuffer内存映射文件实现高性能文件读写的呢？</strong></p>
<p>在Java中，MappedByteBuffer映射文件要求文件大小小于2GB，RocketMQ中的每个commitlog大小最大为1G，单个ConsumeQueue文件大小月维护5.7MB。是符合MappedByteBuffer文件映射要求的。</p>
<p>当commitlog通过MappedByteBuffer的map()函数映射到内存中后，就可以对其进行读写操作，操作本身完全是基于内存进行的，因此效率很高。消息直接写入到PageCache中，再异步地被异步刷盘线程持久化到磁盘文件中。</p>
<p>当进行读取操作时，文件如果在PageCache中，则直接从内存中读取，而大部分文件是会在内存中命中的，少部分不在PageCache中的文件需要发生一次缺页中断重新映射到内存页中，被读到。</p>
<p>我们在上文中已经知道，一个Page大小一般为4KB，因此一次缺页中断会将一批数据映射到内存中，这也是性能提高的原因之一。</p>
<h3 id="其他零拷贝策略"><a href="#其他零拷贝策略" class="headerlink" title="其他零拷贝策略"></a>其他零拷贝策略</h3><ul>
<li>硬件：基于DMA传输数据</li>
<li>软件：基于Linux的sendFile</li>
</ul>
<p>操作系统层面的零拷贝微观细节如下（假设应用为Java进程）：</p>
<ul>
<li>JVM向OS发出read()系统调用触发上下文切换，从用户态切换到内核态</li>
<li>从外部存储（如硬盘）读取文件内容，通过直接内存访问（DMA）存入内核地址空间的缓冲区</li>
<li>将数据从内核缓冲区拷贝到用户空间缓冲区，read()系统调用返回，并从内核态切换回用户态</li>
<li>JVM向OS发出write()系统调用，触发上下文切换，从用户态切换到内核态</li>
<li>将数据从用户缓冲区拷贝到内核中与目的地Socket关联的缓冲区</li>
<li>数据最终经由Socket通过DMA传送到硬件（如网卡）缓冲区，write()系统调用返回，并从内核态切换回用户态</li>
</ul>
<h3 id="内存预映射机制"><a href="#内存预映射机制" class="headerlink" title="内存预映射机制"></a>内存预映射机制</h3><p>RocketMQ在消息写入过程中，通过调用CommitLog的 <strong>putMessage()</strong> 方法，</p>
<p>CommitLog会先从MappedFileQueue队列中获取一个 MappedFile，如果没有就新建一个。</p>
<p>这里MappedFile的创建过程是先构建一个AllocateRequest请求，具体做法是：</p>
<ul>
<li>将下一个文件的路径、下下个文件的路径、文件大小为作为参数封装为AllocateRequest对象添加至队列中</li>
<li>在Broker启动时，后台创建并运行AllocateMappedFileService服务线程。该线程会不停地run；只要请求队列里存在请求，就会执行MappedFile映射文件的创建和预分配工作。</li>
<li>分配的时候有两种策略，一种是使用Mmap的方式来构建MappedFile实例，另一种是从TransientStorePool堆外内存池中获取相应的DirectByteBuffer来构建MappedFile（具体采用哪种策略与刷盘的方式有关）</li>
<li>在创建分配完下个MappedFile后，会将下下个MappedFile预先创建并保存至请求队列中等待下次获取时直接返回</li>
</ul>
<p>这种策略便是RocketMQ预分配MappedFile，也叫 <strong>内存预映射机制</strong>。 它的思路很巧妙，能够在下次获取时候直接返回MappedFile实例而不用等待MappedFile创建分配所产生的时间延迟。</p>
<h3 id="内存预热"><a href="#内存预热" class="headerlink" title="内存预热"></a>内存预热</h3><p>RocketMQ在创建并分配MappedFile的过程中预先写入了一些随机值到Mmap映射出的内存空间里。原因在于：</p>
<blockquote>
<p>仅分配内存并进行mlock系统调用后并不会为程序完全锁定这些分配的内存，原因在于其中的分页可能是写时复制的。因此，就有必要对每个内存页面中写入一个假的值。</p>
</blockquote>
<p>还有一个问题，当调用Mmap进行内存映射后，OS只是建立了虚拟内存地址至物理地址的映射表，而实际并没有加载任何文件至内存中。</p>
<p>程序要访问数据时，OS会检查该部分的分页是否已经在内存中，如果不在，则发出一次 <strong>缺页中断</strong>。X86的Linux中一个标准页面大小是4KB，那么1G的CommitLog需要发生 <strong>1024KB/4KB=256次</strong>  缺页中断，才能使得对应的数据完全加载至物理内存中。</p>
<p>为了避免OS检查分页是否在内存中的过程出现大量缺页中断，RocketMQ在做Mmap内存映射的同时进行了madvise系统调用，目的是使OS做一次内存映射后，使对应的文件数据尽可能多的预加载至内存中，降低缺页中断次数，从而达到内存预热的效果。</p>
<p>RocketMQ通过map+madvise映射后预热机制，将磁盘中的数据尽可能多的加载到PageCache中，保证后续对ConsumeQueue和CommitLog的读取过程中，能够尽可能从内存中读取数据，提升读写性能。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>根据上文的论述，结合我们的讨论和思考，我们能够总结RocketMQ存储架构的优缺点：</p>
<blockquote>
<p>优点</p>
</blockquote>
<ul>
<li>ConsumeQueue消息逻辑队列较为轻量级，易于理解</li>
<li>对磁盘的访问串行化，能够避免磁盘竟争，不会因为队列增加而导致IOWAIT增高</li>
</ul>
<blockquote>
<p>缺点</p>
</blockquote>
<ul>
<li>对于CommitLog而言，写入消息虽然是顺序写，但是读却变成了完全随机读</li>
<li>Consumer端订阅消费一条消息，需要先读ConsumeQueue，再读CommitLog，这在一定程度上增加了性能开销</li>
</ul>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://cloud.tencent.com/developer/article/1352677" target="_blank" rel="external">https://cloud.tencent.com/developer/article/1352677</a></p>
<p><a href="https://blog.csdn.net/smallcatbaby/article/details/93799959" target="_blank" rel="external">https://blog.csdn.net/smallcatbaby/article/details/93799959</a></p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;大家好，跟我学RocketMQ系列并没有结束。随着笔者对RocketMQ的学习与感悟不断深入，我们的旅程也在继续。&lt;/p&gt;
&lt;p&gt;本文我将带领读者朋友们一睹RocketMQ实现高性能消息存储的原理，以及它背后的核心Mmap的风采。&lt;/p&gt;
&lt;h2 id=&quot;RocketMQ消息持久化-消息不丢失-原理&quot;&gt;&lt;a href=&quot;#RocketMQ消息持久化-消息不丢失-原理&quot; class=&quot;headerlink&quot; title=&quot;RocketMQ消息持久化(消息不丢失)原理&quot;&gt;&lt;/a&gt;RocketMQ消息持久化(消息不丢失)原理&lt;/h2&gt;&lt;p&gt;在之前的文章中我们已经得知，broker通过调用以下代码实现消息持久化&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;putMessageResult = this.brokerController.getMessageStore().putMessage(msgInner);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;我们先不深入putMessage方法的内部实现，单说它背后的原理：&lt;strong&gt;CommitLog的顺序写入机制&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;CommitLog顺序写，其实就是一个WAL，即write ahead log。&lt;/p&gt;
    
    </summary>
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/categories/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/tags/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
  </entry>
  
</feed>
