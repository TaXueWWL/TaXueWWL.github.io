<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>朝·闻·道</title>
  <subtitle>SnoWalker&#39;s Blog</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://wuwenliang.net/"/>
  <updated>2022-02-20T16:21:39.428Z</updated>
  <id>http://wuwenliang.net/</id>
  
  <author>
    <name>SnoWalker</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>源码级探究Mybatis原理-以查询为例</title>
    <link href="http://wuwenliang.net/2022/02/20/%E6%BA%90%E7%A0%81%E7%BA%A7%E6%8E%A2%E7%A9%B6Mybatis%E5%8E%9F%E7%90%86-%E4%BB%A5%E6%9F%A5%E8%AF%A2%E4%B8%BA%E4%BE%8B/"/>
    <id>http://wuwenliang.net/2022/02/20/源码级探究Mybatis原理-以查询为例/</id>
    <published>2022-02-20T14:03:15.000Z</published>
    <updated>2022-02-20T16:21:39.428Z</updated>
    
    <content type="html"><![CDATA[<p>作为一名Java后端开发者，尤其是国内开发者，从刚参加工作开始就与Mybatis打交道了。</p>
<p>用了这么久的Mybatis难免会心生疑问：</p>
<ul>
<li>我只是写了个Mapper接口，再配合xml或者注解，把SQL一写，就可以执行数据库操作，这是为何？</li>
<li>都说Mybatis是对JDBC的封装，可是我却看不到JDBC相关的接口和对象，它们到哪里去了？</li>
<li>为什么在Spring中使用Mybatis，不用加@Repository/@Component之类的注解，就可以随用随注入（如：@Autowired）?</li>
</ul>
<blockquote>
<p>硬核万字长文，点个再看，转发，多谢啦~</p>
</blockquote>
<a id="more"></a>
<p>随着工作经验越多，对这些问题的疑惑就会越发强烈。而读源码是解决这些疑问的根本方法。</p>
<p>那么就跟随笔者的脚步，试着用一篇文章，以一个查询为例，从源码角度一步一步揭开Mybatis的神秘面纱。</p>
<h2 id="一、先看一个demo"><a href="#一、先看一个demo" class="headerlink" title="一、先看一个demo"></a>一、先看一个demo</h2><pre><code>private SqlSessionFactory sqlSessionFactory;

@Before
public void prepare() throws IOException {
    String resource = &quot;mybatis-config.xml&quot;;
    InputStream inputStream = Resources.getResourceAsStream(resource);
    sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);
}

/**
 * 通过 SqlSession.getMapper(XXXMapper.class)  接口方式
 * @throws IOException
 */
@Test
public void testSelect() throws IOException {
    SqlSession session = sqlSessionFactory.openSession(); // ExecutorType.BATCH
    try {
        BlogMapper mapper = session.getMapper(BlogMapper.class);
        Blog blog = mapper.selectBlogById(1);
        System.out.println(blog);
    } finally {
        session.close();
    }
}
</code></pre><p>这是一个非Spring项目的Test用例类，逻辑很直观，就是在测试通过id查询一行记录；在执行查询之间加载配置文件。</p>
<p>执行该测试用例，日志输出如下：</p>
<pre><code>Opening JDBC Connection
Created connection 1325808650.
Setting autocommit to false on JDBC Connection [com.mysql.jdbc.JDBC4Connection@4f063c0a]
==&gt;  Preparing: select * from blog where bid = ? 
==&gt; Parameters: 1(Integer)
&lt;==    Columns: bid, name, author_id, type
&lt;==        Row: 1, RabbitMQ延时消息, 1001, 0
getNullableResult---1NORMAL
&lt;==      Total: 1
Blog(bid=1, name=RabbitMQ延时消息, authorId=1001, blogType=0)
</code></pre><p>我们就通过这个ById查询的案例，对Mybatis运行的过程抽丝剥茧，还原出一个完整的脉络。</p>
<h2 id="二、一图总览全局"><a href="#二、一图总览全局" class="headerlink" title="二、一图总览全局"></a>二、一图总览全局</h2><blockquote>
<p>按照惯例我们用一张简单概括的流程图引领全局，先建立一个宏观的印象。</p>
</blockquote>
<p><img src="/2022/02/20/源码级探究Mybatis原理-以查询为例/1.png" alt="1.png"></p>
<p>从图中可以看到，Mybatis主要的工作流程分为以下几步：</p>
<ol>
<li>加载并解析配置文件</li>
<li>获取SqlSession对象作为与数据库交互的接口</li>
<li>通过Executor对象封装数据库操作，执行SQL操作</li>
<li>调用底层的JDBC接口，与数据库进行真正的交互</li>
<li>向数据库提交参数，并封装返回参数</li>
</ol>
<h3 id="加载并解析配置文件"><a href="#加载并解析配置文件" class="headerlink" title="加载并解析配置文件"></a>加载并解析配置文件</h3><p>在Mybatis启动的时候回去加载配置文件，一般来说文件包含全局配置文件（文件名为 <strong>mybatis-config.xml</strong>） ，以及映射器配置文件（也就是各种Mapper.xml文件）；</p>
<h3 id="获取SqlSession对象作为与数据库交互的接口"><a href="#获取SqlSession对象作为与数据库交互的接口" class="headerlink" title="获取SqlSession对象作为与数据库交互的接口"></a>获取SqlSession对象作为与数据库交互的接口</h3><p>Mybatis在加载完配置文件之后，会去获取SqlSession对象，这个对象是应用程序与数据库之间的桥梁，封装了程序与数据库之间的连接。</p>
<p>一般来说，一个SqlSession对象中包含了一个Connection，我们都知道Connection是线程不安全的，因此导致SqlSession对象也是线程不安全的。因此如果将SqlSession作为成员变量使用，存在风险。（应当使用SqlSessionTemplate，这部分后面再说）。</p>
<blockquote>
<p>注意：SqlSession是提供给应用层的一个访问数据库的接口，它并不是真正的SQL执行者，它内部封装了JDBC核心对象，如Statement，ResultSet等。</p>
</blockquote>
<h3 id="通过SqlSessionFactory获取SqlSession会话"><a href="#通过SqlSessionFactory获取SqlSession会话" class="headerlink" title="通过SqlSessionFactory获取SqlSession会话"></a>通过SqlSessionFactory获取SqlSession会话</h3><p>如果要获取一个SqlSession会话，就需要有会话工厂，即：SqlSessionFactory。它包含了所有的配置信息，而Factory又是通过Builder创建的，这部分后文代码分析中会说。</p>
<h3 id="通过Executor对象封装数据库操作，执行SQL操作"><a href="#通过Executor对象封装数据库操作，执行SQL操作" class="headerlink" title="通过Executor对象封装数据库操作，执行SQL操作"></a>通过Executor对象封装数据库操作，执行SQL操作</h3><p>SqlSession持有Executor对象，Executor在执行query、update、insert等操作时，会创建一系列的对象处理参数、处理结果集，核心的对象是StatementHandler，它本质上是对Statement的封装。</p>
<h2 id="三、走进源码，一探究竟"><a href="#三、走进源码，一探究竟" class="headerlink" title="三、走进源码，一探究竟"></a>三、走进源码，一探究竟</h2><h3 id="3-1-SqlSessionFactory的创建"><a href="#3-1-SqlSessionFactory的创建" class="headerlink" title="3.1 SqlSessionFactory的创建"></a>3.1 SqlSessionFactory的创建</h3><blockquote>
<p>首先是SqlSession的创建过程；SqlSession需要通过SqlSessionFactory创建，而SqlSessionFactory又是通过SqlSessionFactoryBuilder创建的。</p>
</blockquote>
<pre><code># org.apache.ibatis.session.SqlSessionFactoryBuilder#build
public SqlSessionFactory build(InputStream inputStream) {
  return build(inputStream, null, null);
}
</code></pre><p>事实上，inputStream就是配置文件的文件输入流，它传给了SqlSessionFactoryBuilder的build重载方法，我们看一下这个方法的实现。</p>
<pre><code>public SqlSessionFactory build(InputStream inputStream, String environment, Properties properties) {
  try {
    // 用于解析 mybatis-config.xml，同时创建了 Configuration 对象 &gt;&gt;
    XMLConfigBuilder parser = new XMLConfigBuilder(inputStream, environment, properties);
    // 解析XML，最终返回一个 DefaultSqlSessionFactory &gt;&gt;
    return build(parser.parse());
  } catch (Exception e) {
    throw ExceptionFactory.wrapException(&quot;Error building SqlSession.&quot;, e);
  } finally {
    ErrorContext.instance().reset();
    try {
      inputStream.close();
    } catch (IOException e) {
      // Intentionally ignore. Prefer previous error.
    }
  }
}
</code></pre><p>可以看到，SqlSessionFactoryBuilder底层是通过xml解析方式，对配置文件进行解析，并基于解析的结果构建了SqlSessionFactory的实例，这里返回的是默认的SqlSessionFactory—&gt;DefaultSqlSessionFactory。</p>
<pre><code>public SqlSessionFactory build(Configuration config) {
  return new DefaultSqlSessionFactory(config);
}
</code></pre><p><strong>注意：此处就已经通过配置文件解析出了Configuration，并通过DefaultSqlSessionFactory构造方法创建了DefaultSqlSessionFactory实例。后文要用！</strong></p>
<blockquote>
<p>xml解析过程，感兴趣的读者可以自行研究，简单的说无非就是对xml文件的dom节点进行读取和匹配，获取属性加载到内存，Mybatis自己基于javax的xml操作api封装了一个工具类，<strong>org.apache.ibatis.parsing.XPathParser</strong> 。</p>
</blockquote>
<h3 id="3-2-SqlSession的创建"><a href="#3-2-SqlSession的创建" class="headerlink" title="3.2 SqlSession的创建"></a>3.2 SqlSession的创建</h3><p>在使用的demo中，我们通过SqlSessionFactory获取到一个SqlSession实例。</p>
<pre><code>SqlSession session = sqlSessionFactory.openSession();
</code></pre><p>进入 openSession 方法一探究竟。</p>
<pre><code># org.apache.ibatis.session.defaults.DefaultSqlSessionFactory#openSession()
public SqlSession openSession() {
  return openSessionFromDataSource(configuration.getDefaultExecutorType(), null, false);
}
</code></pre><p>继续进入 openSessionFromDataSource 方法：</p>
<pre><code>private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) {
  Transaction tx = null;
  try {
    final Environment environment = configuration.getEnvironment();
    // 获取事务工厂
    final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment);
    // 创建事务
    tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit);
    // 根据事务工厂和默认的执行器类型，创建执行器 &gt;&gt;
    final Executor executor = configuration.newExecutor(tx, execType);
    return new DefaultSqlSession(configuration, executor, autoCommit);
  } catch (Exception e) {
    closeTransaction(tx); // may have fetched a connection so lets call close()
    throw ExceptionFactory.wrapException(&quot;Error opening session.  Cause: &quot; + e, e);
  } finally {
    ErrorContext.instance().reset();
  }
}
</code></pre><p>这里的逻辑比较核心，主要做了几件事：</p>
<ol>
<li>获取到事务工厂；</li>
<li>通过事务工厂创建了事务，如果是使用Spring框架，则由Spring框架开启事务；</li>
<li>根据事务工厂和默认的执行器类型，创建执行器</li>
</ol>
<p>最后通过DefaultSqlSession的构造方法，创建出DefaultSqlSession实例，它是SqlSession接口的默认实现。</p>
<p>到此，我们就持有了一个SqlSession对象，并且它还持有了一个Executor执行器实例。</p>
<h3 id="代理Mapper对象，执行SQL"><a href="#代理Mapper对象，执行SQL" class="headerlink" title="代理Mapper对象，执行SQL"></a>代理Mapper对象，执行SQL</h3><p>回到我们的demo代码中：</p>
<pre><code>@Test
public void testSelect() throws IOException {
    SqlSession session = sqlSessionFactory.openSession(); // ExecutorType.BATCH
    try {
        // 重点看这行代码
        BlogMapper mapper = session.getMapper(BlogMapper.class);
        Blog blog = mapper.selectBlogById(1);
        System.out.println(blog);
    } finally {
        session.close();
    }
}
</code></pre><p>我们已经拿到了SqlSession，接着通过 <strong>session.getMapper(BlogMapper.class)</strong>; 获取到了BlogMapper接口的实现类。</p>
<p>注意，我说的并不是获取到了BlogMapper，因为大家使用过Mybatis框架都知道BlogMapper是个接口，那么此处拿到的，必然是BlogMapper的实例。</p>
<p>接口的实例，嗯，有点意思了，我们明明只写了个接口，并没有实现这个接口啊？</p>
<p>是不是想到了什么？对，就是动态代理。</p>
<p>此处获取到的Mapper实例，就是Mybatis框架帮我们创建出的代理对象。</p>
<blockquote>
<p>进入 DefaultSqlSession#getMapper 方法</p>
</blockquote>
<pre><code>@Override
public &lt;T&gt; T getMapper(Class&lt;T&gt; type) {
  return configuration.getMapper(type, this);
}
</code></pre><p>ok，继续往下看：</p>
<pre><code>public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) {
  return mapperRegistry.getMapper(type, sqlSession);
}
</code></pre><p>这里，我们发现Mapper对象是通过 mapperRegistry 这个所谓的Mapper注册中心中获取到的，它的数据结构是一个HashMap:</p>
<pre><code># org.apache.ibatis.session.Configuration
protected final MapperRegistry mapperRegistry = new MapperRegistry(this);

# org.apache.ibatis.binding.MapperRegistry
public class MapperRegistry {
  private final Configuration config;
  private final Map&lt;Class&lt;?&gt;, MapperProxyFactory&lt;?&gt;&gt; knownMappers = new HashMap&lt;&gt;();
</code></pre><p>既然我们能够通过Mapper接口类型get到接口的代理类，那它是多会儿put到Map里的?</p>
<p>仔细想一下应当能够想到，我们此时已经是在sql的执行期了，在这之前必然是配置文件的解析期间执行的put操作。具体代码如下：</p>
<pre><code>/**
* org.apache.ibatis.builder.xml.XMLConfigBuilder#mapperElement
* Mapper解析
* @param parent
* @throws Exception
*/
private void mapperElement(XNode parent) throws Exception {
  if (parent != null) {
    for (XNode child : parent.getChildren()) {
      // 不同的定义方式的扫描，最终都是调用 addMapper()方法
      // （添加到 MapperRegistry）。这个方法和 getMapper() 对应

      // package    包

      if (&quot;package&quot;.equals(child.getName())) {
        String mapperPackage = child.getStringAttribute(&quot;name&quot;);
        configuration.addMappers(mapperPackage);

      } else {
        String resource = child.getStringAttribute(&quot;resource&quot;);
        String url = child.getStringAttribute(&quot;url&quot;);
        String mapperClass = child.getStringAttribute(&quot;class&quot;);

        if (resource != null &amp;&amp; url == null &amp;&amp; mapperClass == null) {

          // resource    相对路径

          ErrorContext.instance().resource(resource);
          InputStream inputStream = Resources.getResourceAsStream(resource);
          XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, resource, configuration.getSqlFragments());
          // 解析 Mapper.xml，总体上做了两件事情 &gt;&gt;
          mapperParser.parse();

        } else if (resource == null &amp;&amp; url != null &amp;&amp; mapperClass == null) {

          // url    绝对路径

          ErrorContext.instance().resource(url);
          InputStream inputStream = Resources.getUrlAsStream(url);
          XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, url, configuration.getSqlFragments());
          mapperParser.parse();

        } else if (resource == null &amp;&amp; url == null &amp;&amp; mapperClass != null) {
          // class     单个接口
          Class&lt;?&gt; mapperInterface = Resources.classForName(mapperClass);
          configuration.addMapper(mapperInterface);
        } else {
          throw new BuilderException(&quot;A mapper element may only specify a url, resource or class, but not more than one.&quot;);
        }
      }
    }
  }
}
</code></pre><p>通过这段代码我们可以看到，无论是通过指定扫描包路径，还是resources相对路径，或者url绝对路径，或者单个Mapper添加的方式，Mybatis本质上都是通过 <strong>addMapper()方法添加到 MapperRegistry</strong>。</p>
<blockquote>
<p>继续回到Mapper代理对象创建过程中来。</p>
</blockquote>
<pre><code># org.apache.ibatis.session.Configuration#getMapper
public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) {
  return mapperRegistry.getMapper(type, sqlSession);
}
</code></pre><p>继续看mapperRegistry.getMapper方法逻辑。</p>
<pre><code>public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) {
  final MapperProxyFactory&lt;T&gt; mapperProxyFactory = (MapperProxyFactory&lt;T&gt;) knownMappers.get(type);
  if (mapperProxyFactory == null) {
    throw new BindingException(&quot;Type &quot; + type + &quot; is not known to the MapperRegistry.&quot;);
  }
  try {
    return mapperProxyFactory.newInstance(sqlSession);
  } catch (Exception e) {
    throw new BindingException(&quot;Error getting mapper instance. Cause: &quot; + e, e);
  }
}
</code></pre><p>我们发现，通过接口类型从HashMap中取到了一个 <strong>MapperProxyFactory</strong> Mapper代理工厂的实例。</p>
<blockquote>
<p>MapperProxyFactory实际上是对Mapper接口的包装，我们只需要看源码就知道了。</p>
</blockquote>
<pre><code>public class MapperProxyFactory&lt;T&gt; {

  private final Class&lt;T&gt; mapperInterface;
  private final Map&lt;Method, MapperMethodInvoker&gt; methodCache = new ConcurrentHashMap&lt;&gt;();
</code></pre><blockquote>
<p>构造方法接受一个Mapper的class类型，对其进行封装。</p>
</blockquote>
<pre><code>public MapperProxyFactory(Class&lt;T&gt; mapperInterface) {
  this.mapperInterface = mapperInterface;
}
</code></pre><p>获取到MapperProxyFactory实例之后，通过 <strong>mapperProxyFactory.newInstance(sqlSession)</strong> 就创建出了Mapper的代理对象。</p>
<pre><code>public T newInstance(SqlSession sqlSession) {
  final MapperProxy&lt;T&gt; mapperProxy = new MapperProxy&lt;&gt;(sqlSession, mapperInterface, methodCache);
  return newInstance(mapperProxy);
}
</code></pre><p>这里通过SqlSession、Mapper接口、方法缓存（<strong>简单的说就是Mapper的那一堆方法，每次反射创建太耗费性能了，就缓存到一个Map里</strong>）创建出MapperProxy 对象，进一步调用的如下方法：</p>
<pre><code>@SuppressWarnings(&quot;unchecked&quot;)
protected T newInstance(MapperProxy&lt;T&gt; mapperProxy) {
  // 1：类加载器:2：被代理类实现的接口、3：实现了 InvocationHandler 的触发管理类
  return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] { mapperInterface }, mapperProxy);
}
</code></pre><p>这里把创建代理对象的操作委托给了MapperProxy，<strong>我们发现，它的核心就是创建代理Mapper的代理对象 （h对象）。</strong></p>
<h3 id="MapperProxy具体是如何创建的Mapper代理？"><a href="#MapperProxy具体是如何创建的Mapper代理？" class="headerlink" title="MapperProxy具体是如何创建的Mapper代理？"></a>MapperProxy具体是如何创建的Mapper代理？</h3><p>我们都知道，动态代理在JDK中是通过实现InvocationHandler接口实现的，那么大胆猜想MapperProxy必然实现了InvocationHandler接口。</p>
<pre><code>public class MapperProxy&lt;T&gt; implements InvocationHandler, Serializable {
</code></pre><p>果然如此。</p>
<p>我们来看它的invoke方法实现：</p>
<pre><code>@Override
public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
  try {
    // toString hashCode equals getClass等方法，无需走到执行SQL的流程
    if (Object.class.equals(method.getDeclaringClass())) {
      return method.invoke(this, args);
    } else {
      // 提升获取 mapperMethod 的效率，到 MapperMethodInvoker（内部接口） 的 invoke
      // 普通方法会走到 PlainMethodInvoker（内部类） 的 invoke
      return cachedInvoker(method).invoke(proxy, method, args, sqlSession);
    }
  } catch (Throwable t) {
    throw ExceptionUtil.unwrapThrowable(t);
  }
}
</code></pre><p>可以看到，如果是普通方法，直接执行，不需要特殊处理；</p>
<p>否则就获取匹配的缓存Mapper方法，执行数据库操作。</p>
<blockquote>
<p>重点看一下  cachedInvoker(method).invoke(proxy, method, args, sqlSession); 逻辑。</p>
</blockquote>
<pre><code>private MapperMethodInvoker cachedInvoker(Method method) throws Throwable {
  try {

    // Java8 中 Map 的方法，根据 key 获取值，如果值是 null，则把后面Object 的值赋给 key
    // 如果获取不到，就创建
    // 获取的是 MapperMethodInvoker（接口） 对象，只有一个invoke方法

    return methodCache.computeIfAbsent(method, m -&gt; {
      if (m.isDefault()) {

        // 接口的默认方法(Java8)，只要实现接口都会继承接口的默认方法，例如 List.sort()

        try {
          if (privateLookupInMethod == null) {
            return new DefaultMethodInvoker(getMethodHandleJava8(method));
          } else {
            return new DefaultMethodInvoker(getMethodHandleJava9(method));
          }
        } catch (IllegalAccessException | InstantiationException | InvocationTargetException
            | NoSuchMethodException e) {
          throw new RuntimeException(e);
        }

      } else {

        // 创建了一个 MapperMethod
        return new PlainMethodInvoker(new MapperMethod(mapperInterface, method, sqlSession.getConfiguration()));

      }
    });
  } catch (RuntimeException re) {
    Throwable cause = re.getCause();
    throw cause == null ? re : cause;
  }
}
</code></pre><p>这里针对Java8接口的默认方法做了些处理，这个地方不用特殊关注，我们重点看else逻辑：</p>
<pre><code>// 创建了一个 MapperMethod
return new PlainMethodInvoker(
    new MapperMethod(
      mapperInterface, 
      method,
      sqlSession.getConfiguration()));
</code></pre><h2 id="Mybatis执行sql语句的真正开端："><a href="#Mybatis执行sql语句的真正开端：" class="headerlink" title="Mybatis执行sql语句的真正开端："></a>Mybatis执行sql语句的真正开端：</h2><blockquote>
<p>上文中，我们费尽努力，获取到了 <strong>PlainMethodInvoker</strong> 实例，其实到这里，才是Mybatis执行SQL真正的起点。</p>
</blockquote>
<p>不要慌，继续跟上我的脚步，我们一鼓作气往后看。</p>
<p>上文中，我们知道Mapper对象实际上是Mapper接口的代理对象，而且是JDK的动态代理。</p>
<p>当执行Mapper的各种数据库操作方法时，实际上是调用的代理对象的方法，也就是invoke方法。</p>
<p>对于Mapper方法而言，其实就是调用的PlainMethodInvoker的invoke方法。</p>
<p>忘了？那么我们再复习一下这部分的代码：</p>
<pre><code>// org.apache.ibatis.binding.MapperProxy#invoke
// 普通方法会走到 PlainMethodInvoker（内部类） 的 invoke
return cachedInvoker(method).invoke(proxy, method, args, sqlSession);
</code></pre><p>接着来看PlainMethodInvoker的invoke方法：</p>
<pre><code>@Override
public Object invoke(
                    Object proxy, 
                    Method method, 
                    Object[] args, 
                    SqlSession sqlSession) throws Throwable {
  // SQL执行的真正起点
  return mapperMethod.execute(sqlSession, args);
}
</code></pre><p>实际上这里的mapperMethod就是我们Mapper接口或者说XML文件中定义的方法名了。</p>
<blockquote>
<p>接着就是重头戏，MapperMethod#execute 方法，完整代码我贴这儿了。</p>
</blockquote>
<pre><code>// org.apache.ibatis.binding.MapperMethod#execute
public Object execute(SqlSession sqlSession, Object[] args) {
  Object result;
  switch (command.getType()) {
    case INSERT: {
      Object param = method.convertArgsToSqlCommandParam(args);
      result = rowCountResult(sqlSession.insert(command.getName(), param));
      break;
    }
    case UPDATE: {
      Object param = method.convertArgsToSqlCommandParam(args);
      result = rowCountResult(sqlSession.update(command.getName(), param));
      break;
    }
    case DELETE: {
      Object param = method.convertArgsToSqlCommandParam(args);
      result = rowCountResult(sqlSession.delete(command.getName(), param));
      break;
    }
    case SELECT:
      if (method.returnsVoid() &amp;&amp; method.hasResultHandler()) {
        executeWithResultHandler(sqlSession, args);
        result = null;
      } else if (method.returnsMany()) {
        result = executeForMany(sqlSession, args);
      } else if (method.returnsMap()) {
        result = executeForMap(sqlSession, args);
      } else if (method.returnsCursor()) {
        result = executeForCursor(sqlSession, args);
      } else {
        Object param = method.convertArgsToSqlCommandParam(args);
        // 普通 select 语句的执行入口 &gt;&gt;
        result = sqlSession.selectOne(command.getName(), param);
        if (method.returnsOptional()
            &amp;&amp; (result == null || !method.getReturnType().equals(result.getClass()))) {
          result = Optional.ofNullable(result);
        }
      }
      break;
    case FLUSH:
      result = sqlSession.flushStatements();
      break;
    default:
      throw new BindingException(&quot;Unknown execution method for: &quot; + command.getName());
  }
  if (result == null &amp;&amp; method.getReturnType().isPrimitive() &amp;&amp; !method.returnsVoid()) {
    throw new BindingException(&quot;Mapper method &apos;&quot; + command.getName()
        + &quot; attempted to return null from a method with a primitive return type (&quot; + method.getReturnType() + &quot;).&quot;);
  }
  return result;
}
</code></pre><p>重点看那个switch case，不用注释一眼看过去基本上也能看个八九不离十，这里就是通过sql的类型去执行不同的jdbc操作。</p>
<blockquote>
<p>可以看到，熟悉的操作他来了，通过SqlSession完成一系列的数据库操作。</p>
</blockquote>
<p>我们的demo是一个查询操作，那么我们就挑select来看看。</p>
<p>普通select语句的入口如下：</p>
<pre><code>result = sqlSession.selectOne(command.getName(), param);
</code></pre><p>继续深入：</p>
<pre><code>// DefaultSqlSession#selectOne(java.lang.String, java.lang.Object)
@Override
public &lt;T&gt; T selectOne(String statement, Object parameter) {
  // 来到了 DefaultSqlSession
  // Popular vote was to return null on 0 results and throw exception on too many.
  List&lt;T&gt; list = this.selectList(statement, parameter);
  if (list.size() == 1) {
    return list.get(0);
  } else if (list.size() &gt; 1) {
    throw new TooManyResultsException(&quot;Expected one result (or null) to be returned by selectOne(), but found: &quot; + list.size());
  } else {
    return null;
  }
}
</code></pre><p>可以看到是通过selectList来完成查询多个和单个。</p>
<pre><code>@Override
public &lt;E&gt; List&lt;E&gt; selectList(String statement, Object parameter) {
  // 为了提供多种重载（简化方法使用），和默认值
  // 让参数少的调用参数多的方法，只实现一次
  return this.selectList(statement, parameter, RowBounds.DEFAULT);
}
</code></pre><p>继续看多参重载方法：</p>
<pre><code>@Override
public &lt;E&gt; List&lt;E&gt; selectList(String statement, Object parameter, RowBounds rowBounds) {
  try {
    MappedStatement ms = configuration.getMappedStatement(statement);
    // 如果 cacheEnabled = true（默认），Executor会被 CachingExecutor装饰
    return executor.query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER);
  } catch (Exception e) {
    throw ExceptionFactory.wrapException(&quot;Error querying database.  Cause: &quot; + e, e);
  } finally {
    ErrorContext.instance().reset();
  }
}
</code></pre><p>核心代码就是executor.query，我们进去看看：</p>
<pre><code>@Override
public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException {
  BoundSql boundSql = ms.getBoundSql(parameter);
  // 一级缓存和二级缓存的CacheKey是同一个
  CacheKey key = createCacheKey(ms, parameter, rowBounds, boundSql);
  return query(ms, parameter, rowBounds, resultHandler, key, boundSql);
}
</code></pre><p>这里涉及到一级缓存和二级缓存，不是重点，我们就想看看最终是怎么执行的jdbc操作，那么就只需要继续看query重载。</p>
<pre><code>// org.apache.ibatis.executor.BaseExecutor#query
@Override
public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException {

  // 异常体系之 ErrorContext
  ErrorContext.instance().resource(ms.getResource()).activity(&quot;executing a query&quot;).object(ms.getId());

  if (closed) {
    throw new ExecutorException(&quot;Executor was closed.&quot;);
  }

  if (queryStack == 0 &amp;&amp; ms.isFlushCacheRequired()) {
    // flushCache=&quot;true&quot;时，即使是查询，也清空一级缓存
    clearLocalCache();
  }

  List&lt;E&gt; list;
  try {

    // 防止递归查询重复处理缓存
    queryStack++;
    // 查询一级缓存
    // ResultHandler 和 ResultSetHandler的区别
    list = resultHandler == null ? (List&lt;E&gt;) localCache.getObject(key) : null;

    if (list != null) {
      handleLocallyCachedOutputParameters(ms, key, parameter, boundSql);
    } else {

      // 真正的查询流程
      list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql);

      ...省略N行代码...
</code></pre><p>涉及到缓存的，通通与我无关，只看真正的查询流程 <strong>queryFromDatabase</strong>。</p>
<pre><code>private &lt;E&gt; List&lt;E&gt; queryFromDatabase(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException {
  List&lt;E&gt; list;
  // 先占位
  localCache.putObject(key, EXECUTION_PLACEHOLDER);
  try {
    // 三种 Executor 的区别，看doUpdate
    // 默认Simple
    list = doQuery(ms, parameter, rowBounds, resultHandler, boundSql);
  } finally {
    // 移除占位符
    localCache.removeObject(key);
  }
  // 写入一级缓存
  localCache.putObject(key, list);
  if (ms.getStatementType() == StatementType.CALLABLE) {
    localOutputParameterCache.putObject(key, parameter);
  }
  return list;
}
</code></pre><h3 id="看到jdbc了，胜利的曙光。"><a href="#看到jdbc了，胜利的曙光。" class="headerlink" title="看到jdbc了，胜利的曙光。"></a>看到jdbc了，胜利的曙光。</h3><p>舒服，继续看doQuery方法，看到resultHandler了么，结果处理器，感觉离结果更近了。</p>
<pre><code>// org.apache.ibatis.executor.SimpleExecutor#doQuery
@Override
public &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException {
  Statement stmt = null;
  try {
    Configuration configuration = ms.getConfiguration();
    // 注意，已经来到SQL处理的关键对象 StatementHandler &gt;&gt;
    StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql);
    // 获取一个 Statement对象
    stmt = prepareStatement(handler, ms.getStatementLog());
    // 执行查询
    return handler.query(stmt, resultHandler);
  } finally {
    // 用完就关闭
    closeStatement(stmt);
  }
}
</code></pre><p>查询用的Exucutor就是默认的SimpleExecutor，看到了熟悉的prepareStatement获取流程，基本上就到底层jdbc了。那么我们就看看 <strong>prepareStatement(handler, ms.getStatementLog());</strong></p>
<pre><code>private Statement prepareStatement(StatementHandler handler, Log statementLog) throws SQLException {
  Statement stmt;
  Connection connection = getConnection(statementLog);
  // 获取 Statement 对象
  stmt = handler.prepare(connection, transaction.getTimeout());
  // 为 Statement 设置参数
  handler.parameterize(stmt);
  return stmt;
}
</code></pre><p>看到这里，就到jdbc层面了，我们看到了熟悉的Connection，获取到connection之后再获取Statement。</p>
<p>这里的Statement就是java.sql的statement接口。</p>
<blockquote>
<p>org.apache.ibatis.executor.statement.SimpleStatementHandler#query</p>
</blockquote>
<pre><code>@Override
public &lt;E&gt; List&lt;E&gt; query(Statement statement, ResultHandler resultHandler) throws SQLException {
  String sql = boundSql.getSql();
  statement.execute(sql);
  return resultSetHandler.handleResultSets(statement);
}
</code></pre><p>已经获取到了sql，通过Statement去执行sql，在通过resultSetHandler处理结果集。</p>
<h4 id="通过Statement去执行sql"><a href="#通过Statement去执行sql" class="headerlink" title="通过Statement去执行sql"></a>通过Statement去执行sql</h4><pre><code>statement.execute(sql);
</code></pre><p>这里就已经是jdbc层面的操作了，通过与数据库建立的connection提交并执行sql。</p>
<h4 id="通过resultSetHandler处理结果集"><a href="#通过resultSetHandler处理结果集" class="headerlink" title="通过resultSetHandler处理结果集"></a>通过resultSetHandler处理结果集</h4><blockquote>
<p>都到最后了，我们也不慌了，那么就看看org.apache.ibatis.executor.resultset.DefaultResultSetHandler#handleResultSets是如何处理结果集的。</p>
</blockquote>
<pre><code>@Override
public List&lt;Object&gt; handleResultSets(Statement stmt) throws SQLException {
  ErrorContext.instance().activity(&quot;handling results&quot;).object(mappedStatement.getId());

  final List&lt;Object&gt; multipleResults = new ArrayList&lt;&gt;();

  int resultSetCount = 0;
  ResultSetWrapper rsw = getFirstResultSet(stmt);

  List&lt;ResultMap&gt; resultMaps = mappedStatement.getResultMaps();
  int resultMapCount = resultMaps.size();
  validateResultMapsCount(rsw, resultMapCount);
  while (rsw != null &amp;&amp; resultMapCount &gt; resultSetCount) {
    ResultMap resultMap = resultMaps.get(resultSetCount);
    handleResultSet(rsw, resultMap, multipleResults, null);
    rsw = getNextResultSet(stmt);
    cleanUpAfterHandlingResultSet();
    resultSetCount++;
  }

  String[] resultSets = mappedStatement.getResultSets();
  if (resultSets != null) {
    while (rsw != null &amp;&amp; resultSetCount &lt; resultSets.length) {
      ResultMapping parentMapping = nextResultMaps.get(resultSets[resultSetCount]);
      if (parentMapping != null) {
        String nestedResultMapId = parentMapping.getNestedResultMapId();
        ResultMap resultMap = configuration.getResultMap(nestedResultMapId);
        // 在此处处理结果集
        handleResultSet(rsw, resultMap, null, parentMapping);
      }
      rsw = getNextResultSet(stmt);
      cleanUpAfterHandlingResultSet();
      resultSetCount++;
    }
  }

  return collapseSingleResultList(multipleResults);
}
</code></pre><p>这么一坨代码，只需要重点看</p>
<pre><code>handleResultSet(rsw, resultMap, null, parentMapping);

private void handleResultSet(ResultSetWrapper rsw, ResultMap resultMap, List&lt;Object&gt; multipleResults, ResultMapping parentMapping) throws SQLException {
  try {
    if (parentMapping != null) {
      handleRowValues(rsw, resultMap, null, RowBounds.DEFAULT, parentMapping);
    } else {
      if (resultHandler == null) {
        DefaultResultHandler defaultResultHandler = new DefaultResultHandler(objectFactory);
        handleRowValues(rsw, resultMap, defaultResultHandler, rowBounds, null);
        multipleResults.add(defaultResultHandler.getResultList());
      } else {
        handleRowValues(rsw, resultMap, resultHandler, rowBounds, null);
      }
    }
  } finally {
    // issue #228 (close resultsets)
    closeResultSet(rsw.getResultSet());
  }
}
</code></pre><p>看看handleRowValues的逻辑 (有点心累)</p>
<p>最终，来到了这个地方：</p>
<pre><code>// org.apache.ibatis.executor.resultset.DefaultResultSetHandler
//         #handleRowValuesForSimpleResultMap
private void handleRowValuesForSimpleResultMap(ResultSetWrapper rsw, ResultMap resultMap, ResultHandler&lt;?&gt; resultHandler, RowBounds rowBounds, ResultMapping parentMapping)
    throws SQLException {
  DefaultResultContext&lt;Object&gt; resultContext = new DefaultResultContext&lt;&gt;();

  // 看到了吧，没什么好说的，就是jdbc的结果集处理
  ResultSet resultSet = rsw.getResultSet();

  skipRows(resultSet, rowBounds);
  while (shouldProcessMoreRows(resultContext, rowBounds) &amp;&amp; !resultSet.isClosed() &amp;&amp; resultSet.next()) {
    ResultMap discriminatedResultMap = resolveDiscriminatedResultMap(resultSet, resultMap, null);
    Object rowValue = getRowValue(rsw, discriminatedResultMap, null);
    storeObject(resultHandler, resultContext, rowValue, parentMapping, resultSet);
  }
}
</code></pre><p>看到了熟悉的ResultSet获取结果集的操作，Mybatis执行sql的流程基本就结束了。</p>
<p>底层还是熟悉的JDBC操作。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>其实写了这么多，也没啥想总结的，我们通过一个查询操作，完整的把Mybatis从解析文件到执行sql，再到结果集处理都从源码级别剖析了一遍。</p>
<p>那么我们回答一下开头的问题：</p>
<h3 id="我只是写了个Mapper接口，再配合xml或者注解，把SQL一写，就可以执行数据库操作，这是为何？"><a href="#我只是写了个Mapper接口，再配合xml或者注解，把SQL一写，就可以执行数据库操作，这是为何？" class="headerlink" title="我只是写了个Mapper接口，再配合xml或者注解，把SQL一写，就可以执行数据库操作，这是为何？"></a>我只是写了个Mapper接口，再配合xml或者注解，把SQL一写，就可以执行数据库操作，这是为何？</h3><p>其实我们获取到的Mapper对象，已经是Mybatis帮我们生成的代理对象了，这个代理对象拥有与jdbc交互的一切必要条件。</p>
<h3 id="都说Mybatis是对JDBC的封装，可是我却看不到JDBC相关的接口和对象，它们到哪里去了？"><a href="#都说Mybatis是对JDBC的封装，可是我却看不到JDBC相关的接口和对象，它们到哪里去了？" class="headerlink" title="都说Mybatis是对JDBC的封装，可是我却看不到JDBC相关的接口和对象，它们到哪里去了？"></a>都说Mybatis是对JDBC的封装，可是我却看不到JDBC相关的接口和对象，它们到哪里去了？</h3><p>稍微往上翻翻，我们刚讲了，实际上最底层就是封装的jdbc的接口。</p>
<p>我们看不到但是用到了，并且用起来还很爽，这就是封装的魅力啊。</p>
<h3 id="为什么在Spring中使用Mybatis，不用加-Repository-Component之类的注解，就可以随用随注入（如：-Autowired）"><a href="#为什么在Spring中使用Mybatis，不用加-Repository-Component之类的注解，就可以随用随注入（如：-Autowired）" class="headerlink" title="为什么在Spring中使用Mybatis，不用加@Repository/@Component之类的注解，就可以随用随注入（如：@Autowired）?"></a>为什么在Spring中使用Mybatis，不用加@Repository/@Component之类的注解，就可以随用随注入（如：@Autowired）?</h3><p>这个问题，就放到之后的文章讲解吧，那么就敬请期待下一篇：Mybatis与Spring的爱情故事（从源码层面解析，Mybatis是如何利用Spring扩展点，实现与Spring整合的。）</p>
<p>最后，贴张图，概括一下这个过程。图是借来的，仅供学习讨论，侵删。</p>
<blockquote>
<p>创建会话工厂SqlSessionFactory</p>
</blockquote>
<p><img src="/2022/02/20/源码级探究Mybatis原理-以查询为例/flow/1.png" alt="flow/1.png"></p>
<blockquote>
<p>创建会话SqlSession</p>
</blockquote>
<p><img src="/2022/02/20/源码级探究Mybatis原理-以查询为例/flow/2.png" alt="flow/2.png"></p>
<blockquote>
<p>创建代理对象</p>
</blockquote>
<p><img src="/2022/02/20/源码级探究Mybatis原理-以查询为例/flow/3.png" alt="flow/3.png"></p>
<blockquote>
<p>调用代理对象，执行SQL流程</p>
</blockquote>
<p><img src="/2022/02/20/源码级探究Mybatis原理-以查询为例/flow/4.png" alt="flow/4.png"></p>
<p>那么，不见不散。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作为一名Java后端开发者，尤其是国内开发者，从刚参加工作开始就与Mybatis打交道了。&lt;/p&gt;
&lt;p&gt;用了这么久的Mybatis难免会心生疑问：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我只是写了个Mapper接口，再配合xml或者注解，把SQL一写，就可以执行数据库操作，这是为何？&lt;/li&gt;
&lt;li&gt;都说Mybatis是对JDBC的封装，可是我却看不到JDBC相关的接口和对象，它们到哪里去了？&lt;/li&gt;
&lt;li&gt;为什么在Spring中使用Mybatis，不用加@Repository/@Component之类的注解，就可以随用随注入（如：@Autowired）?&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;硬核万字长文，点个再看，转发，多谢啦~&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Java" scheme="http://wuwenliang.net/categories/Java/"/>
    
    
      <category term="Java" scheme="http://wuwenliang.net/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Spring扩展点1-研磨ImportBeanDefinitionRegistrar</title>
    <link href="http://wuwenliang.net/2022/01/29/Spring%E6%89%A9%E5%B1%95%E7%82%B91-%E7%A0%94%E7%A3%A8ImportBeanDefinitionRegistrar/"/>
    <id>http://wuwenliang.net/2022/01/29/Spring扩展点1-研磨ImportBeanDefinitionRegistrar/</id>
    <published>2022-01-29T03:05:41.000Z</published>
    <updated>2022-01-29T04:24:33.367Z</updated>
    
    <content type="html"><![CDATA[<p>本文开始，我们将系统地对Spring框架的扩展点进行学习，通过案例分析与图例结合，step by step地对Spring看似神秘的扩展点的机理与应用进行研究。</p>
<p>首先通过一张图对Spring框架各种扩展点的调用顺序（Bean生命周期）进行先入为主的概览。</p>
<p><img src="/2022/01/29/Spring扩展点1-研磨ImportBeanDefinitionRegistrar/0.png" alt="0.png"></p>
<a id="more"></a>
<p>可以看到图片的一开始便是Spring对Bean定义（BeanDefinition）进行解析和注册，Bean的注册主要就是通过ImportBeanDefinitionRegistrar实现的。</p>
<p>Spring框架主要就是通过ImportBeanDefinitionRegistrar实现对bean的动态注册。源码如下：</p>
<pre><code>public interface ImportBeanDefinitionRegistrar {
    // 通过解析给定的注解元信息，向Spring容器中注册Bean定义
    default void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry,
            BeanNameGenerator importBeanNameGenerator) {

        registerBeanDefinitions(importingClassMetadata, registry);
    }
    default void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) {
    }
}
</code></pre><p>实现ImportBeanDefinitionRegistrar接口的类的都会被ConfigurationClassPostProcessor处理，ConfigurationClassPostProcessor实现了BeanFactoryPostProcessor接口，所以ImportBeanDefinitionRegistrar中动态注册的bean是优先于依赖其的bean初始化的，同时它也可以被aop、validator等机制处理。</p>
<h2 id="编码实现手动Bean注入"><a href="#编码实现手动Bean注入" class="headerlink" title="编码实现手动Bean注入"></a>编码实现手动Bean注入</h2><blockquote>
<p>日常的业务开发中，我们很少会通过ImportBeanDefinitionRegistrar来对bean进行注入。</p>
<p>而是通过xml文件声明或者注解如：@Component、@Service、@Bean等方式对bean进行注入和声明。</p>
<p>那么什么场景下才需要通过ImportBeanDefinitionRegistrar注册并注入bean呢？</p>
</blockquote>
<p>在中间件开发场景下，就会用到手动bean注入。原因在于中间件/框架的开发者并不知道调用方/框架使用者是通过什么方式对bean进行注入的。</p>
<p>当然我们也可以让使用者们显式的对框架中的bean进行定义，但是这样就显著的增加了工作量和出错率，因此对于框架开发而言，常常通过ImportBeanDefinitionRegistrar实现bean的隐式注入和声明，减少调用方整合框架的复杂度。</p>
<blockquote>
<p>我们通过一个模拟场景来介绍一下如何通过编码实现bean的手动隐式注入。、</p>
</blockquote>
<h3 id="1、定义ImportBeanDefinitionRegistrar实现类"><a href="#1、定义ImportBeanDefinitionRegistrar实现类" class="headerlink" title="1、定义ImportBeanDefinitionRegistrar实现类"></a>1、定义ImportBeanDefinitionRegistrar实现类</h3><p>首先定义一个实现ImportBeanDefinitionRegistrar接口的类，并编写bean注册逻辑。</p>
<pre><code>public class MyBeanDefinationRegistry implements ImportBeanDefinitionRegistrar, ResourceLoaderAware, BeanFactoryAware {

    private BeanFactory beanFactory;
    private ResourceLoader resourceLoader;

    @Override
    public void setBeanFactory(BeanFactory beanFactory) throws BeansException {
        this.beanFactory = beanFactory;
    }

    @Override
    public void setResourceLoader(ResourceLoader resourceLoader) {
        this.resourceLoader = resourceLoader;
    }

    @Override
    public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) {

        MyClassPathBeanDefinitionScanner scanner = new MyClassPathBeanDefinitionScanner(registry, false);
        scanner.setResourceLoader(resourceLoader);
        scanner.registerFilters();
        scanner.doScan(&quot;com.spring.framework&quot;);

        GenericBeanDefinition genericBeanDefinition = new GenericBeanDefinition();
        genericBeanDefinition.setBeanClass(TestBean.class);
        genericBeanDefinition.setScope(BeanDefinition.SCOPE_SINGLETON);
        registry.registerBeanDefinition(&quot;testBean&quot;, genericBeanDefinition);
    }
}
</code></pre><p>重点关注 <strong>BeanDefinitionRegistry</strong> 方法，这里提供了两种bean扫描方式。</p>
<h4 id="方式1：基于包路径的扫描"><a href="#方式1：基于包路径的扫描" class="headerlink" title="方式1：基于包路径的扫描"></a>方式1：基于包路径的扫描</h4><pre><code>MyClassPathBeanDefinitionScanner scanner = 
    new MyClassPathBeanDefinitionScanner(registry, false);
scanner.setResourceLoader(resourceLoader);
scanner.registerFilters();
scanner.doScan(&quot;com.spring.framework&quot;);
</code></pre><ol>
<li>自定义一个ClassPathBeanDefinitionScanner实例，并将bean定义注册器BeanDefinitionRegistry引用传递进去，这是一种委托机制；</li>
<li>设置ResourceLoader，ResourceLoader的引用通过ResourceLoaderAware获得，并指向当前类的成员变量；</li>
<li>调用registerFilters方法（该方法为自定义方法，本质是调用了addIncludeFilter），让Spring去扫描带有特定标志的类进行管理与加载；（具体的代码稍后进行分析）；</li>
<li>调用doScan，传递需要扫描的包路径，这个路径就是框架开发者自定义的包路径，该路径下存放的就是框架本身的bean，<strong>这个路径是完全由框架的开发者决定的，而且我们一般可以认为，该路径一旦定义就不会更改。并且该路径也不适合暴露给框架的调用者</strong>。</li>
</ol>
<h4 id="方式2：直接注册BeanDefinition"><a href="#方式2：直接注册BeanDefinition" class="headerlink" title="方式2：直接注册BeanDefinition"></a>方式2：直接注册BeanDefinition</h4><pre><code>GenericBeanDefinition genericBeanDefinition = new GenericBeanDefinition();
genericBeanDefinition.setBeanClass(TestBean.class);
genericBeanDefinition.setScope(BeanDefinition.SCOPE_SINGLETON);
registry.registerBeanDefinition(&quot;testBean&quot;, genericBeanDefinition);
</code></pre><p>方式2比较简单，但是相对的也比方式1繁琐。</p>
<blockquote>
<p>TestBean 是模拟的一个框架的内部bean组件，实际开发中可以根据需要填充必要的属性和方法，这里只是作为演示。</p>
</blockquote>
<pre><code>public class TestBean {
}
</code></pre><p>通过声明GenericBeanDefinition，并未其添加需要注册的Bean的class，scope（单例or多例），beanName等属性，具体的属性可以看下图：</p>
<p><img src="/2022/01/29/Spring扩展点1-研磨ImportBeanDefinitionRegistrar/1,png" alt="1.png"></p>
<p>最后通过 <strong>registry.registerBeanDefinition</strong> 将设置好属性的GenericBeanDefinition注册，并设置beanName；</p>
<h4 id="对比方式1方式2"><a href="#对比方式1方式2" class="headerlink" title="对比方式1方式2"></a>对比方式1方式2</h4><p>通过代码我们可以直观的看到，方式1比方式2更加方便，可以实现批量bean的扫描与注入；</p>
<p>而方式2则需要逐个bean进行注入，但是相对的，方式2也更加灵活，能够实现 <strong>细粒度</strong> 的beanDefinition声明和定义。</p>
<h3 id="2、定义ClassPathBeanDefinitionScanner实现类"><a href="#2、定义ClassPathBeanDefinitionScanner实现类" class="headerlink" title="2、定义ClassPathBeanDefinitionScanner实现类"></a>2、定义ClassPathBeanDefinitionScanner实现类</h3><p>通过定义ClassPathBeanDefinitionScanner的实现类，告诉Spring需要对哪些类进行管理（addIncludeFilter）以及不需要关注哪些类（addExcludeFilter）。</p>
<pre><code>public class MyClassPathBeanDefinitionScanner extends ClassPathBeanDefinitionScanner {

    public MyClassPathBeanDefinitionScanner(BeanDefinitionRegistry registry, boolean useDefaultFilters) {
        super(registry, useDefaultFilters);
    }

    /**
    * 比较重要的一个点就是registerFilters()这个方法，
    * 在里面我们可以定义让Spring去扫描带有特定标志的类选择进行管理或者是选择不管理；
    * 通过addIncludeFilter()方法和通过addExcludeFilter()方法；
    */
    protected void registerFilters() {
        /**
        *  TODO addIncludeFilter  满足任意includeFilters会被加载
        */
        addIncludeFilter(new AnnotationTypeFilter(SnoWalkerAutoInject.class));
    }

    @Override
    protected Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) {
        return super.doScan(basePackages);
    }
}
</code></pre><p>可以看到，扫描器ClassPathBeanDefinitionScanner扫描类路径上的需要被管理的类，通过BeanFactory创建Bean给ApplicationComtext(Spring容器)管理；</p>
<h4 id="registerFilters分析"><a href="#registerFilters分析" class="headerlink" title="registerFilters分析"></a>registerFilters分析</h4><p>registerFilters是自定义的方法，核心的逻辑就是通过addIncludeFilter添加了一个包扫描的规则：</p>
<p>这里是通过注解类型的Filter通知Spring容器对添加了SnoWalkerAutoInject自定义注解的bean进行管理。</p>
<p>我们可以看到，自定义的MyClassPathBeanDefinitionScanner重写了父类的doScan方法，本质上调用了父类的doScan，以实现对指定路径下的bean进行扫描。</p>
<p>最终实际上是在ApplicationContext中调用了doScan，实现了对bean定义的扫描及实例化，我们可以看一下源码实现：</p>
<pre><code>/**
 * Create a new AnnotationConfigApplicationContext, scanning for components
 * in the given packages, registering bean definitions for those components,
 * and automatically refreshing the context.
 * @param basePackages the packages to scan for component classes
 */
public AnnotationConfigApplicationContext(String... basePackages) {
    this();
    scan(basePackages);
    refresh();
}
</code></pre><p>AnnotationConfigApplicationContext构造方法中，对package进行了扫描，并调用refresh方法对bean进行初始化和实例化。</p>
<h3 id="3、自定义注解"><a href="#3、自定义注解" class="headerlink" title="3、自定义注解"></a>3、自定义注解</h3><p>自定义注解，并添加到需要装载到Spring容器中的框架类上：</p>
<pre><code>@Documented
@Inherited
@Retention(RetentionPolicy.RUNTIME)
@Target({ElementType.TYPE, ElementType.FIELD, ElementType.METHOD, ElementType.PARAMETER})
public @interface SnoWalkerAutoInject {
}
</code></pre><p>定义几个模拟的框架类，用以模拟框架的逻辑。实际的开发中，我们可以按照需求的实际需要，开发框架代码，并标记自定义的注解。</p>
<pre><code>@SnoWalkerAutoInject
public class FrameWorkConfigA {

    public FrameWorkConfigA() {
        System.out.println(&quot;自定义框架组件A-初始化逻辑&quot;);
    }
}

@SnoWalkerAutoInject
public class FrameWorkConfigB {

    public FrameWorkConfigB() {
        System.out.println(&quot;自定义框架组件B-初始化逻辑&quot;);
    }
}

@SnoWalkerAutoInject
public class FrameWorkConfigC {

    public FrameWorkConfigC() {
        System.out.println(&quot;自定义框架组件C-初始化逻辑&quot;);
    }
}
</code></pre><h3 id="4、配置ImportBeanDefinitionRegistrar实现类"><a href="#4、配置ImportBeanDefinitionRegistrar实现类" class="headerlink" title="4、配置ImportBeanDefinitionRegistrar实现类"></a>4、配置ImportBeanDefinitionRegistrar实现类</h3><p>如何使用自定义的ImportBeanDefinitionRegistrar实现类对bean进行装载呢？</p>
<p>最终我们还是需要定义一个配置类，通过@Import注解配置ImportBeanDefinitionRegistrar实现。</p>
<pre><code>@Configuration
@Import(MyBeanDefinationRegistry.class)
@ComponentScan(&quot;com.spring.framework&quot;)
public class MyConf {
}
</code></pre><ol>
<li>MyConf是自定义的配置类，标注了 @Configuration 注解。</li>
<li>通过@Import将实现了ImportBeanDefinitionRegistrar接口的MyBeanDefinationRegistry包含进来；</li>
<li>添加扫描包，以方便spring对该包下的类进行扫描并进行选择性的装载；</li>
</ol>
<h3 id="4、测试"><a href="#4、测试" class="headerlink" title="4、测试"></a>4、测试</h3><p>编写测试类：</p>
<pre><code>public class App {

    public static void main(String[] args) {
        ApplicationContext applicationContext = new AnnotationConfigApplicationContext(&quot;com.spring&quot;);

        final TestBean testBean = (TestBean) applicationContext.getBean(&quot;testBean&quot;);
        System.out.println(testBean.getClass());
    }
}
</code></pre><ol>
<li>首先我们声明并初始化一个AnnotationConfigApplicationContext容器；</li>
<li>接着从容器中通过BeanName获取通过GenericBeanDefinition定义的TestBean实例，打印其Class类型；</li>
<li>观察日志输出，期望能够看到框架代码FrameWorkConfigA、FrameWorkConfigB、FrameWorkConfigC的构造方法日志打印，并看到TestgBean的Class类型打印。</li>
</ol>
<p>运行测试类，观察控制台日志输出：</p>
<pre><code>自定义框架组件A-初始化逻辑
自定义框架组件B-初始化逻辑
自定义框架组件C-初始化逻辑

class com.spring.TestBean
</code></pre><p>可以看到符合预期，这表明，通过ImportBeanDefinitionRegistrar自定义手动bean注入符合预期。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文我们全篇对ImportBeanDefinitionRegistrar在Spring容器装载bean的过程进行了综述，并通过一个模拟框架开发的案例，对如何通过ImportBeanDefinitionRegistrar实现bean的自定义注入进行了代码级别的讲解和分析。</p>
<p>如果在实际的开发案例中需要实现自定义的bean注入，减少调用方整合的复杂度，那么我们完全可以通过本文讲解的方式，利用ImportBeanDefinitionRegistrar扩展点实现。</p>
<h2 id="下期预告："><a href="#下期预告：" class="headerlink" title="下期预告："></a>下期预告：</h2><p>下期我们将分析讲解BeanPostProcessor扩展点在Spring框架中的作用，并讲解BeanPostProcessor在实战开发中的使用。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文开始，我们将系统地对Spring框架的扩展点进行学习，通过案例分析与图例结合，step by step地对Spring看似神秘的扩展点的机理与应用进行研究。&lt;/p&gt;
&lt;p&gt;首先通过一张图对Spring框架各种扩展点的调用顺序（Bean生命周期）进行先入为主的概览。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2022/01/29/Spring扩展点1-研磨ImportBeanDefinitionRegistrar/0.png&quot; alt=&quot;0.png&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Spring扩展点" scheme="http://wuwenliang.net/categories/Spring%E6%89%A9%E5%B1%95%E7%82%B9/"/>
    
    
      <category term="Spring扩展点" scheme="http://wuwenliang.net/tags/Spring%E6%89%A9%E5%B1%95%E7%82%B9/"/>
    
  </entry>
  
  <entry>
    <title>归于平静，甘于平凡</title>
    <link href="http://wuwenliang.net/2021/12/31/%E5%BD%92%E4%BA%8E%E5%B9%B3%E9%9D%99%EF%BC%8C%E7%94%98%E4%BA%8E%E5%B9%B3%E5%87%A1/"/>
    <id>http://wuwenliang.net/2021/12/31/归于平静，甘于平凡/</id>
    <published>2021-12-31T14:54:57.000Z</published>
    <updated>2021-12-31T15:15:12.686Z</updated>
    
    <content type="html"><![CDATA[<p>题诗：</p>
<pre><code>不要温和地走进那良夜，
老年应当在日暮时燃烧咆哮；
怒斥，怒斥光明的消逝。
虽然智慧的人临终时懂得黑暗有理，
因为他们的话没有迸发出闪电，他们
也并不温和地走进那个良夜。
善良的人，当最后一浪过去，高呼他们脆弱的善行
可能曾会多么光辉地在绿色的海湾里舞蹈，
怒斥，怒斥光明的消逝。
狂暴的人抓住并歌唱过翱翔的太阳，
懂得，但为时太晚，他们使太阳在途中悲伤，
也并不温和地走进那个良夜。
严肃的人，接近死亡，用炫目的视觉看出
失明的眼睛可以像流星一样闪耀欢欣，
怒斥，怒斥光明的消逝。
您啊，我的父亲．在那悲哀的高处．
现在用您的热泪诅咒我，祝福我吧．我求您
不要温和地走进那个良夜。
怒斥，怒斥光明的消逝。
</code></pre><p>平常的日子，地球又一次完成了它伟大的公转，于是，一年又过去。</p>
<p>往年每逢公历年的末尾，总是会像写故事一样，洋洋洒洒的罗列自己一年来达成的目标，嗟叹一番未完成的事情，然后立下当时自信能够在接下来一年<br>能够完成的flag，最后再下一次所谓年终总结中，继续这个循环。</p>
<p>这次，我承认我又不能免俗的继续写这个所谓的“年终总结”。只是觉得，如果不写的话，我将又丢掉一个本就少的可怜的习惯。</p>
<p>仅仅是出于习惯，我写给自己。</p>
<p>总得找个主题，这一年，复杂，我想不出别的词来概括我的一年，下意识的想到了复杂。</p>
<p>这是一个男孩变成所谓男人的故事，经历很多，结婚，生子，跳槽，网暴，写书…..太多的事情，让你变得急躁。</p>
<p>做加法容易，做减法难。</p>
<p>着急地想要做完这件事，奔赴下一件事；</p>
<p>从一个孩子变为一个父亲，只觉得，脚步都变得不同往常。</p>
<p>从此不是为了自己而活，一切的美好语言比不上陪伴二字。</p>
<p>感谢妻的辛苦，感谢父母的照顾，感谢陪伴。</p>
<p>经历的事情确实很多，但此时的心态却不同往常，往日肯定会大篇幅的去逐个罗列，然后写上一段所谓心得。这都是过去式了。</p>
<p>要向前看。</p>
<p>活着，生活着，努力生活着，就很满足了。</p>
<p>于是我想到了八个字，归于平静，甘于平凡。</p>
<p>事情太多，加法做太多，心情变得急躁，于是什么都想要，于是总会计较得失。</p>
<p>来年，接下来的日子里，要学会做减法，断舍离，关注重要的，忽略次要的，要接受自己是一个普通人的事实，不虚妄，不浮夸。</p>
<p>甘于平凡，修身修心，过好平常的每天，陪伴身边的人。</p>
<p>不炫耀，不盲从，负责任，扮演好每个需要扮演的角色，不逾矩。</p>
<p>不再立虚无的目标，学会衡量承诺的重量。</p>
<p>感谢过去的自己，做好现在的自己，迎接更好的自己。</p>
<p>迎接更好的2022。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;题诗：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;不要温和地走进那良夜，
老年应当在日暮时燃烧咆哮；
怒斥，怒斥光明的消逝。
虽然智慧的人临终时懂得黑暗有理，
因为他们的话没有迸发出闪电，他们
也并不温和地走进那个良夜。
善良的人，当最后一浪过去，高呼他们脆弱的善行
可能曾会多么光辉地
    
    </summary>
    
      <category term="年度总结" scheme="http://wuwenliang.net/categories/%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="年度总结" scheme="http://wuwenliang.net/tags/%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>RocksDB了解一下？</title>
    <link href="http://wuwenliang.net/2021/07/22/Rocksdb%E4%BA%86%E8%A7%A3%E4%B8%80%E4%B8%8B%EF%BC%9F/"/>
    <id>http://wuwenliang.net/2021/07/22/Rocksdb了解一下？/</id>
    <published>2021-07-22T14:55:04.000Z</published>
    <updated>2021-07-22T15:50:39.863Z</updated>
    
    <content type="html"><![CDATA[<p>项目中需要实现高效的IO操作，不仅支持查询、写入数据，还需要实现数据的持久化。选型最终选择了RocksDB，那么本文就来一睹RocksDB的芳容。</p>
<h2 id="RocksDB是什么？"><a href="#RocksDB是什么？" class="headerlink" title="RocksDB是什么？"></a>RocksDB是什么？</h2><blockquote>
<p>RocksDB是Facebook开发的一款高效的数据库软件，是采用C++编写而成的。</p>
</blockquote>
<p>RocksDB是一款key-value型数据存储设施，具备四个特点，其具有四大特点。</p>
<p><strong>高性能</strong>：RocksDB使用一套C++编写而成的高性能日志结构的数据库引擎。 它的Key和value支持任意大小的字节流。</p>
<p><strong>可适配性</strong>：RocksDB适合于多种不同工作场景。从像MyRocks这样的数据存储引擎到应用数据缓存, 甚至是嵌入式工作场景，RocksDB都可以从容面对这些不同的数据工作需求。</p>
<p><strong>为快速存储而优化</strong>：RocksDB为快速而又低延迟的存储设备（例如闪存或者高速硬盘）进行了特殊优化处理，将最大限度发挥闪存和RAM的高度率读写性能。</p>
<p><strong>基础和高级的数据库操作</strong>：RocksDB提供了一些基础的操作，例如打开和关闭数据库。它对于合并、压缩、过滤等高级操作，也提供了支持。</p>
<p>如果对RocksDB感兴趣，可以去读它的源码，地址为：<a href="https://github.com/facebook/rocksdb" target="_blank" rel="external">https://github.com/facebook/rocksdb</a></p>
<h2 id="在Java工程中使用RocksDB"><a href="#在Java工程中使用RocksDB" class="headerlink" title="在Java工程中使用RocksDB"></a>在Java工程中使用RocksDB</h2><p>如何在Java工程中使用RocksDB呢？</p>
<p>首先建立一个maven工程，在pom.xml中引入RocksDB依赖：</p>
<pre><code>&lt;!-- https://mvnrepository.com/artifact/org.rocksdb/rocksdbjni --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.rocksdb&lt;/groupId&gt;
    &lt;artifactId&gt;rocksdbjni&lt;/artifactId&gt;
    &lt;version&gt;6.20.3&lt;/version&gt;
&lt;/dependency&gt;
</code></pre><p>接着我们通过一个demo尝试在Java中使用RocksDB。</p>
<h3 id="初始化RocksDB"><a href="#初始化RocksDB" class="headerlink" title="初始化RocksDB"></a>初始化RocksDB</h3><pre><code>private RocksDB rocksDB;

private String path = &quot;D:/rocksdb&quot;;

public RocksDBDemo() {
    RocksDB.loadLibrary();
    Options options = new Options();
    options.setCreateIfMissing(true);
    try {
        rocksDB = RocksDB.open(options, path);
    } catch (RocksDBException e) {
        e.printStackTrace();
    }
}

public RocksDB rocksDB() {
    return this.rocksDB;
}
</code></pre><p>首先指定一个路径用于创建RocksDB的log文件：rocksdb写入时，直接以append方式写到log文件以及memtable，随即返回，因此非常快速。</p>
<p>接着通过RocksDB.loadLibrary();导入库，然后设置Options，并打开rocksDB，此时成员变量rocksDB就可以拿来进行操作了。</p>
<h3 id="RocksDB读写"><a href="#RocksDB读写" class="headerlink" title="RocksDB读写"></a>RocksDB读写</h3><pre><code>RocksDBDemo rocksDBDemo = new RocksDBDemo();
RocksDB rocksDB = rocksDBDemo.rocksDB();
// 写入
rocksDB.put(&quot;name&quot;.getBytes(), &quot;snowalker&quot;.getBytes());
// 读取
byte[] bytes = rocksDB.get((&quot;name&quot;.getBytes()));
System.out.println(&quot;读取结果:&quot; + new String(bytes));

// 遍历
RocksIterator iter = rocksDB.newIterator();
for (iter.seekToFirst();iter.isValid();iter.next()) {
    System.out.println(&quot;iter key: &quot; + new String(iter.key()) + &quot;,iter value: &quot; +
            new String(iter.value()));
}
</code></pre><p>RocksDBDemo是我们的测试类名，首先获取rocksDB引用，然后调用put，get方法进行读写操作。</p>
<p>其中put方法签名为：</p>
<pre><code>public void put(final byte[] key, final byte[] value)
    throws RocksDBException {
    put(nativeHandle_, key, 0, key.length, value, 0, value.length);
}
</code></pre><p>get方法签名为：</p>
<pre><code>public byte[] get(final byte[] key) throws RocksDBException {
    return get(nativeHandle_, key, 0, key.length);
}
</code></pre><p>通过rocksDB.newIterator()可以获取迭代器，借助迭代器能够执行迭代操作，这里是读取了一下key与value。</p>
<h3 id="rocksDB的write操作"><a href="#rocksDB的write操作" class="headerlink" title="rocksDB的write操作"></a>rocksDB的write操作</h3><p>rocksdb的一个WriteBatch是原子操作，要么全部成功，要么全部失败，</p>
<blockquote>
<p>具体的实现原理是在整个log的写的过程中只会调用Write操作，最后会调用一次flush，所以如果中间发生机器crash，所有的都会失败，否则所有的都会成功。</p>
</blockquote>
<p>看一段实际代码：</p>
<pre><code>// write batch test
try (final WriteOptions writeOpt = new WriteOptions()) {
    for (int i = 0; i &lt;= 10; ++i) {
        try (final WriteBatch batch = new WriteBatch()) {
            for (int j = 0; j &lt;= 10; ++j) {
                batch.put(String.format(&quot;%d * %d%s&quot;, i, j, &quot;--batch&quot;).getBytes(),
                        String.format(&quot;%d&quot;, i * j).getBytes());
            }
            rocksDB.write(writeOpt, batch);
        }
    }
}
</code></pre><p>这里实际上将乘法表写入了rocksDB。</p>
<p>运行代码，观察目录D:/rocksdb中出现了以下文件：</p>
<p><img src="/2021/07/22/Rocksdb了解一下？/1.PNG" alt="1.PNG"></p>
<p>简单对这几种文件进行讲解：</p>
<p>我们可以从后缀看出：主要有这几种类型</p>
<ul>
<li>sst文件</li>
<li>CURRENT文件</li>
<li>manifest文件</li>
<li>log文件</li>
<li>LOG文件和LOCK文件</li>
</ul>
<p>其中</p>
<ol>
<li>sst文件存储的是落地的数据</li>
<li>CURRENT文件存储的是当前最新的是哪个manifest文件</li>
<li>manifest文件存储的是Version的变化</li>
<li>log文件是rocksdb的write ahead log，就是在写db之前写的数据日志文件，类似binlog</li>
<li>LOG文件是一些日志信息，是供调试用的</li>
<li>LOCK是打开db锁，只允许同时有一个进程打开db</li>
</ol>
<p>这里我们重点看一下log文件中的内容，由于写入的byte，可能有乱码。</p>
<p><img src="/2021/07/22/Rocksdb了解一下？/2.PNG" alt="2.PNG"></p>
<p>从图中可以看到，实际上是顺序写入了我们在代码中设置的key-value。</p>
<h2 id="解释一下rocksdb的flush操作"><a href="#解释一下rocksdb的flush操作" class="headerlink" title="解释一下rocksdb的flush操作"></a>解释一下rocksdb的flush操作</h2><p>Flush是指将memtable的数据导入到sst中，变成持久化存储，从而不必担心数据丢失了。</p>
<pre><code>1.首先在memtable的add的时候，
会检测是否memtable的大小达到了max write buffer，
如果是就将should_flush_置为true，
并会在WriteBatch的Handler里面调用CheckMemtableFull，
将当前column family加入flush_scheduler。

2.在Write的时候，调用ScheduleFlushes，
将需要flush的column family的memtable切换一个新的，
同时将原来的memtable加入cfd的imm中，
如果这个column family data的imm数量大于min_write_buffer_number_to_merge，
并启动一个新的线程调用BGWorkFlush

由于真正的Flush过程是在另一个线程完成的，所以这个地方并不会block写过程
</code></pre><h2 id="rocksDB的WAL（write-ahead-log）"><a href="#rocksDB的WAL（write-ahead-log）" class="headerlink" title="rocksDB的WAL（write ahead log）"></a>rocksDB的WAL（write ahead log）</h2><p>rocksdb的write ahead log（WAL）是指：<br>每次写操作，rocksdb会先写write ahead log，然后才会写db<br>write ahead log可以配置到单独的空间，并且可以配置WAL文件的单独的删除机制。</p>
<p>这种原因是为了保存WAL文件，达到特殊的目的，比如，其他sst文件放在不可靠存储里面，而WAL放到可靠存储里面。</p>
<p>对RocksDB 的写操作而言，每次都必写到两个地方：</p>
<ol>
<li>基于内存的数据结构memtable（达到quota 后会flush 至SST file）。</li>
<li>预写日志-Write Ahead Log（WAL）。<br>如果出现异常情况，WAL 可以用来完整恢复memtable 中的数据，恢复db 的原有的状态。</li>
</ol>
<p>默认配置下，RocksDB 通过每次用户写之后flush WAL，来保证进程crash 后的一致性。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文我们主要对rocksDB做了一个了解和学习，一般来说，使用它的目的在于高性能的写入，实现数据的快速持久化。</p>
<p>业界不乏优秀的中间件底层依赖了rocksDB，如TiDB。</p>
<p>###</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;项目中需要实现高效的IO操作，不仅支持查询、写入数据，还需要实现数据的持久化。选型最终选择了RocksDB，那么本文就来一睹RocksDB的芳容。&lt;/p&gt;
&lt;h2 id=&quot;RocksDB是什么？&quot;&gt;&lt;a href=&quot;#RocksDB是什么？&quot; class=&quot;headerli
    
    </summary>
    
      <category term="专题-分布式" scheme="http://wuwenliang.net/categories/%E4%B8%93%E9%A2%98-%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="专题-分布式" scheme="http://wuwenliang.net/tags/%E4%B8%93%E9%A2%98-%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>复杂软件开发之道4-小试牛刀,教练我想写代码</title>
    <link href="http://wuwenliang.net/2021/04/15/%E5%A4%8D%E6%9D%82%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%E4%B9%8B%E9%81%934-%E5%B0%8F%E8%AF%95%E7%89%9B%E5%88%80-%E6%95%99%E7%BB%83%E6%88%91%E6%83%B3%E5%86%99%E4%BB%A3%E7%A0%81/"/>
    <id>http://wuwenliang.net/2021/04/15/复杂软件开发之道4-小试牛刀-教练我想写代码/</id>
    <published>2021-04-14T23:59:31.000Z</published>
    <updated>2021-04-15T00:49:31.999Z</updated>
    
    <content type="html"><![CDATA[<p>复杂软件开发之道系列进行到现在，主要讲的还是理论和思考，但是如何针对DDD编写代码这一问题想必是大家一直关心的问题。</p>
<p>本文我们就小试牛刀，展示一下通过DDD方式编写代码。</p>
<h2 id="1-只有新项⽬才能考虑⽤DDD吗"><a href="#1-只有新项⽬才能考虑⽤DDD吗" class="headerlink" title="1.只有新项⽬才能考虑⽤DDD吗?"></a>1.只有新项⽬才能考虑⽤DDD吗?</h2><p><strong>当然不是</strong>，DDD这套⽅法论不仅适合从零开始的新项⽬的建模，⽽且适 合复杂业务系统的重构。 当然如果能在新模型的建⽴的过程中就使⽤DDD作为指导，是最好不过的事情，原因在于你会省略对原 有业务系统代码逻辑的梳理和适配过程，众所周知，这不是⼀件容易的事情。</p>
<a id="more"></a>
<h2 id="2-我想在遗留项⽬重构中使⽤DDD，我该怎么做？"><a href="#2-我想在遗留项⽬重构中使⽤DDD，我该怎么做？" class="headerlink" title="2 我想在遗留项⽬重构中使⽤DDD，我该怎么做？"></a>2 我想在遗留项⽬重构中使⽤DDD，我该怎么做？</h2><p>emmmm，恭喜你提出了⼀个好问题，这个问题展开讲的时⻓甚⾄会超过我们本次分享的所有内容加起来的时⻓。（展开讲涉及到领域建模的战略 战术设计，这个后续专题分享） 不过这个问题的本质还是值得探究⼀番。 </p>
<p>⾸先，遗留系统，DDD这两个加起来本就不是那么容易的事情，所以⼤家难免有以下顾虑：</p>
<ol>
<li>懂这块儿业务的同学并不多;</li>
<li>没有足够的落地资料进行参考;</li>
<li>对使用DDD没有底气，不知道从何下手;</li>
<li>客观上，开发周期紧张，排期难以准确预估;</li>
<li>代码逻辑复杂，梳理起来具备一定难度;</li>
<li>对原有模型的二次抽象过于复杂，不知从何下手。</li>
</ol>
<p>有顾虑在所难免，但是如果我们⽤了DDD去建模并且最终成功的落地了这件事情，对我们有什么收益或者说好处呢？好处/收益有如下几点：</p>
<ol>
<li>最直接的受益是对DDD具备了落地经验;</li>
<li>对复杂业务重构具备了落地经验;</li>
<li>积累了丰富的文档和资料，方便新人快速理解业务并上手;</li>
<li>能够对领域划分有所思考和实践;</li>
<li>使业务代码腐化速率降低，稳定支持一定时间内的正常迭代;</li>
<li>客观上拥有了一个具备稳定业务核心的系统，方便快速迭代核心外的业务逻辑，而且可以尽量保证内部模型健壮沉稳地发展;</li>
<li>对于参与者本身的沟通能力和思考能力也是十分明显的。</li>
</ol>
<p>伟⼈说，道路是曲折的，前途是光明的。对于DDD⽽⾔亦如是，只要最终得以落地，那么我们的受益就会⼤幅度<br>⾼于产出，对于我们RD⾃身的影响也是⻓⾜可观的。 那么具体应该如何去做呢，我们需要按照图中的这些步骤去做：</p>
<p><img src="/2021/04/15/复杂软件开发之道4-小试牛刀-教练我想写代码/1.png" alt="1.png"></p>
<h2 id="3-具体的代码是如何应⽤DDD建模思想的"><a href="#3-具体的代码是如何应⽤DDD建模思想的" class="headerlink" title="3. 具体的代码是如何应⽤DDD建模思想的"></a>3. 具体的代码是如何应⽤DDD建模思想的</h2><p>限于篇幅和准备时间，我们通过⼀个简单的业务场景，展示⼀下充⾎模型、领域事件发布、 命令查询分离的代码书写⽅式，权当抛砖引⽟了。</p>
<blockquote>
<p>背景介绍，我们就⼀个简单的为账户进⾏加款这个业务场景，通过DDD的分包和编码⽅式，直观展示⼀下具体的 代码编写⽅式。这个场景的主要流程如下图</p>
</blockquote>
<p><img src="/2021/04/15/复杂软件开发之道4-小试牛刀-教练我想写代码/13.png" alt="13.png"></p>
<p>这个过程中涉及到的对象及其关系⼜是怎样的？</p>
<p>通过名词动词法，我们能够得出以下的交互过程 </p>
<ol>
<li>[执行]-&gt;转账请求-&gt;[发布]-&gt;转账请求已接受事件</li>
<li>账户-&gt;[执⾏]-&gt;充值动作-&gt;[发布]-&gt;账户已完成事件</li>
</ol>
<p>引⼊命令查询模式，旨在展示另⼀种编码⻛格，不⽤命令查询模式（CQRS）也是可以的。 这⾥想补充的是，通过DDD编码没有⼀个统⼀的规范或者样板，我这⾥展示的也并不⼀定是最优的，但是我们始终还是要秉承⼀个观念<br><strong>“还对象以⾏为，⽤代码映射真实世界”</strong>。</p>
<p>简单看⼀下代码的结构，采⽤了经典的四层分包进⾏组织：</p>
<p><img src="/2021/04/15/复杂软件开发之道4-小试牛刀-教练我想写代码/2.png" alt="2.png"></p>
<p>展开来看如下：</p>
<p><img src="/2021/04/15/复杂软件开发之道4-小试牛刀-教练我想写代码/3.png" alt="3.png"></p>
<h3 id="3-1-通过use-case导向，从业务⻆度去看代码，最后再进⾏总结分析"><a href="#3-1-通过use-case导向，从业务⻆度去看代码，最后再进⾏总结分析" class="headerlink" title="3.1 通过use case导向，从业务⻆度去看代码，最后再进⾏总结分析"></a>3.1 通过use case导向，从业务⻆度去看代码，最后再进⾏总结分析</h3><blockquote>
<p>⾸先是账户充值请求的⼊⼝，发⽣在application层，这⼀层主要提供⽤例级别的⽅法逻辑。</p>
</blockquote>
<p><img src="/2021/04/15/复杂软件开发之道4-小试牛刀-教练我想写代码/4.png" alt="4.png"></p>
<p>通过⼯⼚对命令进⾏转换，转换为内部的请求对象，先对请求持久化之后，认为请求已接受，随即发布事件（事件⼀般都是过去式，此处为充值请求已接受事件），事件发布后，会有监听器进⾏处理。</p>
<p><img src="/2021/04/15/复杂软件开发之道4-小试牛刀-教练我想写代码/5.png" alt="5.png"></p>
<p>从事件中还原请求，并转换为扣款命令，再次请求账户应⽤服务的账户增加服务。</p>
<p><img src="/2021/04/15/复杂软件开发之道4-小试牛刀-教练我想写代码/6.png" alt="6.png"></p>
<p>账户实体通过id唯⼀标识，从持久设施中取出后进⾏处理，⽽不是直接传递该实体，这也是DDD编码中的⼀个实践，传递标识，⽽不是直接传递引⽤。</p>
<p>尽量弱化代码耦合 获取到账户实体，通过账户⾃身的⾏为执⾏充值，这⾥其实就是所谓的<strong>充⾎模型</strong>，即：</p>
<blockquote>
<p>领域⾃身的职责 让领域对象⾃⼰完成，⽽不是借助事务脚本完（传统的xxxxService就是事务脚本，将⾏为从领域对象中 抽离，领域对象退化为数据承载的容器，或者说就是⼀个数据结构）</p>
</blockquote>
<p><img src="/2021/04/15/复杂软件开发之道4-小试牛刀-教练我想写代码/7.png" alt="7.png"></p>
<p><img src="/2021/04/15/复杂软件开发之道4-小试牛刀-教练我想写代码/8.png" alt="8.png"></p>
<p>通过领域对象的⾏为完成充值之后，发布充值完成事件，将变更后的账户持久化（借助Spring的同步事 件发布订阅，⽀持事务传播机制）。</p>
<p><img src="/2021/04/15/复杂软件开发之道4-小试牛刀-教练我想写代码/9.png" alt="9.png"></p>
<p><img src="/2021/04/15/复杂软件开发之道4-小试牛刀-教练我想写代码/10.png" alt="10.png"></p>
<p>账户更新事件监听器，对事件进⾏处理，将充值完成的账户持久化到持久化设施，如DB中。</p>
<p><img src="/2021/04/15/复杂软件开发之道4-小试牛刀-教练我想写代码/11.png" alt="11.png"></p>
<p>通过仓储持久化变更的账户余额（可以使⽤乐观锁，此处不实现）。</p>
<h3 id="小结DDD编码"><a href="#小结DDD编码" class="headerlink" title="小结DDD编码"></a>小结DDD编码</h3><p>简单的总结下吧： </p>
<p>我们通过这个简单的 <strong>账户充值请求接收-&gt;执⾏账户充值-&gt;充值完成后更新账户</strong> 的业务场景，<br>通过领域驱动的⽅式 进⾏编码，可以看到最直接的变化就是：我们把业务的核⼼实现放在账户聚合的内部，而账户实体成为⼀个充⾎模型。 </p>
<p>借助命令查询分离（查询我没有实现，并不复杂，⼤家感兴趣可以⾃⾏了解），领域事件发布订阅等⽅式，以不同于传统的事务脚本的⽅式实现了这个业务。</p>
<p>我们通过这个简单的流程，能够很容易根据事件的发布划分出整个业务流程执⾏的不同阶段，通过领域⾏为可以将核⼼业务操作牢牢把握在领域内部，保证我们的模型不会更快的随着需求迭代⽽腐化。</p>
<p>样例确实简单了些，主要是笔者的时间确实⽐较紧张，权当抛砖引⽟，后续有机会针对编码这块⼉还有更多的分享。</p>
<h3 id="补充：对DDD上下文映射的思考"><a href="#补充：对DDD上下文映射的思考" class="headerlink" title="补充：对DDD上下文映射的思考"></a>补充：对DDD上下文映射的思考</h3><p>软件是对现实世界的抽象和映射，如下图：</p>
<p><img src="/2021/04/15/复杂软件开发之道4-小试牛刀-教练我想写代码/12.png" alt="12.png"></p>
<p>软件发展的规律就是逐步由简单软件向复杂软件转变，使变更总是满⾜当下的需求，通过领域努⼒还原 真实世界，避免过度设计，让代码具备开放封闭的特性，能够避免软件过快腐化。</p>
<p>对于上下文而言，上下⽂关系有以下几种： </p>
<ol>
<li><strong>U(Upstream 上游)/D(DownStream 下游)</strong> : 上游的变动会影响下游，⽐如下游在代码上依赖上游（或者 模型结构），这⾥的上下游不是指数据的流向。</li>
<li><strong>OHS(Open Host Service 开放主机服务/发布语⾔)</strong> : 上游定义⼀种协议，让下游通过协议去使⽤该服 务，并公开这份协议（接⼝），让想⽤的⼈可以使⽤它。 </li>
<li><strong>PL(Published Language 发布语⾔)</strong> : 协定传送资料的语⾔格式，如 XML、JSON 或是 Protocol Buffer等等。</li>
<li><strong>ACL(Anti-corruption Layer 防腐层)</strong> : 是⼀种在不同模型间转换概念与资料的机制。为了要避免你 Bounded Context 的 domain model 概念受到来⾃外部的污染，你可以藉由 ACL 来建⽴⼀层隔离层，利 ⽤Facade模式来将外部概念转换成内部 Domain Model 能理解的概念。此种关系多⽤于遗留系统和团队 外部系统。 </li>
<li><strong>Shared Kernel(共享内核)</strong> : 两个 Bounded Context 共⽤同⼀个模块。当两个团队在开发同⼀个应⽤程 序，并且各⾃的 Bounded Context 共享⼀块重复的领域知识，为了加快开发的脚步，就会将部分共⽤的逻辑抽成 Shared Kernel。这也表明这部分的业务语⾔和领域知识在共享的两个上下⽂是不存在歧义，可以通⽤的。<strong>例如</strong>：两个 Bounded Context 依赖同⼀个⼆⽅库。</li>
<li><strong>Customer-Supplier(客户-供应商)</strong> : 当 Bounded Context 或团队间有上下游关系(单向依赖)时，上游⽅可以独⽴于下游⽅完成开发，⽽下游⽅必须受限于上游⽅的开发计划。当上游⽅开会或做决策时，下游⽅也需要被通知甚⾄⼀起参加会议。这种关系情况下上下游⼀般会有⼀整套的测试⽤例，⽤于维护相互之间的不变性。上游的更改只要能够满⾜约定的不变性，即可不⽤通知下游进⾏变更。例如：事件发布或 者消息队列等⽅式； </li>
<li><strong>Conformist(遵奉者)</strong> : 同样在 Bounded Context 或团队间有上下游关系时出现，但此时上游⽅没有任何<br>动⼒要满⾜下游⽅的需求，这种关係我们就称下游⽅为 Conformist。此关系下有可能出现上游变更后， 短时间内下游逻辑异常的情况，此时需要下游对新的变更进⾏适配。 </li>
<li><strong>Seperate Way(另谋他路)</strong> : 当两个 Bounded Context 或团队间因为技术、沟通或政治因素导致合作成本 过⾼时，就可以考虑断开两者的依赖关系。这并不代表两者毫⽆关系，仍有可能透过 UI 或是⼿动的模式 来进⾏整合限界上下⽂不仅是业务语⾔和领域知识的边界，也是团队合作的边界，清晰地定义不同上下⽂的关系不 仅有助于梳理业务之间的关系，也有助于理解不同团队的合作关系。</li>
</ol>
<h2 id="以终为始，道法⾃然"><a href="#以终为始，道法⾃然" class="headerlink" title="以终为始，道法⾃然"></a>以终为始，道法⾃然</h2><p>唠了这么多，其实我们反复在讨论的只有⼀个问题，<strong>那就是DDD本身并不可怕</strong>，可怕的是⽣搬硬套所谓最佳实践以及对⽅法要解决的问题本质分析不透彻就硬上，这最终会对我们的系统造成反噬。 </p>
<p>即便对DDD整套理论没有系统全⾯的认知，如果你始终秉承着⾯向对象设计、⾯向对象建模的思路，通过 <strong>核⼼模型领域建模 + 结构化编程思想 + ⾯向对象设计模式的合理使⽤</strong>（针对问题域 适度封装与预留扩展点），我们写出来的代码质量的坏味道就会少很多。 </p>
<p>简单的说，是不是DDD驱动的不重要，重要在于够不够OO，⾜够OO，⾜够健壮，是否DDD已经不再重要，我们只需要从DDD中适度的借鉴采⽤适合我们的⽅法/⼯具，达成软件的落地就可以。 </p>
<p>所谓的⼤象⽆形，融汇贯通就是这样的，（就好⽐：张⽆忌当初练习太极剑，从开始到结束，忘记了所有招数， 达到运⽤⾃如，融会贯通的化境。）DDD对于你完全成为⼀套⼯具箱。</p>
<p>⼀切的⼀切都是为了 <strong>“Get things Done”</strong>，让事情是他本来的样⼦，让事情能够落地。这才是我们要使用DDD的价值，这亦是我所认为的DDD的⽬的。因为DDD本质上就是解决问题的一套思想的沉淀。</p>
<h2 id="DDD推荐学习资料"><a href="#DDD推荐学习资料" class="headerlink" title="DDD推荐学习资料"></a>DDD推荐学习资料</h2><p>如果想继续了解DDD，那么可以阅读以下资料，排名不分先后：</p>
<ul>
<li>实现领域驱动设计</li>
<li>领域驱动设计精粹</li>
<li>微服务架构设计模式</li>
<li>极客时间《DDD实战课》</li>
<li>Gitchat《领域驱动设计实践战略+战术》</li>
</ul>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;复杂软件开发之道系列进行到现在，主要讲的还是理论和思考，但是如何针对DDD编写代码这一问题想必是大家一直关心的问题。&lt;/p&gt;
&lt;p&gt;本文我们就小试牛刀，展示一下通过DDD方式编写代码。&lt;/p&gt;
&lt;h2 id=&quot;1-只有新项⽬才能考虑⽤DDD吗&quot;&gt;&lt;a href=&quot;#1-只有新项⽬才能考虑⽤DDD吗&quot; class=&quot;headerlink&quot; title=&quot;1.只有新项⽬才能考虑⽤DDD吗?&quot;&gt;&lt;/a&gt;1.只有新项⽬才能考虑⽤DDD吗?&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;当然不是&lt;/strong&gt;，DDD这套⽅法论不仅适合从零开始的新项⽬的建模，⽽且适 合复杂业务系统的重构。 当然如果能在新模型的建⽴的过程中就使⽤DDD作为指导，是最好不过的事情，原因在于你会省略对原 有业务系统代码逻辑的梳理和适配过程，众所周知，这不是⼀件容易的事情。&lt;/p&gt;
    
    </summary>
    
      <category term="DDD" scheme="http://wuwenliang.net/categories/DDD/"/>
    
    
      <category term="DDD" scheme="http://wuwenliang.net/tags/DDD/"/>
    
  </entry>
  
  <entry>
    <title>灵魂拷问,我理解的DDD是DDD吗?</title>
    <link href="http://wuwenliang.net/2021/04/11/%E7%81%B5%E9%AD%82%E6%8B%B7%E9%97%AE-%E6%88%91%E7%90%86%E8%A7%A3%E7%9A%84DDD%E6%98%AFDDD%E5%90%97/"/>
    <id>http://wuwenliang.net/2021/04/11/灵魂拷问-我理解的DDD是DDD吗/</id>
    <published>2021-04-11T08:58:18.000Z</published>
    <updated>2021-04-11T09:55:55.973Z</updated>
    
    <content type="html"><![CDATA[<p>DDD领域驱动设计今年真的是大火了，这是好事，表明我们的软件开发领域是一直在向前发展的。</p>
<p>但是很多的文章或者培训，都是在说DDD如何如何优秀，简单的举一些例子就行了，有些甚至是完全错误的。</p>
<p>因此笔者决定将自己的实践心得以及与他人讨论的关于DDD的问题整理为一篇文章，通过问题驱动的方式，将领域驱动设计中的一些注意点进行总结，希望能够对读者有所帮助。</p>
<p>主要的问题如下：</p>
<ul>
<li>到底什么才是统⼀语⾔，它有那么重要么？</li>
<li>领域驱动设计仅仅需要开发者参与吗？</li>
<li>领域驱动设计的那些个概念到底是在说什么？实体和值对象有啥区别？</li>
<li>DDD四层架构的好处有哪些？</li>
<li>限界上下文如何划分比较好呢？有没有工具推荐？</li>
<li>聚合粒度如何控制呢？一个聚合根就够了，为什么还要细分各种子域？</li>
<li>ACL(防腐层)应该怎么用？它的作用和优势有哪些？它在DDD分层中处于哪个位置？</li>
</ul>
<a id="more"></a>
<h2 id="到底什么才是统⼀语⾔，它有那么重要么？"><a href="#到底什么才是统⼀语⾔，它有那么重要么？" class="headerlink" title="到底什么才是统⼀语⾔，它有那么重要么？"></a>到底什么才是统⼀语⾔，它有那么重要么？</h2><p>统⼀语⾔，并不是某种具体的标记。⽽是针对不同的业务需求场景，由领域专家、开发⼈员、需求提出⽅、客户（有时候没有该⻆⾊）共同参与讨论，提炼出的领域知识的产出物。 </p>
<p>这套语⾔，可以理解为是不同⻆⾊间同步信息的媒介，⼤家都认同它的定义和含义，只要是基于这套共 识机制进⾏讨论，那么就能较为顺畅的推进需求迭代。</p>
<blockquote>
<p>实际上，统⼀语⾔在DDD中不是单独存在的，⽽是⼀个中间产物，得到它的过程伴随着领域建模的事件⻛暴过程。</p>
</blockquote>
<p>其他建模⽅式有： 名词动词法、四⾊建模法、职责驱动法、事件驱动法等，这些场景属于领域建模的<strong>战略设计部分</strong>，因此我们不在这⾥做过多的解释。</p>
<p>以事件风暴建模过程为例，举⼀个统⼀语⾔的例⼦：</p>
<blockquote>
<p>绿⾊代表 实体 </p>
<p>蓝⾊代表 ⾏为 </p>
<p>橙⾊代表 事件</p>
</blockquote>
<p><img src="/2021/04/11/灵魂拷问-我理解的DDD是DDD吗/1.png" alt="1.png"></p>
<p>图中，我们对账户信息进行了事件风暴，围绕着账户的行为进行了定义，主要有：</p>
<ul>
<li>创建账户</li>
<li>查询账户信息</li>
<li>账户充值</li>
<li>账户扣款</li>
<li>账户退款</li>
<li>账户冻结等行为</li>
</ul>
<p>这些行为本身又会触发一些事件的发送，主要有以下事件：</p>
<ul>
<li>账户已创建</li>
<li>账户已充值</li>
<li>账户已扣款</li>
<li>账户已退款</li>
<li>账户已冻结</li>
</ul>
<h2 id="领域驱动设计仅仅需要开发者参与吗？"><a href="#领域驱动设计仅仅需要开发者参与吗？" class="headerlink" title="领域驱动设计仅仅需要开发者参与吗？"></a>领域驱动设计仅仅需要开发者参与吗？</h2><p>当然不是。领域驱动设计建模过程需要多⽅参与，最后的落地主要是研发参与。</p>
<p>在建模过程中，往往需要以下⻆⾊共同作⽤：</p>
<ul>
<li>领域专家（有些时候，领域专家是产品经理，运营兼职的，甚⾄可能直接由RD同学扮演领域专家） </li>
<li>开发⼈员 </li>
<li>需求提出⽅（如：运营 产品） </li>
<li>客户（有些场景下 产品/运营扮演该⻆⾊）</li>
</ul>
<p>总的来说，领域驱动设计是⼀个团队⾏为，并⾮开发者单独参与。</p>
<h2 id="领域驱动设计的那些个概念到底是在说什么？"><a href="#领域驱动设计的那些个概念到底是在说什么？" class="headerlink" title="领域驱动设计的那些个概念到底是在说什么？"></a>领域驱动设计的那些个概念到底是在说什么？</h2><p>领域驱动设计的概念主要涉及到这些，我们可以全⾯了解，有选择性的使⽤。 实际在开发中常⽤的也就那么⼏个。</p>
<p><img src="/2021/04/11/灵魂拷问-我理解的DDD是DDD吗/2.png" alt="2.png"></p>
<p>这⾥单独说⼀下<strong>实体</strong>和<strong>值对象</strong>吧：</p>
<ul>
<li>实体有主键ID，值对象没有； </li>
<li>值对象本质上就是⼀个数据集合，⽐如说：收货地址、家庭住址就可以⽤值对象表达，只对属性进⾏归类，没有唯⼀ID； </li>
<li>⼈员信息，⽤实体表达，原因在于：我们可以对⼀个实体对象进⾏多次修改，修改后的数据和原来的数据可能会⼤不相同。但是，由于它们拥有相同的 ID，它们依然是同⼀个实体。</li>
</ul>
<h2 id="DDD四层架构的好处有哪些？"><a href="#DDD四层架构的好处有哪些？" class="headerlink" title="DDD四层架构的好处有哪些？"></a>DDD四层架构的好处有哪些？</h2><p>其实DDD四层架构的本质还是分层架构，而软件分层架构本质上还是 <strong>通过层来隔离不同的关注点</strong> （变化相似的地方），以此来解决不同需求变化的问题，使得这种变化可以被控制在一个层里。</p>
<p>因此我认为最大的好处还是分离关注点，屏蔽因下层变更导致的上层变更，使得层间松耦合。</p>
<h2 id="限界上下文如何划分比较好呢？有没有工具推荐？"><a href="#限界上下文如何划分比较好呢？有没有工具推荐？" class="headerlink" title="限界上下文如何划分比较好呢？有没有工具推荐？"></a>限界上下文如何划分比较好呢？有没有工具推荐？</h2><p>重点还是要基于战略设计中的 <strong>事件风暴</strong>，即event storming，这个过程可以多做几次。尽量不要一个人闭门造车，要带着产品，领域专家一起把这个过程做好，做透。</p>
<p>因为从本质上说，事件风暴这个事情没有好或者不好，但是要保证限界上下文的划分是产研和领域专家的共识。</p>
<p>因为每个人对一个领域的认识没有对错，只有深度和角度的不同，甚至于你在不同的时间，团队，对同一个业务，限界上下文的划分也不完全一致。所以说，衡量的标准是，团队协作过程中不同角色间是否达成了共识。</p>
<p>详细展开说，首先还是要建立统一语言，达成共识，及时调整，多做沟通。然后多去推演，发现不合理的地方随时修改。</p>
<p>退一步讲，即便因为条件所限，没有进行标准的领域风暴流程，设计者自己也可以模拟这个过程，把领域，值对象，事件，都拆分出来，平摊在一个版面上，</p>
<ul>
<li>通过分类划分不同的限界上下文；</li>
<li>在每个上下文里找到聚合根</li>
</ul>
<p>总归还是需要走一次这个过程，只不过有时候可能参与的人比较多，有时候就开发自己去做这个事情了。</p>
<p>而且，对领域驱动设计而言，它还是蛮兼容并包的，尤其是战略设计阶段，我们完全可以利用已知的工具去辅助建模，比如说强大的UML语言，使用何种工作是没有一个统一标准的，只要能够完成建模的目标，都是合理的。</p>
<p>至于最终落地的时候采用哪种架构方式，就看团队喜好了，一般还是建议用分层架构，比较容易上手。</p>
<p>实际上在我们的实践过程中发现，想要达到纯正的领域，驱动建模还是比较复杂的，就是说你总归有一些代码是胶水代码，这些胶水代码实际上我们最终还是放到了一些service里面，通过这些service然后去串联各个不同的聚合。</p>
<p>我的建议就是说建模的时候尽量采用纯领域驱动去做（尽量采用充血模型），然后在实际操作的时候还是可以使用一些传统的事务脚本式的编程方法，通过核心的领域驱动建模，加上流程化的穿插去完成建模和开发。我们这种采用的是折中后的充血模型，就是没有采用完全的充血模型，而是半充血，通过application Service将不同领域的能力归拢起来，将流程化的操作沉到domain Service，然后去调用实体本身的行为去完成业务操作。</p>
<p>这种方式在实践中证明是可行的，而且接受度高，参与开发的同学能够很快上手。</p>
<p>总结很赞，一定要结合本公司、业务、团队、产品的实际情况。</p>
<p>总之，限界上下文的划分的确是初期最重要的事情，这件事情需要参与的每个人付出非常多的思考，如果在战略设计阶段产、研、领域专家这个共识没有建立，后面的工作很容易走样。</p>
<h2 id="聚合粒度如何控制呢？一个聚合根就够了，为什么还要细分各种子域？"><a href="#聚合粒度如何控制呢？一个聚合根就够了，为什么还要细分各种子域？" class="headerlink" title="聚合粒度如何控制呢？一个聚合根就够了，为什么还要细分各种子域？"></a>聚合粒度如何控制呢？一个聚合根就够了，为什么还要细分各种子域？</h2><p>首先我们要明确的是DDD中的方案和思路是从业务领域建模出发的，而DDD最大的特点和所谓缺陷 也是领域建模。我们以下单过程中，保存一个订单为例来讨论这个问题。</p>
<p>如果建模不合理，导致出现一个较大的聚合根，那么从聚合根触发的一个save操作必然需要同时联动多个实体。</p>
<p>一般来说，为了保证聚合内实体状态一致，我们还是会采用和事务脚本编码<br>类似的本地事务，我默认你用的是Spring，当然或多或少会有性能问题，至于影响多大，我觉得我说了不算，实践是检验真理的唯一标准。</p>
<p>另一方面，如果是跨聚合的，领域事件就派上用场了。我发表一个不成熟的观点，<strong>DDD本身就是反性能的</strong>，为了高性能，聚合太充血以及聚合过于复杂，本身就是违背对性能要求的初衷。</p>
<p>所以save类操作，还是需要控制一下事务的粒度，但是根本上还是要控制聚合的粒度<br>防止出现一个上帝对象。</p>
<p>另一方面，如果是跨聚合的，领域事件就派上用场了，这时候追求的是最终一致，不太适合采用强一致的事务。</p>
<p>因此还是需要case  by case，结合具体的案例去分析，方案是有很多的。</p>
<p>甚至在非交易场景下，放弃事务也是一种方式，比如，异步持久化。失败重试，异步补偿。</p>
<p>如果交易类场景，聚合过于复杂的情况下，单机性能提升确实不明显，这是DDD的天然特性（说的难听点，这是DDD的问题）。</p>
<h2 id="ACL-防腐层-应该怎么用？它的作用和优势有哪些？它在DDD分层中处于哪个位置？"><a href="#ACL-防腐层-应该怎么用？它的作用和优势有哪些？它在DDD分层中处于哪个位置？" class="headerlink" title="ACL(防腐层)应该怎么用？它的作用和优势有哪些？它在DDD分层中处于哪个位置？"></a>ACL(防腐层)应该怎么用？它的作用和优势有哪些？它在DDD分层中处于哪个位置？</h2><p>首先我们要明确的是，对于跨领域的调用，我们要用到ACL。</p>
<p>严格的做法是，对于所有跨域的调用都必须要经过acl，去跟对方的application层进行交互，一句话就是 <strong>通过application去聚合领域的内部能力，通过acl去防腐，通过事件去进行广播，进行异步交互，通过CQRS来进行一些读服务的优化</strong>。</p>
<p>ACL具体如何使用比较优雅？</p>
<p>我们的实践是，面向接口编程。具体的做法是，将对外访问通过接口提取出一个抽象，将抽象的接口和具体的业务逻辑放在同一层，如：可以放在domainService中。</p>
<p>而ACL接口的实现类则要放在基础设施层，因为基础设施层在DDD的六边形架构中，处于南向网关的位置，而ACL本身是对外的调用，因此属于本业务领域的出口，也就是南向网关。</p>
<p>举个例子，比方说你的一个orderDomainService需要去调用你的账户account ApplicationService这些能力，那么你就需要在你的订单的域内去定义一个账户的acl接口，然后你用你的订单的域去依赖这个acl接口，但是你acl的实现要放在你的infrastructure里面去，如图所示：</p>
<p><img src="/2021/04/11/灵魂拷问-我理解的DDD是DDD吗/3.png" alt="3.png"></p>
<p>为什么这么做呢？其实它本质就体现了一种面向抽象编程的思想。也就是说 <strong>高层模块不应该依赖低层模块，二者都应该依赖其抽象</strong>。</p>
<p>也许有的读者会疑惑，对于domainService和applicationService，感觉他们没什么区别，业务逻辑写在哪儿都差不多。</p>
<p>其实原因很简单，这恰恰说明你面对的业务并不复杂，一个领域实体就是一个聚合根、然后一个领域服务就是一个应用服务，因此看起来applicationService就是domainService的委派。</p>
<p>对于复杂一些的场景，一个聚合根下需要联动超过2个子域，就需要用applicationService对多个domainService进行组合，组合的结果就是一种复合服务，说的高端一些，这样的一个applicationService就是沉淀了一组领域能力。而这样的applicationSerivce就是在对domainSerivce进行编排。</p>
<p>其实你的application层本质上是一种聚合层，它的作用是用来协调整合下面的domain层，然后基于这些domain具体的细分的原子能力进行组合，组织成复合能力并且进行一些事件的发送和通知。</p>
<p>所以我觉得叫application层，叫它聚合能力层也是可以的。我们在一些复杂业务流程中，用到了一些类似于服务编排的一些功能或者方式吧，这里编排的实际上就是application。</p>
<p>其实对于一些复杂的业务来说，你的applications其实是没有事务的，因为你的事物全部都拆分为若干小事务，下沉在各种domainService里面去了，然后你的application层是去聚合这样一个一个的小事务，完成一个复杂的事情，并且在完成了这些事情之后，发送一些事件通知来通知别的领域，或者说别的上下文中的某些词语去完成一些他们自己的工作，这种时候发送的事件就不是简单的领域内事件，而是一些跨领域的事件。</p>
<p>而领域事件本质上是一种最终一致性的事务实现机制。</p>
<p>回到问题上来，我们总结一下：</p>
<ul>
<li>凡是需要提供出去的能力都是自己的领域模型和自己的领域服务；通过application层进行领域能力的聚合和透出；</li>
<li>凡是从别人那里要来的东西，都需要经过防腐层ACL进行屏蔽和处理，以及执行实体转换等二次加工逻辑。</li>
</ul>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;DDD领域驱动设计今年真的是大火了，这是好事，表明我们的软件开发领域是一直在向前发展的。&lt;/p&gt;
&lt;p&gt;但是很多的文章或者培训，都是在说DDD如何如何优秀，简单的举一些例子就行了，有些甚至是完全错误的。&lt;/p&gt;
&lt;p&gt;因此笔者决定将自己的实践心得以及与他人讨论的关于DDD的问题整理为一篇文章，通过问题驱动的方式，将领域驱动设计中的一些注意点进行总结，希望能够对读者有所帮助。&lt;/p&gt;
&lt;p&gt;主要的问题如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;到底什么才是统⼀语⾔，它有那么重要么？&lt;/li&gt;
&lt;li&gt;领域驱动设计仅仅需要开发者参与吗？&lt;/li&gt;
&lt;li&gt;领域驱动设计的那些个概念到底是在说什么？实体和值对象有啥区别？&lt;/li&gt;
&lt;li&gt;DDD四层架构的好处有哪些？&lt;/li&gt;
&lt;li&gt;限界上下文如何划分比较好呢？有没有工具推荐？&lt;/li&gt;
&lt;li&gt;聚合粒度如何控制呢？一个聚合根就够了，为什么还要细分各种子域？&lt;/li&gt;
&lt;li&gt;ACL(防腐层)应该怎么用？它的作用和优势有哪些？它在DDD分层中处于哪个位置？&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="DDD" scheme="http://wuwenliang.net/categories/DDD/"/>
    
    
      <category term="DDD" scheme="http://wuwenliang.net/tags/DDD/"/>
    
  </entry>
  
  <entry>
    <title>一个对账框架的代码实现</title>
    <link href="http://wuwenliang.net/2021/03/06/%E4%B8%80%E4%B8%AA%E5%AF%B9%E8%B4%A6%E6%A1%86%E6%9E%B6%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"/>
    <id>http://wuwenliang.net/2021/03/06/一个对账框架的代码实现/</id>
    <published>2021-03-05T17:22:46.000Z</published>
    <updated>2021-03-05T18:41:19.431Z</updated>
    
    <content type="html"><![CDATA[<p>在笔者的公众号上发布了关于 <strong>对账</strong> 业务分析的一篇文章，<a href=""></a>, 该文也是笔者新书中的一节内容。</p>
<p>本文作为补充，我们从实战角度，从代码角度呈现一个对账框架的实现。</p>
<p>注意：本文中提供的对账框架为广义上的对账，也就是说不局限于支付、交易领域的对账场景，凡是需要通过数据比对进行数据校准、比对、核准的场景，均能够采用本文提供的思路进行实现。</p>
<a id="more"></a>
<h2 id="核心流程"><a href="#核心流程" class="headerlink" title="核心流程"></a>核心流程</h2><p>首先提供一张框架的核心流程图：</p>
<p><img src="/2021/03/06/一个对账框架的代码实现/framework.png" alt="framework.png"></p>
<p>通过该流程图可以看到，我们将获取对账基准数据、获取对账目标数据、定义平账依据、异常数据修复等功能通过接口方式提供了扩展点给用户，方便用户根据自己的业务特点进行定制化的开发，这里是对“开闭原则”的实践。</p>
<p>图中绿色部分为调用者实现的代码逻辑，橙色部分为框架自身的业务逻辑。具体的实现细节在接下来的代码实现中将会详细分析。</p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>最好的描述实际上还是代码，我们根据上文中的流程图，提供代码实现。</p>
<h3 id="卖个关子，先跑一下样例看看效果"><a href="#卖个关子，先跑一下样例看看效果" class="headerlink" title="卖个关子，先跑一下样例看看效果"></a>卖个关子，先跑一下样例看看效果</h3><p>我们先通过运行样例代码，看一下框架实际的使用效果。</p>
<p>具体的调用代码如下：</p>
<pre><code>public static void main(String[] args) {
    // 声明对账处理器
    DataCheckingDefaultProcessor processor = new DataCheckingDefaultProcessor();
    // 执行对账操作
    testHashStrategy(processor);
}

private static void testHashStrategy(DataCheckingDefaultProcessor processor) {
    // 加载Map对账监听器实现
    DataCheckingOnLoadHashListener dataCheckingOnLoadHashListener = new DataCheckingOnLoadHashListenerImpl();
    // 加载数据一致性对比监听器实现
    DataCheckingConsistenceListener dataCheckingConsistenceListener = new DataCheckingConsistenceListenerImpl();

    // 依赖注入
    processor.setDataCheckingConsistenceListener(dataCheckingConsistenceListener);
    processor.setDataCheckingOnLoadHashListener(dataCheckingOnLoadHashListener);

    // 执行对账
    processor.execute();
    // 打印结果
    System.out.println(processor.printCheckResult(&quot;测试对账&quot;));
}
</code></pre><p>具体调用方式，注释写的比较清楚了，我们直接关注一下控制台输出：</p>
<pre><code>模拟执行数据修复
[测试对账],successCount:34,failureCount:66,doubleCheckSuccessCount:0,doubleCheckFailureCount:0

Process finished with exit code 0
</code></pre><p>可见输出了对账的结果，有34个成功，66个不一致</p>
<h3 id="这么优秀的功能，是如何实现的呢？"><a href="#这么优秀的功能，是如何实现的呢？" class="headerlink" title="这么优秀的功能，是如何实现的呢？"></a>这么优秀的功能，是如何实现的呢？</h3><p>通过样例代码可以看出，用户只需要实现对基准数据、目标数据的获取，以及定义平账的依据，框架就能够自动的对基准数据和目标数据进行比对。</p>
<p>并且如果我们定义了数据修复能力，框架还能够实现对数据的修复功能。</p>
<h3 id="数据加载监听器：DataCheckingOnLoadHashListener"><a href="#数据加载监听器：DataCheckingOnLoadHashListener" class="headerlink" title="数据加载监听器：DataCheckingOnLoadHashListener"></a>数据加载监听器：DataCheckingOnLoadHashListener</h3><pre><code>public interface DataCheckingOnLoadHashListener&lt;K&gt; {

    /**
    * 加载对账数据到Map，中，如果采用hash结构对账，则实现该方法
    * Map:
    *      key:    关联id
    *      value:  BasicCheckData 基准对账实体
    * @return
    */
    Map&lt;K, BasicCheckData&gt; loadBasicData2Map();

    /**
    * 加载对账数据到Map，中，如果采用hash结构对账，则实现该方法
    * Map:
    *      key:    关联id
    *      value:  TargetCheckData 目标对账实体
    * @return
    */
    Map&lt;K, TargetCheckData&gt; loadTargeDataMap();
}
</code></pre><p>该接口用于加载对账基准数据与对账的目标数据到内容中，加载之后的数据结构为Map，key为业务唯一标识。</p>
<h3 id="数据一致性定义监听器：DataCheckingConsistenceListener"><a href="#数据一致性定义监听器：DataCheckingConsistenceListener" class="headerlink" title="数据一致性定义监听器：DataCheckingConsistenceListener"></a>数据一致性定义监听器：DataCheckingConsistenceListener</h3><pre><code>public interface DataCheckingConsistenceListener&lt;T&gt; {

    /**
    * 是否一致
    * @param basicCheckEntity
    * @param targetCheckEntity
    * @return
    */
    boolean isCheckConsistent(BasicCheckData basicCheckEntity, TargetCheckData targetCheckEntity);

    /**
    * 数据修复
    */
    void fixData();

    /**
    * 是否需要二次对账
    * @return
    */
    boolean needDoubleCheck();
}
</code></pre><p>DataCheckingConsistenceListener为数据一致性声明的监听器接口，主要方法为 <strong>isCheckConsistent</strong> ，该方法需要调用者实现，根据具体业务场景定义对账是否成功，成功返回true，不一致则返回false。</p>
<h3 id="对账核心处理器：DataCheckingDefaultProcessor"><a href="#对账核心处理器：DataCheckingDefaultProcessor" class="headerlink" title="对账核心处理器：DataCheckingDefaultProcessor"></a>对账核心处理器：DataCheckingDefaultProcessor</h3><p>DataCheckingDefaultProcessor为对账的核心处理器。</p>
<pre><code>public DataCheckingDefaultProcessor(DataCheckingOnLoadHashListener dataCheckingOnLoadHashListener,
                                    DataCheckingConsistenceListener dataCheckingConsistenceListener) {
    Preconditions.checkNotNull(dataCheckingOnLoadHashListener);
    Preconditions.checkNotNull(dataCheckingConsistenceListener);
    this.dataCheckingOnLoadHashListener = dataCheckingOnLoadHashListener;
    this.dataCheckingConsistenceListener = dataCheckingConsistenceListener;
}
</code></pre><p>首先是DataCheckingDefaultProcessor的构造方法，它接收DataCheckingOnLoadHashListener和DataCheckingConsistenceListener的实例。</p>
<p>调用者通过实现接口，并将接口的实现通过该构造方法注入到DataCheckingDefaultProcessor之中。</p>
<pre><code>/**
 * 执行对账
 */
public void execute() {
    check();
}

/**
 * 执行对账
 */
private void check() {
    // 对账前数据准备
    Map&lt;String, BasicCheckData&gt; basicCheckDataMap = dataCheckingOnLoadHashListener.loadBasicData2Map();
    Map&lt;String, TargetCheckData&gt; targetCheckDataMap = dataCheckingOnLoadHashListener.loadTargeDataMap();
    Preconditions.checkNotNull(basicCheckDataMap);
    Preconditions.checkNotNull(targetCheckDataMap);

    // 执行对账
    handleCheckByHashStrategy(basicCheckDataMap, targetCheckDataMap, successCount, failureCount);

    // 需要二次校验则二次校验
    if (dataCheckingConsistenceListener.needDoubleCheck()) {
        handleCheckByHashStrategy(basicCheckDataMap, targetCheckDataMap, doubleCheckSuccessCount, doubleCheckFailureCount);
    }

    // 数据修复
    dataCheckingConsistenceListener.fixData();
}
</code></pre><p>check()方法为核心的对账逻辑。</p>
<ol>
<li>首先通过DataCheckingOnLoadHashListener加载调用者回传的对账基准Map，以及对账目标Map；两个Map的key均为业务唯一标识；</li>
<li>接着通过 <strong>handleCheckByHashStrategy</strong> 执行对账操作，对两个Map进行比对；</li>
<li>如果调用方允许二次校验，则再次执行一次对账操作；</li>
<li>执行业务方实现的数据修复接口，根据业务方的数据修复逻辑进行数据修复。这里实际上是需要通过一个上下文对象将待修复的数据回传给框架，暂时未实现，就留给读者自行实现吧。（<strong>提示：</strong> 通过定义一个上下文对象，通过fixData方法入参传递给调用者）</li>
</ol>
<h4 id="handleCheckByHashStrategy对账核心逻辑"><a href="#handleCheckByHashStrategy对账核心逻辑" class="headerlink" title="handleCheckByHashStrategy对账核心逻辑"></a>handleCheckByHashStrategy对账核心逻辑</h4><p>我们重点关注一下handleCheckByHashStrategy对账核心逻辑：</p>
<pre><code>/**
 * hash结构对账逻辑
 * @param basicCheckDataMap
 * @param targetCheckDataMap
 * @param successCount
 * @param failureCount
 */
private void handleCheckByHashStrategy(Map&lt;String, BasicCheckData&gt; basicCheckDataMap,
                                       Map&lt;String, TargetCheckData&gt; targetCheckDataMap,
                                       AtomicLong successCount,
                                       AtomicLong failureCount) {
    for (Map.Entry&lt;String, BasicCheckData&gt; checkEntry : basicCheckDataMap.entrySet()) {
        String checkEntryKey = checkEntry.getKey();

        BasicCheckData basicCheckData = checkEntry.getValue();
        if (basicCheckData == null) {
            failureCount.incrementAndGet();
            continue;
        }

        TargetCheckData targetCheckData = targetCheckDataMap.get(checkEntryKey);
        if (targetCheckData == null) {
            failureCount.incrementAndGet();
            continue;
        }

        // 校验checkEntryKey是否与对账实体的id一致
        String basicCheckBizId = basicCheckData.getCheckBizId();
        String targetCheckBizId = targetCheckData.getCheckBizId();
        if (!isCheckBizIdEqual(checkEntryKey, basicCheckBizId, targetCheckBizId)) {
            throw new DataCheckRuntimeException(&quot;checkEntryKey must equals basicCheckBizId and checkEntryKey must equals targetCheckBizId!&quot;);
        }

        // 执行对账
        if (!dataCheckingConsistenceListener.isCheckConsistent(basicCheckData, targetCheckData)) {
            failureCount.incrementAndGet();
            continue;
        }

        successCount.incrementAndGet();
    }
}
</code></pre><p>通过逻辑，我们能够清楚的看到，对账核心逻辑实际上是通过对基准对账Map进行迭代，去key（对账唯一依据）所在的目标对账Map查找对应的目标对账实体，并将基准对账实体与目标对账实体进行比对。</p>
<p>比对的核心逻辑为用户实现的 <strong>DataCheckingConsistenceListener.isCheckConsistent</strong> 方法，框架根据用户返回的数据是否一致的标识，决定是对账成功或者失败，并进行相关数据的统计。</p>
<h3 id="为什么这样设计"><a href="#为什么这样设计" class="headerlink" title="为什么这样设计?"></a>为什么这样设计?</h3><p>实际上，我在开发这个对账框架的时候，是参考了RocketMQ中的某些思想。</p>
<p>RocketMQ在进行消息消费时，允许用户通过实现消费监听器接口，来完成不同种类的消费逻辑，比如说通过实现MessageListenerConcurrently接口，实现并发消息消费。</p>
<p>我开发的对账框架中，也通过定义监听器接口，让用户自定义数据加载、数据比对的具体逻辑，将业务相关的逻辑交给用户，框架本身只关注不变的东西。</p>
<p>这里实际上就是一种依赖倒置思想的集中体现，即：</p>
<blockquote>
<p>1、上层模块不应该依赖底层模块，它们都应该依赖于抽象。</p>
<p>2、抽象不应该依赖于细节，细节应该依赖于抽象。</p>
</blockquote>
<p>框架通过依赖抽象，做到了对用户具体逻辑的灵活适配。对框架而言，通过依赖抽象，提高了扩展性，完全不需要耦合具体的实现；对使用者而言，只需要实现框架提供的回调方法，不需要关注框架是如何对自己编写的业务代码进行调用的，这实际上就是依赖倒置带来的优越性。做到了对扩展开放。</p>
<p>实际上，回调接口/方法就是一种介于框架和使用者之间的协议，只要遵从该协议进行开发，就能够达到完成业务逻辑的目的。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文中，我们通过编写一个简单的对账框架，实现了广义对账场景。</p>
<p>同时通过对代码进行分析，也体会到了面向对象设计原则带来的好处，希望本文能够对你有所帮助，更多精彩的内容敬请持续关注我，也欢迎你关注公众号“分布式朝闻道”，与我一同感受代码之美，技术之貌。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在笔者的公众号上发布了关于 &lt;strong&gt;对账&lt;/strong&gt; 业务分析的一篇文章，&lt;a href=&quot;&quot;&gt;&lt;/a&gt;, 该文也是笔者新书中的一节内容。&lt;/p&gt;
&lt;p&gt;本文作为补充，我们从实战角度，从代码角度呈现一个对账框架的实现。&lt;/p&gt;
&lt;p&gt;注意：本文中提供的对账框架为广义上的对账，也就是说不局限于支付、交易领域的对账场景，凡是需要通过数据比对进行数据校准、比对、核准的场景，均能够采用本文提供的思路进行实现。&lt;/p&gt;
    
    </summary>
    
      <category term="专题-分布式" scheme="http://wuwenliang.net/categories/%E4%B8%93%E9%A2%98-%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="专题-分布式" scheme="http://wuwenliang.net/tags/%E4%B8%93%E9%A2%98-%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>聊聊异构交易场景交互流程及一致性保证</title>
    <link href="http://wuwenliang.net/2021/02/04/%E8%81%8A%E8%81%8A%E5%BC%82%E6%9E%84%E4%BA%A4%E6%98%93%E5%9C%BA%E6%99%AF%E4%BA%A4%E4%BA%92%E6%B5%81%E7%A8%8B%E5%8F%8A%E4%B8%80%E8%87%B4%E6%80%A7%E4%BF%9D%E8%AF%81/"/>
    <id>http://wuwenliang.net/2021/02/04/聊聊异构交易场景交互流程及一致性保证/</id>
    <published>2021-02-04T15:45:13.000Z</published>
    <updated>2021-02-04T15:46:01.921Z</updated>
    
    <content type="html"><![CDATA[<p>事情的经过是这样的，群友四哥发来一个问题，问大家有什么看法，我看了下，刚好之前接触过类似的业务场景，因此斗胆就问题谈谈自己的看法，抛砖引玉。</p>
<p>问题如下：</p>
<blockquote>
<p>A系统联机同步调用B系统（A和B不是同一公司系统，不能用分布式事务），</p>
<p>如何保证系统间数据准实时一致性（聊聊设计思路即可）？</p>
<p>提醒：需要考虑调用超时、并发、幂等、反交易先到等。</p>
<p>各种异常场景怎么处理要考虑更完善些，如事务隔离、并发、反交易先到调用方和服务方约定（前端客户不可能一直等着）</p>
</blockquote>
<a id="more"></a>
<p>这种聊思路的问题，往往问的都很大，或者说比较唬人，实际上遇到这种问题，我们要做的就是抽象。</p>
<p>抽象出场景，抽象出问题的核心要点。</p>
<p>我们能够提炼出要点，非同一公司系统（跨网络，异构）、反交易先到（我们基本能确定提问者大概想知道的思路与交易有关）、服务方预定，前端客户不可能一直等待（交易流程往往是长事务流程，不能简单依靠单个接口调用，基本上是异步流程）。</p>
<p>有了这些前提，我们就可以基本抽象出讨论的背景和模型：</p>
<h2 id="模型与背景提炼"><a href="#模型与背景提炼" class="headerlink" title="模型与背景提炼"></a>模型与背景提炼</h2><p>因为前提是A、B系统分属不同的公司，也就是说A B系统是通过公网进行交互的两套异构系统，极有可能实现的技术栈也各不相同，因此互相之间只能通过暴露在外的接口进行交互，我们就认为是通过http接口进行的交互。</p>
<p>由于是A系统调用B系统，因此我们可以抽象为点对点的消息通信场景，其中A为主动拉取方，B为被拉取方。</p>
<p>问题提到说，我们说不能用分布式事务，其实是在说不能使用强一致/类2PC的事务实现，如2PC、3PC、SEATA等，但是可以利用诸如最大努力通知的柔性方式进行数据的同步。</p>
<p>关于最大努力通知方案，笔者之前的一篇文章已经有过详细的讨论</p>
<p>图</p>
<p>有了方案，我们接着抽象出 <strong>交易单</strong> 这个模型，并为其指定状态机：</p>
<ul>
<li>交易单创建时，状态为 <strong>初始化</strong>，</li>
<li>A系统向B系统发送交易单时改为， <strong>处理中</strong></li>
<li>如果B系统同步响应收单失败，则A系统修改状态为 <strong>失败</strong></li>
<li>同步B系统同步响应收单成功，则A系统修改状态为 <strong>已提单</strong></li>
<li>当B系统处理交易完成，通知A系统交易完成，则A系统修改交易单状态为 <strong>成功</strong>，（此处的成功为真实成功，因为已经发生了资金扣除/积分等标的物的消耗）</li>
<li>当B系统处理交易失败，则通知A系统交易失败，则A系统修改交易单状态为 <strong>失败</strong> （此时的失败假定为B系统在扣钱之前就失败）</li>
</ul>
<h1 id="超时处理方式"><a href="#超时处理方式" class="headerlink" title="超时处理方式"></a>超时处理方式</h1><p>我们讨论一下提单请求发生超时应当如何处理。</p>
<p>A系统的出口网关向B系统的入口网关发起提单请求，这是一个同步通信，对于同步请求的失败（如：签名失败，参数异常失败等），A系统可以发起重试，此时这种请求属于真实的失败，因为压根没有发起交易行为，所以原则上数据是一致的，对于资金而言就是没有发生扣减等行为。</p>
<h2 id="掉单查询"><a href="#掉单查询" class="headerlink" title="掉单查询"></a>掉单查询</h2><p>如果A系统提交提单请求超时，此时未能收到B系统回复的同步 <strong>收单成功</strong> 的响应，则这时候就存在数据不一致的情况。这个场景就是所谓的 <strong>掉单</strong>，则A系统需要对掉单的数据（状态为处理中）发起掉单查询操作，思路就是定时发起查询，获取B系统对交易单的处理情况。</p>
<p>一般而言B系统都会通知A系统发起掉单查询的建议时间，如发起交易单10分钟后即可有处理的确定结果，那么A系统就可以对已提交10分钟以上，状态为 <strong>处理中</strong> 的交易单发起掉单查询。也就是说，10分钟后，这类中间态的数据，AB系统间可以达成一致。</p>
<p>特别的，如果一次掉单查询没能查到确定的结果，则可以设置下一次继续查询，这里推荐采用 <strong>时间衰减策略</strong> 进行查询，这是交易场景乃至中间件中常用的一种未知数据定时同步的通用思路。</p>
<p>图</p>
<h2 id="结果通知"><a href="#结果通知" class="headerlink" title="结果通知"></a>结果通知</h2><p>对于交易场景，处于对数据实时性的考虑，我们常常希望下游系统处理完数据之后能够及时通知我们结果。</p>
<p>在这个场景中就是A系统需要对接B系统的 <strong>交易结果实时通知接口</strong>，当交易单被B系统处理完成之后，B系统会对交易单处理结果发起通知，及时回调A系统处理的结果。此时，A系统成为被调用方，B系统为调用方，相比于掉单查询，结果通知几乎是准实时的，从B系统发起通知到A系统接收到通知往往都在百毫秒级别（支付宝支付结果通知能够达到数十毫秒）。</p>
<p>简单总结下，对于超时的处理，我们就是通过掉单查询和实时通知方式，通过主动轮询处理结果与被动接受结果通知的方式，通过推拉结合的方式共同保证AB系统之间的数据达成最终一致。</p>
<h2 id="并发提单"><a href="#并发提单" class="headerlink" title="并发提单"></a>并发提单</h2><p>对于并发提单而言，其实属于老生常谈类的话题。其本质在于分布式场景下请求的防重放处理思路。</p>
<p>核心就在于请求串行化，我们往往通过CAS、加锁等方式进行处理。</p>
<p>具体到具体的实现细节，CAS方式有数据库状态标识（状态机）、加锁方式其实就是分布式锁，简单的说就是通过分布式锁方式进行处理，通过对一笔交易单加分布式锁，获取分布式锁成功的请求才能发起请求，发起请求后写入幂等记录，完成请求后释放锁，防止并发提交。</p>
<h2 id="幂等思路"><a href="#幂等思路" class="headerlink" title="幂等思路"></a>幂等思路</h2><p>关于幂等，展开说可以单独写一篇文章，那么择日不如状态，我们下一篇文章就聊聊幂等处理的那些常用姿势。</p>
<p>这里为了解答问题，我们说说主要思路，对于细节就不展开了，懂的同学们应该能够很快的心领神会，不懂的也没关系，我们下篇文章就会对幂等进行详细的展开。</p>
<p>对于幂等而言，我们通常需要通过幂等校验来进行，比如：</p>
<ul>
<li>高并发场景下，将幂等标识写入Redis缓存，用于对写请求幂等</li>
<li>或者请求如果量不大，则通过数据库唯一约束进行幂等处理，保证只有一笔交易单落库（如唯一约束 订单号），唯一约束是最后一道防线，用于对写请求幂等</li>
<li>低并发场景下，通过先查询，后插入（更新）的方式也可以进行幂等校验，但是高并发场景下会有重复更新/新增的风险，因此往往需要配合分布式锁共同作用，将并发请求串行化</li>
</ul>
<p>单单就幂等来说，查询天然幂等，更新则可以通过上面的方式进行幂等保证。具体的细节我们后续文章专门讲解。</p>
<h2 id="反交易先到"><a href="#反交易先到" class="headerlink" title="反交易先到"></a>反交易先到</h2><p>首先明确何为“反交易”，反交易，顾名思义，反向交易，我们举个例子就好懂了。</p>
<p>比如说，扣款的反交易，就是冲正（比如说，转账操作，扣除A的钱，给B加钱失败。则A扣除的钱需要补回，这个过程就是冲正。实际的冲正涵盖的范围更广，我们只需要简单认为是扣款的反向操作，但是要区别于提现和充值。）</p>
<p>比如说，A系统请求对交易单支付100元，B系统扣款成功后向A系统返回支付成功的通知消息；此时B系统后续操作故障，导致该交易无法继续进行下去，则B系统对A系统扣除的100元执行了冲正之后，通知A系统交易已冲正退单。</p>
<p>所谓反交易先到，就是说网络发生拥塞，导致冲正退单的消息，先于支付成功的消息先到了。</p>
<p>我们的A系统的交易单不是有状态机么，状态机就是处理反交易先到的利器。</p>
<p>我们要求对于交易的处理是串行的，如何串行，其实简单的说，通过状态机就能很好地实现。</p>
<p>当然要说明的一点是，对于实际情况，需要具体业务具体分析，对于我们当前讨论的场景而言，我们通过状态机能够解决问题，具体过程如下，</p>
<p>我们假定，A系统的交易单的状态机只能按照  处理中-&gt;支付成功-&gt;退单 这个流程进行流转，当退单先于支付成功到达时，我们需要在一个事务中同时完成流水的插入，交易单状态的更新。对于更新操作而言，我们的sql期望如下</p>
<blockquote>
<p>update order set order_status=退单 where order_status=支付成功 and order_id=xxxxx</p>
</blockquote>
<p>由于状态机只允许固定的订单状态迁移，我们在更新状态的时候带上老状态，实际上当前的order_status=处理中，因此update失败。最终处理为通知处理失败，A系统告知B系统对该通知进行重发。那么B系统就只能老老实实的重新发起通知，这也是一个合格的交易系统所必须具备的能力。否则你的系统不支持通知重复发起，用户体验也太差了。</p>
<p>此时由于状态机的原因，交易单状态还是处理中，当被拥塞的支付成功的通知到达，交易单状态成功更新为 <strong>支付成功</strong> 此时执行的update语句为</p>
<blockquote>
<p>update order set order_status=支付成功 where order_status=处理中 and order_id=xxxxx</p>
</blockquote>
<p>后续重试的 退单通知（所谓的反交易）到达后，交易单根据状态机便能够成功进行流转，具体的update语句如下：</p>
<blockquote>
<p>update order set order_status=退单 where order_status=支付成功 and order_id=xxxxx</p>
</blockquote>
<p>从我们的分析看出，只要有状态机存在，无论如何，交易单的状态只能按照 <strong>处理中-&gt;支付成功-&gt;退单</strong>   这个方式流转而不会发生状态的跃迁跳跃。</p>
<p>所以我们说，状态机，就是系统间处理反交易先到的利器，状态机也是交易类系统通用的神兵利器。</p>
<h2 id="前端用户不能一直等待处理思路"><a href="#前端用户不能一直等待处理思路" class="headerlink" title="前端用户不能一直等待处理思路"></a>前端用户不能一直等待处理思路</h2><p>还有一点就是前端客户不可能一直等着，实际上在上述的过程中我们已经解答了这个问题。</p>
<p>我们本次分析问题采用整体的方案是基于最大努力通知的思路，核心的步骤就是 <strong>同步提单</strong>，<strong>掉单查询</strong>，<strong>结果通知</strong>。通过对这几个步骤进行结合，我们就能够避免前端一直等待，因为交易属于一个长事务业务，上游/前端只需要提交成功就可以去干别的事情了，剩下的复杂操作让下游系统慢慢处理，这其实就是体现了异步的思维。</p>
<h2 id="通过对账保障数据一致性"><a href="#通过对账保障数据一致性" class="headerlink" title="通过对账保障数据一致性"></a>通过对账保障数据一致性</h2><p>最后还要提一下，对于交易系统而言，数据一致性保证的兜底方案就是对账机制，关于对账，我在近期也会单独写一篇文章进行详细讨论（又一个flag）。</p>
<p>交易系统通常具备t+1的对账，简单的说就是，<strong>每天生成前一天的对账单</strong>，在我们的这个场景中，A系统每天都向B系统请求自己前一天的交易对账单，下载到本地，通过A系统自己的渠道流水号/交易单号，与B系统提供的交易单进行逐条的对账，这个过程往往能够通过定时任务来自动化的执行，把不一致的交易单对平。从而将两个系统之间的数据达成最终一致，比如说，A系统没收到B系统的通知，掉单查询也没有查到的交易单，往往最终通过对账都能够获取到数据的最终状态。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文，我们针对一个问题，给出了交易场景中常见的数据一致性的保障思路，并通过场景提炼，介绍了交易类场景设计过程中需要注意的思路，希望能够对读者朋友们有所帮助。如果有想法或者建议，欢迎进群讨论，笔者建立该微信群用于与读者朋友交流，只要是技术类的问题，都欢迎进群讨论，技术之路，感谢有你。</p>
<pre><code>3
</code></pre><p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;事情的经过是这样的，群友四哥发来一个问题，问大家有什么看法，我看了下，刚好之前接触过类似的业务场景，因此斗胆就问题谈谈自己的看法，抛砖引玉。&lt;/p&gt;
&lt;p&gt;问题如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A系统联机同步调用B系统（A和B不是同一公司系统，不能用分布式事务），&lt;/p&gt;
&lt;p&gt;如何保证系统间数据准实时一致性（聊聊设计思路即可）？&lt;/p&gt;
&lt;p&gt;提醒：需要考虑调用超时、并发、幂等、反交易先到等。&lt;/p&gt;
&lt;p&gt;各种异常场景怎么处理要考虑更完善些，如事务隔离、并发、反交易先到调用方和服务方约定（前端客户不可能一直等着）&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="专题-分布式" scheme="http://wuwenliang.net/categories/%E4%B8%93%E9%A2%98-%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="专题-分布式" scheme="http://wuwenliang.net/tags/%E4%B8%93%E9%A2%98-%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>软素质: 如何快速熟悉业务逻辑并付诸落地？</title>
    <link href="http://wuwenliang.net/2021/01/30/%E8%BD%AF%E7%B4%A0%E8%B4%A8-%E5%A6%82%E4%BD%95%E5%BF%AB%E9%80%9F%E7%86%9F%E6%82%89%E4%B8%9A%E5%8A%A1%E9%80%BB%E8%BE%91%E5%B9%B6%E4%BB%98%E8%AF%B8%E8%90%BD%E5%9C%B0%EF%BC%9F/"/>
    <id>http://wuwenliang.net/2021/01/30/软素质-如何快速熟悉业务逻辑并付诸落地？/</id>
    <published>2021-01-30T13:52:43.000Z</published>
    <updated>2021-01-30T13:56:03.018Z</updated>
    
    <content type="html"><![CDATA[<p>本次我们不分享技术，我们来聊聊软素质，具体点说，我们来聊聊新人程序员如何快速熟悉业务逻辑并付诸落地。</p>
<p>一个新人程序员，经历了面试的层层磨炼，终于尘埃落定入职心仪的公司。初来乍到，对周围的一切都不熟悉，业务不熟悉，同事也不熟悉。</p>
<p>这其中关系最大的就是对业务和代码的熟悉，如果能够掌握快速熟悉业务逻辑的方法，就能够很快进入到工作角色中，从容不迫的开展新的工作。</p>
<p>那么我们本次分享就从这几个方面展开：</p>
<ul>
<li>如何通过读代码建立对系统的全局观，cover链路上下游</li>
<li>如何画图来辅助自己熟悉业务流程</li>
<li>应当如何学习掌握领域知识</li>
<li>对于方案设计有哪些技巧和注意点</li>
<li>问题排查的大概思路</li>
</ul>
<p>PS： 由于大部分的开发者都是面向业务，因此本次讨论对于中间件类的开发不做进一步展开，后面有机会再分享。</p>
<a id="more"></a>
<h2 id="如何通过读代码建立对系统的全局观，cover链路上下游"><a href="#如何通过读代码建立对系统的全局观，cover链路上下游" class="headerlink" title="如何通过读代码建立对系统的全局观，cover链路上下游"></a>如何通过读代码建立对系统的全局观，cover链路上下游</h2><p>不可否认的是读代码本身不是一件轻松的事情，这意味着我们需要强迫自己站在写代码人的角度去揣摩他当初的想法和意图。<br>而这恰恰就是问题的矛盾点：一段代码质量的高低和当事人当初的心境、所处的环境、经验的高低，甚至和当事人的性格都是息息相关的。</p>
<p>这就造成了即便是同样一个需求，由不同年龄、不同背景、不同工作经验的人来写，最终的效果也是风格各异。</p>
<p>但是基本上每个人都有一套自己对于好代码的评判标准，这里不细说。重点还是要站在代码角度去思考业务。</p>
<p>既然代码不得不去读，那么我们首先要明确的是，<strong>读代码的目的是什么</strong>。</p>
<p>私以为看代码的主要目的是，通过读代码，从代码中梳理上下游之间如何进行交互，以及内部业务逻辑是如何处理以达到某种具体的目的。</p>
<p>读代码基本上都有目的，明确从何处开始读以及怎样读很重要。</p>
<p>如果拿到需求就直接冲到代码细节中去，这往往都得不偿失，其实最好先了解下背景。比如说看一下公司内部有没有成熟的文档，这能够让我们对当前的所做的业务有一个全局的认识；尤其是当文档中还画了系统的架构图、主要业务逻辑的流程图，那简直就是雪中送炭，乐不可支了。即便随着时间推移，项目迭代，有些设计已经发生了变化，但是他也能为加深你对系统的理解起到重要作用。如果运气不好，没有图，也没有文档，那就只好自己去摸索梳理了。</p>
<p>那么如何对新业务新系统进行摸索梳理呢，这里主要指出两个大方向，一个就是通过系统的读代码建立认知，一个就是通过查问题/做需求的方式来逐步对系统进行由点到面的认识。</p>
<p>代码如何去读也是一门学问。</p>
<p>如果乱读一气，抓不住重点，往往使自己陷入焦急的心境之中。我认为比较好的方式是 <strong>带着问题去看。</strong></p>
<p>公司级的项目都是有模块划分的，先明确自己想看哪个模块的代码，如果不知道，一是看文档，文档没有就问一下周围的同学，向他们请教这个模块大概的作用，基本上态度诚恳谦逊，大家都会乐于帮你的。如果所在的团队有着成熟的命名规范，其实通过项目/模块的名称基本上也能大概猜个八九不离十。</p>
<p>确定了模块的大概职责之后，就去寻找代码的入口，从入口开始看起，层层往下，自顶向下的去读去梳理。</p>
<blockquote>
<p>如何发现入口？</p>
</blockquote>
<p>这里我举几个常见的代码入口的例子：</p>
<ul>
<li>RPC 接口</li>
<li>Http接口 </li>
<li>消息生产、消费  </li>
</ul>
<p>对于业务而言，主要有以上的三种方式，其余的方式注入：线程池任务提交、binlog数据同步等相对比较小众，而且都具有显著的特征，很容易找到入口，就不再赘述。</p>
<p>举个例子，比方说，我们找到一个名为auth的包，那么就可以大概的猜想，它应该是用户认证相关的业务逻辑，那么就从这个包入手开始梳理。</p>
<p>梳理的主要目的为明确该模块提供了哪些能力。</p>
<p><strong>从一个方法开始</strong>-&gt;<strong>每个方法执行了哪些内部的业务处理/计算</strong>-&gt;<strong>调用了哪些外部接口</strong>-&gt;<strong>与哪些基础设施进行了交互</strong>（数据持久化了哪些表，写了哪些缓存，发了哪些消息都值得记下来）。边梳理边画个图留作一个重构的依据或者以后反复看的一个依据。</p>
<p>这个过程中最好边梳理边整理文档，必要的时候可以画图，比如使用 <strong>visio、processon</strong> 等工具。</p>
<p>一般而言，同一个包/Class中的方法都是一类能力的聚合，因此我们可以分业务场景、业务能力去看，这样一直梳理下去，基本上就能够对这个项目/模块对外提供的能力有一个系统的认知。</p>
<p>这种地毯式读代码的方式往往需要花费较多的时间和精力，如果没有耐心，很可能坚持不下去。</p>
<blockquote>
<p>那么有没有一种方法，能够让自己快速了解系统的坑点，锻炼自己的排错能力呢？</p>
</blockquote>
<p>当然有，那就是查问题。</p>
<p>基本上对于新人，往往不会直接让你做流程复杂的需求，我们团队的实践是，新人可以去查问题，通过查问题反向跟踪代码逻辑，发现问题修复问题。</p>
<p>如果出现了线上问题，通过查看日志、分析告警、监控，定位异常点，最后定位到业务逻辑有异常，通过异常堆栈反向查找代码，确定问题出现的原因，带着问题去看代码，印象是很深刻的。相信聪明的读者也有类似的体会吧。</p>
<p>这里要多说一句，如果是较为严重的错误或者异常，可以和老员工一起排查，发现问题之后最好是赶紧定位问题，不要发散，不要急着总结。先解决问题，等问题解决以后再复盘整理。</p>
<h3 id="对于复杂业务场景，应该如何整理业务逻辑呢？"><a href="#对于复杂业务场景，应该如何整理业务逻辑呢？" class="headerlink" title="对于复杂业务场景，应该如何整理业务逻辑呢？"></a>对于复杂业务场景，应该如何整理业务逻辑呢？</h3><p>太极有阴阳，业务也有复杂与简单。</p>
<p>对于复杂的业务，比如支付、广告、银行等系统，我们应该如何整理业务逻辑呢？</p>
<p>首先要明确的是，这个过程不会是三两天，而是需要在迭代业务需求的过程中不断思考整理总结，时间短则一两年，长则三五年，甚至五年以上。</p>
<p>对于新人而言，初次接触复杂业务，如果有条件就多参与业务组的代码走读与串讲分享，如果条件不具备，就找和同组的同学吃个饭聊聊天，对业务的背景大致有个了解，这样心里会有些底气。</p>
<p>有句玩笑话是这么说的，业务不在文档里，都在老鸟的脑子里。其实不无道理，熟能生巧嘛。</p>
<p>具体到如何进行逻辑的梳理和走读，我们可以先执行问题分类，对大流程主干的梗概进行罗列，需要明确上下游与本模块有哪些交互，最好落地到一个文档。我始终认为并且付诸实践的就是，好记性不如烂笔头，多做笔记多总结是普通人的良药。</p>
<blockquote>
<p>对于一个复杂的需求，如何梳理？</p>
</blockquote>
<p>我觉得，细节很重要。</p>
<ul>
<li>根据PM业务的需求点着手，去思考背后的问题，权衡一下成本，ROI，找一个比较折中经济适用的设计方法，避免过度设计。</li>
<li>对设计方案进行斟酌取舍，不断在大脑中推演；这是笔者的一个优秀的同事给笔者的建议，他说，当你对一个业务比较了解的时候，就可以自己去推演。基本上能够提前推出哪里有问题和风险，并且能够有充足的时间和PM对接，对需求点进行完善。</li>
<li>邀请同组的同学对自己的方案进行check，不识庐山真面目，只缘身在此山中。有些问题，旁观者看的更清楚。</li>
<li>对于需要进行check的点，需要反复check，如上线计划，急停手段；带着主人翁意识去做事，面向失败设计。</li>
</ul>
<h2 id="如何画图来辅助自己熟悉业务流程"><a href="#如何画图来辅助自己熟悉业务流程" class="headerlink" title="如何画图来辅助自己熟悉业务流程"></a>如何画图来辅助自己熟悉业务流程</h2><p>在上文中，我们提到读代码的过程中往往伴随着画图，那么我们应当如何画图来辅助自己熟悉业务流程？</p>
<p>首先我们应当选择一款适合自己的画图工具，比如visio、processon、亿图图示工具等。</p>
<p>有了工具之后，我们需要了解常用的图例，系统学习UML，对主要的几种图形有所了解，比如泳道图、用例图、流程图、ER图。</p>
<p>画图不在于形式，而在于突出思路和重点，画图的过程中，尽量使图形有层次感，想清楚图是给谁看的，先保证内容契合思路、业务，再进行优化与进一步美化。</p>
<h2 id="应当如何学习掌握领域知识"><a href="#应当如何学习掌握领域知识" class="headerlink" title="应当如何学习掌握领域知识"></a>应当如何学习掌握领域知识</h2><p>我们常说，技术是为业务服务的，技术为业务赋能，而业务又促进了技术的演进和发展。</p>
<p>这里的业务往深了说，其实就是所谓的领域，每个领域都有自身领域的知识，用时髦的说法就是所谓的“统一语言”。</p>
<p>我们说，要有深度和广度，单论广度，就是要学习本行业的领域知识，完善自己的对业务体系的认知。</p>
<p>我们对常见的一些领域进行举例：比如说电商中的订单、 物流、支付、销运、清结算、风控、广告等，都是一个一个的业务领域。每个领域都有自己领域内的统一语言。</p>
<p>我们需要对领域内的统一语言、通用名词进行学习和掌握，这样既能够方便与他人的沟通，还能促使我们用专业的语言描述业务，进而促进代码编写的准确性。</p>
<p>这里我简单介绍几种学习业务领域知识的方法：</p>
<ol>
<li>看书，看书是学习领域知识的一个通用方法。随着互联网的发展，业界已经有很多先驱对自己熟悉的领域进行了梳理和总结，我们如果能够进行学习，就站在了巨人的肩膀上，免去了自己进行探索所花费的时间。比如说，广告行业，基本不错的书籍如《程序化广告》、 《计算广告》、 《信息流广告》，电商领域的《电商产品经理》等书籍都是不错的学习资料；</li>
<li>和别人交流，进入新的工作环境，周围的同事都是老师。带着自己的思考和问题，友好的与同事讨论，沟通，请教，也是提高自己业务领域知识了解的一种方式，大部分情况下，有经验的同事会给出一个学习的方向，这是很宝贵的资源。</li>
<li>多看文档，成熟的企业内部往往都有文档的沉淀。找到这些资料并加以学习，对于自己的提高是相当显著的。如果恰巧你的公司就有这样的条件，那么千万不要忽略。</li>
</ol>
<p>对于新人来讲，对一个新的业务领域建立了一个初步的认知之后，基本上能够应对简单的需求开发任务了。否则连需求都理解不了，那还谈何开展工作呢？</p>
<p>这里我还要多说两句，除了掌握业务领域知识外，最好去了解学习一些 <strong>领域驱动设计</strong> 的思想和概念，不断促使自己站在系统整体的思想高度去思考设计自己的系统。毫不夸张的说，“领域驱动设计”是开发者能力突破的秘诀之一。</p>
<h2 id="对于方案设计有哪些技巧和注意点"><a href="#对于方案设计有哪些技巧和注意点" class="headerlink" title="对于方案设计有哪些技巧和注意点"></a>对于方案设计有哪些技巧和注意点</h2><p>这一部分，我们了解一下一个需求的方案设计要注意哪些点。</p>
<p>这部分内容是从笔者的工作中抽象总结出来的，去除了工作特征明显的点，提炼出了共性的注意点。基本上需求的快速迭代需要注意的点都包含进去了：</p>
<p>方案设计我们主要从以下几个点进行说明：</p>
<ul>
<li>需求背景与目标：交代一下这个需求要解决什么问题，达到怎样的目的。这部分内容一般都是PM直接提供的；</li>
<li>概要设计：为了满足产品需求，我们主要需要从哪些地方进行设计，主要有哪些功能点，这里尽量提供一个全流程的泳道图；</li>
<li>详细设计：对概要设计中提到的功能点进行细化，针对每个功能点，给出流程图；不一定非得细化到伪代码级别，但是关键的条件判断和分支都需要体现，能够促使我们提前对逻辑进行深入的思考，也能提升编码效率；</li>
<li>数据结构：重要的领域模型是如何进行建模的，类如何设计，在这部分展示。一般需要提供类图/ER图；</li>
<li>接口设计：如果需要对外提供接口，那么我们就需要提供对外的接口文档，作为对外交互的依据；</li>
<li>配置设计：配置设计主要是针对关键逻辑的降级开关和某些业务阈值，如果线上确实出现问题需要紧急降级，那么我们就可以在文档中快速获取到开关配置，短时间内通过配置急停开关对问题逻辑进行快速下线；</li>
<li>灰度计划：对于重要的项目，我们都不会直接全量，都会通过灰度计划逐步将新逻辑推到全量；提前设计好灰度计划，能够让自己在灰度的过程中从容不迫；</li>
<li>监控指标：对于关键业务逻辑，我们需要设计一些监控告警指标，比如通过钉钉告警，飞书告警，短信告警 电话告警，保证出现严重问题能够感知到，缩短处理问题的时间。对于监控而言，可以考虑使用CAT进行打点上报； </li>
</ul>
<p>针对配置，我们再补充几点：</p>
<ul>
<li>关于灰度，笔者之前发过一篇文章，专门进行过讲解，感兴趣的读者可以点击查看</li>
<li>急停开关，本质上是面向失败设计，让我们能够在不进行代码打包和重复上线的前提下，实现代码逻辑的热下线操作；</li>
</ul>
<p>这里提到的，基本上就是一个方案设计过程中需要考虑的点，如果有遗留还请多多见谅。读者朋友也可以基于这些要点发展出适合自己的方案设计模板。</p>
<h2 id="问题排查的大概思路"><a href="#问题排查的大概思路" class="headerlink" title="问题排查的大概思路"></a>问题排查的大概思路</h2><p>最后，来介绍一下问题排查的大概思路。</p>
<ol>
<li>快速定位问题，经验很重要。同样的问题，不同经验的同学解决耗费的时间是有明显的区别的，因此我们需要不断了解系统的设计，了解业务上下游交互链路，并对业务中容易导致问题发生的节点进行重点排查和优化；</li>
<li>需要对公司内部的常见的监控/问题排查组件进行了解，知道使用什么工具解决什么问题，这样在出现问题的时候能够借助工具提升问题排查的速度。对于开源的问题排查工具也需要了解，重点吸收工具背后的原理和设计思路；</li>
<li>特殊问题需要特殊处理，如果问题定位困难，先想办法止损。待损失控制之后，再进行进一步的排查，要灵活一些。对于常规问题可以通过沉淀问题排查手册来进行辅助；</li>
</ol>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>写了这么多技术类的文章，本文应该算是目前最不技术的一篇。</p>
<p>我们主要讨论了“快速熟悉业务逻辑并辅助逻辑”的手段和一些常见的思路，如果你恰巧刚入职场，那么本文中的内容应该能够帮助你快速度过菜鸟阶段。</p>
<p>如果你觉得文章不错，欢迎点赞转发，祝每位读者都能建立起自己的一套思维框架，在职场中游刃有余。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本次我们不分享技术，我们来聊聊软素质，具体点说，我们来聊聊新人程序员如何快速熟悉业务逻辑并付诸落地。&lt;/p&gt;
&lt;p&gt;一个新人程序员，经历了面试的层层磨炼，终于尘埃落定入职心仪的公司。初来乍到，对周围的一切都不熟悉，业务不熟悉，同事也不熟悉。&lt;/p&gt;
&lt;p&gt;这其中关系最大的就是对业务和代码的熟悉，如果能够掌握快速熟悉业务逻辑的方法，就能够很快进入到工作角色中，从容不迫的开展新的工作。&lt;/p&gt;
&lt;p&gt;那么我们本次分享就从这几个方面展开：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如何通过读代码建立对系统的全局观，cover链路上下游&lt;/li&gt;
&lt;li&gt;如何画图来辅助自己熟悉业务流程&lt;/li&gt;
&lt;li&gt;应当如何学习掌握领域知识&lt;/li&gt;
&lt;li&gt;对于方案设计有哪些技巧和注意点&lt;/li&gt;
&lt;li&gt;问题排查的大概思路&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;PS： 由于大部分的开发者都是面向业务，因此本次讨论对于中间件类的开发不做进一步展开，后面有机会再分享。&lt;/p&gt;
    
    </summary>
    
      <category term="随笔" scheme="http://wuwenliang.net/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="随笔" scheme="http://wuwenliang.net/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>分布式套路之分库分表漫谈</title>
    <link href="http://wuwenliang.net/2021/01/09/%E5%88%86%E5%B8%83%E5%BC%8F%E5%A5%97%E8%B7%AF%E4%B9%8B%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E6%BC%AB%E8%B0%88/"/>
    <id>http://wuwenliang.net/2021/01/09/分布式套路之分库分表漫谈/</id>
    <published>2021-01-09T09:33:36.000Z</published>
    <updated>2021-01-09T10:59:16.041Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>本文是笔者在一次技术直播过程中的文字大纲，基本上是即兴的，口语化严重。<br>因此对大纲进行整理，用文字方式进行展现。</p>
</blockquote>
<p>既然是“漫谈分库分表”，那么我们需要确定我们要谈什么，不谈什么。</p>
<ol>
<li><p>首先，我们不讨论具体的分库分表框架的实现和源码，这不是我们讨论的范围。</p>
</li>
<li><p>我们讨论的是思路，主要讨论如何分库分表的套路，有什么坑，有什么心得，不针对具体的细节进行展开式讨论。当然我自己的能力有限，只是希望能够抛砖引玉。</p>
</li>
<li><p>我们要明确，分库分表，<strong>并不是一个银弹</strong>，它只是我们针对MySQL单机性能不够的情况下，想要节约成本的一种方式。对于boss来说，既想要想要节约成本，又想要支撑业务，提供稳定持久度性能。</p>
</li>
</ol>
<a id="more"></a>
<p>程序员发挥出聪明才智，绞尽脑汁，日复一日的努力与实践，最终产生出主要的两种方式：</p>
<ol>
<li>agent嵌入式模式，用一个jar包，集成到我们的代码里，在代码里通过路由规则，分片键方式进行分库分表，属于嵌入式方式。</li>
<li>cs模式（客户端-服务端模式），提供一个三方组件， 如： mycat，sharding-sphere中的proxy方式，类似于mycat；存在中心化，需要保证三方组件的高可用。</li>
</ol>
<p>如果有更好的技术选型，我们宁愿不用分库分表，因为它本身就是一个复杂的解决方案。只是一种折中，更合适的是NewSQL、商业化数据库（比方说，Oracle，在大部分场景下，性能足够用，但是费用高昂）。</p>
<p>如果真的有一天，出现了一个优秀的、经济的newSQL, 比方说 oceanbase，tidb，那么我们基本上可以告别分库分表。</p>
<p>我们之所以选择使用分库分表策略，根本上还是因为，一方面是因为我们的使用成本不能太高；一方面，单机DB数据库性能不够了；一方面，newSQL当前还不成熟，太贵，不敢用。</p>
<p>分库分表用的厂家挺多的，有丰富的开源框架，有社区，还有成熟的案例，所以我们采用，</p>
<p>直接原因在于，阿里站台了，我们国内的风气是，阿里用啥我用啥，阿里怎么做我这么 跟风严重。我的想法是，我们还是有自己的技术前瞻性一些看法，最好不要唯阿里，唯技术。</p>
<p>说了这么多，我们回归正题，开始看问题。</p>
<h3 id="1-只做分表可以吗？还是必须要分表又分库，如果是分库的话-库是在多个服务器上吗？这个怎么来考虑"><a href="#1-只做分表可以吗？还是必须要分表又分库，如果是分库的话-库是在多个服务器上吗？这个怎么来考虑" class="headerlink" title="1. 只做分表可以吗？还是必须要分表又分库，如果是分库的话 库是在多个服务器上吗？这个怎么来考虑"></a>1. 只做分表可以吗？还是必须要分表又分库，如果是分库的话 库是在多个服务器上吗？这个怎么来考虑</h3><p>我想说，还是要<strong>看业务规模</strong>，既看当前的业务规模，也看未来3-5年的业务发展趋势。</p>
<p>涉及到技术选型，我们的宗旨是，<strong>永远选择最适合当下业务的、成本最低的，收益最高的</strong>，合适的就是最好的。</p>
<p>我们选择的方案最好是技术团队刚刚好能够hold住的选型。如果选型已经不适合当前的业务发展，那么大可以换套更适合的。这个本来就是事物发展的必然规律。</p>
<p>要么，业务还没发展到一个更高层次，就已经GG了，那么刚刚好，不用浪费钱买更好的设施，刚好止损；</p>
<p>要么，就是当前的方案确实不够用了，我们换了一套更牛X的，虽然说这样会花更多的钱，请更多的人，但是，这不正和我们的心意么，我们的目的本身就是通过合适的技术架构，更加优秀的代码，支持业务发展。</p>
<p>一句话总结就是，既然不得不花钱，那该花就花吧。</p>
<h4 id="分场景讨论"><a href="#分场景讨论" class="headerlink" title="分场景讨论"></a>分场景讨论</h4><p>一图胜千言，我们分别看看这两种场景。</p>
<p>对于 <strong>离线数据分析场景</strong></p>
<p>只分表是够的，因为你主要用来分析数据，分析数据完成之后的数据就可以删掉了。异步任务删掉若干月/天的数据。</p>
<p><img src="/2021/01/09/分布式套路之分库分表漫谈/offline-app.png" alt="offline-app.png"></p>
<p>对于 <strong>实时业务系统</strong></p>
<p>如果是一个分布式的业务系统 2C，需要承载巨量的流量的，建议 <strong>分库分表</strong> 同时考虑。</p>
<p><img src="/2021/01/09/分布式套路之分库分表漫谈/online-app.png" alt="online-app.png"></p>
<h4 id="分库分库的前提，预估业务量"><a href="#分库分库的前提，预估业务量" class="headerlink" title="分库分库的前提，预估业务量"></a>分库分库的前提，预估业务量</h4><p>分库分表的前提，是预估业务量，我们提供一个经验值，不代表最合适的，只是一个定性的分析：</p>
<pre><code>QPS 500-1000以下，   那么采用主从读写分离，基本上足够支撑业务了；

QPS 1000-10000，考虑分布分表是一个比较合适的事情 

12000TPS 30000QPS 32库 1024表 
1000多万 16000QPS 16库512表
</code></pre><p>本质上来说：分库分表是<strong>一锤子买卖</strong>，前期的设计很重要，决定了后期扩容以及数据迁移的难度。在前期设计的时候，大概率我们需要做好未来3-5年的规划，短的话需要做1-2年的规划，根据规划来确定是不是要分库分表，以及分多少库、多少表。</p>
<p>回到问题本身，这个主要取决于当前的业务量，以及业务量的增速。</p>
<p>我们根据这几个维度，给出一组公式：</p>
<pre><code>某年数据增量M = （1 + 数据年增速K）^ n  * 初始数据量 N

第一年增量 M1 = (1+k)   * N 
第二年增量 M2 = (1+K)^2 * N
第三年增量 M3 = (1+K)^3 * N

三年数据总量 M&apos; = N + m1 + m2 + m3
</code></pre><p>我们就以单表承载1000万数据来算，一共要有几张表，当前不一定是1000w，2000w-5000w都可以，这个首先是一个经验值，其次还需要定量分析。</p>
<p>定量的分析，就需要进行压测。我们需要针对你的线上的配置，用一个库的实例去压测，压出你的这个配置下，在不影响系统吞吐量的前提下，单表的最大容量，压测是一个稳妥的环节，能够在前期很好的指导我们进行设计。</p>
<h4 id="我们接着讨论，什么时候需要分库，必须要保证每个数据库都是一个独立的实例么？"><a href="#我们接着讨论，什么时候需要分库，必须要保证每个数据库都是一个独立的实例么？" class="headerlink" title="我们接着讨论，什么时候需要分库，必须要保证每个数据库都是一个独立的实例么？"></a>我们接着讨论，什么时候需要分库，必须要保证每个数据库都是一个独立的实例么？</h4><p>并不是，我们还是要具体问题具体分析。</p>
<p>如果是开发环境，也就是研发RD自己写代码用的库，那么多套库在一台机器上也可以，毕竟开发环境没有并发量，最多拿来开发，只要不用来压测就没啥问题。</p>
<p>如果是线上环境，除了要将库部署到多台机器，还得考虑读写分离，以及库的高可用。线上线下的主要区别在于，<strong>线上有高可用的要求，而线下不需要</strong>。</p>
<p>思考一下，两者区别是什么，区别就在于<strong>成本的控制</strong>。</p>
<p>我们给出结论，具体什么时候要把数据库部署到一台机器实例，还是要看场景，看成本，看自己需不需要。具体问题具体分析。</p>
<h3 id="2-路由键怎么生成？用雪花算法可以吗？如果原来的数据库主键是自增的，没有业务唯一约束，如果迁移之后，原先的数据怎么在分库分表中进行路由"><a href="#2-路由键怎么生成？用雪花算法可以吗？如果原来的数据库主键是自增的，没有业务唯一约束，如果迁移之后，原先的数据怎么在分库分表中进行路由" class="headerlink" title="2. 路由键怎么生成？用雪花算法可以吗？如果原来的数据库主键是自增的，没有业务唯一约束，如果迁移之后，原先的数据怎么在分库分表中进行路由"></a>2. 路由键怎么生成？用雪花算法可以吗？如果原来的数据库主键是自增的，没有业务唯一约束，如果迁移之后，原先的数据怎么在分库分表中进行路由</h3><p>好问题。</p>
<p>首先说，路由键怎么生成？</p>
<p>本质上，<strong>这是一个如何实现一个可靠的分布式发号器的问题</strong>。我们只说思路，因为展开说都能但单独说好半天了。</p>
<p>思路：</p>
<p>对于某些框架而言，他们有自己的主键生成器，比如说shardingSphere/ShardingJDBC 类SnowFlake算法；</p>
<ol>
<li>UUID：字符串形式，确实是唯一，但是可读性差，不好做数学计算，不直观，比较长，占用空间大</li>
<li>SNOWFLAKE：可以用，也可以用改进leaf，leaf本身就是一套完善的分布式发号器，自己也有高可用保障。</li>
</ol>
<p>当然还有别的方式：</p>
<p>因为既然已经做了分库分表，大概率你的系统也是分布式的吧，那么用进程内的发号不是一个理想的方式。</p>
<p>如果要简单实现一种分布式发号服务，我们可以利用 redis increment 实现一套发号器，也可以借助数据库的自增唯一id来做，但是我们还是需要自己进行开发，实现一个发号系统。</p>
<p>简单的上一个图，表达一下思路，这块儿内容之后会单独写文章来讲。</p>
<p><img src="/2021/01/09/分布式套路之分库分表漫谈/2-routekey.png" alt="2-routekey.png"></p>
<p>总结一下就是，本质上，这是一个如何实现一个可靠的分布式发号器的问题。</p>
<p>所以得依赖某个具体的分布式发号机制  这个问题不用纠结，关注一下最终的选型就好，多进行权衡。</p>
<h3 id="3-如果本身是一个单库，并且没有路由键，完全拿主键当唯一标识了，我分库分表怎么玩？"><a href="#3-如果本身是一个单库，并且没有路由键，完全拿主键当唯一标识了，我分库分表怎么玩？" class="headerlink" title="3. 如果本身是一个单库，并且没有路由键，完全拿主键当唯一标识了，我分库分表怎么玩？"></a>3. 如果本身是一个单库，并且没有路由键，完全拿主键当唯一标识了，我分库分表怎么玩？</h3><p>很简单，你原来的唯一标识是什么，分库分表之后还用这个就行了。</p>
<p>但是，因为本身没有一个业务属性的键，所以建议在进行数据迁移之后，加入一个业务属性的自然主键，并且大概率你需要配置一下新的路由规则。</p>
<p>具体的过程为：</p>
<ol>
<li>迁移数据</li>
<li>更改路由配置  指定一个新的查询规则，分库分表的路由规则</li>
<li>改代码，把代码中涉及到C R U D 的代码，比如说DAO、repository中包含的代码，代码都加上路由规则，简单的说你还是可以用原来的id去执行查询 、插入 、删除的，但是主要的改动点就在于你需要有一个路由规则。</li>
</ol>
<p>我们说，数据库迁移到分不分表的核心：是保证数据的完整性，代码该重构就重构，很难有一个全面的不需要改代码的方案，我们只能折中权衡，降低复杂度。</p>
<p>原先的主键id，迁移到分库分表新库中，已经不是连续的了，但是还需要保证unique，新的数据库表中的自增主键还需要有，但是没有业务属性了，之所以分库分表之后还需要有自增主键，主要在于提升插入效率，查询效率。通过主键索引树，进行回表操作。</p>
<p>相当于你原先用了自增id是有业务属性的，这里说句题外话，<strong>请尽量不要使用自增主键代表业务含义</strong>。</p>
<h3 id="3-分片键怎么选择"><a href="#3-分片键怎么选择" class="headerlink" title="3. 分片键怎么选择"></a>3. 分片键怎么选择</h3><p>我们的答案依旧不能给出一个准确的说法，我只能说，要根据业务场景的要求去选择。</p>
<p>这么说太笼统了，我们通过几个例子来表达一下。</p>
<pre><code>对于用户表，使用用户唯一标识， 如：userId作为分片键；
对于账户表，使用账户唯一标识，如：accountId作为分片键；
对于订单表，使用订单唯一标识， 如：orderId作为分片键；
对于商家相关信息表，使用商家唯一标识， 如：merchantId作为分片键；
......
</code></pre><p>如果我们要查一个用户的订单，那么我们应该用userId去路由表，插入订单到订单表，保证一个用户的所有订单都能够分布在一个表分片上。这样做能够很好的避免引入分布式事务。</p>
<p>如果说，维度不是用户，而是其他维度，比方说，我们想<strong>查询某个商家的所有用户的订单</strong>，</p>
<p>那么我们就应该用商家的merchantId也去存一份数据，路由的时候用商家id去路由，只要是这个商家的用户订单，我们写入到商家的订单表里，那么对于商家所属的订单，我们就可以从某个分片上获取到。</p>
<p>用一个图表达，能够很明确的体现上述的说明内容：</p>
<blockquote>
<p>对于用户而言，分片键作用方式如下图：<br><img src="/2021/01/09/分布式套路之分库分表漫谈/usertable.png" alt="usertable.png"></p>
<p>对于商家而言，分片键作用方式如下图：<br><img src="/2021/01/09/分布式套路之分库分表漫谈/merchanttable.png" alt="merchanttable.png"></p>
</blockquote>
<p>所以我们的结论就是：要根据业务场景的要求去选择，具体问题具体分析，尽量保证不引入分布式事务，提升查询效率。</p>
<p>补充一句，对于主流的做法，如果需要有复杂查询，要么依据不同维度去进行双写，要么直接通过引入异构的方式去查询，比方说使用elastic search，或者使用hive等方式。</p>
<h3 id="4-批量插入数据的时候，会往各个分库去插，在实际业务中是否要做分布式事务"><a href="#4-批量插入数据的时候，会往各个分库去插，在实际业务中是否要做分布式事务" class="headerlink" title="4.批量插入数据的时候，会往各个分库去插，在实际业务中是否要做分布式事务"></a>4.批量插入数据的时候，会往各个分库去插，在实际业务中是否要做分布式事务</h3><p>第三个问题或多或少也提到了这个问题的答案。</p>
<p>我们在落地分库分表的过程中，<strong>要尽量避免引入分布式事务</strong>。</p>
<p>因为从上面第三个问题，你会发现，如果我们有路由键，问题就简单的多了，我们大部分情况下不需要引入分布式事务，但是如果没有就很痛苦。</p>
<p>对于乱序插入且需要保证插入事务性的场景，就需要分布式事务。但是这样做效率太低，也不合适。</p>
<p>首先乱序插入的场景并不多，其次如果引入分布式事务，那么事务的粒度也不小，而且对于插入的性能有着显著的影响。不是最佳的方式。</p>
<p>我的建议就是，还是基于最终一致性去做，否则引入分布式事务，太影响效率了，而且也会增加系统的复杂度，我觉得我们设计系统的宗旨就是，能不用复杂的方案就不用，有时间喝喝茶，干点别的何乐而不为呢。</p>
<blockquote>
<p>所以这个问题的结论就是：尽量避免分布式事务，如果不得不引入，需要尽量缩小事务的范围和粒度。通过折中，多去考虑一下方案的可行性，<br>性能很重要，没有分布式事务也能做，怎么做，就是通过最终一致性。</p>
</blockquote>
<p>但是，如果你说 “我就是避免不了分布式事务啊，那咋办嘛”。那就用吧，若无必要，勿增实体。不得不用，就用，没什么好说的。</p>
<h3 id="5-如果一个库有很多张表，对一张表进行分库分表了，此时不分库不分表的表怎么放置，-是否指定到分库里某一个库里面？"><a href="#5-如果一个库有很多张表，对一张表进行分库分表了，此时不分库不分表的表怎么放置，-是否指定到分库里某一个库里面？" class="headerlink" title="5.如果一个库有很多张表，对一张表进行分库分表了，此时不分库不分表的表怎么放置， 是否指定到分库里某一个库里面？"></a>5.如果一个库有很多张表，对一张表进行分库分表了，此时不分库不分表的表怎么放置， 是否指定到分库里某一个库里面？</h3><p>本质上：这是非分库分表的数据与分库分表数据的分布的一个问题。</p>
<p>实际上，分库分表中间件往往都有对应功能，这个功能往往叫做<strong>默认路由规则</strong>，怎么理解呢？</p>
<p>就是说，对于没有分库分表的这些表，走<strong>默认路由规则</strong>  就行了，这样的话始终会路由到default DataSource上去。</p>
<p>相当于是一个白名单。找一下中间件的文档，看看默认路由规则怎么配，基本上中间件都考虑这个问题了，对于ShardingSphere而言，一个配置样例如下：</p>
<pre><code>CustomerNoShardingDBAlgorithm
    default-table-strategy: （缺省表分区策略）
        complex:
        sharding-columns: db_sharding_id
        algorithm-class-name: com.xxx.XxxClass
    tables:
        ops_account_info: （必须要配置这个，才能使用缺省分表策略）
        actual-data-nodes: db-001.ops_account_info
</code></pre><p>详细的举个例子，比方说：</p>
<blockquote>
<p>一个服务在原有的数据库进行分库（比如user库分为了user01,user02）的时候，是把不分表的表强制路由走某一个数据库吗(比如把不分表的表都路由到user01)？</p>
</blockquote>
<p>这里说到的本质就是： 默认路由规则，我们只需要配置某些表走默认路由规则就行了，比方说，我们现在有user 表 order表，config表，其中user表、 order分库分表，而config没有分库分表。</p>
<p>那么我们只需要把config表放在user库的0库，1库，2库，随便某个位置，</p>
<p>放好之后，我们只需要在分库分表中间件的配置文件中配置默认路由规则，把config表特殊配置一下，只要查config表，就走到这个指定的库上去。</p>
<p>其他的也类似 ，只要有这种需求，就增加对应的配置。</p>
<p>一定要显式告诉中间件，哪些表不走路由规则，并且要告诉它，这些表具体放在哪儿，<br>最好是放在请求量不大的库里，或者说单独搞一个库也可以，这个库放的都是不进行分库分表的表，<br>并配置不走路由规则就完事儿了，其实还是默认路由规则。</p>
<p>为什么这么做呢？有什么意图呢？</p>
<blockquote>
<p>我的理解就是：之所以我们分库分表的原因，就是因为请求很大需要降低并发度；而对于请求频率小的表，我们可以不分库分表还是通过单表方式使用，那么就可以配置为默认路由规则就好。</p>
</blockquote>
<h3 id="8-数据迁移流程以及如何保证数据一致性"><a href="#8-数据迁移流程以及如何保证数据一致性" class="headerlink" title="8.数据迁移流程以及如何保证数据一致性"></a>8.数据迁移流程以及如何保证数据一致性</h3><p>简单的概括，数据迁移依赖于数据的双写；数据一致性，依赖于数据完整性校验。</p>
<p>对于迁移而言，我们有以下步骤：</p>
<p><img src="/2021/01/09/分布式套路之分库分表漫谈/sync.png" alt="sync.png"></p>
<ol>
<li>先修改代码，加入双写分库分表代码；进行上线</li>
<li><p>开始进行数据双写，同步增量数据 ；</p>
<p>双写，主要目的是追上实时数据，给全量同步数据一个deadline，保证从这个时间之后的数据都是完整的（同时，通过异步数据完整性校验程序去校验数据完整性，但是如果我们能够保证双写可靠性，这个对比可做可不做。最好还是做一下）</p>
</li>
<li><p>全量历史数据同步，并校验数据完整性；</p>
<p>一般全量数据同步，不用同步写的方式，原因在于同步写入一方面代码耦合度高，一方面是对系统有影响。所以我们往往通过异步方式进行写入，这个过程后文有图进行说明；</p>
</li>
<li><p>去掉双写代码，将查询分库分表的逻辑全量；<br>通过开关切换，在全量数据同步完成之后切换到全量读写分库分表逻辑即可。此时老的逻辑已经没有请求路由过去了，我们只需要找个发版窗口把老逻辑下线就可以，此时线上已经完全迁移到分库分表的代码流程。</p>
</li>
</ol>
<p>最后我想说，一定要回归，一定要回归，一定要回归！！！</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文本来没有计划要写，之所以还是写出来，主要需要感谢群里的朱兄，他给我提供了很多思考的问题，让我能够比较系统的整理了分库分表的思路。</p>
<p>本文其实是一场直播的现场即兴大纲，后来被我总结为一个文章，感兴趣的朋友可以去看下视频，已经上传到哔哩哔哩。</p>
<p><a href="https://www.bilibili.com/video/BV15h41127oQ/" target="_blank" rel="external">图文并茂, 分库分表套路与方案详解</a></p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文是笔者在一次技术直播过程中的文字大纲，基本上是即兴的，口语化严重。&lt;br&gt;因此对大纲进行整理，用文字方式进行展现。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;既然是“漫谈分库分表”，那么我们需要确定我们要谈什么，不谈什么。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;首先，我们不讨论具体的分库分表框架的实现和源码，这不是我们讨论的范围。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;我们讨论的是思路，主要讨论如何分库分表的套路，有什么坑，有什么心得，不针对具体的细节进行展开式讨论。当然我自己的能力有限，只是希望能够抛砖引玉。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;我们要明确，分库分表，&lt;strong&gt;并不是一个银弹&lt;/strong&gt;，它只是我们针对MySQL单机性能不够的情况下，想要节约成本的一种方式。对于boss来说，既想要想要节约成本，又想要支撑业务，提供稳定持久度性能。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="Java" scheme="http://wuwenliang.net/categories/Java/"/>
    
    
      <category term="Java" scheme="http://wuwenliang.net/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>分布式系统开发套路之并发任务执行</title>
    <link href="http://wuwenliang.net/2020/12/31/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%BC%80%E5%8F%91%E5%A5%97%E8%B7%AF%E4%B9%8B%E5%B9%B6%E5%8F%91%E4%BB%BB%E5%8A%A1%E6%89%A7%E8%A1%8C/"/>
    <id>http://wuwenliang.net/2020/12/31/分布式系统开发套路之并发任务执行/</id>
    <published>2020-12-31T14:25:27.000Z</published>
    <updated>2021-01-02T17:08:48.813Z</updated>
    
    <content type="html"><![CDATA[<p>分布式系统开发过程中，我们常常会遇到同时访问多个远程接口，然后在自己的业务逻辑内聚合多个接口的调用结果。这个过程，类比到现实中很像“烧水泡茶”。</p>
<p>在正式讲技术实现之前，我们先以“烧水泡茶”为例，讨论一下并发任务执行在现实中是如何进行的。</p>
<p>烧水泡茶，往往分为如下几步：</p>
<ol>
<li>清洗热水壶 (3min)</li>
<li>烧开水    (8min)</li>
<li>清洗茶壶  (2min)</li>
<li>清洗茶杯  (5min)</li>
<li>准备茶叶  (1min)</li>
<li>泡茶     (3min)</li>
</ol>
<p>这个例子，源自著名数学家华罗庚的《统筹方法》一文，先生试图通过这样一个例子，为我们讲解如何进行统筹，组合不同的步骤，能够在最短的时间内喝到茶水。</p>
<p>那么我们就试着分析一下这个案例，如果我们不加优化，直接通过串行方式进行泡茶工序，那么具体的执行路径就如下图所示：</p>
<p><img src="/2020/12/31/分布式系统开发套路之并发任务执行/sync-tea.png" alt="sync-tea.png"></p>
<a id="more"></a>
<p>也就是说，我们进行“烧水泡茶”的过程是完全串行操作的，假设每个步骤之间是无缝的，那么最终花费的时间 <strong>T0 = 3 + 8 + 2 + 5 + 1 + 3 = 22min</strong>。</p>
<p>我们发现，烧开水的时间很长，在这个时间内完全可以去做别的事情，也就是烧开水的过程可以与其他的步骤并行执行。因为必须要把热水壶洗干净才能烧开水，毕竟卫生是第一位的嘛。也就是说第一步“清洗热水壶”需要单独进行。我们尝试对上面的串行流程稍作统筹优化，得到优化后的泡茶流程。</p>
<p><img src="/2020/12/31/分布式系统开发套路之并发任务执行/async-tea.png" alt="async-tea.png"></p>
<p>我们发现，烧开水的时间 （8min）= 清洗茶壶  (2min) + 清洗茶杯  (5min) + 准备茶叶  (1min)，也就是在等待水烧开的空档里，我们可以按顺序去执行剩余的准备步骤，最后等茶具和开水都准备到位，就可以开始泡茶，然后享受美好的品茗时光了。</p>
<p>改进后的流程，最终花费的时间 <strong>T1 = 3 + 8 + 3 = 14min</strong>。相比完全串行的方式，节省了8分钟。毕竟时间就是金钱，能够提前八分钟喝到美味的茗茶，想想也是一件美好的事情。</p>
<p>从这个例子能够看出，合理的安排不同操作步骤的执行顺序和关系，让没有强关联的步骤能够并发执行，尽量减少不同步骤执行的串行程度，能够在一定程度上达到提升业务逻辑执行效率的目的。</p>
<p>回到技术问题上来，在Java的分布式开发领域，我们常常通过Future + Callable来并发执行任务，提高业务操作的并发度。</p>
<h2 id="聊聊Callable"><a href="#聊聊Callable" class="headerlink" title="聊聊Callable"></a>聊聊Callable</h2><p>首先聊聊Callable。</p>
<blockquote>
<p>Callable位于java.util.concurrent包下，它是一个接口，只声明了一个方法，方法名为call()，简明扼要：</p>
</blockquote>
<p>Callable的声明如下：</p>
<pre><code>public interface Callable&lt;V&gt; {
    /**
    * Computes a result, or throws an exception if unable to do so.
    *
    * @return computed result
    * @throws Exception if unable to compute a result
    */
    V call() throws Exception;
}
</code></pre><p>通过注释和接口声明，可以看出Callable是一个泛型接口，并且call()函数返回的类型就是传递进来的泛型V。</p>
<p>Callable的使用通常需要借助线程池ExecutorService；在ExecutorService中有多个submit的重载方法，其中就有接受Callable实例的方法：</p>
<pre><code>&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);
</code></pre><h2 id="聊聊Future"><a href="#聊聊Future" class="headerlink" title="聊聊Future"></a>聊聊Future</h2><p>了解了Callable之后，我们再了解一下Future。在上文中，我们已经能够通过ExecutorService的submit重载方法看出端倪，submit方法的返回值为一个Future带泛型T。</p>
<p>Future类同样位于java.util.concurrent（再次夸一下，道格李大叔真的优秀）包下，是一个接口：</p>
<pre><code>public interface Future&lt;V&gt; {

    boolean cancel(boolean mayInterruptIfRunning);

    boolean isCancelled();

    boolean isDone();

    V get() throws InterruptedException, ExecutionException;

    V get(long timeout, TimeUnit unit)
        throws InterruptedException, ExecutionException, TimeoutException;
}
</code></pre><p>为了展示方便我去除了注释。</p>
<p>一句话概括Future：我们通过Future能够实现对具体Runnable或者Callable任务的执行结果进行取消（cancel）、查询是否完成（isDone）、获取结果等操作（get）。</p>
<p>当我们需要对一个异步任务获取其返回结果时，可以通过get方法进行操作，get方法支持指定超时时间，当达到超时时间，则会抛出TimeoutException，因此对于超时时间需要谨慎指定，重要的是，该方法会阻塞直到任务返回结果。</p>
<p>我们简单对Future的几个方法的作用进行介绍，方便读者进行理解：</p>
<p>　在Future接口中声明了5个方法，下面依次解释每个方法的作用：</p>
<ol>
<li><p>cancel方法用来取消任务；当任务取消成功则返回true，任务取消失败则返回false。参数mayInterruptIfRunning表示是否允许取消正在执行中且没有执行完毕的任务；</p>
<p>如果设置true，则表示可以取消正在执行过程中的任务。</p>
<p>如果任务已经完成，则无论mayInterruptIfRunning为true还是false，此方法肯定返回false，即如果取消已经完成的任务会返回false；</p>
<p>如果任务正在执行，若mayInterruptIfRunning设置为true，则返回true，若mayInterruptIfRunning设置为false，则返回false；</p>
<p>如果任务还没有执行，则无论mayInterruptIfRunning为true还是false，肯定返回true。</p>
</li>
<li>isCancelled方法表示任务是否被取消成功；如果在任务正常完成前被取消成功，则返回 true；</li>
<li>isDone方法表示任务是否已经完成，若任务完成，则返回true；</li>
<li>get()方法用来获取执行结果，这个方法会产生阻塞，会一直等到任务执行完毕才返回；</li>
<li>get(long timeout, TimeUnit unit)用来获取执行结果，它允许指定超时时间；</li>
</ol>
<h3 id="趁热乎，再看看FutureTask"><a href="#趁热乎，再看看FutureTask" class="headerlink" title="趁热乎，再看看FutureTask"></a>趁热乎，再看看FutureTask</h3><p>日常开发中，我们发现还有个类经常出现在我们的视线中，它就是FutureTask。</p>
<p>我们看看FutureTask的声明就知道它具体是干什么用了。</p>
<pre><code>public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt;
</code></pre><p>我们发现FutureTask实现了接口RunnableFuture，我们再顺着看RunnableFuture声明:</p>
<pre><code>public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; {
    /**
    * Sets this Future to the result of its computation
    * unless it has been cancelled.
    */
    void run();
}
</code></pre><p>我们发现，最终RunnableFuture本质上是Runnable与Future的子类，也就是说它既可以作为Runnable被线程执行，又可以作为Future得到Callable的返回值。</p>
<p>根据里氏替换原则，可以认为FutureTask同时具备Runnable与Future的特性。</p>
<p>毫不夸张的说，FutureTask是事实上的Future接口的唯一实现类。</p>
<p>我们看一下FutureTask的构造器：</p>
<pre><code>public FutureTask(Callable&lt;V&gt; callable) {
}

public FutureTask(Runnable runnable, V result) {
}
</code></pre><p>它提供了两个构造器，能够接收Callable or  Runnable的实例。</p>
<p>用一句话概括，实战中，我们可以使用FutureTask替代Runnable与Future。</p>
<h2 id="如何在实战中应用异步任务并发执行？"><a href="#如何在实战中应用异步任务并发执行？" class="headerlink" title="如何在实战中应用异步任务并发执行？"></a>如何在实战中应用异步任务并发执行？</h2><p>说了这么多，具体应该怎么用呢？</p>
<p>我们还是基于开头提到的“烧水泡茶”例子，用代码方式直观的展示，在实战中，面对多个任务并发执行的场景，应该如何去做。</p>
<h3 id="首先需要一个异步线程池"><a href="#首先需要一个异步线程池" class="headerlink" title="首先需要一个异步线程池"></a>首先需要一个异步线程池</h3><p>根据理论部分的分析，我们得知，执行异步任务需要一个线程池，这里我们定义一个ThreadPoolExecutor</p>
<pre><code>private ExecutorService executorService = new ThreadPoolExecutor(
            Runtime.getRuntime().availableProcessors(),
            2 * Runtime.getRuntime().availableProcessors() + 1,
            5000,
            TimeUnit.SECONDS,
            new LinkedBlockingQueue&lt;Runnable&gt;(),
            new ThreadPoolExecutor.AbortPolicy()
        );
</code></pre><p>再看一次并发泡茶的流程图，我们知道，烧开水、清洗茶壶、清洗茶杯、准备茶叶 这几步是能够并发执行的，我们接着定义对应的任务执行Callable实现类。</p>
<p><img src="/2020/12/31/分布式系统开发套路之并发任务执行/async-tea.png" alt="async-tea.png"></p>
<h3 id="定义准备工作（清洗茶壶、清洗茶杯、准备茶叶）Callable实现类"><a href="#定义准备工作（清洗茶壶、清洗茶杯、准备茶叶）Callable实现类" class="headerlink" title="定义准备工作（清洗茶壶、清洗茶杯、准备茶叶）Callable实现类"></a>定义准备工作（清洗茶壶、清洗茶杯、准备茶叶）Callable实现类</h3><pre><code>public class PrepareTaskCallableTask implements Callable&lt;List&lt;String&gt;&gt; {

    @Override
    public List&lt;String&gt; call() throws Exception {
        List&lt;String&gt; prepareTasks = new ArrayList&lt;&gt;(3);

        // 清洗茶杯
        String cleanTeapot = cleanTeapot();
        // 清洗茶壶
        String cleanTeacup = cleanTeacup();
        // 准备茶叶
        String prepareTea = prepareTea();

        prepareTasks.add(cleanTeapot);
        prepareTasks.add(cleanTeacup);
        prepareTasks.add(prepareTea);

        return prepareTasks;
    }

    /**
    * 清洗茶壶
    * @return
    */
    public String cleanTeapot() {
        try {
            // 执行清洗茶壶任务
            System.out.println(Thread.currentThread().getName() + &quot;-执行[清洗茶壶]任务开始..........&quot;);
            // 清洗茶壶二分钟
            Thread.sleep(2000);
            System.out.println(Thread.currentThread().getName() + &quot;-执行[清洗茶壶]任务结束..........&quot;);
            return &quot;清洗茶壶共使用2分钟&quot;;
        } catch (Exception e) {
            return null;
        }
    }

    /**
    * 清洗茶杯
    * @return
    */
    public String cleanTeacup() {
        try {
            // 执行清洗茶杯任务
            System.out.println(Thread.currentThread().getName() + &quot;-执行[清洗茶杯]任务开始..........&quot;);
            // 清洗茶杯五分钟
            Thread.sleep(5000);
            System.out.println(Thread.currentThread().getName() + &quot;-执行[清洗茶杯]任务结束..........&quot;);
            return &quot;清洗茶杯共使用5分钟&quot;;
        } catch (Exception e) {
            return null;
        }
    }

    /**
    * 准备茶叶
    * @return
    */
    public String prepareTea() {
        try {
            // 执行准备茶叶任务
            System.out.println(Thread.currentThread().getName() + &quot;-执行[准备茶叶]任务开始..........&quot;);
            // 准备茶叶一分钟
            Thread.sleep(1000);
            System.out.println(Thread.currentThread().getName() + &quot;-执行[准备茶叶]任务结束..........&quot;);
            return &quot;清洗茶壶共使用1分钟&quot;;
        } catch (Exception e) {
            return null;
        }
    }
}
</code></pre><p>定义一个CleanTeapotCallableTask类，实现接口Callable，我们定义泛型为List＜String＞用以说明问题，将串行步骤执行结果封装到List中。</p>
<p>我们通过Thread.sleep对应的时长，借以模拟对应的步骤。</p>
<p>实战中，泛型类型往往是远程的对象引用实例，我们只需要指定类型为对应的对象引用实例即可。</p>
<h3 id="定义烧开水Callable实现类"><a href="#定义烧开水Callable实现类" class="headerlink" title="定义烧开水Callable实现类"></a>定义烧开水Callable实现类</h3><pre><code>public class BoilWaterCallableTask implements Callable&lt;String&gt; {

    @Override
    public String call() throws Exception {
        // 执行烧水任务
        System.out.println(Thread.currentThread().getName() + &quot;-执行[烧水任务]开始..........&quot;);
        // 烧水八分钟
        Thread.sleep(8000);
        System.out.println(Thread.currentThread().getName() + &quot;-执行[烧水任务]结束..........&quot;);
        return &quot;烧开水共使用8分钟&quot;;
    }
}
</code></pre><p>定义烧开水对应的异步任务Callable实现类，设置烧开水用时共需8分钟，并返回烧开水结果字符串。</p>
<h3 id="通过线程池-callable-future执行异步任务"><a href="#通过线程池-callable-future执行异步任务" class="headerlink" title="通过线程池+callable+future执行异步任务"></a>通过线程池+callable+future执行异步任务</h3><p>原材料已经准备完毕，接着就是我们的重头戏，通过线程池+callable+future执行异步任务。</p>
<p>直接看代码：</p>
<pre><code>public static void main(String[] args) throws ExecutionException, InterruptedException {
    long startTime = System.currentTimeMillis();
    // 提交 准备工作任务（清洗茶壶+清洗茶杯+准备茶叶） 到线程池
    PrepareTaskCallableTask prepareTaskCallableTask = new PrepareTaskCallableTask();
    Future&lt;List&lt;String&gt;&gt; prepareTaskFuture = executorService.submit(prepareTaskCallableTask);
    // 提交 烧开水任务 到线程池
    BoilWaterCallableTask boilWaterCallableTask = new BoilWaterCallableTask();
    Future&lt;String&gt; boilWaterFuture = executorService.submit(boilWaterCallableTask);

    // 并行任务结果获取
    List&lt;String&gt; prepareResultList = prepareTaskFuture.get();
    String boilWaterResult = boilWaterFuture.get();
    long finishedTime = System.currentTimeMillis();

    long taskTime = finishedTime - startTime;
    System.out.println(&quot;共耗时:&quot; + taskTime + &quot;毫秒&quot;);
    System.out.println(prepareResultList);

    executorService.shutdown();
}
</code></pre><p>代码分析如下：</p>
<ol>
<li>我们通过自定义的线程池并发提交了准备工作任务、烧开水任务到线程池；</li>
<li>通过对应任务提交返回的Future对象引用的get()方法并行获取任务结果</li>
<li>最后打印任务执行时间与任务执行结果</li>
</ol>
<p>运行结果如下：</p>
<pre><code>pool-1-thread-1-执行[清洗茶壶]任务开始..........
pool-1-thread-2-执行[烧水任务]开始..........
pool-1-thread-1-执行[清洗茶壶]任务结束..........
pool-1-thread-1-执行[清洗茶杯]任务开始..........
pool-1-thread-2-执行[烧水任务]结束..........
pool-1-thread-1-执行[清洗茶杯]任务结束..........
pool-1-thread-1-执行[准备茶叶]任务开始..........
pool-1-thread-1-执行[准备茶叶]任务结束..........
共耗时:8002毫秒
[清洗茶壶共使用2分钟, 清洗茶杯共使用5分钟, 清洗茶壶共使用1分钟]
烧开水共使用8分钟
</code></pre><p>可以看到两个任务通过并发执行的方式，提升了执行效率。</p>
<h3 id="思考：如果并行任务执行的时间不一样长会怎样？"><a href="#思考：如果并行任务执行的时间不一样长会怎样？" class="headerlink" title="思考：如果并行任务执行的时间不一样长会怎样？"></a>思考：如果并行任务执行的时间不一样长会怎样？</h3><p>上文中的“烧水泡茶”例子中，<strong>烧开水的时间 （8min）= 清洗茶壶  (2min) + 清洗茶杯  (5min) + 准备茶叶  (1min)</strong>，也就是两个并行任务执行的时间刚好相同，</p>
<p>但是实际开发中，我们面临的往往是不同任务的并发执行，他们各自的执行时长也往往各不相同，放在这个例子中，如果准备工作中任意一个耽误了时间，那么烧开水的时间就小于准备时间。比如说，一下子来了很多客人，茶杯需要准备多准备几个，等开水烧好了，茶杯还是没有清洗干净。此时，流程图变成了这个样子：</p>
<p><img src="/2020/12/31/分布式系统开发套路之并发任务执行/async-tea2.png" alt="async-tea2.png"></p>
<p>假设清洗茶杯的时间增加到了7分钟，则 准备时间 = 清洗茶壶  (2min) + <strong>清洗茶杯  (7min)</strong> + 准备茶叶  (1min) = <strong>10min</strong> 那么修改一下代码，再次执行，可以看到运行结果变成了：</p>
<pre><code>pool-1-thread-1-执行[清洗茶壶]任务开始..........
pool-1-thread-2-执行[烧水任务]开始..........
pool-1-thread-1-执行[清洗茶壶]任务结束..........
pool-1-thread-1-执行[清洗茶杯]任务开始..........
pool-1-thread-2-执行[烧水任务]结束..........
pool-1-thread-1-执行[清洗茶杯]任务结束..........
pool-1-thread-1-执行[准备茶叶]任务开始..........
pool-1-thread-1-执行[准备茶叶]任务结束..........
共耗时:10002毫秒
[清洗茶壶共使用2分钟, 清洗茶杯共使用7分钟, 清洗茶壶共使用1分钟]
烧开水共使用8分钟
</code></pre><h3 id="思考：多任务并发提交，如何提高运行效率？"><a href="#思考：多任务并发提交，如何提高运行效率？" class="headerlink" title="思考：多任务并发提交，如何提高运行效率？"></a>思考：多任务并发提交，如何提高运行效率？</h3><p>总执行时长变为10分钟，那么我们就可以得出一个结论：</p>
<p><strong>当存在多个并发任务执行时，最终消耗的时间为并发任务中执行时间最长的那个任务所花费的时间。</strong>  </p>
<p>这个结论理解起来也很容易，多个任务并发执行，别的任务都执行完了，就剩下那个执行最慢的任务了，当最慢的任务执行完成的时候，全部任务也就执行完成了。有点类似“木桶原理”，木桶能够承载的水量取决于最短的那条木板的长度，对应到我们的并发任务执行场景中来就是：<strong>要缩短并发任务执行的总时长，需要优先考虑优化执行最耗时的那个任务所耗费的时间</strong>。</p>
<p>这也是我们这一小节题目的答案。</p>
<p>对串行流程采用多任务并发提交这个操作本身就已经大幅度提升了代码逻辑的执行效率，进一步优化，我们应当优先关注多个任务中最耗时的那一个任务，对其执行优化，能够显著提升整体任务的执行效率，缩短执行耗时。</p>
<h2 id="思考：如果存在大量相同任务，如何使用并发任务提交来提升执行效率？"><a href="#思考：如果存在大量相同任务，如何使用并发任务提交来提升执行效率？" class="headerlink" title="思考：如果存在大量相同任务，如何使用并发任务提交来提升执行效率？"></a>思考：如果存在大量相同任务，如何使用并发任务提交来提升执行效率？</h2><p>上文中提到的场景，执行步骤能够穷举出来。</p>
<p>可是现实总是多变的，我们还是以本文的“烧水泡茶”为例，以清洗茶杯流程，假设我们洗一个茶杯要10秒，洗10个就是100秒，一个人能够做的过来，假设我们一次要洗1000个杯子，让一个人洗，需要耗费10000s，也就是约等于167分钟，接近三个小时。想想也是一个恐怖的事情，假设这是一个大型的宴会，等到1000个杯子洗完，宴会都快结束了，宾客们还是没能喝上酒水。严重影响用户体验。</p>
<p>这种场景，在代码开发中，就是通过循环调用，在一个线程中做大量工作，比如批量对账场景，在一个线程中对所有的商家执行对账，任务纯串行化，并发度完全没有，如果商家数量有几百万，耗时需要几个小时，效率很低。</p>
<p>这个时候，作为一个有追求的开发者，我们会下意识的想，我们是不是可以基于多线程并发任务提交，来并行执行这种大批量、重复度高的任务呢？</p>
<p>当然可以，就使用上文中的 <strong>线程池 + future + callable</strong> 就能够达到目的。</p>
<h3 id="场景定义：多人同时洗杯子"><a href="#场景定义：多人同时洗杯子" class="headerlink" title="场景定义：多人同时洗杯子"></a>场景定义：多人同时洗杯子</h3><p>我们就以<strong>多人洗杯子</strong> 这个业务场景进行案例实战模拟，为了缩短案例运行时间（本质上和现实没有区别），我们假设有1000个杯子，10个人洗，每人清洗100个杯子，每个杯子清洗时间平均耗时1秒，我们用并发任务批量提交的方式看一下相比于单人串行方式有多大的性能提升。</p>
<h4 id="定义洗杯子Callable实现类"><a href="#定义洗杯子Callable实现类" class="headerlink" title="定义洗杯子Callable实现类"></a>定义洗杯子Callable实现类</h4><p>我们还是编写一个洗杯子的Callable实现类：</p>
<pre><code>public class CleanTeacupCallableTask implements Callable&lt;String&gt; {

    /**工人编号*/
    private String id;
    /**需要清洗的茶杯数量*/
    private int amount;

    public CleanTeacupCallableTask(String id, int amount) {
        this.id = id;
        this.amount = amount;
    }

    @Override
    public String call() throws Exception {
        try {
            if (amount &lt;= 0) {
                return null;
            }
            // 执行清洗茶杯任务
            System.out.println(Thread.currentThread().getName() + &quot;-执行[清洗茶杯]任务开始..........&quot; + &quot;数量:&quot; + amount);

            long totalTimeMills = 0L;
            for (int i = 0; i &lt; amount; i++) {
                totalTimeMills = amount * 1000;
            }
            Thread.sleep(totalTimeMills);
            System.out.println(Thread.currentThread().getName() + &quot;-执行[清洗茶杯]任务结束..........&quot; + &quot;数量:&quot; + amount);
            return id + &quot;-清洗茶杯共使用&quot; + totalTimeMills / 1000 + &quot;秒&quot;;
        } catch (Exception e) {
            return null;
        }
    }
}
</code></pre><p>我们计划为每个工人分配一个茶杯清洗任务CleanTeacupCallableTask，它的构造方法接收两个参数： 工人编号、需要清洗的茶杯数量。</p>
<p>则 <strong>每个工人需要花费的清洗总时长 = 单个茶杯清洗耗时 * 需要清洗的茶杯数量</strong>。</p>
<h4 id="编写测试代码"><a href="#编写测试代码" class="headerlink" title="编写测试代码"></a>编写测试代码</h4><p>我们接着编写测试代码，通过线程池批量提交茶杯并发清洗任务。</p>
<pre><code>public static void main(String[] args) throws ExecutionException, InterruptedException {
    long startTime = System.currentTimeMillis();

    // 杯子共1000个
    int cupAmount = 1000;
    // 共10个工人
    int workerAmount = 10;
    // 每人清洗数量
    int cleanCupsPerWorker = cupAmount / workerAmount;

    // 定义Future列表
    List&lt;Future&lt;String&gt;&gt; futures = new ArrayList&lt;&gt;(workerAmount);
    for (int i = 0; i &lt; workerAmount; i++) {
        CleanTeacupCallableTask cleanTeacupCallableTask = new CleanTeacupCallableTask(&quot;worker-&quot; + i, cleanCupsPerWorker);
        Future&lt;String&gt; cleanTeacupFuture = executorService.submit(cleanTeacupCallableTask);
        // future对象引用添加到futures列表
        futures.add(cleanTeacupFuture);
    }

    // 返回结果列表
    List&lt;String&gt; resultList = new ArrayList&lt;&gt;(workerAmount);
    futures.stream().forEach(cleanTeacupFuture -&gt; {
        // 尝试获取远端结果
        String result = null;
        try {
            result = cleanTeacupFuture.get();
        } catch (Exception e) {
            result = null;
        }
        resultList.add(result);
    });

    // 遍历结果列表
    for (int i = 0; i &lt; resultList.size(); i++) {
        System.out.println(resultList.get(i));
    }

    long finishedTime = System.currentTimeMillis();
    long taskTime = finishedTime - startTime;
    System.out.println(&quot;共耗时:&quot; + taskTime + &quot;毫秒&quot;);

    executorService.shutdown();
}
</code></pre><p>代码注释也比较详细，我们主要做了以下几件事情：</p>
<ol>
<li>定义了待清洗的茶杯总数、清理工人数量，并计算得出每个工人需要清洗的茶杯数量；</li>
<li>为每个工人提交了一个茶杯清洗异步任务，并将返回的future结果封装到一个List中；</li>
<li>遍历future列表，尝试获取远端的返回值，并将返回值封装到一个List中；</li>
<li>打印结果并计算耗时</li>
</ol>
<h4 id="多人同时洗杯子运行结果"><a href="#多人同时洗杯子运行结果" class="headerlink" title="多人同时洗杯子运行结果"></a>多人同时洗杯子运行结果</h4><pre><code>pool-1-thread-1-执行[清洗茶杯]任务开始..........数量:100
pool-1-thread-5-执行[清洗茶杯]任务开始..........数量:100
pool-1-thread-4-执行[清洗茶杯]任务开始..........数量:100
pool-1-thread-3-执行[清洗茶杯]任务开始..........数量:100
pool-1-thread-2-执行[清洗茶杯]任务开始..........数量:100
pool-1-thread-7-执行[清洗茶杯]任务开始..........数量:100
pool-1-thread-6-执行[清洗茶杯]任务开始..........数量:100
pool-1-thread-9-执行[清洗茶杯]任务开始..........数量:100
pool-1-thread-8-执行[清洗茶杯]任务开始..........数量:100
pool-1-thread-10-执行[清洗茶杯]任务开始..........数量:100


pool-1-thread-8-执行[清洗茶杯]任务结束..........数量:100
pool-1-thread-3-执行[清洗茶杯]任务结束..........数量:100
pool-1-thread-4-执行[清洗茶杯]任务结束..........数量:100
pool-1-thread-9-执行[清洗茶杯]任务结束..........数量:100
pool-1-thread-5-执行[清洗茶杯]任务结束..........数量:100
pool-1-thread-2-执行[清洗茶杯]任务结束..........数量:100
pool-1-thread-6-执行[清洗茶杯]任务结束..........数量:100
pool-1-thread-7-执行[清洗茶杯]任务结束..........数量:100
pool-1-thread-1-执行[清洗茶杯]任务结束..........数量:100
pool-1-thread-10-执行[清洗茶杯]任务结束..........数量:100

worker-0-清洗茶杯共使用100秒
worker-1-清洗茶杯共使用100秒
worker-2-清洗茶杯共使用100秒
worker-3-清洗茶杯共使用100秒
worker-4-清洗茶杯共使用100秒
worker-5-清洗茶杯共使用100秒
worker-6-清洗茶杯共使用100秒
worker-7-清洗茶杯共使用100秒
worker-8-清洗茶杯共使用100秒
worker-9-清洗茶杯共使用100秒

共耗时:100002毫秒
</code></pre><p>可以看到，我们为10个工人分配了10个线程并发提交了10个茶杯清洗任务，10个工人同时开始了各自的茶杯清洗工作，最终当所有工人清洗完茶杯之后，共耗时100秒（PS:笔者使用的笔记本安装一颗8核心16线程CPU，能够同时开启16线程执行并行任务）。</p>
<p>这符合我们最初做的假设，即对于1000个杯子，10个工人并行清洗，每个杯子清洗平均耗时1s，只需要花费100秒；相同的工作由单个工人执行，则需要结结实实花费1000秒。通过并行方式，将任务执行效率提升了整整10倍，这是很客观的性能提升。</p>
<p>用图形来表示是这样的：</p>
<h5 id="单个工人串行清洗杯子"><a href="#单个工人串行清洗杯子" class="headerlink" title="单个工人串行清洗杯子"></a>单个工人串行清洗杯子</h5><p><img src="/2020/12/31/分布式系统开发套路之并发任务执行/single-clean-teacup.png" alt="single-clean-teacup.png"></p>
<h5 id="多个工人并发清洗杯子"><a href="#多个工人并发清洗杯子" class="headerlink" title="多个工人并发清洗杯子"></a>多个工人并发清洗杯子</h5><p><img src="/2020/12/31/分布式系统开发套路之并发任务执行/multi-clean-teacup.png" alt="multi-clean-teacup.png"></p>
<h3 id="注意：一种错误的使用方式"><a href="#注意：一种错误的使用方式" class="headerlink" title="注意：一种错误的使用方式"></a>注意：一种错误的使用方式</h3><p>上文中，我们通过“烧水泡茶”、“多人清洗杯子”等案例，讲解了<strong>多步骤并发任务提交</strong> 以及 <strong>批量任务并发提交</strong> 的思路及代码实现，均达到了目的。</p>
<p>但是实际开发中，我们发现有的同学初衷是想通过并发任务提交方式提升系统执行效率，但由于学艺不精或者一时糊涂，使用了错误的方式，将并发代码最终通过串行方式运行了，并没能实现通过多线程方式提升逻辑运行效率的目的。我们此处就看一下常见的错误使用方式是如何“巧夺天工”地将代码串行化的，我们还是以“烧水泡茶”案例来说明。</p>
<p>具体的任务编写代码没有什么问题，问题出在并发任务提交的逻辑编写上，错误使用方式的代码是这么写的：</p>
<pre><code>public static void main(String[] args) throws ExecutionException, InterruptedException {
    long startTime = System.currentTimeMillis();

    // 提交 准备工作任务（清洗茶壶+清洗茶杯+准备茶叶） 到线程池
    PrepareTaskCallableTask prepareTaskCallableTask = new PrepareTaskCallableTask();
    Future&lt;List&lt;String&gt;&gt; prepareTaskFuture = executorService.submit(prepareTaskCallableTask);
    List&lt;String&gt; prepareResultList = prepareTaskFuture.get();
    // 提交 烧开水任务 到线程池
    BoilWaterCallableTask boilWaterCallableTask = new BoilWaterCallableTask();
    Future&lt;String&gt; boilWaterFuture = executorService.submit(boilWaterCallableTask);
    String boilWaterResult = boilWaterFuture.get();

    long finishedTime = System.currentTimeMillis();

    long taskTime = finishedTime - startTime;
    System.out.println(&quot;共耗时:&quot; + taskTime + &quot;毫秒&quot;);
    System.out.println(prepareResultList);
    System.out.println(boilWaterResult);

    executorService.shutdown();
}
</code></pre><p>对比正确的写法，有没有发现问题出在哪儿？</p>
<p>相信聪明的你已经看出来了，错误的写法是针对每个任务的提交结果分别进行了get()操作，当A任务提交之后就通过get()尝试获取结果，阻塞了主线程；当A任务执行结果获取到之后再提交B任务，并通过get()尝试获取结果，最终执行的结果如下：</p>
<pre><code>pool-1-thread-1-执行[清洗茶壶]任务开始..........
pool-1-thread-1-执行[清洗茶壶]任务结束..........
pool-1-thread-1-执行[清洗茶杯]任务开始..........
pool-1-thread-1-执行[清洗茶杯]任务结束..........
pool-1-thread-1-执行[准备茶叶]任务开始..........
pool-1-thread-1-执行[准备茶叶]任务结束..........
pool-1-thread-2-执行[烧水任务]开始..........
pool-1-thread-2-执行[烧水任务]结束..........
共耗时:16003毫秒
[清洗茶壶共使用2分钟, 清洗茶杯共使用5分钟, 清洗茶壶共使用1分钟]
烧开水共使用8分钟
</code></pre><p>可以看到，两个任务执行时长 = 准备工作8分钟 + 烧开水8分钟 = 16分钟！</p>
<p>也就是说，这种错误的使用方式，将并发任务本质上写成了串行任务！如果是对实效性要求很高的业务场景，后果是很严重的！尤其是实时对账、实时多接口查询，将大幅度提升系统的单次调用执行时长，严重影响接口RT，如果是2C业务，将直接影响到用户体验。</p>
<h2 id="反思及总结"><a href="#反思及总结" class="headerlink" title="反思及总结"></a>反思及总结</h2><p>本文篇幅较长，内容虽看似简单，但充斥着玄机。</p>
<p>我们通过一个“烧水泡茶”的例子引出并发任务提交的场景，并展示了代码具体如何编写。</p>
<p>随后，基于批量任务执行的场景，又给出了对应的代码案例，对于离线任务批处理，在线实时批量调用，通过线程池异步并发任务批量执行的方式能够大幅度提升业务执行效率。</p>
<p>文章最后，我们给出了一个并发任务编写的“bad case”，这警示我们：对于技术细节，要尽量知其然，知其所以然。只知道皮毛很容易用错，而对于多线程的技术点，一旦用错，极易引发严重后果。</p>
<p>文章中提供了大量的图例和运行结果展示，希望能够通过笔者笨拙的描述，对你在实战中运用 线程池+future+callable 异步任务执行逻辑的编写有所帮助。</p>
<h2 id="下期预告"><a href="#下期预告" class="headerlink" title="下期预告"></a>下期预告</h2><p>你以为到这里就结束了？</p>
<p>熟悉笔者风格的同学马上就意识到，问题没有这么简单。</p>
<p>在Java8中，更新了新的异步任务执行框架–CompletableFuture，它提供了丰富的并发任务组合提交、回调等特性。</p>
<p>在这个技术日益内卷的时代，对底层干饭型程序员，唯有学习才能破局。那么我们下期就通过CompletableFuture继续讲解更多的异步任务并发执行的姿势，让我们不见不散。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;分布式系统开发过程中，我们常常会遇到同时访问多个远程接口，然后在自己的业务逻辑内聚合多个接口的调用结果。这个过程，类比到现实中很像“烧水泡茶”。&lt;/p&gt;
&lt;p&gt;在正式讲技术实现之前，我们先以“烧水泡茶”为例，讨论一下并发任务执行在现实中是如何进行的。&lt;/p&gt;
&lt;p&gt;烧水泡茶，往往分为如下几步：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;清洗热水壶 (3min)&lt;/li&gt;
&lt;li&gt;烧开水    (8min)&lt;/li&gt;
&lt;li&gt;清洗茶壶  (2min)&lt;/li&gt;
&lt;li&gt;清洗茶杯  (5min)&lt;/li&gt;
&lt;li&gt;准备茶叶  (1min)&lt;/li&gt;
&lt;li&gt;泡茶     (3min)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这个例子，源自著名数学家华罗庚的《统筹方法》一文，先生试图通过这样一个例子，为我们讲解如何进行统筹，组合不同的步骤，能够在最短的时间内喝到茶水。&lt;/p&gt;
&lt;p&gt;那么我们就试着分析一下这个案例，如果我们不加优化，直接通过串行方式进行泡茶工序，那么具体的执行路径就如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/12/31/分布式系统开发套路之并发任务执行/sync-tea.png&quot; alt=&quot;sync-tea.png&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Java" scheme="http://wuwenliang.net/categories/Java/"/>
    
    
      <category term="Java" scheme="http://wuwenliang.net/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>安好,不易,惊喜,我的2020总结</title>
    <link href="http://wuwenliang.net/2020/12/31/%E5%AE%89%E5%A5%BD-%E4%B8%8D%E6%98%93-%E6%83%8A%E5%96%9C-%E6%88%91%E7%9A%842020%E6%80%BB%E7%BB%93/"/>
    <id>http://wuwenliang.net/2020/12/31/安好-不易-惊喜-我的2020总结/</id>
    <published>2020-12-31T06:47:27.000Z</published>
    <updated>2020-12-31T07:16:29.797Z</updated>
    
    <content type="html"><![CDATA[<p>一直推迟到现在，才逼迫自己打开编辑器，敲下题目。</p>
<p>原本都不计划写年终总结了，总觉得没什么可写。这一年，黑天鹅飞过的一年；这一年，节奏飞快的一年；这一年，与口罩度过最长时光的一年；这一年，也是白驹过隙，充满变化的一年。</p>
<p>妻说，写吧，写了这么多年，而且今年这么特别，等多年以后回头再读，想必会有别样的感悟。我无言。</p>
<p>那就写吧，于2020的末尾，我郑重的写下这个题目，关键词，安好、不易、惊喜。</p>
<p>安好，身边的所有人都安好。</p>
<p>年初的疫情席卷而来，经历了在家办公，经历了严密的管控，安好，都好。</p>
<p>2020，好好活着，就是最大的收获。再也没有比生命更让人值得眷恋。</p>
<p>年纪大了，泪点低了，看着新闻里各个地方的感人事迹，人间英雄，大爱无疆，每次都湿了双眼，然后心怀感恩。</p>
<p>活着，活在这片土地，身为国人而活着，骄傲而自信。</p>
<p>母亲从伤病中恢复，浓密的头发再次茂盛，眼角的笑容又一次绽放，一切安好。</p>
<p>不易，在疫情中换了工作，确实不易，当自己从决定换工作到开始行动，再到最终尘埃落定，只用了5天。妻全程陪伴，给予我全方位的关心和鼓励。因为有她所以我能够一直向前。</p>
<p>来到袋鼠团，我发现我爱上了这个团队，学习型的团队，美团就是一所大学，如果你热爱学习，她会提供各种学习的机会，让你提升，让你去挑战自我。虽然白开水有时候确实不太好喝，嗓子难受，不过这不妨碍我们对她的赞美。</p>
<p>来到一个年轻的，充满激情的，有温度的团队，是我的荣幸。2021年，期待和你们继续披荆斩棘，继续纵情，不断向前。</p>
<p>惊喜，我收到了可以说是前半生最珍贵的礼物，也将会是我付出最大努力去关爱的作品。我即将为人父。</p>
<p>惊喜，又有些紧张，伴随着好奇，我陪着妻，等待着他/她的来临，呵，孩子，我们的孩子，陪你一起成长。</p>
<p>感谢妻，给我一个家庭，让我学着成为一个父亲。</p>
<p>总结是条理的，也是纷乱的，有很多事情想说，但是又觉得不足以与这些并列。</p>
<p>往年总是会对自己一年来学习的东西总结，看了多少书，技术提升了多少。</p>
<p>现在感觉这些都是应该做的，还是简单说说吧。</p>
<p>年末在leader的建议之下，建立了公众号，从此博客成为了文章的备份，也收获了300多粉丝，不算多，但是对我而言，有粉丝在，就是对我的督促，我会在公众号里把自己的工作经验和想法全数分享，倾听别人的意见，收获彼此共同的成长。</p>
<p>加入了一个有温度的技术群，群名也很有朝气和学习气息 “业精于勤荒于嬉”，群里的小伙伴涵盖了70 80 90 00 后，大家为了同一个目标“交流技术，提升能力”聚集在一起，和他们交流已经成为生活中的一部分，公众号中的文章也有来自他们的灵感和付出。2021，我们一起立下flag，继续努力提升自己。</p>
<p>2021，黑天鹅还在盘旋，但生活仍在继续。</p>
<p>保持学习热情，继续提升自己的软硬实力，再让自己平和一些，成熟一些；立个flag吧，万一实现了呢。公众号会继续更新，分布式开发中那些常见的套路，会在2021年更新结束；DDD实战经验系列，也会继续更新；</p>
<p>保护好身体，多陪陪家人，学着做一个合格的父亲，像我父亲一样。</p>
<p>保持思考，要多想，保持质疑，不从众，坚持对的，有原则。努力做一个有温度的人，努力做一个有想法的人。</p>
<p>一切过往，皆为序章，我们的征途是星辰大海。</p>
<p>2021，你好。</p>
<p>写于2021.12.31下午，北京。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一直推迟到现在，才逼迫自己打开编辑器，敲下题目。&lt;/p&gt;
&lt;p&gt;原本都不计划写年终总结了，总觉得没什么可写。这一年，黑天鹅飞过的一年；这一年，节奏飞快的一年；这一年，与口罩度过最长时光的一年；这一年，也是白驹过隙，充满变化的一年。&lt;/p&gt;
&lt;p&gt;妻说，写吧，写了这么多年，而
    
    </summary>
    
      <category term="年度总结" scheme="http://wuwenliang.net/categories/%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="年度总结" scheme="http://wuwenliang.net/tags/%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>灵魂拷问:用了DDD分包就是落地了领域驱动设计吗?谈谈DDD本质</title>
    <link href="http://wuwenliang.net/2020/12/14/%E7%81%B5%E9%AD%82%E6%8B%B7%E9%97%AE-%E7%94%A8%E4%BA%86DDD%E5%88%86%E5%8C%85%E5%B0%B1%E6%98%AF%E8%90%BD%E5%9C%B0%E4%BA%86%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E5%90%97-%E8%B0%88%E8%B0%88DDD%E6%9C%AC%E8%B4%A8/"/>
    <id>http://wuwenliang.net/2020/12/14/灵魂拷问-用了DDD分包就是落地了领域驱动设计吗-谈谈DDD本质/</id>
    <published>2020-12-14T14:30:24.000Z</published>
    <updated>2020-12-14T14:36:11.388Z</updated>
    
    <content type="html"><![CDATA[<p>学习DDD的时候，作为开发更关心它技术层面的东西，尤其体现在DDD的分包方式、编码技巧等方面。</p>
<p>我们不禁发问，用了DDD的分包，就是实践落地了DDD了么？</p>
<p>不卖关子，直接说答案，并不是。</p>
<p>用了DDD的分包，只能说满足了DDD的形，并没有抓住DDD的神。DDD的神是什么，归根到底还是面向对象，领域建模。所谓的各种分包方式本质上还是为了满足DDD面向对象的本质,方便开发者进行代码编写而提供的一种”战术设计”工具.</p>
<p>要深入讨论这个问题,我们需要花一点时间来学习讨论一下DDD中常见的几种分包。</p>
<a id="more"></a>
<h3 id="DDD分包概述"><a href="#DDD分包概述" class="headerlink" title="DDD分包概述"></a>DDD分包概述</h3><p>基于DDD的分包主要有两大流派：分层架构以及六边形架构。</p>
<p>分层架构以四层架构为主，基于四层架构又诞生出衍生的五层架构、六层架构等等。</p>
<p>六边形架构出自 Robert C Martin提出的整洁架构，后续又衍生出了洋葱架构。</p>
<p>可谓是百家争鸣。实际开发中，最为我们熟知的当属四层架构与六边形架构了，其余的各种架构都是基于这两种架构方式的变体。</p>
<h3 id="四层分层架构"><a href="#四层分层架构" class="headerlink" title="四层分层架构"></a>四层分层架构</h3><p>四层架构的分层如下图：</p>
<p><img src="/2020/12/14/灵魂拷问-用了DDD分包就是落地了领域驱动设计吗-谈谈DDD本质/1.png" alt="1.png"></p>
<p>从上往下依次为：</p>
<pre><code>|-user interface            用户界面层/表示层
 |-application                应用层
 |-domain                    领域层
 |-infrastructure            基础设施层
</code></pre><p>我们对这几层的主要功能逐个分析：</p>
<p><strong>User Interface</strong> 为用户界面层（或表示层），负责为用户做信息展示以及对用户输入的命令进行解释与输出。这里指的用户可以是另一个计算机系统，不一定是使用用户界面的人。</p>
<p><strong>Application</strong> 为应用层，应用层主要提供了用例级别的功能。它定义了软件要完成的任务，并且借助表达领域概念的对象来组织并解决问题，可以理解为通过胶水粘合了各种领域概念。<br>这一层所负责的工作对业务来说意义重大，也是与其它系统的应用层进行交互的必要渠道。应用层要尽量简单，它应当尽量不包含业务规则或者知识，而只负责协调下一层中的领域对象，为领域对象分配工作，<br>使它们互相协作。应用层反应不了业务情况的状态，但是可以表达另外一种状态，为用户或程序显示某个任务的进度。</p>
<p><strong>Domain</strong> 为领域层（或模型层），负责表达业务概念，业务状态信息以及业务规则。尽管保存业务状态的技术细节是由基础设施层实现的，但是反映业务情况的状态确实是由领域层控制并且使用的。领域层是业务软件的核心，它体现了DDD的核心：领域模型。</p>
<p><strong>Infrastructure</strong> 层为基础实施层，它向其他层提供通用的技术能力：为应用层传递消息，为领域层提供持久化机制，为用户界面层绘制屏幕组件，等等。基础设施层还能够通过架构框架来支持四个层次间的交互模式。</p>
<p>说完概念，还是不够直观表现DDD四层架构在实际开发中扮演的角色与包含的功能，稍安勿躁，我们举几个例子说明一下：</p>
<p>在实际开发中，User Interface层主要包含Restful消息处理/RPC 接口交互/消息消费入口，配置文件解析，等等。</p>
<p>Application层主要是多进程管理及调度，多线程管理及调度，多协程调度和状态机管理，跨领域业务组织与交互（比如：对外调用的出口就可以在application进行体现，也就是所谓的防腐层），等等。</p>
<p>Domain层主要是领域模型的实现，包括领域对象的确立，这些对象的生命周期管理及关系，领域服务的定义，领域事件的发布，等等。</p>
<p>infrastructure层主要是业务平台，编程框架，第三方库的封装，基础算法，等等i，它为上层提供了技术层面的支持，往往与具体的业务细节无关。</p>
<h3 id="六边形架构"><a href="#六边形架构" class="headerlink" title="六边形架构"></a>六边形架构</h3><p>六边形架构也称为端口与适配器架构，一个典型的六边形架构如图</p>
<p><img src="/2020/12/14/灵魂拷问-用了DDD分包就是落地了领域驱动设计吗-谈谈DDD本质/2.png" alt="2.png"></p>
<p>六边形每条不同的边代表了不同类型的端口，端口要么处理输入，要么处理输出。对于每种外界类型，都有一个适配器与之对应，外界通过应用层API与内部进行交互。</p>
<p>上图中有3个客户请求均抵达相同的输入端口（适配器A、B和C），另一个客户请求使用了适配器D。<br>假设前3个请求使用了HTTP协议（浏览器、REST和SOAP等），而后一个请求使用了AMQP协议（比如RabbitMQ）。</p>
<p>端口并没有明确的定义，它是一个非常灵活的概念。无论采用哪种方式对端口进行划分，当客户请求到达时，都应该有相应的适配器对输入进行转化，<br>然后端口将调用应用程序的某个操作或者向应用程序发送一个事件，控制权由此交给内部区域。</p>
<p>应用程序通过公共API接收客户请求，使用领域模型来处理请求。</p>
<p>我们可以将DDD战术设计建模元素Repository的实现看作是持久化适配器，该适配器用于访问先前存储的聚合实例或者保存新的聚合实例。</p>
<p>正如图中的适配器E、F和G所展示的，我们可以通过不同的方式实现资源库，比如关系型数据库、基于文档的存储、分布式缓存或内存存储等。</p>
<p>如果应用程序向外界发送领域事件消息，我们将使用适配器H进行处理。该适配器处理消息输出，而上面提到的处理AMQP消息的适配器则是处理消息输入的，因此应该使用不同的端口。</p>
<p>这张图是笔者从《微服务架构设计模式》中摘录出来的</p>
<p><img src="/2020/12/14/灵魂拷问-用了DDD分包就是落地了领域驱动设计吗-谈谈DDD本质/3.jpg" alt="3.jpg"></p>
<p>它通过<strong>OrderService</strong>表达了一个订单服务，它的核心通过六边形架构组织，由业务逻辑和一个或多个与其他服务和外部应用程序连接的适配器组成。</p>
<p>图中，<strong>REST API Adaptor</strong> ：表示入站适配器，实现REST API，这些API会调用业务逻辑（其实就是传统开发下的controller/api之类的劳什子，换了个马甲就显得高大上了）</p>
<p><strong>OrderCommandHandlers</strong>：入站适配器，它接收来自消息通道的命令式消息，并调用业务逻辑（其实就是传统开发下的消息消费者，比如Kafka中的listener之类的，没什么新意）</p>
<p><strong>Database Adaptor</strong>：业务逻辑调用以访问数据库的出站适配器。（好家伙，出站适配器，换了名字显得十分阳春白雪，<br>按照下里巴人的理解，就是 <strong>相对业务逻辑而言，数据库位于业务逻辑之外。因此持久化领域实体这操作，方向是由领域模型指向系统之外的</strong>，所以叫出站适配器）</p>
<p><strong>Domain Event Publishing Adapter</strong>：将事件发布到消息代理的出站适配器（这其实就是传统开发下的消息生产者，比如Kafka这种的Producer）之所以也是出站适配器，是因为消息发送到消息中间件后，相对业务逻辑而言，也是处于业务逻辑之外。</p>
<p>我们可以看到，六边形架构中的出站适配器、入站适配器，一旦映射到传统开发中的概念，都是我们日常开发中经常接触到的。本质上还是换汤不换药，不得不佩服软件行业造词的能力。</p>
<h3 id="阶段总结"><a href="#阶段总结" class="headerlink" title="阶段总结"></a>阶段总结</h3><p>我们对上面的讲解做一个小小的总结。</p>
<p>四层架构与六边形架构，表面上看起来是不同的两种架构分层方式，本质上，他们是同一事物的一体两面，<br>是不同的思想对于同一个事物在不同时期思考总结的产物，虽然表象不同，但本质却能够收敛对应起来的。</p>
<p>具体是如何对应的呢？</p>
<p>DDD四层架构中UserInterface和infrastructure可以对应到六边形架构中的适配器（入站和出站适配器均可，按照实际的角色具体分析对待）；</p>
<p>四层架构中的application能够对应到六边形架构中的应用程序层；</p>
<p>四层架构中的domain能够对应到六边形架构中的领域模型层。</p>
<p>了解了DDD四层架构和六边形架构,我们又回到文章开头的问题上来.</p>
<p>既然说DDD在架构分层上往往能够通过四层架构、六边形架构表达，那么我们用了四层架构/六边形架构去做编码，我们不就是落地了领域驱动设计了么？</p>
<p>文章的开头我们直接给了回答，NO，用了分包并不代表落地了领域驱动设计。</p>
<p>我们经常听到一个成语，“形神兼备”。</p>
<p>分包只是DDD的形，如果只是一味的套用DDD的分包，很容易重新回到传统的三层架构中来，用俗话说就叫 <strong>“开倒车”</strong>，而这个过程常常伴随着代码腐化，最终会演化为《人月神话》中提到的 <strong>“焦油坑”</strong>。</p>
<h2 id="再谈DDD本质"><a href="#再谈DDD本质" class="headerlink" title="再谈DDD本质"></a>再谈DDD本质</h2><p>这个系列，虽然是针对DDD进行的，但是笔者却不厌其烦的试图去挖掘所谓的本质。原因在于不想将这个主题单纯的写成一个科普类的概念普及系列，如果是这样的话，倒不如直接去看书来的更快更直接。</p>
<p>之所以不断去强调DDD的本质，还是想以我的视角，去呈现一些我在学习DDD的过程中的一些思考，提供给读者做参考，进而去努力使读者在学习过程中避免浪费时间踩坑，更深层的意图在于努力避免读者进入学习的误区。</p>
<p>好了，我们还是回到正题。</p>
<p>在之前的文章中，笔者也提到过：“DDD本质是面向对象为核心，通过领域建模还原现实世界”。</p>
<p>DDD作为一种指导复杂软件设计开发的方法论，其根源还是基于面向对象思想，围绕着对象本身的行为和属性，为不同对象划分边界，<br>并规范约束了多个对象（所谓领域）分组间的通信/交互方式。</p>
<p>简单的说，DDD的本质还是面向对象编程，通过为对象注入有业务属性的行为，还对象以血肉；以对象建模映射现实世界的具体业务场景和真实交互行为，<br>通过业务概念映射代码逻辑，借助一整套的战略设计与战术设计，让系统从流程化的贫血状态机转变为具有有序业务交互的充血引擎。</p>
<p>我们可以说，通过DDD指导建模，到最终落地的过程，就是将真实世界的业务场景映射为领域模型及其交互流程的过程。</p>
<p>学习DDD的时候，作为初学者总是容易陷入它拿一整套复杂方法论之中，DDD自身的概念、所谓的战略设计、所谓的战术设计，<br>其本质都是为了方便开发者/领域专家/业务需求方统一沟通语言，并指导模型构建最终进行代码落地的工具。</p>
<p>可以这么说，不论是战术设计还是战略设计，本质都是为了方便将真实世界映射到软件模型中。</p>
<p>有了这样的认知，再回过头去学习了解战略设计、战术设计及其衍生概念，就会更加容易。</p>
<p>如果只想记住一句话，那么只需要知道：<br>DDD其实是一系列面向对象软件设计建模的方法论集合，其本质还是面向对象编程，其根本目的在于更加系统化指导复杂软件建模与落地，更好的将现实世界的复杂业务场景抽象为有序简洁易维护的软件系统。</p>
<p>当然，开发简洁有序易维护的软件系统，只用DDD是远远不够的，还需要有丰富的工程思想、整洁架构思想、扎实的编码功底、系统的软件工程理论等共同作用，这也是DDD这套方法论一直在发展的方向，它不断吸纳其他良好的最佳实践为己用，不断扩展边界。时至今日，DDD已经是涵盖建模、开发、测试、管理等领域的综合软件开发指导理论与思想。</p>
<h2 id="正本清源，万法归宗"><a href="#正本清源，万法归宗" class="headerlink" title="正本清源，万法归宗"></a>正本清源，万法归宗</h2><p>DDD的分包方式是领域建模的结果在代码分层上的映射，只是解决了“代码编写完成之后往哪里放”的问题，</p>
<p>我们甚至可以大胆的断言，即便不采用DDD的分层，还是基于原有的 <strong>interface-&gt;service-&gt;domain-&gt;dao</strong> 的分层，只要基于面向对象分析建模，</p>
<p>最终落地的代码他和DDD建模的结果也会殊途同归，因为</p>
<p>问题的根本其实还是在于领域如何划分，领域之间如何进行交互的问题。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;学习DDD的时候，作为开发更关心它技术层面的东西，尤其体现在DDD的分包方式、编码技巧等方面。&lt;/p&gt;
&lt;p&gt;我们不禁发问，用了DDD的分包，就是实践落地了DDD了么？&lt;/p&gt;
&lt;p&gt;不卖关子，直接说答案，并不是。&lt;/p&gt;
&lt;p&gt;用了DDD的分包，只能说满足了DDD的形，并没有抓住DDD的神。DDD的神是什么，归根到底还是面向对象，领域建模。所谓的各种分包方式本质上还是为了满足DDD面向对象的本质,方便开发者进行代码编写而提供的一种”战术设计”工具.&lt;/p&gt;
&lt;p&gt;要深入讨论这个问题,我们需要花一点时间来学习讨论一下DDD中常见的几种分包。&lt;/p&gt;
    
    </summary>
    
      <category term="DDD" scheme="http://wuwenliang.net/categories/DDD/"/>
    
    
      <category term="DDD" scheme="http://wuwenliang.net/tags/DDD/"/>
    
  </entry>
  
  <entry>
    <title>DDD领域驱动设计与软件复杂度的那些事</title>
    <link href="http://wuwenliang.net/2020/12/02/DDD%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%E4%B8%8E%E8%BD%AF%E4%BB%B6%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/"/>
    <id>http://wuwenliang.net/2020/12/02/DDD领域驱动设计与软件复杂度的那些事/</id>
    <published>2020-12-02T13:03:18.000Z</published>
    <updated>2020-12-02T14:02:49.944Z</updated>
    
    <content type="html"><![CDATA[<p>软件开发领域中，软件复杂度是一个由来已久的话题，从软件的诞生到成熟再到消亡，或多或少总会伴随着软件复杂度的讨论。</p>
<p>我们不禁发问，软件复杂度究竟从何而来？</p>
<p>谈到软件复杂度，有三个话题不得不提及，他们分别是软件规模，软件结构，以及业务的变化。</p>
<p>首先是 <strong>软件规模</strong>，它涉及到软件本身的代码量，迭代时长以及迭代的次数/数量，以及该软件经手的开发者数量等。这几个要素都会对软件规模造成显著影响，可以回想一下自己接手别人祖传代码时那种忐忑不安、小心翼翼的心态，生怕因为自己的失误导致出现bug甚至背锅的情况；并且代码规模越大，业务逻辑越冗长，这种心态就越发强烈。</p>
<a id="more"></a>
<p>接着说说 <strong>软件结构</strong>。一般来说，设计质量高的软件系统都有着明显的共同特征：比如良好的架构、规范的接口设计、清晰的业务逻辑与注释、完备的文档、代码具有良好的扩展性，符合开闭原则等等。而质量低下的代码则各有各的恐怖之处：比如到处乱放的实体、随处引用的service、深不可测的嵌套、冗赘的分支、一眼望过去不明所以的结构、核心逻辑与校验代码放在同一个方法中，一屏幕显示不全、缺乏甚至完全不存在有意义的注释……  对于这种不规范的软件结构所引发的业务复杂度，我想大家也是感同身受了。</p>
<p>最后是 <strong>业务的变化</strong>，简单说就是需求变更。相信这也是每个开发者经常面临的状况，因为需求变更我们与产品经理相爱相杀，因为需求变更我们经常见证凌晨四点的城市，也因为需求变更让我们在设计的时候不得不考虑可配置、易扩展。之所以需求频繁变更/业务经常变化，主要原因在于如今的互联网，风口频频诞生，机会稍纵即逝，从增量市场逐步过渡到存量市场，获客难度指数级增加，互联网玩法也日新月异，这个过程中又伴随着业务量的激增，产品与运营每日都在被无休止的“增长”KPI压力中裹挟，一定程度上也为需求频繁变更推波助澜。</p>
<p>那么我们应该如何应对软件复杂度呢？</p>
<p><strong>针对软件规模日益庞大</strong>，我们需要对复杂的问题域分而治之，化大为小，各个击破。通过分治思想，控制软件规模。</p>
<p>通过对单体应用进行拆分，化大为小，将单体的演化为分布式的；单体拆分的过程也伴随着对代码的重构过程，通过对模型进行分类和拆分，逐步提升通用模型的重用程度，让每个模型的行为都尽量满足单一职责设计原则；通过自顶向下，逐步细化的结构化编程思想，对业务流程进行细粒度的重构和优化，让业务逻辑呈现出清晰的主脉络，不至于化成一锅粥，一眼望过去不知其所以然。</p>
<p><strong>针对软件结构复杂的问题</strong>，解决的核心思路是保持软件清晰一致的结构。说起来还是蛮简单，实现起来还是存在相当的复杂度。原因在于，不同的业务，问题域不同，而问题域本身的难易程度又是软件复杂度的决定性因素之一。但是即便如此，深耕软件领域多年的大师们还是总结抽象出了一系列的抽象软件结构（架构模式）供我们参考学习。</p>
<p>比如bob大叔提出的整洁架构；比如DDD的多种分层模式（如：四层架构、五层结构、六边形架构、洋葱架构等）；这些各具特色的架构模式，他们都具备分离关注点、划分问题域边界、依赖倒置、隔离变化易扩展的特点。这些特点恰恰都体现了通用的优秀设计原则。</p>
<p><strong>针对软件变化迅速这一问题</strong>，我们认为要积极的拥抱变化，既然变化不可逆，那么顺应变化就好。但是在顺应变化的同时还是要尽量对变化因素进行隔离，控制变化范围。我们提出三个要素来拥抱变化：</p>
<ul>
<li><p><em>可进化性</em>：对软件涉及到的问题域划分单元边界，确定每个设计单元应当履行的职责以及需要与其他单元交互的接口；这些设计单元具备不同的设计粒度，如：函数、对象、模块、组件以及服务等；这其中涉及到的每个设计单元都拥有自己的边界，并且边界内实现细节不会影响到外部的其他设计单元，相当于隔离了关注点，这样做的结果就是我们可以非常容易地替换单元内部的实现细节，保证了它们的可进化性；</p>
</li>
<li><p><em>可扩展性</em>：为了满足系统的可扩展性，关键点在于我们需要学会识别软件系统中的变化点（业务热点）。常见的变化点包括但不限于业务规则、算法策略、外部服务、硬件支持、命令请求、协议标准、数据格式、业务流程、系统配置、界面表现等。处理这些变化点的核心就是“封装”，通过隐藏细节、引入中间层等方式来隔离变化、降低耦合。常见的一些优秀架构风格，如基于事件的集成、引入管道—过滤器等模式，都可以在一定程度上提高系统可扩展性。</p>
</li>
<li><p><em>可定制性</em>：这个特性意味着我们可以提供定制化的功能与服务。Roy Thomas Fielding博士 （HTTP 和 URI 等 Web 架构标准的主要设计者）在《架构风格与基于网络的软件架构设计》提到：“支持可定制性的风格也可能会提高简单性和可扩展性”。听起来有些抽象，我举个例子大家就理解了，比方说：在 SaaS 风格的系统架构中，我们常常通过引入元数据（Metadata）来支持系统的可定制。插件模式也是满足可定制性的常见做法，它通过提供统一的插件接口，使得用户可以在系统之外按照指定接口编写插件来扩展定制化的功能。比如Java的SPI机制、Dubbo的SPI和Filter机制等，都是可定制性的体现。它们都支持开发者通过它们提供的扩展点实现定制化的业务逻辑，这也是开放-封闭原则的体现。</p>
</li>
</ul>
<h2 id="DDD是如何应对软件复杂度的？"><a href="#DDD是如何应对软件复杂度的？" class="headerlink" title="DDD是如何应对软件复杂度的？"></a>DDD是如何应对软件复杂度的？</h2><p>说了这么多软件复杂度以及宏观的应对方法，我们又不禁陷入疑惑：感觉说的都挺有道理，但是这和DDD又有什么关系？</p>
<p>实际上，我们说了这么多的主要目的就是在于引出DDD对软件复杂度的应对方法，正是因为DDD能够应对软件复杂度，为我们提供了一种能够从根本上化解软件腐化的解决方案，而这也恰恰是DDD的价值所在。</p>
<p>我们说过，软件复杂度的原因在于“变化”，而变化的根源因素在于 <strong>“需求的不确定性”</strong>。Eric Evans认为，“很多应用程序最主要的复杂性并不在技术上，而是来自领域本身、用户的活动或者业务”。</p>
<p>恰巧DDD的关注点正是 <strong>“领域 + 领域内以及领域之间的逻辑”</strong>。站在DDD的角度，软件系统的本质在于为客户/用户提供具有业务价值的领域能力和功能，从而解决具体的领域内的问题。</p>
<p>从Eric的话中，我们也能提炼出需求的分类：业务类需求和技术类需求。</p>
<p>对于业务类需求而言，它的复杂度核心在于业务复杂度。它包含多个方面：功能数量日益膨胀、功能之间的依赖关系逐步增加、不同涉众之间沟通交流不顺畅，不具备统一的语言交流模型；当这些不良因素聚集起来，到达一定程度，到达腐化的一定的程度，便能够看到经常被开发者诟病的“大泥球“、“shit山”。</p>
<p>对于技术类需求，或者另一种说法叫质量需求而言，它的核心复杂度在于技术本身，比如安全要求、高并发要求、高性能要求以及高可用方面的要求。</p>
<p>DDD解决业务类需求以及技术类需求的方式是清晰且直捣黄龙的：</p>
<p>首先, 典型的DDD实现了业务复杂度和技术复杂度的隔离，通过分层架构隔离了关注点，举个例子，在传统的DDD四层架构中，DDD划分出了领域层、仓储层、基础设施层、接口层；<br>在领域层中，存放业务逻辑的关注点，即所谓的领域行为；在应用层中，DDD暴露出了 <strong>业务用例级别</strong> （Use Case）的服务接口，粘合业务逻辑与技术实现；在基础设施层中，DDD集中放置了支撑业务逻辑的技术实现，如：MQ消息发送、对缓存的操作等；在仓储层中，DDD放置了和领域状态相关的逻辑，打通了领域状态持久化与存储设施之间的联系。</p>
<p>比方说，在一个电商系统的领域逻辑中，业务规则包含了校验订单的有效性、计算订单总金额、提交和审核订单流程等业务逻辑。而技术关注点则从实现的层面保障这些业务能够正确完成，包括确保分布式系统之间的数据一致性，确保服务之间通信的正确性等。</p>
<p>除了划分不同分层外，DDD还提出了一个建设性的概念: <strong>“限界上下文（Bounded Context）”</strong>，通过限界上下文对业务流程分而治之，切分为不同的子系统，在每个子系统中利用DDD的分层架构/六边形架构等思想分别进行逻辑分层。通过这样的分治之后，DDD帮我们将业务复杂度隔离到了每个细分的领域内部，而且DDD本身的分治思想，也帮助我们隔离了业务需求和技术需求的关注点。</p>
<p>这么一通说明之后，感觉对DDD应对软件复杂度的方式有了一定的了解，但是总觉得不那么深刻，一方面是因为这个问题本身就不容易把握全局，还有个原因是没有一个清晰直观的图谱能够参考。稍安勿躁，我们这就通过一个图片来直观感受一下DDD分层结构的魅力：</p>
<p><img src="/2020/12/02/DDD领域驱动设计与软件复杂度的那些事/ddd-structure.png" alt="ddd-structure.png"></p>
<p>这是一个典型的领域驱动设计分层架构，蓝色区域的内容与业务逻辑有关，而灰色区域的内容则与技术实现有关。这二者泾渭分明，最后汇合在应用层。<br>应用层确定了业务逻辑与技术实现的边界，通过直接依赖或者依赖注入（DI，Dependency Injection）的方式将二者结合起来。充分体现了DDD能够隔离技术复杂度与业务复杂度的特点。</p>
<h2 id="回到问题，我们为什么要用领域模型指导系统建模与落地？"><a href="#回到问题，我们为什么要用领域模型指导系统建模与落地？" class="headerlink" title="回到问题，我们为什么要用领域模型指导系统建模与落地？"></a>回到问题，我们为什么要用领域模型指导系统建模与落地？</h2><p>结合讲解，我们再次回到问题本身，<strong>为什么要用领域模型指导系统建模与落地？</strong></p>
<p>经过上面的一系列分析与思考，答案呼之欲出：正是因为DDD本身具备的这些特质，它的核心概念  <strong>领域模型</strong> 本质上就是对业务需求的一种抽象，它表达了<strong>领域概念、领域规则以及领域概念之间的关系</strong>。</p>
<p>在领域建模过程中提取出的<strong>统一语言</strong>，会成为具体落地的指导思想，通过它能够降低开发者与需求方的沟通成本，化解歧义；通过 <strong>剖析业务需求，抽象领域概念，提炼领域知识，总结统一语言</strong>；并运用抽象的领域模型去表达，就可以达到对领域逻辑的化繁为简。</p>
<p>这一切的核心便是模型，模型是对业务流程和参与者的封装，实现了对业务细节的隐藏、封装，赋予了实体以行为，这恰恰是面向对象的精髓：还实体以行为，变贫血为充血。</p>
<p>同时模型还是抽象的一种表达方式，它提取了领域知识的共同特征，并且保留了面对变化时能够良好扩展的可能性。</p>
<p>这么多内容，如果只用记住一句话，那么我们一定要知道：</p>
<p><strong>我们之所以选择领域模型指导系统建模与落地，就是因为它能够很好的对业务需求进行抽象，更适合研发与需求方展开沟通合作，对于复杂场景的业务效果更为明显。</strong></p>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p>《实现领域驱动设计》Vaughn Vernon著  滕云译 </p>
<p>《领域驱动设计事件 战术+战略》  gitchat专栏  张逸</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;软件开发领域中，软件复杂度是一个由来已久的话题，从软件的诞生到成熟再到消亡，或多或少总会伴随着软件复杂度的讨论。&lt;/p&gt;
&lt;p&gt;我们不禁发问，软件复杂度究竟从何而来？&lt;/p&gt;
&lt;p&gt;谈到软件复杂度，有三个话题不得不提及，他们分别是软件规模，软件结构，以及业务的变化。&lt;/p&gt;
&lt;p&gt;首先是 &lt;strong&gt;软件规模&lt;/strong&gt;，它涉及到软件本身的代码量，迭代时长以及迭代的次数/数量，以及该软件经手的开发者数量等。这几个要素都会对软件规模造成显著影响，可以回想一下自己接手别人祖传代码时那种忐忑不安、小心翼翼的心态，生怕因为自己的失误导致出现bug甚至背锅的情况；并且代码规模越大，业务逻辑越冗长，这种心态就越发强烈。&lt;/p&gt;
    
    </summary>
    
      <category term="DDD" scheme="http://wuwenliang.net/categories/DDD/"/>
    
    
      <category term="DDD" scheme="http://wuwenliang.net/tags/DDD/"/>
    
  </entry>
  
  <entry>
    <title>复杂软件解决之道DDD(1)认识领域驱动设计</title>
    <link href="http://wuwenliang.net/2020/12/01/%E5%A4%8D%E6%9D%82%E8%BD%AF%E4%BB%B6%E8%A7%A3%E5%86%B3%E4%B9%8B%E9%81%93DDD-1-%E8%AE%A4%E8%AF%86%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/"/>
    <id>http://wuwenliang.net/2020/12/01/复杂软件解决之道DDD-1-认识领域驱动设计/</id>
    <published>2020-11-30T16:17:51.000Z</published>
    <updated>2020-11-30T16:18:53.387Z</updated>
    
    <content type="html"><![CDATA[<p>今日的后端开发，我们常常听到大家提到“领域驱动设计”、“DDD”等名词，听起来感觉很高端，自己也忍不住想了解，但是又不知从何下手。</p>
<p>不慌，我们这个系列的意义就在于用浅显易懂又不是深度的叙述手法，为大家全方位的介绍普及DDD领域驱动设计的知识，并最终落地到自己的项目中。</p>
<p>那么，我们直接进入正题，领域驱动设计（接下来为叙述方便，用DDD代指）到底是什么？</p>
<a id="more"></a>
<p>首先，领域驱动设计，顾名思义，它是一种设计的方法论。它的核心在于领域驱动，实际上，它的提出已经有些年头，为何感觉最近突然火了呢？这都离不开微服务的大火。</p>
<p>随着微服务的日益普及以及落地，我们主键发现，盲目的进行微服务拆分非但不能带来显著的受益，反而会使原本的业务逻辑更加复杂，我们急需一种方法理论来知道微服务的拆分。此时DDD进入我们的视线，大家发现，DDD正是一直依赖梦寐以求的适合微服务拆分的指导思想。</p>
<p>经过DDD思想指导之后的微服务架构，更加清晰，代码也更容易维护。</p>
<p>之所以这么说的原因在于，传统的基于事务脚本的代码编写方式，本质上还是单体开发中的流程式开发模式，只是在逻辑上泛泛的进行分离，本质上并没有降低分布式、大并发场景下业务间交互的复杂度，反而由于拆分，增加了代码修改成本，一定程度上增加了需求变更之后，代码腐化的风险。</p>
<p>而同样的业务，在经过DDD领域建模之后，业务边界得到了更为清晰的划分，服务的职责更为条理内聚，后续迭代维护、重构、增加特性的成本显著降低了。</p>
<p>DDD有这么明显的优势，这都得益于它的核心思想：基于面向对象，用软件建模还原了真实世界。</p>
<p>通过领域建模驱动设计的系统，拥有界限清晰的领域模型；代码划分与实际的业务能够很清晰的进行对应，这保证了业务模型与代码模型的深层次映射的一致性。这种一致性的好处在于，确实的将真实世界的交互流程与软件系统的抽象交互逻辑真正对应起来，做到了“在软件层面尽可能的还原了真实世界”。</p>
<p>我们在上文提到说，DDD是一种设计方法论。那么，DDD不是什么呢？</p>
<p>DDD不是某种特定的软件开发框架，它凌驾于具体的开发框架之上，即便我们不引入某种具体的开发框架，如：Spring、Guice之类的框架，仅仅使用原生的编程语言的语法特性，也可以落地DDD。我们说，DDD是框架无关的。</p>
<p>DDD和具体的程序设计语言无关，使用Java/C++/Go/C#等等语言，都能够实现DDD的那些思想，不过，如果语言本身支持面向对象，会更加适合DDD，主要是因为DDD天然体现面向对象。我们说，DDD是语言无关的。</p>
<p>DDD和具体的技术选型无关，这里针对的是更加贴近DDD战术设计的部分，比如说，对于领域事件的实现，我们就有多种方式。可以基于观察者模式直接编码实现、可以直接使用Guava的eventBus实现、也可以使用Spring的事件发布机制，当然，直接基于某种具体的MQ中间件实现也是没有问题的。因此我们说，DDD是技术选型自由的。</p>
<p>了解了DDD是什么，以及它不是什么，我们对DDD有了一个基本的先入为主的认知。此时有些读者便有些兴奋，别急，我们看一下DDD适合的场景再高兴也来得及。</p>
<p>先说结论，DDD既适合简单业务，也适合复杂业务。有些读者忍不住想吐槽我了，这不是废话么。确实不是废话。</p>
<p>DDD的外沿足够支持复杂业务的建模，它被提出的主要目的也是为了解决复杂场景下的业务设计与建模，但是这并不代表它对简单业务无能为力。</p>
<p>我们说，DDD在简单业务场景下也完全适用，只是用DDD得到的受益不那么明显，我们使用传统的事务脚本方式相对来说效率更高更容易落地，毕竟对于开发者而言，学习成本更低。根据奥卡姆剃刀法则，在目的相同的情况下，当然是使用简单的方式对我们受益更加高了。</p>
<p>对于复杂的业务场景，DDD就能够明显的体现出它的价值。比如：电商类业务、支付类业务、营销类业务等。笔者当前从事的广告领域，同样有着复杂的业务场景，涉及到下单、结算、发券、活动、投放、创意、电销等业务场景，DDD对类似于这种复杂综合的业务场景进行建模就会如鱼得水，效果显著。</p>
<p>针对DDD的基本概念，说了这么多，如果只想记住一句话，那么只需要知道：</p>
<p><strong>领域驱动设计是为了解决复杂业务场景下软件建模与领域边界划分的问题而提出的一种基于面向对象的设计方法论，它通过一系列的概念、步骤、方法，确定业务与应用的边界，最终目的为达到业务模型与代码模型的一致性，实现在软件层面还原真实世界的目标</strong>。</p>
<p>凡理论的提出到为人熟知都经历了一系列的变更和发展，对于DDD也不例外。我们接着了解下领域驱动设计的发展史。</p>
<p>领域驱动设计这一名词，由埃里克·埃文斯（Eric Evans）在2003发表的《领域驱动设计》一书提出。这本书理论性极强，奠定了领域驱动设计这一综合性软件设计理论的基础。书籍本身也成为DDD的“圣经”，其中文翻译晦涩难懂，有英文阅读能力且想一睹芳容的读者，可以大胆去看英文原本（笔者才识学浅，只看过中文版第一部分内容就甩一边了，改看了《实现领域驱动设计》）。</p>
<p>从《领域驱动设计》一书的首版发表年限我们也能看出，DDD理论本身与分布式、微服务对比，绝对算的上是步入中年的“老大哥”了。</p>
<p>这就是万恶之源：</p>
<p><img src="/2020/12/01/复杂软件解决之道DDD-1-认识领域驱动设计/ddd.jpg" alt="领域驱动设计"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文中，我们先入为主的针对领域驱动设计DDD提出了几个问题并一一进行了解答。</p>
<p>初步对DDD是什么，不是什么，DDD要解决的问题，DDD适用的场景做了一个概述讲解。有了这个前提，我们接下来将对软件复杂度进行讲解，并重点对DDD是如何应对软件复杂度这个重要问题进行分析，敬请期待！</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今日的后端开发，我们常常听到大家提到“领域驱动设计”、“DDD”等名词，听起来感觉很高端，自己也忍不住想了解，但是又不知从何下手。&lt;/p&gt;
&lt;p&gt;不慌，我们这个系列的意义就在于用浅显易懂又不是深度的叙述手法，为大家全方位的介绍普及DDD领域驱动设计的知识，并最终落地到自己的项目中。&lt;/p&gt;
&lt;p&gt;那么，我们直接进入正题，领域驱动设计（接下来为叙述方便，用DDD代指）到底是什么？&lt;/p&gt;
    
    </summary>
    
      <category term="DDD" scheme="http://wuwenliang.net/categories/DDD/"/>
    
    
      <category term="DDD" scheme="http://wuwenliang.net/tags/DDD/"/>
    
  </entry>
  
  <entry>
    <title>复杂软件解决之道DDD概论</title>
    <link href="http://wuwenliang.net/2020/11/29/%E5%A4%8D%E6%9D%82%E8%BD%AF%E4%BB%B6%E8%A7%A3%E5%86%B3%E4%B9%8B%E9%81%93DDD%E6%A6%82%E8%AE%BA/"/>
    <id>http://wuwenliang.net/2020/11/29/复杂软件解决之道DDD概论/</id>
    <published>2020-11-29T15:15:43.000Z</published>
    <updated>2020-11-29T16:18:06.249Z</updated>
    
    <content type="html"><![CDATA[<p>随着业务发展，软件本身也需要不断进行迭代以适应业务变换。</p>
<p>我们可以说，软件存在的价值就是映射真实世界，解决业务问题，从而创造更多价值，为大众提供更加便利的服务。</p>
<p>面对复杂业务场景，我们往往通过不断增加业务分支，对原有的冰山一样的代码逻辑进行小心翼翼的修改，生怕因为自己的修改导致全局出现不可挽回的损失。</p>
<p>这种不断迭代的历史遗留代码，几十年前的《人月神话》已经下过一次定义–“焦油坑”。</p>
<p>我们也常常调侃，自己不是在写代码，而是在Ctrl C / V, 在代码的“shit mountain”山不断进行着业务逻辑的搬运，并时刻祈祷系统别出异常，从而成为背锅的那个人。</p>
<p>这种现实是否能够通过一定的方式/方法/技巧改善甚至说这种类型问题能否改善呢？</p>
<a id="more"></a>
<p>答案是显而易见的，随着软件行业的发展，在业界不断耕耘的专家/资深工程师，确实总结出了很多软件开发的套路/技巧/方法论，供我们开发者使用，并能够解决一定场景下的问题。</p>
<p>DDD（Domain Driven Development 领域驱动设计）也是其中的一个重要方法论，它作为一种综合的、新生的、不断发展完善的业务领域建模思想，在微服务和服务化大行其道的今天，不断推陈出新，指导新兴软件从零到一落地、辅助复杂遗留业务场景重构。</p>
<p>我们可以说，DDD本质上就是一种复杂软件解决之道，了解并运用DDD提供的思想和方法论，能够帮助我们更好的理解、改善、落地复杂多变的业务场景，并能够让开发者将技术更好的运用到业务场景中，使我们的软件系统更符合面向对象的思路：即在软件系统中映射并还原真实世界。</p>
<p>笔者将在未来的一段较长时间内，将自己在DDD领域驱动方面的学习、思考、落地经验，用一个系列的文章进行分享，并殷切希望能够用通俗易懂、规范的语言，为读者全方位的呈现DDD的魅力。</p>
<p>这个系列将主要分为三大模块：</p>
<ul>
<li>概论，将主要从概念，架构思维，方法论探究，案例浅析等方面对DDD做一个全局的宏观分析和学习</li>
<li>实战，将通过一个贴近真实业务场景的案例，对笔者在DDD落地方面的思考进行分享</li>
<li>反思，将通过一系列的思考和代码片段，站在业务和技术综合角度，对DDD、架构、编码技巧、职业发展等角度，阐述笔者对DDD本质与架构方面的思考；</li>
</ul>
<p>三大模块全部落地是一个长期的事情，可能半年，可能一年，也可能更长，但笔者会坚持做这件事。</p>
<p>作为概论部分的首篇，我将主要讲解一下概论系列主要行文思路和纲要，以便为后文详述奠定基础。</p>
<h2 id="思维框架，脉络梳理"><a href="#思维框架，脉络梳理" class="headerlink" title="思维框架，脉络梳理"></a>思维框架，脉络梳理</h2><p><img src="/2020/11/29/复杂软件解决之道DDD概论/DDD-menu.png" alt="DDD-menu.png"></p>
<p>图中的橙色部分为内容主干，绿色部分为扩展延伸。</p>
<p>具体分析一下：</p>
<ol>
<li>我将从宏观上讨论一下，究竟什么是DDD，这部分内容没有太多的发挥空间；</li>
<li>接着阐述DDD的发展史，凡理论皆有其发展过程，都符合历史唯物主义；</li>
<li>讨论一下问什么要用DDD，引出对软件复杂度的思考，并进一步讨论DDD是如何应对软件复杂度的；</li>
<li>说到DDD就不得不解释一个概念，“统一语言；我将解释一下什么是统一语言，它有什么作用，并引出DDD参与者；</li>
<li>对DDD核心概念进行举例说明</li>
<li>对DDD常见分包进行阐述，并解答灵魂拷问：“用了DDD分包就是落地了DDD么？”；</li>
<li>详细讨论DDD的本质：通过建模还原真实世界；</li>
<li>讨论一下DDD适用场景，新项目/老项目都能应用么；</li>
<li>通过一个简单案例，先入为主的表达DDD的编码风格，权当抛砖引玉；</li>
<li>回到问题的起点：讨论软件退化的根源；</li>
<li>在概论部分的最后，推荐一些自学DDD的资料，以便读者朋友能够进一步深入了解学习DDD；</li>
</ol>
<p>接下来的文章，我们就会从DDD的历史入手，逐步探寻DDD的魅力。那么就请亲爱的你跟随者我的视角，与我一同领略DDD领域建模的无限精彩吧！</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;随着业务发展，软件本身也需要不断进行迭代以适应业务变换。&lt;/p&gt;
&lt;p&gt;我们可以说，软件存在的价值就是映射真实世界，解决业务问题，从而创造更多价值，为大众提供更加便利的服务。&lt;/p&gt;
&lt;p&gt;面对复杂业务场景，我们往往通过不断增加业务分支，对原有的冰山一样的代码逻辑进行小心翼翼的修改，生怕因为自己的修改导致全局出现不可挽回的损失。&lt;/p&gt;
&lt;p&gt;这种不断迭代的历史遗留代码，几十年前的《人月神话》已经下过一次定义–“焦油坑”。&lt;/p&gt;
&lt;p&gt;我们也常常调侃，自己不是在写代码，而是在Ctrl C / V, 在代码的“shit mountain”山不断进行着业务逻辑的搬运，并时刻祈祷系统别出异常，从而成为背锅的那个人。&lt;/p&gt;
&lt;p&gt;这种现实是否能够通过一定的方式/方法/技巧改善甚至说这种类型问题能否改善呢？&lt;/p&gt;
    
    </summary>
    
      <category term="DDD" scheme="http://wuwenliang.net/categories/DDD/"/>
    
    
      <category term="DDD" scheme="http://wuwenliang.net/tags/DDD/"/>
    
  </entry>
  
  <entry>
    <title>Java后端研发套路之灰度策略</title>
    <link href="http://wuwenliang.net/2020/11/01/Java%E5%90%8E%E7%AB%AF%E7%A0%94%E5%8F%91%E5%A5%97%E8%B7%AF%E4%B9%8B%E7%81%B0%E5%BA%A6%E7%AD%96%E7%95%A5/"/>
    <id>http://wuwenliang.net/2020/11/01/Java后端研发套路之灰度策略/</id>
    <published>2020-11-01T14:58:00.000Z</published>
    <updated>2020-11-03T17:59:45.194Z</updated>
    
    <content type="html"><![CDATA[<p>日常开发中，对于遗留系统代码逻辑的改造，通常不会粗暴地采用停机更新方式直接迁移到新业务逻辑，往往需要通过灰度方式逐步迁移到新逻辑，最后再把老业务逻辑下线。</p>
<p>这个过程中就涉及到新老业务逻辑并存的问题，而这个问题是需要研发同学去通过工具、编码、配置等方式实现灰度策略，制定灰度计划，并付诸实施，保障系统能够平稳地从老业务逻辑迁移至新业务逻辑。</p>
<p>通常情况下，如果是http接口灰度，我们可以利用网关的特性，如nginx自身的能力，根据cookie中传递的唯一标识进行百分比分流，通过免开发的方式进行灰度。</p>
<p>但在实际开发中，我们面对的系统不仅仅是网关类系统，大部分情况下，分布式系统开发场景下面对的是RPC类接口或者异步消息逻辑，对于这类型代码逻辑的灰度就需要研发同学通过编码方式，细粒度的进行灰度。</p>
<p>本文中，我们就后者展开代码级别的讨论和分享，向读者介绍笔者在日常开发中，面对接口级别的灰度场景是如何通过编码实现具体的灰度策略的，本文权当抛砖引玉，为读者全景展示​后端研发套路之灰度场景下的瑞士军刀具体是如何使用的。在今后的开发工作中如果你遇到类似场景，可以参考笔者思路，开发适合自己业务的灰度套路。</p>
<a id="more"></a>
<h3 id="兜底利器：全局开关"><a href="#兜底利器：全局开关" class="headerlink" title="兜底利器：全局开关"></a>兜底利器：全局开关</h3><p>在灰度策略的开发过程中，有一样东西是一定要考虑的。</p>
<p>无论灰度策略实现多么复杂，多么优雅。这个东西是万万不能不考虑的，它就是 全局兜底开关。用一句流行话来说，就是专治各种花里胡哨。</p>
<p>全局兜底开关的主要目的在于：急停，简单的说就是当灰度逻辑明显朝着不符合预期的方向进行，或者服务本身依赖的下游系统出现异常，导致服务本身也处于亚健康状态（如：出现大量超时、突增业务告警、大量异常日志打印导致磁盘可用容量急剧下降等情况）。</p>
<p>如果在开发阶段考虑到并增加了全局开关，那么在突发情况出现的时候就可以从容的打开开关，让异常逻辑“急刹车”。然后就可以从容不迫的对问题进行分析解决，不至于因为灰度逻辑出现异常而措手不及，甚至导致绩效受到影响，乃至拥抱变化。<br>​<br>事实上，在互联网场景代码开发中，我们的系统往往都微服务化了，应用大多数是分布式部署的，因此全局配置往往依赖分布式配置中心这一关键基础设施。</p>
<p>常见的分布式配置中心选型有Qconf、Nacos、Apollo。我们基于Apollo来进行源码的展示，关于Apollo的使用，可以直接参考 <a href="https://github.com/ctripcorp/apollo/wiki/Java%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97" target="_blank" rel="external">官方文档</a>; 关于框架的使用，其他的分布式配置框架都大同小异，这不是本文关注的重点，问题的关键在于体会分布式配置中心在分布式系统中全局配置下发的思路。（当然，如果说确实没有条件实践分布式配置中心，基于数据库搞一个配置表的读写也是可以的，只不过此时的全局配置是强依赖数据库的。事实上，Nacos、Apollo底层也会依赖数据库。）</p>
<p>说了这么多，全局开关的代码具体如何实现呢？</p>
<pre><code>public boolean globalSwitch() {
    // 获取Apollo 配置实例
    Config config = ConfigService.getAppConfig();
    // 读取服务端配置的全局开关，默认值为false 转换为boolean
    return Boolean.valueOf(config.getProperty(&quot;global_config_key&quot;, &quot;false&quot;));
}
</code></pre><p>这段代码逻辑很容易理解，​就做了两件事：</p>
<ul>
<li>首先获取Apollo 配置实例</li>
<li>接着读取服务端配置的全局开关，默认值为false，读取到配置值后转换为boolean返回​。返回true，表明全局开关已经打开​</li>
</ul>
<p>全局开关的核心思路就是从配置中心通过key获取对应的配置value，转换为boolean返回。对于大多数的配置中心客户端而言，允许指定默认值，哪怕客户端与服务端连接断开还是能够从本地缓存获取默认值，防止由于读取不到配置而影响服务的可用性。</p>
<h3 id="精准灰度：白名单机制"><a href="#精准灰度：白名单机制" class="headerlink" title="精准灰度：白名单机制"></a>精准灰度：白名单机制</h3><p>有了全局开关作为兜底保证，就可以实现具体的灰度策略了。</p>
<p>首先介绍的是灰度策略常客，白名单机制（有些场景也称黑名单机制，根据具体业务场景决定具体的含义）。</p>
<p>白名单机制，顾名思义，其实就是精准灰度策略，对显式指定的目标进行配置，最终使其进入新的业务逻辑。</p>
<p>比如我们可以在线上系统中配置测试账号，通过将测试账号配置到白名单中，然后模拟真实请求，就可以在不影响线上用户数据的前提下，对新业务流程进行回归验证。</p>
<p>从这个角度看的话，白名单机制也是一种数据隔离的手段，它能够允许我们在执行了线上逻辑的前提下，又不至于污染其他数据。</p>
<p>​再进一步思考，我认为从根本上讲，白名单机制本质上是一种精确触达方案，给系统提供了少量、精细化的逻辑筛选机制。</p>
<p>一个基于用户/商户维度进行白名单筛选的代码实现如下：</p>
<pre><code>/**
 * 根据用户id进行灰度，假设灰度配置为111,222,333,444
 * @param userId
 * @return
 */
public boolean whiteListGray(String userId) {
    if (StringUtils.isEmpty(userId)) {
        return false;
    }
    // 获取Apollo 配置实例
    Config config = ConfigService.getAppConfig();
    // 读取服务端配置的灰度白名单用户列表，默认值为false
    String value = config.getProperty(&quot;user_white_list_gray_key&quot;, &quot;&quot;);
    // 根据配置的分隔符转换配置为List
    List&lt;String&gt; configList = new ArrayList&lt;&gt;(Arrays.asList(value.trim().split(&quot;,&quot;)));

    if (CollectionUtils.isEmpty(configList)) {
        return false;
    }
    // 判断配置项List中是否包含当前userId
    if (configList.contains(userId)) {
        return true;
    }
    return false;
}
</code></pre><p>​假设分布式配置服务上对用户的灰度配置为 “111,222,333,444”，若当前请求的userId为配置中的其中一项，则调用该方法返回的结果为true，表明当前用户处于灰度白名单中，反之则表明当前请求的用户不属于灰度用户，返回false。</p>
<h3 id="推全策略：百分比机制"><a href="#推全策略：百分比机制" class="headerlink" title="推全策略：百分比机制"></a>推全策略：百分比机制</h3><p>说完了白名单机制，我们再介绍一种推进式灰度策略，通过修改配置，使得灰度逻辑在总体执行过程中的占比逐步增加，直至全量。</p>
<p>这个机制就是百分比机制。</p>
<p>它的执行逻辑也很好理解，请求进入灰度计算流程之后，该流程会对灰度比例进行计算，常见的计算策略为灰度唯一id对100进行取模（id % 100），根据执行结果判断当前请求符合的百分比。假设计算结果为n, 当前配置的百分比数字为p​:</p>
<p>若n ≤ p，则表示满足灰度条件，当前请求执行灰度逻辑；反之表示当前不满足灰度条件，仍然执行原有逻辑。</p>
<p>看起来是有些简单，但是根据奥卡姆剃刀法则，若无必要，勿增实体。简单的方案往往是更加有效且易于维护的。</p>
<p>只要我们从0-100逐步增加配置阈值p，那么就能够很轻松的实现灰度逻辑逐步推进至全量的过程。</p>
<p>一个基于用户/商户维度进行百分比灰度的代码实现如下：</p>
<pre><code>/**
 * 百分比灰度 默认为0，userId 模 100，余数为灰度百分比
 * @param userId
 * @return
 */
public boolean percentGray(String userId) {
    if (StringUtils.isEmpty(userId)) {
        return false;
    }

    // 校验百分比灰度开关是否打开
    Config config = ConfigService.getAppConfig();
    if (!Boolean.valueOf(config.getProperty(&quot;percent_gray_key&quot;, &quot;false&quot;))) {
        return false;
    }
    // 百分比灰度，默认为0，userId 模 100，余数为灰度百分比,
    try {
        // 获取配置中心配置的取模阈值，本地默认为0，即无灰度
        int percentThreshold = Integer.valueOf(config.getProperty(&quot;percent_gray_mode_percent_key&quot;, &quot;0&quot;));
        // 如果userId不是数字或不能直接转换为数字，则截取数字部分再转换
        int percentThresholdRealTime = Long.valueOf(Long.valueOf(userId) % 100).intValue();
        // 校验范围
        if (percentThresholdRealTime &gt; percentThreshold) {
            return false;
        }
        return true;
    } catch (Exception e) {
        // 异常日志输出

    }
    return false;
}
</code></pre><p>为了保险起见，我们为百分比灰度配置专用的急停开关，当百分比灰度急停开关打开，才会进入到百分比计算流程，否则哪怕由于失误配置了百分比取模的阈值（比如配置为50），只要百分比灰度的开关是关闭的，那么就不会进入到百分比计算的流程中。</p>
<p>这里也体现了防御式编程思想。</p>
<h3 id="综合灰度策略"><a href="#综合灰度策略" class="headerlink" title="综合灰度策略"></a>综合灰度策略</h3><p>实际开发中，我们通常会组合使用上文中提到的灰度策略，实现灵活的灰度配置，以应对复杂业务场景。</p>
<p>具体的过程，用语言描述就是：</p>
<ul>
<li>首先外层还是要有全局开关，用于紧急情况下执行急停；</li>
<li>当请求到来后，先校验全局开关是否打开，如果打开，则继续判断是否满足白名单；否则直接返回，继续执行原有逻辑​；</li>
<li>如果命中白名单，则直接执行灰度业务逻辑；否则继续判断是否满足百分比灰度；</li>
<li>计算当前灰度维度id对100取模结果，判断结果是否小于等于百分比阈值，如果满足，则表示命中灰度，执行灰度业务逻辑，反之则表示其不满足当前灰度，继续执行原有业务逻辑。</li>
</ul>
<p>用一张流程图直观表达一下这个过程，便于加深理解：</p>
<p><img src="/2020/11/01/Java后端研发套路之灰度策略/./mixmode.png" alt="复合灰度流程"></p>
<p>当然，作为研发还是愿意看到代码是怎样落地的，别急，满足你。</p>
<p>复合灰度策略的关键代码实现样本如下（其余部分同上文中提到的代码，此处不重复粘贴）：</p>
<pre><code>/**
 * 复合灰度
 * @param userId
 * @return
 */
public boolean isHitGray(String userId) {
    return globalSwitch() || whiteListGray(userId) || percentGray(userId);
}
</code></pre><p>不要怀疑，就是如此简洁​。</p>
<p>我们只需要实现一个复合灰度方法，通过逻辑或将全局开关灰度、白名单灰度、百分比灰度逻辑连接起来。</p>
<p>三者综合作用，就能够满足我们在上文中通过流程图展示出的复合灰度逻辑。</p>
<p>即：在打开全局开关的前提下，校验是否命中白名单灰度或者符合百分比灰度；但凡全局开关关闭，就返回false，也就是不执行灰度逻辑。</p>
<p>如果不理解，可以回过头在仔细看下流程图，相信你一定能够豁然开朗。</p>
<h3 id="扩展：遗留系统重构与灰度策略"><a href="#扩展：遗留系统重构与灰度策略" class="headerlink" title="扩展：遗留系统重构与灰度策略"></a>扩展：遗留系统重构与灰度策略</h3><p>不久前，有个技术群的朋友咨询了一个问题：</p>
<p>不久前，有个技术群的朋友咨询了一个问题：</p>
<blockquote>
<p>“我们有一个系统，目前是all in one架构，逻辑上通过包（package）划分模块。现在要使用微服务方式进行重构，应该怎样从现有的架构迁移到单独的微服务上来？要求是，迁移过程中不能停机，还需要保证新需求迭代不能停止，并且老的业务逻辑也会进行修改，应该怎么做？”</p>
</blockquote>
<p>我的回答是这样的，答案经过书面化编辑。</p>
<p>这个问题实际上是一个遗留系统重构的场景，并且需要考虑如何将遗留代码在不停机的情况下切换到新系统中。</p>
<p>我的建议是，对于新的产品需求，业务流程直接在新模块中开发，对于老的业务流程还是在原先的业务逻辑上迭代。</p>
<blockquote>
<p>那么具体的迁移过程是怎样的呢？</p>
</blockquote>
<p>实际上也不复杂，问题的核心是不停机迁移，这个比较重要。我们分两类接口讨论。</p>
<p>1.如果是rpc类接口， 我们针对要迁移的功能，在新模块中将老模块的业务逻辑整体迁移过来，老模块的逻辑在保持逻辑不变的情况下，增加灰度分支，分支内调用新模块的代码逻辑。</p>
<p>非灰度逻辑仍旧为原先的遗留代码，随着灰度逐渐进行，老业务逻辑会逐步迁移到新流程，最终原先的老逻辑就不会有请求进入，就可以在某个窗口期直接通过一次灰度发版，把老代码删除。</p>
<p>此时，当灰度执行完毕之后就到达全量，接口逻辑已经完全切到新流程。</p>
<p>这个方式是上游不需要对接口感知的逻辑，另外一种方法是，在调用方进行灰度，服务的消费方编写灰度逻辑，灰度逻辑指向新的模块服务，当灰度结束后，移除原先对老服务的调用，然后在灰度发版的过程中将老服务提供方代码下线。</p>
<p>这个方式上游需要感知下游服务提供方，需要事先修改服务调用配置，并且编写对新接口的调用逻辑，也是一种常见的RPC接口灰度方式。简单讲就是上游业务逻辑层进行灰度逻辑的开发，下游只提供接口实现。好处是下游不关心灰度逻辑，代码整洁度高。坏处是上游有额外的代码开发量，且上游需要关注灰度进程。</p>
<p>2.需要灰度的逻辑是基于http接口，灰度逻辑也RPC也类似，最常见的策略是在http网关接入层增加灰度逻辑，在灰度逻辑块中加入对新模块中逻辑的调用，通过复合灰度策略逐步迁移到新的逻辑中，最后待灰度流程执行到全量之后，把老逻辑的遗留代码删除掉灰度到全量就可以。</p>
<h3 id="本文总结"><a href="#本文总结" class="headerlink" title="本文总结"></a>本文总结</h3><p>本文，笔者带领大家系统的整理了Java后端研发中常见的灰度策略，重点介绍了三种灰度策略：全局开关、黑白名单机制、百分比灰度机制以及将三者组合起来的复合策略。</p>
<p>通过灰度逻辑说明结合代码实战案例，从理论到落地展现了灰度策略的方方面面，这个策略在实际的开发中会经常用到，尤其是当业务处于成熟期，需要不断迭代重构，灰度策略会是开发者经常用到的工具。</p>
<p>系统掌握常见的灰度策略，会大幅度减少新老逻辑切换的风险，提升系统稳定性，并且在潜移默化中提升开发者对系统稳定性的思考，在方案设计中自觉考虑降级，促进系统良性迭代。</p>
<p>当然灰度策略也不是银弹，大量灰度逻辑的编写，会直接增加业务逻辑的复杂度，增加测试难度。并且当业务逻辑全量之后，灰度逻辑往往会成为“脏代码”，此时就可以考虑删除。</p>
<p>但是实际情况常常是，新加入的同学因为不了解灰度策略是否已经全量，并且生产系统本身就很少删除代码，导致灰度逻辑积少成多，最终成为系统走向腐化的推手之一。</p>
<p>解决灰度逻辑堆积的一个实践是：指定灰度计划，显式表明全量时间，在全量之后做好灰度逻辑删除，通过代码review与比对，确保没有多删除代码；测试同学介入对流程进行回归测试，确保业务逻辑符合预期。</p>
<p>通过严谨的灰度策略和回归测试，代码review，既保证灰度流程正常进行，最终迁移到新流程，又保证过时的灰度逻辑不会污染业务代码。</p>
<p>笔者的经验有限，更多的灰度策略使用技巧和心得还需要我们在实际开发中慢慢体会总结，最终沉淀出一套适合自己的工业级的灰度策略。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;日常开发中，对于遗留系统代码逻辑的改造，通常不会粗暴地采用停机更新方式直接迁移到新业务逻辑，往往需要通过灰度方式逐步迁移到新逻辑，最后再把老业务逻辑下线。&lt;/p&gt;
&lt;p&gt;这个过程中就涉及到新老业务逻辑并存的问题，而这个问题是需要研发同学去通过工具、编码、配置等方式实现灰度策略，制定灰度计划，并付诸实施，保障系统能够平稳地从老业务逻辑迁移至新业务逻辑。&lt;/p&gt;
&lt;p&gt;通常情况下，如果是http接口灰度，我们可以利用网关的特性，如nginx自身的能力，根据cookie中传递的唯一标识进行百分比分流，通过免开发的方式进行灰度。&lt;/p&gt;
&lt;p&gt;但在实际开发中，我们面对的系统不仅仅是网关类系统，大部分情况下，分布式系统开发场景下面对的是RPC类接口或者异步消息逻辑，对于这类型代码逻辑的灰度就需要研发同学通过编码方式，细粒度的进行灰度。&lt;/p&gt;
&lt;p&gt;本文中，我们就后者展开代码级别的讨论和分享，向读者介绍笔者在日常开发中，面对接口级别的灰度场景是如何通过编码实现具体的灰度策略的，本文权当抛砖引玉，为读者全景展示​后端研发套路之灰度场景下的瑞士军刀具体是如何使用的。在今后的开发工作中如果你遇到类似场景，可以参考笔者思路，开发适合自己业务的灰度套路。&lt;/p&gt;
    
    </summary>
    
      <category term="Java" scheme="http://wuwenliang.net/categories/Java/"/>
    
    
      <category term="Java" scheme="http://wuwenliang.net/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Java内存阻塞队列实例</title>
    <link href="http://wuwenliang.net/2020/10/20/Java%E5%86%85%E5%AD%98%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97%E5%AE%9E%E4%BE%8B/"/>
    <id>http://wuwenliang.net/2020/10/20/Java内存阻塞队列实例/</id>
    <published>2020-10-20T15:54:46.000Z</published>
    <updated>2020-10-20T16:40:32.323Z</updated>
    
    <content type="html"><![CDATA[<p>在之前的一篇文章 <a href="http://wuwenliang.net/2019/08/19/%E6%89%8B%E5%86%99JDK%E7%BB%84%E4%BB%B6%E4%B9%8B%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97BlockedQueue/">手写JDK组件之阻塞队列BlockedQueue</a> 中  ，我们模仿Java的ArrayBlockingQueue实现了一个阻塞队列。并通过该案例对阻塞队列的实现机制有了一个初步的认识。</p>
<p>实际上，Java中的阻塞队列用处还是比较广泛的，尤其是当我们不需要使用复杂的分布式消息队列，只是想要基于生产者-消费者模型，解耦业务逻辑，那么我们就可以借助内存队列实现。</p>
<p>这类型业务场景往往具备以下特点：</p>
<ul>
<li>消息发送量不多</li>
<li>消息的安全性不高，可以容忍丢失</li>
<li>不需要保证HA</li>
<li>不需要提供完备的failover机制</li>
</ul>
<p>举个例子，比如说当订单下单成功后我们想发送一个站内信，通知商户或者用户下单成功，仅仅作为一个提醒。类似这种场景，我们就可以借助内存队列实现。</p>
<p>基于我们刚提出的这个场景，编写一个demo进行验证。</p>
<a id="more"></a>
<h2 id="场景抽象"><a href="#场景抽象" class="headerlink" title="场景抽象"></a>场景抽象</h2><blockquote>
<p>我们为该场景划分几个部分</p>
</blockquote>
<h3 id="消息发送端"><a href="#消息发送端" class="headerlink" title="消息发送端"></a>消息发送端</h3><p>封装了消息发送、消息合法性校验、消息体转化、内容序列化以及入队逻辑，提供友好的api被业务代码所使用。</p>
<h3 id="阻塞队列"><a href="#阻塞队列" class="headerlink" title="阻塞队列"></a>阻塞队列</h3><p>基于Java的BlockQueue实现，在外层进行一定封装。</p>
<h3 id="消息消费端"><a href="#消息消费端" class="headerlink" title="消息消费端"></a>消息消费端</h3><p>负责读取、并对对列中消息进行消费，当没有消息时进行阻塞等待，遇到异常时会交给异常处理机制进行处理。</p>
<h3 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h3><p>负责在消费消息过程中，出现异常时的后续处理。</p>
<p>常见的处理方式如：</p>
<ul>
<li>对消息经过处理后重新丢回队列</li>
<li>对消息进行持久化，后续进行重发等处理方式。</li>
</ul>
<p>为了提升消息的处理效率，对消费任务通常会通过一个线程去监听队列并阻塞等待。并且这个线程一般都是随应用启动而启动，即：消费端的线程是随着应用初始化而创建，并且常驻内存。</p>
<h2 id="代码讲解"><a href="#代码讲解" class="headerlink" title="代码讲解"></a>代码讲解</h2><p>简单了解了原理和场景，我们直接看代码实现。</p>
<h3 id="核心队列逻辑MailSendQueue-java"><a href="#核心队列逻辑MailSendQueue-java" class="headerlink" title="核心队列逻辑MailSendQueue.java"></a>核心队列逻辑MailSendQueue.java</h3><pre><code>public class MailSendQueue {

    private Logger logger = LoggerFactory.getLogger(MailSendQueue.class);

    /**队列大小*/
    public static final int QUEUE_MAX_SIZE = 100;

    private static MailSendQueue mailSendQueue = new MailSendQueue();

    /**阻塞队列*/
    private BlockingQueue&lt;MailMessageVO&gt; blockingQueue = new LinkedBlockingQueue&lt;MailMessageVO&gt;(QUEUE_MAX_SIZE);

    public static MailSendQueue getInstance() {
        return mailSendQueue;
    }

    /**
    * 消息入队
    *
    * @param alarmMessageVO
    * @return
    */
    public boolean push(MailMessageVO alarmMessageVO) {
        return this.blockingQueue.offer(alarmMessageVO);
    }

    /**
    * 消息出队
    *
    * @return
    */
    public MailMessageVO poll() {
        MailMessageVO result = null;
        try {
            result = this.blockingQueue.take();
        } catch (InterruptedException e) {
            logger.error(&quot;message poll error.&quot;, e);
        }
        return result;
    }

    /**
    * 获取队列大小
    *
    * @return
    */
    public int size() {
        return this.blockingQueue.size();
    }
}
</code></pre><p>类MailSendQueue是我们的邮件发送阻塞队列核心逻辑，它的核心是LinkedBlockingQueue，接受的元素为业务定义的邮件发送对象MailMessageVO。</p>
<p>MailSendQueue提供方法 <strong>push(MailMessageVO alarmMessageVO)</strong> 供消息发送，提供方法 <strong>poll()</strong> 供消息消费。</p>
<p>其中push方法核心为调用BlockingQueue的offer方法，</p>
<p><strong>offer方法会将指定元素插入此队列中（如果立即可行且不会违反容量限制），当插入成功时返回 true，如果当前没有可用的空间，则返回 false，不会抛异常：</strong></p>
<p>出队方法poll()的核心逻辑为调用blockingQueue的take()方法，</p>
<p><strong>take方法会从队列头部获取元素，获取后此队列的头部，在元素变得可用之前一直等待 。queue的长度 == 0 的时候，一直阻塞</strong></p>
<h3 id="生产者逻辑"><a href="#生产者逻辑" class="headerlink" title="生产者逻辑"></a>生产者逻辑</h3><pre><code>public class MessageProducer {
    public void sendMessage(MailMessageVO mailMessageVO) {
        MailSendQueue.getInstance().push(mailMessageVO);
    }
}
</code></pre><p>生产者逻辑很简洁，就是获取MailSendQueue实例，将消息对象入队。</p>
<h3 id="消费者逻辑"><a href="#消费者逻辑" class="headerlink" title="消费者逻辑"></a>消费者逻辑</h3><pre><code>public class MessageConsumer implements Runnable {

    private static final Logger LOGGER = Logger.getLogger(&quot;MessageConsumer&quot;);

    private Thread thread;

    public void start() {
        Thread thread = new Thread(this);
        thread.start();
    }

    @Override
    public void run() {
        while (true) {
            try {
                MailMessageVO mailMessageVO = MailSendQueue.getInstance().poll();
                consume(mailMessageVO);
            } catch (Exception e) {
                LOGGER.warning(&quot;Poll AlarmMessageVO from AlarmMessageQueue error or send alarm mail error.&quot;);
            }
        }
    }

    private void consume(MailMessageVO mailMessageVO) {
        Thread.currentThread().setName(&quot;MessageConsumer-thread&quot;);
        System.out.println(Thread.currentThread().getName() + &quot;-消费消息: &quot; + JSON.toJSONString(mailMessageVO));
    }
}
</code></pre><p>消费者逻辑通过线程触发，通过while，无限循环阻塞等待及消费消息。</p>
<p>此处的业务场景不需要对消费异常的消息进行重试，但在实际工作中，需要根据具体的业务场景去决定是否需要在catch里面进行异常处理流程。</p>
<p>根据经验，实际开发中，我们尽量考虑异常的重试机制，尤其是异步的消息处理场景，尽量对异常流程增加重试操作。比如，常见的措施就是对异常消息进行持久化操作。</p>
<h3 id="调用逻辑"><a href="#调用逻辑" class="headerlink" title="调用逻辑"></a>调用逻辑</h3><p>接着看一下如何进行调用。</p>
<pre><code>public class Client {

    public static void main(String[] args) throws InterruptedException {
        MessageProducer producer = new MessageProducer();
        MessageConsumer consumer = new MessageConsumer();
        consumer.start();

        for (int i = 0; i &lt; 100; i++) {
            MailMessageVO message = new MailMessageVO();
            message.setId(i).setContent(&quot;消息发送,第&quot; + i + &quot;条&quot;);
            producer.sendMessage(message);
            Thread.sleep(1000);
        }

    }
}
</code></pre><p>我们的场景是，发送100条消息，观察消费者的消费情况，日志输出如下：</p>
<pre><code>MessageConsumer-thread-消费消息: {&quot;content&quot;:&quot;消息发送,第0条&quot;,&quot;id&quot;:0}
MessageConsumer-thread-消费消息: {&quot;content&quot;:&quot;消息发送,第1条&quot;,&quot;id&quot;:1}
MessageConsumer-thread-消费消息: {&quot;content&quot;:&quot;消息发送,第2条&quot;,&quot;id&quot;:2}
MessageConsumer-thread-消费消息: {&quot;content&quot;:&quot;消息发送,第3条&quot;,&quot;id&quot;:3}
MessageConsumer-thread-消费消息: {&quot;content&quot;:&quot;消息发送,第4条&quot;,&quot;id&quot;:4}
......
</code></pre><p>可以看到输出符合预期。</p>
<p>此处要注意的是，之所以在消费者内部通过异步线程进行消费处理，主要原因在于消费端是阻塞的，如果在主线程中直接执行，效率较低。</p>
<h3 id="MailMessageVO"><a href="#MailMessageVO" class="headerlink" title="MailMessageVO"></a>MailMessageVO</h3><p>最后贴一下消息体的代码，用于备份。</p>
<pre><code>public class MailMessageVO {

    private int id;
    private String content;
    ...省略get set...
</code></pre><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文我们通过一个案例，基于Java的阻塞队列实现了一个异步的生产-消费模型，提供了一种简单的内存队列的实现方式。</p>
<p>在后续的文章中，我将继续带领读者完善代码，对内存队列使用中的异常场景进行补充讲解，从而掌握到更加贴近生产的内存队列使用经验。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在之前的一篇文章 &lt;a href=&quot;http://wuwenliang.net/2019/08/19/%E6%89%8B%E5%86%99JDK%E7%BB%84%E4%BB%B6%E4%B9%8B%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97BlockedQueue/&quot;&gt;手写JDK组件之阻塞队列BlockedQueue&lt;/a&gt; 中  ，我们模仿Java的ArrayBlockingQueue实现了一个阻塞队列。并通过该案例对阻塞队列的实现机制有了一个初步的认识。&lt;/p&gt;
&lt;p&gt;实际上，Java中的阻塞队列用处还是比较广泛的，尤其是当我们不需要使用复杂的分布式消息队列，只是想要基于生产者-消费者模型，解耦业务逻辑，那么我们就可以借助内存队列实现。&lt;/p&gt;
&lt;p&gt;这类型业务场景往往具备以下特点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;消息发送量不多&lt;/li&gt;
&lt;li&gt;消息的安全性不高，可以容忍丢失&lt;/li&gt;
&lt;li&gt;不需要保证HA&lt;/li&gt;
&lt;li&gt;不需要提供完备的failover机制&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;举个例子，比如说当订单下单成功后我们想发送一个站内信，通知商户或者用户下单成功，仅仅作为一个提醒。类似这种场景，我们就可以借助内存队列实现。&lt;/p&gt;
&lt;p&gt;基于我们刚提出的这个场景，编写一个demo进行验证。&lt;/p&gt;
    
    </summary>
    
      <category term="Java" scheme="http://wuwenliang.net/categories/Java/"/>
    
    
      <category term="Java" scheme="http://wuwenliang.net/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>跟我学RocketMQ之多DC部署HA方案概论</title>
    <link href="http://wuwenliang.net/2020/08/09/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ%E4%B9%8B%E5%A4%9ADC%E9%83%A8%E7%BD%B2HA%E6%96%B9%E6%A1%88%E6%A6%82%E8%AE%BA/"/>
    <id>http://wuwenliang.net/2020/08/09/跟我学RocketMQ之多DC部署HA方案概论/</id>
    <published>2020-08-09T14:46:46.000Z</published>
    <updated>2020-08-09T15:23:51.454Z</updated>
    
    <content type="html"><![CDATA[<p>在企业级生产环境，我们处于高可用的考虑，常常会部署多套MQ集群，提供集群高可用，保证高SLA。</p>
<p>具体到RoceketMQ，在生产环境下我们也需要考虑高可用部署，尤其是跨机房（跨DC）情况下的高可用。</p>
<a id="more"></a>
<h3 id="方案介绍"><a href="#方案介绍" class="headerlink" title="方案介绍"></a>方案介绍</h3><p>我们提供两组RocketMQ集群，假设他们分布在北京电信与联通两处机房。</p>
<p>生产端生产时默认发往电信机房，在电信RocketMQ集群不可用时，切换到联通RocketMQ集群上，从而保证消息生产过程不被打断。</p>
<p>而在消费端，同时启用两个消费者分别消费电信RocketMQ集群与联通RocketMQ集群，保证一定能消费到全量的消息。</p>
<p><strong>整个部署方式的示意图如下</strong><br><img src="/2020/08/09/跟我学RocketMQ之多DC部署HA方案概论/2.png" alt="部署方式"></p>
<p>正常场景下数据流向是 <strong>1 -&gt; 2 -&gt; 4</strong></p>
<p>发生切换后数据流向是 <strong>1 -&gt; 3 -&gt; 5</strong></p>
<h3 id="优缺点分析"><a href="#优缺点分析" class="headerlink" title="优缺点分析"></a>优缺点分析</h3><p>该方案存在几个关键点：</p>
<ol>
<li>生产者何时切换，换言之如何判定RocketMQ集群状态为不可用？</li>
<li>发生切换后，是否需要切换回来，以及何时需要切换回来？</li>
<li>切换后是否会造成消息丢失，如何解决？</li>
<li>切换后是否会造成消息顺序错乱，如何解决？</li>
<li>该高可用方案可以Cover哪些场景，以及无法Cover哪些场景？</li>
</ol>
<p>我们在下文中具体分析以上问题：</p>
<p><strong>1. 生产者何时发生切换，换言之，如何判定北京电信RocketMQ集群状态为不可用？</strong></p>
<p>策略：生产端由生产者自行根据本地发送状况决定，例如连续发送失败N次，则在本地标记该集群A为不可用状态。切换到集群B进行生产。</p>
<p><strong>2. 发生切换后，是否需要以及何时切换回来？</strong></p>
<p>生产端的健康检查线程会周期性的检查两个集群的状态，集群A故障后，必定会通过运维操作恢复，然后健康检查后将集群A的状态恢复为可用状态。此时是否需要切换有业务自行决定。</p>
<p>生产端为RocketMQ集群A和RocketMQ集群B配置分别一个优先级，如果两个集群优先级相同，在RocketMQ集群A恢复后不需要切换回去。如果RocketMQ集群A的优先级高于RocketMQ集群B，则在RocketMQ集群A恢复后切换会A。这样可以提供足够的灵活性。</p>
<p>建议在两个RocketMQ集群的性能与质量没有显著差异时，故障集群恢复后，不要切换回去。减少一次切换的开销。</p>
<p><strong>3. 切换后是否会造成消息丢失如何解决？</strong></p>
<p>生产端一旦认定集群A不可用会立即不再往集群A进行生产，而转向B进行生产。此时的消费端的两个消费者则会被动的发现消费者A不再接收到消息，而消费者B转而开始接收消息。消费端并不关注集群究竟发生了什么。</p>
<p>如果集群A是真的宕机或者断网，那么在集群A内积压的消息，故障期间无法再被消费者获取。如果消息具有强时效性，这部分数据应当被认为丢失，如果不具有强时效性，那么切换回去后，能被继续消费掉，可以认为不会丢失消息。如果集群A并非真的宕机或者断网，其实能提供消费，只是生产端认为其不可用，那么集群A内的消息会被消费者消费完，不会丢失消息。</p>
<p>综上，对于具有强时效性的业务场景，可以认为切换时存在消息丢失。因此业务需要有额外补偿机制，保证在某些消息一直未被消费时，通知到生产端，并触发重新生产。</p>
<p>同时，消费端做好消息去重的准备，因为切换回去后，可能会产生重复消费。</p>
<p><strong>4. 切换后是否会造成消息乱序如何解决？</strong></p>
<p>对于有序消息，生产端一般会根据Hash把同Key的消息发送到同一个Partition，然后消费者顺序消费Partition，从而保证消息的有序性。</p>
<p>切换之前以及切换之后，消息生产和消费仍然满足上述规律，因此消息仍旧是有序的。</p>
<p>切换的那一刻，会出现部分消息在故障集群A中，后续消息在集群B中，此时消费端可能会出现两种情况：</p>
<p>情况1：消费者A无法再取得故障集群A中的消息，消费者B开始获取集群B中的消息。会出现部分消息丢失，但是没有出现消息乱序。</p>
<p>情况2：消费者A仍然能够取得故障集群A中的消息，且消费者B开始获取集群B中的消息。此时会出现消费者A和消费者B两者之间部分消息乱序。</p>
<p>对于情况2，业务可以根据需要对消息添加一些版本信息，也就是发送方对消息进行全局的排序，作为消息顺序依据。</p>
<p><strong>5. 该高可用方案可以Cover哪些场景，无法Cover哪些场景？</strong></p>
<p>可以Cover的场景：</p>
<ul>
<li>电信/联通一处的RocketMQ集群所在机房宕机</li>
<li>电信/联通一处的RocketMQ集群所在机房断网</li>
<li>电信/联通一处的RocketMQ集群本身不可用</li>
</ul>
<p>不能Cover的场景：</p>
<ul>
<li>电信/联通两处RocketMQ集群同时宕机、断网、不可用</li>
<li>消费者所在机房与正在服务的RocketMQ集群之间网络不通</li>
</ul>
<h3 id="方案缺点"><a href="#方案缺点" class="headerlink" title="方案缺点"></a>方案缺点</h3><ol>
<li>需要生产端实现状态判断与切换逻辑，存在一定的工作量。</li>
<li>正常情况下只有一个集群在提供服务，资源存在浪费。</li>
</ol>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>到此我们对跨机房的高可用RocketMQ集群的部署就有了一定的了解，可以看到还是有很多额外的工作要做。</p>
<p>如果业务量不需要，则不需要建设如此复杂的架构，毕竟架构是演进出来的而不仅仅是设计出来的。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在企业级生产环境，我们处于高可用的考虑，常常会部署多套MQ集群，提供集群高可用，保证高SLA。&lt;/p&gt;
&lt;p&gt;具体到RoceketMQ，在生产环境下我们也需要考虑高可用部署，尤其是跨机房（跨DC）情况下的高可用。&lt;/p&gt;
    
    </summary>
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/categories/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
    
      <category term="跟我学RocketMQ" scheme="http://wuwenliang.net/tags/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ/"/>
    
  </entry>
  
  <entry>
    <title>再谈RestTemplate实战应用</title>
    <link href="http://wuwenliang.net/2020/06/28/%E5%86%8D%E8%B0%88RestTemplate%E5%AE%9E%E6%88%98%E5%BA%94%E7%94%A8/"/>
    <id>http://wuwenliang.net/2020/06/28/再谈RestTemplate实战应用/</id>
    <published>2020-06-28T10:08:27.000Z</published>
    <updated>2020-06-28T11:27:11.703Z</updated>
    
    <content type="html"><![CDATA[<p>笔者在两年前写过一篇RestTemplate使用相关的文章，地址: <a href="http://wuwenliang.net/2018/07/23/springboot%E4%B8%AD%E4%BD%BF%E7%94%A8RestTemplate%E8%B0%83%E7%94%A8web%E6%9C%8D%E5%8A%A1%E5%B0%8F%E7%BB%93/">springboot中使用RestTemplate调用web服务小结</a>。</p>
<p>文章写作时SpringBoot版本尚在1.x徘徊，随着SpringBoot版本升级，有些用法在2.x版本中已经不适用。恰逢最近又用到了RestTemplate进行HTTP接口对接，<br>因此写作本文对最新的使用方法进行小结，方便后续参考，也希望能够帮到读者更好的使用RestTemplate在2.x的SpringBoot中进行HTTP接口的调用。</p>
<p>对于Get方式请求，2.x与1.x是兼容的，因此可以直接阅读上文中提到的链接，本文就不再重复赘述。</p>
<a id="more"></a>
<h2 id="配置RestTemplate"><a href="#配置RestTemplate" class="headerlink" title="配置RestTemplate"></a>配置RestTemplate</h2><p>首先需要配置RestTemplate，这是使用它的必要条件。</p>
<p>在项目中引入web依赖，maven坐标如下：</p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
    &lt;version&gt;2.1.3.RELEASE&lt;/version&gt;
&lt;/dependency&gt;
</code></pre><p>只需要这个依赖即可。接着在项目中添加一个配置类，引入RestTemplate的bean定义，你可以直接引入下面的类。</p>
<pre><code>@Configuration
public class RestTemplateConfig {

    @Bean
    public RestTemplate restTemplate(ClientHttpRequestFactory factory){
        return new RestTemplate(factory);
    }

    @Bean
    public ClientHttpRequestFactory simpleClientHttpRequestFactory(){
        SimpleClientHttpRequestFactory factory = new SimpleClientHttpRequestFactory();
        /**读超时单位为ms*/
        factory.setReadTimeout(10000);
        /**连接超时单位为ms*/
        factory.setConnectTimeout(10000);
        return factory;
    }
}
</code></pre><p>这里，我指定读取超时时间和连接超时时间为10s，读者朋友可以根据自己的具体情况灵活配置。</p>
<h2 id="POST请求之表单提交"><a href="#POST请求之表单提交" class="headerlink" title="POST请求之表单提交"></a>POST请求之表单提交</h2><p>使用POST请求方式最常见的就是表单提交，更加专业的说法就是：content-type为 <strong>application/x-www-form-urlencoded</strong>。</p>
<p>使用RestTemplate请求 content-type为 <strong>application/x-www-form-urlencoded</strong> 格式的步骤如下：</p>
<h3 id="设置请求头"><a href="#设置请求头" class="headerlink" title="设置请求头"></a>设置请求头</h3><pre><code>HttpHeaders headers = new HttpHeaders();
headers.setContentType(MediaType.APPLICATION_FORM_URLENCODED);
</code></pre><p>在请求头中设置请求的content-type为application/x-www-form-urlencoded </p>
<h3 id="设置请求参数"><a href="#设置请求参数" class="headerlink" title="设置请求参数"></a>设置请求参数</h3><pre><code>MultiValueMap&lt;String, String&gt; requestParam= new LinkedMultiValueMap&lt;&gt;();
requestParam.add(&quot;paramA&quot;, paramA);
requestParam.add(&quot;paramB&quot;, paramB);
</code></pre><p>这里通过MultiValueMap设置请求参数，如果用get方式展示的话，格式类似于paramA=paramA&amp;paramB=paramB</p>
<h3 id="发送请求"><a href="#发送请求" class="headerlink" title="发送请求"></a>发送请求</h3><pre><code>HttpEntity&lt;MultiValueMap&lt;String, String&gt;&gt; requestEntity =
        new HttpEntity&lt;&gt;(requestParam, headers);

ResponseEntity&lt;String&gt; responseEntity = restTemplate.exchange(
        requestUrl, HttpMethod.POST, requestEntity, String.class);
</code></pre><ol>
<li>通过HttpEntity封装请求参数与headers</li>
<li>通过restTemplate.exchange方法发送请求，请求地址为requestUrl；请求方法为POST，请求参数为requestEntity，请求体数据格式为String</li>
</ol>
<p>exchange的完整方法签名如下：</p>
<pre><code>/**
 * Execute the HTTP method to the given URI template, writing the given request entity to the request, and
 * returns the response as {@link ResponseEntity}.
 * &lt;p&gt;URI Template variables are expanded using the given URI variables, if any.
 * @param url the URL
 * @param method the HTTP method (GET, POST, etc)
 * @param requestEntity the entity (headers and/or body) to write to the request
 * may be {@code null})
 * @param responseType the type of the return value
 * @param uriVariables the variables to expand in the template
 * @return the response as entity
 * @since 3.0.2
 */
&lt;T&gt; ResponseEntity&lt;T&gt; exchange(String url, HttpMethod method, @Nullable HttpEntity&lt;?&gt; requestEntity,
        Class&lt;T&gt; responseType, Object... uriVariables) throws RestClientException;
</code></pre><p>我们直接引用注释的解释：</p>
<ol>
<li>对给定的URI模板执行HTTP方法，将给定的请求实体写入请求，然后将响应返回为{@link ResponseEntity}。</li>
<li>URI模板变量使用给定的URI变量（如果有的话）进行扩展<ol>
<li>url              —请求地址网址</li>
<li>method           —HTTP方法（GET、POST等）</li>
<li>requestEntity    —要写入请求的实体（头和/或正文），可能是{@code null}）</li>
<li>responseType     —返回值的类型</li>
<li>uriVariables     —要在模板中展开的变量</li>
</ol>
</li>
<li>最终以实体形式返回响应</li>
</ol>
<h3 id="解析返回参"><a href="#解析返回参" class="headerlink" title="解析返回参"></a>解析返回参</h3><pre><code>// 这是一段防御代码
if (responseEntity == null) {
    return null;
}

String checkResponseBody = responseEntity.getBody();

// 这是一段防御代码
if (StringUtils.isBlank(checkResponseBody)) {
    return null;
}
</code></pre><p>通过<strong>responseEntity.getBody()</strong> 获取响应体。</p>
<h3 id="反序列化响应体为业务参数"><a href="#反序列化响应体为业务参数" class="headerlink" title="反序列化响应体为业务参数"></a>反序列化响应体为业务参数</h3><p>通过上一步的代码，我们已经能够从响应中获取到responseBody。</p>
<p>接着就可以使用自己喜欢的方式将其反序列化为对象。我习惯使用jackson。</p>
<p>一段简单的反序列化代码如下：</p>
<pre><code>JsonNode responseNode = OBJECT_MAPPER.readTree(checkResponseBody);
String status = responseNode.get(&quot;paramA&quot;).asText();
String msg = responseNode.get(&quot;paramB&quot;).asText();
</code></pre><p>这里解析出来的结果用json方式展示就是如下的样式：</p>
<pre><code>{
    &quot;paramA&quot; : &quot;paramA_value&quot;,
    &quot;paramB&quot; : &quot;paramB_value&quot;,
}
</code></pre><h2 id="POST请求之发送json"><a href="#POST请求之发送json" class="headerlink" title="POST请求之发送json"></a>POST请求之发送json</h2><p>除了上述的常见方式（表单提交）外，当前有些较为前卫的单位热衷于在请求阶段也发送json格式的数据，</p>
<p>相当于直接提交一个json文档。服务端需要对该json文档进行解析，从而完成一定的工作。</p>
<p>json格式的content-type为 <strong>application/json</strong></p>
<p>这里直接引用之前笔者写的开源秒杀案例中的代码进行讲解。</p>
<h3 id="设置请求头-1"><a href="#设置请求头-1" class="headerlink" title="设置请求头"></a>设置请求头</h3><pre><code>// 构造要序列化为json的业务对象
QueryOrdersResponse queryOrdersResponse = new QueryOrdersResponse();
queryOrdersRequest.setSign(sign);
ObjectMapper objectMapper = new ObjectMapper();

// 组装请求头
HttpHeaders headers = new HttpHeaders();
headers.setContentType(org.springframework.http.MediaType.APPLICATION_JSON);

// 构造请求体
HttpEntity&lt;QueryOrdersRequest&gt; httpEntity = new HttpEntity&lt;&gt;(queryOrdersRequest, headers);
</code></pre><ol>
<li>构造待发送的业务实体，为其设置属性</li>
<li>组装请求头，设置content-type为 <strong>application/json</strong></li>
<li>初始化HttpEntity， 通过有参构造方法设置业务实体与headers】</li>
</ol>
<h3 id="发送请求-1"><a href="#发送请求-1" class="headerlink" title="发送请求"></a>发送请求</h3><pre><code>// 2.发送请求
ResponseEntity&lt;String&gt; responseEntity = null;

// 2.1 发起请求
responseEntity = restTemplate.postForEntity(queryOrdersUrl, httpEntity, String.class);
System.out.println(&quot;----&quot; + JSON.toJSONString(responseEntity));
</code></pre><p>json格式的请求可以直接通过restTemplate.postForEntity发送，它的完整方法签名如下</p>
<pre><code>&lt;T&gt; ResponseEntity&lt;T&gt; postForEntity(String url, @Nullable Object request, Class&lt;T&gt; responseType,
    Object... uriVariables) throws RestClientException;
</code></pre><h3 id="解析返回参数"><a href="#解析返回参数" class="headerlink" title="解析返回参数"></a>解析返回参数</h3><p> 接收到ResponseEntity之后，通过 responseEntity.getBody();获取到responseBody，解析方式就和上文中提到的一致了。</p>
<p> 我们可以使用jackson/gson（笔者就不推荐用fastJson了，因为众人皆知的原因，八阿哥有点多啊……）来进行解析了。</p>
<pre><code>// 2.2. 解析返回参数
String responseBody = responseEntity.getBody();
queryOrdersResponse = objectMapper.readValue(responseBody, QueryOrdersResponse.class);
LOGGER.info(&quot;解析订单状态查询接口出参:[{}]&quot;, queryOrdersResponse.toString());
</code></pre><p>到此我们就实现了通过RestTemplate发送JSON格式的POST请求。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文偏应用实战，重点讲解了SpringBoot2.x版本中整合RestTemplate，并使用POST方法发送 <strong>application/x-www-form-urlencoded</strong> 及 <strong>application/json</strong> 两种超媒体文本的步骤。</p>
<p>方便自己以后能够快速落地，并希望能够对读者有所帮助。</p>
<p>相关原理解析会在未来的文章中发布，敬请期待。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;笔者在两年前写过一篇RestTemplate使用相关的文章，地址: &lt;a href=&quot;http://wuwenliang.net/2018/07/23/springboot%E4%B8%AD%E4%BD%BF%E7%94%A8RestTemplate%E8%B0%83%E7%94%A8web%E6%9C%8D%E5%8A%A1%E5%B0%8F%E7%BB%93/&quot;&gt;springboot中使用RestTemplate调用web服务小结&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;文章写作时SpringBoot版本尚在1.x徘徊，随着SpringBoot版本升级，有些用法在2.x版本中已经不适用。恰逢最近又用到了RestTemplate进行HTTP接口对接，&lt;br&gt;因此写作本文对最新的使用方法进行小结，方便后续参考，也希望能够帮到读者更好的使用RestTemplate在2.x的SpringBoot中进行HTTP接口的调用。&lt;/p&gt;
&lt;p&gt;对于Get方式请求，2.x与1.x是兼容的，因此可以直接阅读上文中提到的链接，本文就不再重复赘述。&lt;/p&gt;
    
    </summary>
    
      <category term="spring-boot" scheme="http://wuwenliang.net/categories/spring-boot/"/>
    
    
      <category term="spring-boot" scheme="http://wuwenliang.net/tags/spring-boot/"/>
    
  </entry>
  
</feed>
