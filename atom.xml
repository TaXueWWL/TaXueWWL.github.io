<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>朝·闻·道</title>
  <subtitle>SnoWalker&#39;s Blog</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://wuwenliang.net/"/>
  <updated>2022-02-28T10:15:59.190Z</updated>
  <id>http://wuwenliang.net/</id>
  
  <author>
    <name>SnoWalker</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Disruptor实战-多生产者多消费者</title>
    <link href="http://wuwenliang.net/2022/02/28/Disruptor%E5%AE%9E%E6%88%98-%E5%A4%9A%E7%94%9F%E4%BA%A7%E8%80%85%E5%A4%9A%E6%B6%88%E8%B4%B9%E8%80%85/"/>
    <id>http://wuwenliang.net/2022/02/28/Disruptor实战-多生产者多消费者/</id>
    <published>2022-02-28T10:15:59.000Z</published>
    <updated>2022-02-28T10:15:59.190Z</updated>
    
    <content type="html"><![CDATA[<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;hr&gt;&lt;br&gt;版权声明：&lt;br&gt;&lt;br&gt;原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。&lt;br&gt;&lt;/p&gt;

    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Disruptor实战-单生产者多消费者</title>
    <link href="http://wuwenliang.net/2022/02/28/Disruptor%E5%AE%9E%E6%88%98-%E5%8D%95%E7%94%9F%E4%BA%A7%E8%80%85%E5%A4%9A%E6%B6%88%E8%B4%B9%E8%80%85/"/>
    <id>http://wuwenliang.net/2022/02/28/Disruptor实战-单生产者多消费者/</id>
    <published>2022-02-28T10:15:52.000Z</published>
    <updated>2022-02-28T10:15:52.230Z</updated>
    
    <content type="html"><![CDATA[<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;hr&gt;&lt;br&gt;版权声明：&lt;br&gt;&lt;br&gt;原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。&lt;br&gt;&lt;/p&gt;

    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Disruptor实战-单生产者单消费者</title>
    <link href="http://wuwenliang.net/2022/02/28/Disruptor%E5%AE%9E%E6%88%98-%E5%8D%95%E7%94%9F%E4%BA%A7%E8%80%85%E5%8D%95%E6%B6%88%E8%B4%B9%E8%80%85/"/>
    <id>http://wuwenliang.net/2022/02/28/Disruptor实战-单生产者单消费者/</id>
    <published>2022-02-28T10:15:45.000Z</published>
    <updated>2022-02-28T10:15:45.726Z</updated>
    
    <content type="html"><![CDATA[<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;hr&gt;&lt;br&gt;版权声明：&lt;br&gt;&lt;br&gt;原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。&lt;br&gt;&lt;/p&gt;

    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Disruptor高性能之道-等待策略</title>
    <link href="http://wuwenliang.net/2022/02/28/Disruptor%E9%AB%98%E6%80%A7%E8%83%BD%E4%B9%8B%E9%81%93-%E7%AD%89%E5%BE%85%E7%AD%96%E7%95%A5/"/>
    <id>http://wuwenliang.net/2022/02/28/Disruptor高性能之道-等待策略/</id>
    <published>2022-02-28T10:10:34.000Z</published>
    <updated>2022-02-28T10:10:34.115Z</updated>
    
    <content type="html"><![CDATA[<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;hr&gt;&lt;br&gt;版权声明：&lt;br&gt;&lt;br&gt;原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。&lt;br&gt;&lt;/p&gt;

    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Disruptor高性能之道-环形数组RingBuffer</title>
    <link href="http://wuwenliang.net/2022/02/28/Disruptor%E9%AB%98%E6%80%A7%E8%83%BD%E4%B9%8B%E9%81%93-%E7%8E%AF%E5%BD%A2%E6%95%B0%E7%BB%84RingBuffer/"/>
    <id>http://wuwenliang.net/2022/02/28/Disruptor高性能之道-环形数组RingBuffer/</id>
    <published>2022-02-28T10:10:16.000Z</published>
    <updated>2022-02-28T13:57:13.504Z</updated>
    
    <content type="html"><![CDATA[<p>Ringbuffer（环形缓冲区/环形数组）是Disruptor的核心底层数据结构。</p>
<p>它不同于传统的阻塞队列（如：ArrayBlockingQueue）是从某一端入队，另外一端出队，而是一种收尾相连的环形结构。</p>
<p><img src="/2022/02/28/Disruptor高性能之道-环形数组RingBuffer/ringbuffer.png" alt="ringbuffer.png"></p>
<p>之所以叫它 buffer，我想大概是因为这个环形队列是作为不同线程（or上下文）之间传递数据媒介，类似于一个缓冲区。</p>
<p>RingBuffer拥有一个序号，指向数组中下一个可用的元素，需要注意的是Disruptor中的RingBuffer没有头尾指针，而只通过序号（sequence）就实现了生产者与消费者之间的进度协调。</p>
<h2 id="RingBuffer可以一直填充吗？"><a href="#RingBuffer可以一直填充吗？" class="headerlink" title="RingBuffer可以一直填充吗？"></a>RingBuffer可以一直填充吗？</h2><p>假如不断地填充RingBuffer，那么必然会发生sequence一直增加，直到绕过环，覆盖原有的内容。</p>
<p>Disruptor是通过barrier实现了是否要覆盖原有内容的判断，这部分内容后面会说到。</p>
<h2 id="如何定位RingBuffer中的元素呢？"><a href="#如何定位RingBuffer中的元素呢？" class="headerlink" title="如何定位RingBuffer中的元素呢？"></a>如何定位RingBuffer中的元素呢？</h2><p>正如我们在前面所说，RingBuffer本质上是个数组，那么必然可以通过数组的偏移量offset或者说index，定位到具体的元素。</p>
<p>在实际的开发中，我们常通过取模运算来获取元素在数组中的偏移量。也就是  <strong>序号 % 长度 == 索引</strong></p>
<p>假设有8个元素，那么元素序号为13的元素就位于：</p>
<blockquote>
<p>13 % 8 = 5</p>
</blockquote>
<p>对于Disruptor而言，它强制要求数组的size初始化为 2的N次方，如 1024 * 1024。</p>
<blockquote>
<p>设置为2的N次方有这样的好处：可以通过位运算更快速定位到元素位置。公式为：</p>
<p>seq &amp; (ringBufferSize - 1) == index</p>
</blockquote>
<p>在Disruptor中， ringBufferSize-1 成为mask，即掩码。</p>
<h2 id="RingBuffer中的数据是如何预热的？"><a href="#RingBuffer中的数据是如何预热的？" class="headerlink" title="RingBuffer中的数据是如何预热的？"></a>RingBuffer中的数据是如何预热的？</h2><p>RingBuffer通过预分配对象机制来降低GC的影响。在实际运行过程中，业务从RingBuffer中获取对应sequence位置的对象引用，对该引用指向的对象属性赋值，通过覆盖写方式而不是直接覆盖整个对象的方式，保证了对象引用在整个disruptor存活的周期内都存在，保证GCRoot始终存在，因此能够大幅降低GC的影响。</p>
<p>这也是Disruptor高性能保证的策略之一。</p>
<p>具体的实现，查看Disruptor源码：</p>
<p>Disruptor初始化过程中会初始化RingBuffer:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">RingBuffer( EventFactory&lt;E&gt; eventFactory,Sequencer sequencer)&#123;</div><div class="line">    super(eventFactory, sequencer);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>RingBuffer是RingBufferFields子类：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">public final class RingBuffer&lt;E&gt; extends RingBufferFields&lt;E&gt; implements Cursored, EventSequencer&lt;E&gt;, EventSink&lt;E&gt;</div></pre></td></tr></table></figure>
<p>初始化RingBuffer时会先调用父类构造：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">RingBufferFields(EventFactory&lt;E&gt; eventFactory, Sequencer sequencer) &#123;</div><div class="line">    this.sequencer = sequencer;</div><div class="line">    this.bufferSize = sequencer.getBufferSize();</div><div class="line"></div><div class="line">    if (bufferSize &lt; 1)</div><div class="line">    &#123;</div><div class="line">        throw new IllegalArgumentException(&quot;bufferSize must not be less than 1&quot;);</div><div class="line">    &#125;</div><div class="line">    if (Integer.bitCount(bufferSize) != 1)</div><div class="line">    &#123;</div><div class="line">        throw new IllegalArgumentException(&quot;bufferSize must be a power of 2&quot;);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    // 用于计算index的掩码，公式：seq &amp; (ringBufferSize - 1) == index</div><div class="line"></div><div class="line">    this.indexMask = bufferSize - 1;</div><div class="line"></div><div class="line">    // 初始化RingBuffer数组</div><div class="line"></div><div class="line">    this.entries = new Object[sequencer.getBufferSize() + 2 * BUFFER_PAD];</div><div class="line"></div><div class="line">    // 预填充RingBuffer数组</div><div class="line">    fill(eventFactory);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>接着调用fill方法预填充数组，实现逻辑就是为数组的每个index填充一个对象实例。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">private void fill(EventFactory&lt;E&gt; eventFactory)&#123;</div><div class="line">    for (int i = 0; i &lt; bufferSize; i++)&#123;</div><div class="line">        entries[BUFFER_PAD + i] = eventFactory.newInstance();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>填充操作通过用户定义的eventFactory实现，该工厂一般写法为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">public class OrderEventFactory implements EventFactory&lt;OrderEvent&gt; &#123;</div><div class="line">    @Override</div><div class="line">    public OrderEvent newInstance() &#123;</div><div class="line">        // new 一个空的orderEvent对象即可</div><div class="line">        // 就是为了返回空的event对象</div><div class="line">        return new OrderEvent();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Ringbuffer（环形缓冲区/环形数组）是Disruptor的核心底层数据结构。&lt;/p&gt;
&lt;p&gt;它不同于传统的阻塞队列（如：ArrayBlockingQueue）是从某一端入队，另外一端出队，而是一种收尾相连的环形结构。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2022/0
    
    </summary>
    
      <category term="disruptor" scheme="http://wuwenliang.net/categories/disruptor/"/>
    
    
      <category term="disruptor" scheme="http://wuwenliang.net/tags/disruptor/"/>
    
  </entry>
  
  <entry>
    <title>Disruptor高性能之道-缓存行填充</title>
    <link href="http://wuwenliang.net/2022/02/28/Disruptor%E9%AB%98%E6%80%A7%E8%83%BD%E4%B9%8B%E9%81%93-%E7%BC%93%E5%AD%98%E8%A1%8C%E5%A1%AB%E5%85%85/"/>
    <id>http://wuwenliang.net/2022/02/28/Disruptor高性能之道-缓存行填充/</id>
    <published>2022-02-28T10:09:11.000Z</published>
    <updated>2022-02-28T10:09:11.011Z</updated>
    
    <content type="html"><![CDATA[<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;hr&gt;&lt;br&gt;版权声明：&lt;br&gt;&lt;br&gt;原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。&lt;br&gt;&lt;/p&gt;

    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Disruptor高性能之道-无锁</title>
    <link href="http://wuwenliang.net/2022/02/28/Disruptor%E9%AB%98%E6%80%A7%E8%83%BD%E4%B9%8B%E9%81%93-%E6%97%A0%E9%94%81/"/>
    <id>http://wuwenliang.net/2022/02/28/Disruptor高性能之道-无锁/</id>
    <published>2022-02-28T10:08:59.000Z</published>
    <updated>2022-02-28T10:08:59.108Z</updated>
    
    <content type="html"><![CDATA[<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;hr&gt;&lt;br&gt;版权声明：&lt;br&gt;&lt;br&gt;原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。&lt;br&gt;&lt;/p&gt;

    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>认识高性能并发框架Disruptor</title>
    <link href="http://wuwenliang.net/2022/02/28/%E8%AE%A4%E8%AF%86%E9%AB%98%E6%80%A7%E8%83%BD%E5%B9%B6%E5%8F%91%E6%A1%86%E6%9E%B6Disruptor/"/>
    <id>http://wuwenliang.net/2022/02/28/认识高性能并发框架Disruptor/</id>
    <published>2022-02-28T10:07:11.000Z</published>
    <updated>2022-02-28T11:05:15.322Z</updated>
    
    <content type="html"><![CDATA[<p>Disruptor，一款超高性能、超低延迟的并发编程框架。这里用了两个“超”来突出它在性能上的优越性。</p>
<p>它的性能远远超过了传统并发编程基于锁同步，阻塞队列的实现方案，在高性能后端编程中，disruptor是一个不错的选择。</p>
<h2 id="Disruptor从何而来？"><a href="#Disruptor从何而来？" class="headerlink" title="Disruptor从何而来？"></a>Disruptor从何而来？</h2><p>Disruptor的爆火起源于软件开发大师 martin fowler（马丁富勒）在自己网站上一篇文章，<a href="https://martinfowler.com/articles/lmax.html" target="_blank" rel="external">原文链接</a> 文章介绍了外汇交易平台LMAX使用并开源的一种架构方案。</p>
<p>LMAX使用该方案实现了难以置信的 “单线程每秒处理600w订单” 的惊人能力。业务处理逻辑基于 完全运行内存运行 + 事件溯源 方式驱动。</p>
<p>Disruptor目前已经被LMAX开源，github地址 <a href="https://github.com/LMAX-Exchange/disruptor" target="_blank" rel="external">https://github.com/LMAX-Exchange/disruptor</a>。</p>
<h2 id="Disruptor有何特点？"><a href="#Disruptor有何特点？" class="headerlink" title="Disruptor有何特点？"></a>Disruptor有何特点？</h2><blockquote>
<p>Disruptor性能优越，必然有其设计上的独到之处，一般来说，我们认为Disruptor有以下特点：</p>
</blockquote>
<ul>
<li>Disruptor是面向并发编程的高性能框架，它在开发上简化了并发程序编码难度，性能上也是JUC并发包的数倍乃至十几倍；</li>
<li>Disruptor是CPU友好的、无锁的，基于单线程方式对任务进行调度，减少了上下文切换对系统资源的开销；</li>
<li>Disruptor底层数据结构基于数组，通过预加载方式提前加载对象到内存；Disruptor不会清理缓存中的数据，而是通过覆盖对象属性方式实现数据的读写，这降低了GC频率，使得系统资源的使用趋于平稳；</li>
<li>Disruptor能够避免“伪共享”，通过缓存行填充机制，Disruptor避免了伪共享对并发读写变量的消耗，消除了不必要缓存未命中。</li>
</ul>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Disruptor，一款超高性能、超低延迟的并发编程框架。这里用了两个“超”来突出它在性能上的优越性。&lt;/p&gt;
&lt;p&gt;它的性能远远超过了传统并发编程基于锁同步，阻塞队列的实现方案，在高性能后端编程中，disruptor是一个不错的选择。&lt;/p&gt;
&lt;h2 id=&quot;Disrup
    
    </summary>
    
      <category term="disruptor" scheme="http://wuwenliang.net/categories/disruptor/"/>
    
    
      <category term="disruptor" scheme="http://wuwenliang.net/tags/disruptor/"/>
    
  </entry>
  
  <entry>
    <title>金融系统101-股市交易那些事儿</title>
    <link href="http://wuwenliang.net/2022/02/23/%E9%87%91%E8%9E%8D%E7%B3%BB%E7%BB%9F101-%E8%82%A1%E5%B8%82%E4%BA%A4%E6%98%93%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/"/>
    <id>http://wuwenliang.net/2022/02/23/金融系统101-股市交易那些事儿/</id>
    <published>2022-02-23T15:20:38.000Z</published>
    <updated>2022-02-23T15:56:15.238Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>金融是这个世界运转不可或缺的部分，学习一点儿金融交易知识也是我们了解世界运行规律的一种方式。本系列“金融交易101”主要目的为普及一些金融交易相关的基础概念，不作为任何的投资建议与参考。希望我们在了解了这些金融证券交易的知识之后，能够明辨风险，谨慎理财。</p>
</blockquote>
<p>股市，顾名思义，股票市场。核心在于股票，市场的运转围绕着股票这一核心概念展开。</p>
<a id="more"></a>
<h2 id="中国股市的发展"><a href="#中国股市的发展" class="headerlink" title="中国股市的发展"></a>中国股市的发展</h2><blockquote>
<p>接触一个概念，要从其发展历史梳理脉络。</p>
</blockquote>
<p>我国股市在1989年开始试点，实行T+1交割、T+1交收机制。</p>
<p>主要交易所，如上海证券交易所（上交所）、深圳证券交易所（深交所）在A股市场均实行T+1交收。</p>
<p>交易双方在交易次日完成与交易有关证券、款项的收付，买卖双方的行为为：<strong>买方收到证券、卖方收到款项</strong>。</p>
<p>随着商品经济的发展，公司的规模越来越大，需要大量的长期资本。而如果单靠公司自身的资本化积累，是很难满足生产发展的需求的，所以必须从外部筹集资金。</p>
<p>而公司筹集长期资本一般有三种方式：一是向银行借贷；二是发行公司债券；三是发行股票。其中，股票市场是上市公司筹集资金的主要途径之一。原因在于前两种方式的利息较高，且存在时间限制，这不仅增加了公司的经营成本，而且使公司的资本难以稳定，因而有很大的局限性。</p>
<p>而利用发行股票的方式来筹集资金，则无须还本付息，只需在利润中划拨一部分出来支付红利即可。把这三种筹资方式综合比较起来，发行股票的方式无疑是最符合经济原则的，对公司来说是最有利的。所以发行股票来筹集资本就成为发展大企业经济的一种重要形式，而股票交易在整个证券交易中因此而占有相当重要的地位。</p>
<h2 id="股市相关术语"><a href="#股市相关术语" class="headerlink" title="股市相关术语"></a>股市相关术语</h2><blockquote>
<p>了解股市相关的术语，也就是了解股市的领域特定语言，对于进一步学习有着重要意义。学习术语也是走进一个领域的必经之路。</p>
</blockquote>
<ul>
<li>集合竞价</li>
</ul>
<blockquote>
<p>集合竞价是指对一段时间内接收的买卖申报一次性集中撮合的竞价方式。</p>
</blockquote>
<p>  9：15——9：20这五分钟，交易主机可接收买卖申报，也可接收撤单申报，但不对买卖申报或撤销申报做处理。<br>  9：20——9：25、14:57——15:00，交易主机不接受参与竞价交易的撤销申报。</p>
<ul>
<li>股票价格</li>
</ul>
<blockquote>
<p>是指股票在证券市场上买卖时的价格，市场不断撮合交易， 股票价格也由此不断产生变化， 这是直接反映股票价值的重要信息。</p>
</blockquote>
<ul>
<li>成交量(VOL)</li>
</ul>
<blockquote>
<p>成交量是股票在某一个单位时间内（分钟、小时、天）的成交数量。市场活跃时， 供不应求， 成交量一般比较大； 市场冷清时， 供大于求， 成交量萎缩， 代表人气低下。</p>
</blockquote>
<ul>
<li>外盘</li>
</ul>
<blockquote>
<p>外盘就是股票的买家以卖家的卖出价而买入成交，当成交价在卖出价时，将成交数量加入外盘累计数量中，这是一种买盘比较积极的表现。</p>
</blockquote>
<ul>
<li>内盘</li>
</ul>
<blockquote>
<p>内盘是指卖家以买家的买入价而卖出成交， 当成交价在买入价时，将成交数量加入内盘累计数量中， 这是一种抛售比较明显的表现。</p>
</blockquote>
<ul>
<li>开盘价</li>
</ul>
<blockquote>
<p>是指某种证券在证券交易所每个交易日开市后的第一笔每股买卖成交价格。世界上大多数证券交易所都采用成交额最大原则来确定开盘价。</p>
<p>如果开市后一段时间内（通常为半小时）某种证券没有买卖或没有成交，则取前一日的收盘价作为当日证券的开盘价。如果某证券连续数日未成交，则由证券交易所的场内中介经纪人根据客户对该证券买卖委托的价格走势提出指导价，促使成交后作为该证券的开盘价。在无形化交易市场中，如果某种证券连续数日未成交，以前一日的收盘价作为它的开盘价。</p>
</blockquote>
<ul>
<li>收盘价</li>
</ul>
<blockquote>
<p>指某种证券在证券交易所一天交易活动结束前最后一笔交易的成交价格。如当日没有成交，则采用上一交易日的收盘价作为当天的收盘价。收盘价是当日行情的标准，又是下一个交易日开盘价的依据，可据以预测未来证券市场行情；所以投资者对行情分析时，一般采用收盘价作为计算依据。</p>
</blockquote>
<ul>
<li>涨跌幅限制</li>
</ul>
<blockquote>
<p>是指在一个交易日内，除上市首日证券外，国内证券的交易价格相对上一交易日收市价格的涨跌幅度不得超过10%；超过涨跌限价的委托为无效委托。[<strong>这个机制本质上是一种“韭菜”保护程序，在美股并不存在类似的限制</strong>]</p>
</blockquote>
<h2 id="股票行情"><a href="#股票行情" class="headerlink" title="股票行情"></a>股票行情</h2><blockquote>
<p>股票行情指股票交易所内各只股票的涨幅变化及交易流通情况。每只股票的行情实质是由<strong>价格</strong>与<strong>时间</strong>组成。</p>
</blockquote>
<p><strong>股票价格</strong>，是指股票在证券市场上买卖时的价格。股票本身没有价值，仅是一种凭证。</p>
<p>其有价格的原因是它能给其持有者带来股利收入，故买卖股票实际上是购买或出售一种领取股利收入的凭证。票面价值是参与公司利润分配的基础，股利水平是一定量的股份资本与实现的股利比率，利息率是货币资本的利息率水平。</p>
<p>股票的<strong>买卖价格</strong>，即股票行市的高低，直接取决于股息的数额与银行存款利率的高低。它直接受供求的影响，而供求又受股票市场内外诸多因素影响，从而使股票的行市背离其票面价值。例如公司的经营状况、信誉、发展前景、股利分配政策以及公司外部的经济周期变动、利率、货币供应量和国家的政治、经济与重大政策等是影响股价波动的潜在因素，而股票市场中发生的交易量、交易方式和交易者成份等等可以造成股价短期波动。另外，人为地操纵股票价格，也会引起股价的涨落。</p>
<h2 id="股票交易规则"><a href="#股票交易规则" class="headerlink" title="股票交易规则"></a>股票交易规则</h2><ul>
<li>交易时间</li>
</ul>
<blockquote>
<p>股票交易时间在工作日的上午和下午，上午是9:30-11:30，下午是13:00-15:00。我们管开始交易叫“<strong>开盘</strong>”，交易结束叫“<strong>收盘</strong>”。</p>
</blockquote>
<ul>
<li>交易品种</li>
</ul>
<blockquote>
<p>交易品种属于在上交所、深交所上市的股票（A股、B股）、债券（国债和企业债券）、封闭式基金、ETF基金和权证等。 A股股票是以<strong>人民币</strong>进行交易的股票，是投资者股票交易的主要品种。B股股票是以<strong>外币</strong>进行交易的股票。上海证券交易所的B股以美元进行交易，深圳证券交易所的B股以港币进行交易。</p>
</blockquote>
<ul>
<li>交易制度</li>
</ul>
<blockquote>
<p>实行 T+1 操作，当天买入的股票第二天才能卖出。不能透支及买空卖空。(<strong>区别于币市的7*24实时交易，这种方式更加安全可靠，且能够在监管之下避免诸如对敲等非法交易手段。</strong>)</p>
</blockquote>
<ul>
<li>交易单位</li>
</ul>
<blockquote>
<p>买入股票或基金，申报数量应当为100股(份)或其整数倍，A股、基金的申报价格最小变动单位为0.01元人民币。股票(基金)单笔申报最大数量应当低于100万股(份)。</p>
</blockquote>
<p>备注：100股称为“1手”。</p>
<h2 id="股票是如何交易的？"><a href="#股票是如何交易的？" class="headerlink" title="股票是如何交易的？"></a>股票是如何交易的？</h2><p>股票在股市属于一种“商品”，它会在买卖双方之间交易。</p>
<p>买卖双方，即买方、卖方。</p>
<p><strong>“多”</strong> 和 <strong>“空”</strong>，这两个词在金融市场上很常见，所谓“多”，就是指上涨、向好，所谓“空”，就是下跌，向差。</p>
<h3 id="什么是看多-看空-做多-做空"><a href="#什么是看多-看空-做多-做空" class="headerlink" title="什么是看多/看空/做多/做空"></a>什么是看多/看空/做多/做空</h3><p>所以“看多”，就是指对之后的行情走势比较看好，比如说“看多某只股票”就是觉得这个股票之后会涨。 “看空”则相反。再就是“做多”，“做”的意思等同于“交易”了。“做多”就是认为未来会涨，所以买入。</p>
<p>那”做空“就是认为未来会跌，然后卖出了？卖出其实并不是做空，因为卖出了，其实就跟你没关系了。所谓“卖空“，是指认为未来某只股票会跌，所以先借到比如30万股该股票，然后以现价（比如10元/股）卖出，等到股票下跌后（比如跌到5元/股），再买回来还给别人，从而实现盈利。因为 <strong>国内没有卖空</strong> 的机制，所以大家可能并不熟悉， 在期货市场就可以实现做空。</p>
<p>看空与看多并不会直接影响股市价格走势，而做多与做空则会实际对价格走势造成影响。</p>
<p>做多，即买入股票，股市本身是撮合交易，它遵循“价格优先、时间优先”的规律。</p>
<p>对于买方而言，出价越高，越容易成交；</p>
<p>对于卖方而言，出价越低，越容易成交。</p>
<p>所以做多成交，会使得市场中的股价不断抬升，相反，做空成交则会使得市场中的价格走势不断降低。</p>
<p>从这里我们也能看出，这种多空交易本身是一种博弈，而完善的金融市场本质上就是这样的一个具备“多空”矛盾于一身的市场。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文主要对金融市场中的股票交易进行了概要讲解，希望这些入门级别的概念能够帮助读者打开金融学习的大门，为更好的了解世界是如何运转的打好基础。</p>
<blockquote>
<p>预告：后续会基础推出撮合交易原理及代码实现的文章，敬请期待。</p>
</blockquote>
<h2 id="参考内容"><a href="#参考内容" class="headerlink" title="参考内容"></a>参考内容</h2><ul>
<li>智牛股-6-股票与撮合交易</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;金融是这个世界运转不可或缺的部分，学习一点儿金融交易知识也是我们了解世界运行规律的一种方式。本系列“金融交易101”主要目的为普及一些金融交易相关的基础概念，不作为任何的投资建议与参考。希望我们在了解了这些金融证券交易的知识之后，能够明辨风险，谨慎理财。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;股市，顾名思义，股票市场。核心在于股票，市场的运转围绕着股票这一核心概念展开。&lt;/p&gt;
    
    </summary>
    
      <category term="金融系统" scheme="http://wuwenliang.net/categories/%E9%87%91%E8%9E%8D%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="金融系统" scheme="http://wuwenliang.net/tags/%E9%87%91%E8%9E%8D%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>调优利器-火焰图使用图鉴</title>
    <link href="http://wuwenliang.net/2022/02/22/%E8%B0%83%E4%BC%98%E5%88%A9%E5%99%A8-%E7%81%AB%E7%84%B0%E5%9B%BE%E4%BD%BF%E7%94%A8%E5%9B%BE%E9%89%B4/"/>
    <id>http://wuwenliang.net/2022/02/22/调优利器-火焰图使用图鉴/</id>
    <published>2022-02-22T04:54:43.000Z</published>
    <updated>2022-02-22T05:57:22.672Z</updated>
    
    <content type="html"><![CDATA[<p>本来想起个题目叫 “什么？你还没用过这个工具？” 或者 “再见，火焰图”。但是想了想，己所不欲，勿施于人。</p>
<p>正常写个题目就好了，非搞这么多噱头，就是为了所谓的阅读量和点击量。</p>
<p>如果内容是干货，对人有帮助还好，要是满怀期待打开，进去划拉划拉，越看越不对劲，最后拉到末尾才近乎“上当了”，又是可恶的推广软文，这种感觉就如同吃了翔味的巧克力一样，让人反胃。</p>
<blockquote>
<p>言归正传，今天来聊聊性能调优利器，火焰图的安装、使用及分析方法。</p>
<p>火焰图（Flame Graph）是由 Linux 性能优化大师 Brendan Gregg 发明的，和所有其他的 profiling 方法不同的是，火焰图以一个全局的视野来看待时间分布，它从底部往顶部，列出所有可能导致性能瓶颈的调用栈。</p>
</blockquote>
<p>先看一个火焰图的样例，看不懂不要紧，后文会解释怎么去理解，稍安勿躁。</p>
<p><img src="/2022/02/22/调优利器-火焰图使用图鉴/fire.PNG" alt="fire.PNG"></p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>要获得火焰图，需要安装一套组件，核心的组件主要有</p>
<ul>
<li>async-profiler : 性能数据采集</li>
<li>FlameGraph     : 性能数据分析，并生成火焰图</li>
</ul>
<p>接下来按顺序讲解安装过程，读者朋友如果严格按照这个步骤来操作，一般都没有问题。</p>
<h3 id="原料准备"><a href="#原料准备" class="headerlink" title="原料准备"></a>原料准备</h3><p>至少需要有一套linux机器，笔者用的是centos-7。</p>
<p>可以搞个阿里云的ecs，也可以搞个虚拟机，当然直接在公司机器上操作也未尝不可，但是要注意安全，root权限下操作要小心（你懂的）。</p>
<h3 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h3><p>在正式安装之前，先确保环境已经准备好。否则环境搞了半天搞不定，直接放弃，打出GG。</p>
<blockquote>
<p>至少保证jdk、perl、c++编译器已经安装完毕。</p>
</blockquote>
<ol>
<li>安装Java，不用多说了哇，网上教程一大堆。</li>
</ol>
<blockquote>
<p>yum -y install git</p>
</blockquote>
<ol>
<li>安装GCC编译器</li>
</ol>
<blockquote>
<p>yum install gcc gcc-c++</p>
</blockquote>
<p>如果去搜索一下火焰图的其他教程，你可以会发现，有些教程让你安装 perf，我也试过了，装了perf，然后用perf-map-agent去搜集性能数据，直接失败了。</p>
<p>换成async-profiler，直接一次成功。不想踩坑的同学，直接用async-profiler吧，省心。</p>
<h3 id="获取源码"><a href="#获取源码" class="headerlink" title="获取源码"></a>获取源码</h3><p>很多教程都说，要安装git，然后使用git clone方式下载源码，但是他们没有交代的是，除了git安装外，你还需要经过配置才可以实现源码下载。</p>
<p>其实源码获取有更简便的方式，或许也不太简便吧，管他呢。</p>
<blockquote>
<p>安装lrzsz，用于上传文件</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install -y lrzsz</div></pre></td></tr></table></figure>
<blockquote>
<p>安装完成之后，获取async-profiler源码包。</p>
</blockquote>
<p>进入async-profiler源码地址，<a href="https://github.com/jvm-profiling-tools/async-profiler，" target="_blank" rel="external">https://github.com/jvm-profiling-tools/async-profiler，</a> 微信禁止外链，读者可以自行复制粘贴至浏览器访问。</p>
<p><img src="/2022/02/22/调优利器-火焰图使用图鉴/download-async.PNG" alt="download-async.PNG"></p>
<p>点击图中红线圈住的 <strong>“download zip”</strong> ，待下载完成之后，通过 <strong>sz -y</strong> 方式上传源码包。</p>
<p><img src="/2022/02/22/调优利器-火焰图使用图鉴/upload-async.PNG" alt="upload-async.PNG"></p>
<blockquote>
<p>使用相同的方式，将FlameGraph的源码包也上传至服务器。</p>
</blockquote>
<p>进入FlameGraph源码地址，<a href="https://github.com/brendangregg/FlameGraph" target="_blank" rel="external">https://github.com/brendangregg/FlameGraph</a> 下载源码压缩包，也一并上传至服务器。</p>
<p>具体的图不贴了，和上面一模一样。</p>
<h3 id="安装async-profiler"><a href="#安装async-profiler" class="headerlink" title="安装async-profiler"></a>安装async-profiler</h3><p>接着就到重头戏了，首先介绍如何安装async-profiler。</p>
<p>进入async-profiler源码上传路径，解压源码（直接unzip async-profiler.zip），进入解压后的文件目录。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd async-profiler</div><div class="line">make</div></pre></td></tr></table></figure>
<p>make完成之后，等待安装完成即可。</p>
<h3 id="安装FlameGraph"><a href="#安装FlameGraph" class="headerlink" title="安装FlameGraph"></a>安装FlameGraph</h3><p>实际上FlameGraph也无需安装，将代码上传并解压，就可以直接使用。</p>
<h2 id="【实战】分析Java性能，生成火焰图"><a href="#【实战】分析Java性能，生成火焰图" class="headerlink" title="【实战】分析Java性能，生成火焰图"></a>【实战】分析Java性能，生成火焰图</h2><p>接着讲一个实战案例。</p>
<p>首先，要有一个分析目标程序，我在服务器上部署了一个基于netty的im聊天demo，同时启动服务端与客户端。</p>
<p>启动服务端：</p>
<blockquote>
<p>nohup java -jar im-server-1.0.0-jar-with-dependencies.jar &gt; Log.log 2&gt;&amp;1 &amp;</p>
</blockquote>
<p>启动客户端，指定服务端地址（客户端与服务端在同一个机器）</p>
<blockquote>
<p>java -jar  -Dremote_ip=127.0.0.1 im-client-1.0.0-jar-with-dependencies.jar </p>
</blockquote>
<h3 id="启动性能分析"><a href="#启动性能分析" class="headerlink" title="启动性能分析"></a>启动性能分析</h3><p>启动性能分析，持续收集一分钟服务端性能指标。</p>
<p>先获取服务端的PID：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"> </div><div class="line">[root@snowalker ~]# ps -ef | grep java</div><div class="line">root      9349     1  0 Feb11 ?        00:09:40 java -jar im-server-1.0.0-jar-with-dependencies.jar</div></pre></td></tr></table></figure>
<p>PID为9349，接着启动async-profiler收集java进程的性能指标。</p>
<blockquote>
<p>./profiler.sh -d 60 -o collapsed -f /tmp/test_01.txt ${pid}</p>
</blockquote>
<p>简单解释下，</p>
<ul>
<li>-d表示的是持续时长，60代表持续采集时间60s；</li>
<li>-o表示的是采集规范，这里用的是collapsed；</li>
<li>-f后面的路径，表示的是数据采集后生成的数据存放的文件路径（这里放在了/tmp/test_01.txt）</li>
<li>${pid} 表示的是采集目标进程的pid，也就是上面提到的30937</li>
</ul>
<p>pid为进程实际的进程id，这里就是9349，那么只需要执行命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">./profiler.sh -d 60 -o collapsed -f /tmp/test_02.txt 9349</div></pre></td></tr></table></figure>
<p>运行期间，处于阻塞状态，直到约定时间完成。</p>
<p>运行期间，接着模拟用户聊天，连续发送消息至服务端：</p>
<p><img src="/2022/02/22/调优利器-火焰图使用图鉴/send-message.PNG" alt="send-message.PNG"></p>
<p>性能数据收集结束之后，到/tmp/ 查看输出的性能指标文件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">[root@snowalker tmp]# ll</div><div class="line">-rw-r--r-- 1 root root   6008 Feb 22 12:45 test_02.txt</div></pre></td></tr></table></figure>
<p>可以看到，性能指标已经收集完成，接着就到火焰图生成工具-<strong>FlameGraph</strong>的出场时间了。</p>
<h3 id="生成火焰图"><a href="#生成火焰图" class="headerlink" title="生成火焰图"></a>生成火焰图</h3><p>执行命令</p>
<blockquote>
<p>perl flamegraph.pl –colors=java /tmp/test_02.txt &gt; /tmp/test_02.svg</p>
</blockquote>
<p>查看tmp路径下文件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">[root@snowalker tmp]# ll</div><div class="line">-rw-r--r-- 1 root root  32452 Feb 22 12:46 test_02.svg</div><div class="line">-rw-r--r-- 1 root root   6008 Feb 22 12:45 test_02.txt</div></pre></td></tr></table></figure>
<p>可以看到已经生成一张svg格式的图片，下载图片到本地：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sz test_02.svg</div></pre></td></tr></table></figure></p>
<p>使用浏览器打开图片，一张美观的火焰图展现在面前：</p>
<p><img src="/2022/02/22/调优利器-火焰图使用图鉴/" alt="fire.png"></p>
<h2 id="如何阅读火焰图？"><a href="#如何阅读火焰图？" class="headerlink" title="如何阅读火焰图？"></a>如何阅读火焰图？</h2><p>有了火焰图，我们得读懂它才能利用它进行性能优化。</p>
<p>一眼看过去，红红火火的，密密麻麻，可能你觉得案例中 不够密密麻麻，如果分析的是线上的程序，那复杂程度足够让人眼花缭乱。</p>
<p>那么我们应该如何理解火焰图的内容呢？</p>
<p>简单的说：</p>
<ol>
<li>火焰图，每一列代表一个调用栈，每一个格子代表一个函数</li>
<li>纵轴，即垂直方向的y轴，展示了栈的深度，按照调用关系从下到上排列。最顶上格子代表采样时，正在占用 cpu 的函数。</li>
<li>横轴，即水平方向的x轴，表示：火焰图将采集的多个调用栈信息，通过按字母横向排序的方式将众多信息聚合在一起。需要注意的是它并不代表时间。【横轴没有特殊的含义，不代表调用关系！】</li>
<li>横轴格子的 <strong>宽度</strong> 代表其在采样中出现频率，<em>所以一个格子的宽度越大，说明它是瓶颈原因的可能性就越大。</em></li>
<li>火焰图格子的颜色是随机的暖色调，方便区分各个调用信息。</li>
<li>其他的采样方式也可以使用火焰图， on-cpu 火焰图横轴是指 cpu 占用时间，off-cpu 火焰图横轴则代表阻塞时间。</li>
<li>采样方式可以是单线程、多线程、多进程甚至是多 host，进阶用法参考文档：<a href="https://www.brendangregg.com/flamegraphs.html" target="_blank" rel="external">https://www.brendangregg.com/flamegraphs.html</a></li>
</ol>
<p>另外，多说两句，火焰图的栈深度与y轴高度成正比，可以这么认为：造成性能问题的基本都处于调用栈的栈顶位置。</p>
<p>因为栈顶位置的性能问题会间接拖慢整个调用栈，简单的举个例子：方法A调用方法B，方法B调用方法C。</p>
<p>如果方法C执行的慢会则间接导致方法B慢，从而导致方法A慢。符合我们说的通过分析栈顶从而达到分析瓶颈的目的。</p>
<p>如果A方法本身就慢呢？通过火焰图也是可以看出来的，这种底层栈的宽度很宽，但是建立在其撒花姑娘的调用链线条都很窄，火焰图呈现“┻”型，那么我们基本可以确定，栈底方法本身就存在性能问题。</p>
<p>我们的一个分析火焰图的基本原则就是，从栈顶看起，往栈底分析。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本来想起个题目叫 “什么？你还没用过这个工具？” 或者 “再见，火焰图”。但是想了想，己所不欲，勿施于人。&lt;/p&gt;
&lt;p&gt;正常写个题目就好了，非搞这么多噱头，就是为了所谓的阅读量和点击量。&lt;/p&gt;
&lt;p&gt;如果内容是干货，对人有帮助还好，要是满怀期待打开，进去划拉划拉，越看越
    
    </summary>
    
      <category term="Java" scheme="http://wuwenliang.net/categories/Java/"/>
    
    
      <category term="Java" scheme="http://wuwenliang.net/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>源码级探究Mybatis原理-以查询为例</title>
    <link href="http://wuwenliang.net/2022/02/20/%E6%BA%90%E7%A0%81%E7%BA%A7%E6%8E%A2%E7%A9%B6Mybatis%E5%8E%9F%E7%90%86-%E4%BB%A5%E6%9F%A5%E8%AF%A2%E4%B8%BA%E4%BE%8B/"/>
    <id>http://wuwenliang.net/2022/02/20/源码级探究Mybatis原理-以查询为例/</id>
    <published>2022-02-20T14:03:15.000Z</published>
    <updated>2022-02-20T16:21:39.428Z</updated>
    
    <content type="html"><![CDATA[<p>作为一名Java后端开发者，尤其是国内开发者，从刚参加工作开始就与Mybatis打交道了。</p>
<p>用了这么久的Mybatis难免会心生疑问：</p>
<ul>
<li>我只是写了个Mapper接口，再配合xml或者注解，把SQL一写，就可以执行数据库操作，这是为何？</li>
<li>都说Mybatis是对JDBC的封装，可是我却看不到JDBC相关的接口和对象，它们到哪里去了？</li>
<li>为什么在Spring中使用Mybatis，不用加@Repository/@Component之类的注解，就可以随用随注入（如：@Autowired）?</li>
</ul>
<blockquote>
<p>硬核万字长文，点个再看，转发，多谢啦~</p>
</blockquote>
<a id="more"></a>
<p>随着工作经验越多，对这些问题的疑惑就会越发强烈。而读源码是解决这些疑问的根本方法。</p>
<p>那么就跟随笔者的脚步，试着用一篇文章，以一个查询为例，从源码角度一步一步揭开Mybatis的神秘面纱。</p>
<h2 id="一、先看一个demo"><a href="#一、先看一个demo" class="headerlink" title="一、先看一个demo"></a>一、先看一个demo</h2><pre><code>private SqlSessionFactory sqlSessionFactory;

@Before
public void prepare() throws IOException {
    String resource = &quot;mybatis-config.xml&quot;;
    InputStream inputStream = Resources.getResourceAsStream(resource);
    sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);
}

/**
 * 通过 SqlSession.getMapper(XXXMapper.class)  接口方式
 * @throws IOException
 */
@Test
public void testSelect() throws IOException {
    SqlSession session = sqlSessionFactory.openSession(); // ExecutorType.BATCH
    try {
        BlogMapper mapper = session.getMapper(BlogMapper.class);
        Blog blog = mapper.selectBlogById(1);
        System.out.println(blog);
    } finally {
        session.close();
    }
}
</code></pre><p>这是一个非Spring项目的Test用例类，逻辑很直观，就是在测试通过id查询一行记录；在执行查询之间加载配置文件。</p>
<p>执行该测试用例，日志输出如下：</p>
<pre><code>Opening JDBC Connection
Created connection 1325808650.
Setting autocommit to false on JDBC Connection [com.mysql.jdbc.JDBC4Connection@4f063c0a]
==&gt;  Preparing: select * from blog where bid = ? 
==&gt; Parameters: 1(Integer)
&lt;==    Columns: bid, name, author_id, type
&lt;==        Row: 1, RabbitMQ延时消息, 1001, 0
getNullableResult---1NORMAL
&lt;==      Total: 1
Blog(bid=1, name=RabbitMQ延时消息, authorId=1001, blogType=0)
</code></pre><p>我们就通过这个ById查询的案例，对Mybatis运行的过程抽丝剥茧，还原出一个完整的脉络。</p>
<h2 id="二、一图总览全局"><a href="#二、一图总览全局" class="headerlink" title="二、一图总览全局"></a>二、一图总览全局</h2><blockquote>
<p>按照惯例我们用一张简单概括的流程图引领全局，先建立一个宏观的印象。</p>
</blockquote>
<p><img src="/2022/02/20/源码级探究Mybatis原理-以查询为例/1.png" alt="1.png"></p>
<p>从图中可以看到，Mybatis主要的工作流程分为以下几步：</p>
<ol>
<li>加载并解析配置文件</li>
<li>获取SqlSession对象作为与数据库交互的接口</li>
<li>通过Executor对象封装数据库操作，执行SQL操作</li>
<li>调用底层的JDBC接口，与数据库进行真正的交互</li>
<li>向数据库提交参数，并封装返回参数</li>
</ol>
<h3 id="加载并解析配置文件"><a href="#加载并解析配置文件" class="headerlink" title="加载并解析配置文件"></a>加载并解析配置文件</h3><p>在Mybatis启动的时候回去加载配置文件，一般来说文件包含全局配置文件（文件名为 <strong>mybatis-config.xml</strong>） ，以及映射器配置文件（也就是各种Mapper.xml文件）；</p>
<h3 id="获取SqlSession对象作为与数据库交互的接口"><a href="#获取SqlSession对象作为与数据库交互的接口" class="headerlink" title="获取SqlSession对象作为与数据库交互的接口"></a>获取SqlSession对象作为与数据库交互的接口</h3><p>Mybatis在加载完配置文件之后，会去获取SqlSession对象，这个对象是应用程序与数据库之间的桥梁，封装了程序与数据库之间的连接。</p>
<p>一般来说，一个SqlSession对象中包含了一个Connection，我们都知道Connection是线程不安全的，因此导致SqlSession对象也是线程不安全的。因此如果将SqlSession作为成员变量使用，存在风险。（应当使用SqlSessionTemplate，这部分后面再说）。</p>
<blockquote>
<p>注意：SqlSession是提供给应用层的一个访问数据库的接口，它并不是真正的SQL执行者，它内部封装了JDBC核心对象，如Statement，ResultSet等。</p>
</blockquote>
<h3 id="通过SqlSessionFactory获取SqlSession会话"><a href="#通过SqlSessionFactory获取SqlSession会话" class="headerlink" title="通过SqlSessionFactory获取SqlSession会话"></a>通过SqlSessionFactory获取SqlSession会话</h3><p>如果要获取一个SqlSession会话，就需要有会话工厂，即：SqlSessionFactory。它包含了所有的配置信息，而Factory又是通过Builder创建的，这部分后文代码分析中会说。</p>
<h3 id="通过Executor对象封装数据库操作，执行SQL操作"><a href="#通过Executor对象封装数据库操作，执行SQL操作" class="headerlink" title="通过Executor对象封装数据库操作，执行SQL操作"></a>通过Executor对象封装数据库操作，执行SQL操作</h3><p>SqlSession持有Executor对象，Executor在执行query、update、insert等操作时，会创建一系列的对象处理参数、处理结果集，核心的对象是StatementHandler，它本质上是对Statement的封装。</p>
<h2 id="三、走进源码，一探究竟"><a href="#三、走进源码，一探究竟" class="headerlink" title="三、走进源码，一探究竟"></a>三、走进源码，一探究竟</h2><h3 id="3-1-SqlSessionFactory的创建"><a href="#3-1-SqlSessionFactory的创建" class="headerlink" title="3.1 SqlSessionFactory的创建"></a>3.1 SqlSessionFactory的创建</h3><blockquote>
<p>首先是SqlSession的创建过程；SqlSession需要通过SqlSessionFactory创建，而SqlSessionFactory又是通过SqlSessionFactoryBuilder创建的。</p>
</blockquote>
<pre><code># org.apache.ibatis.session.SqlSessionFactoryBuilder#build
public SqlSessionFactory build(InputStream inputStream) {
  return build(inputStream, null, null);
}
</code></pre><p>事实上，inputStream就是配置文件的文件输入流，它传给了SqlSessionFactoryBuilder的build重载方法，我们看一下这个方法的实现。</p>
<pre><code>public SqlSessionFactory build(InputStream inputStream, String environment, Properties properties) {
  try {
    // 用于解析 mybatis-config.xml，同时创建了 Configuration 对象 &gt;&gt;
    XMLConfigBuilder parser = new XMLConfigBuilder(inputStream, environment, properties);
    // 解析XML，最终返回一个 DefaultSqlSessionFactory &gt;&gt;
    return build(parser.parse());
  } catch (Exception e) {
    throw ExceptionFactory.wrapException(&quot;Error building SqlSession.&quot;, e);
  } finally {
    ErrorContext.instance().reset();
    try {
      inputStream.close();
    } catch (IOException e) {
      // Intentionally ignore. Prefer previous error.
    }
  }
}
</code></pre><p>可以看到，SqlSessionFactoryBuilder底层是通过xml解析方式，对配置文件进行解析，并基于解析的结果构建了SqlSessionFactory的实例，这里返回的是默认的SqlSessionFactory—&gt;DefaultSqlSessionFactory。</p>
<pre><code>public SqlSessionFactory build(Configuration config) {
  return new DefaultSqlSessionFactory(config);
}
</code></pre><p><strong>注意：此处就已经通过配置文件解析出了Configuration，并通过DefaultSqlSessionFactory构造方法创建了DefaultSqlSessionFactory实例。后文要用！</strong></p>
<blockquote>
<p>xml解析过程，感兴趣的读者可以自行研究，简单的说无非就是对xml文件的dom节点进行读取和匹配，获取属性加载到内存，Mybatis自己基于javax的xml操作api封装了一个工具类，<strong>org.apache.ibatis.parsing.XPathParser</strong> 。</p>
</blockquote>
<h3 id="3-2-SqlSession的创建"><a href="#3-2-SqlSession的创建" class="headerlink" title="3.2 SqlSession的创建"></a>3.2 SqlSession的创建</h3><p>在使用的demo中，我们通过SqlSessionFactory获取到一个SqlSession实例。</p>
<pre><code>SqlSession session = sqlSessionFactory.openSession();
</code></pre><p>进入 openSession 方法一探究竟。</p>
<pre><code># org.apache.ibatis.session.defaults.DefaultSqlSessionFactory#openSession()
public SqlSession openSession() {
  return openSessionFromDataSource(configuration.getDefaultExecutorType(), null, false);
}
</code></pre><p>继续进入 openSessionFromDataSource 方法：</p>
<pre><code>private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) {
  Transaction tx = null;
  try {
    final Environment environment = configuration.getEnvironment();
    // 获取事务工厂
    final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment);
    // 创建事务
    tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit);
    // 根据事务工厂和默认的执行器类型，创建执行器 &gt;&gt;
    final Executor executor = configuration.newExecutor(tx, execType);
    return new DefaultSqlSession(configuration, executor, autoCommit);
  } catch (Exception e) {
    closeTransaction(tx); // may have fetched a connection so lets call close()
    throw ExceptionFactory.wrapException(&quot;Error opening session.  Cause: &quot; + e, e);
  } finally {
    ErrorContext.instance().reset();
  }
}
</code></pre><p>这里的逻辑比较核心，主要做了几件事：</p>
<ol>
<li>获取到事务工厂；</li>
<li>通过事务工厂创建了事务，如果是使用Spring框架，则由Spring框架开启事务；</li>
<li>根据事务工厂和默认的执行器类型，创建执行器</li>
</ol>
<p>最后通过DefaultSqlSession的构造方法，创建出DefaultSqlSession实例，它是SqlSession接口的默认实现。</p>
<p>到此，我们就持有了一个SqlSession对象，并且它还持有了一个Executor执行器实例。</p>
<h3 id="代理Mapper对象，执行SQL"><a href="#代理Mapper对象，执行SQL" class="headerlink" title="代理Mapper对象，执行SQL"></a>代理Mapper对象，执行SQL</h3><p>回到我们的demo代码中：</p>
<pre><code>@Test
public void testSelect() throws IOException {
    SqlSession session = sqlSessionFactory.openSession(); // ExecutorType.BATCH
    try {
        // 重点看这行代码
        BlogMapper mapper = session.getMapper(BlogMapper.class);
        Blog blog = mapper.selectBlogById(1);
        System.out.println(blog);
    } finally {
        session.close();
    }
}
</code></pre><p>我们已经拿到了SqlSession，接着通过 <strong>session.getMapper(BlogMapper.class)</strong>; 获取到了BlogMapper接口的实现类。</p>
<p>注意，我说的并不是获取到了BlogMapper，因为大家使用过Mybatis框架都知道BlogMapper是个接口，那么此处拿到的，必然是BlogMapper的实例。</p>
<p>接口的实例，嗯，有点意思了，我们明明只写了个接口，并没有实现这个接口啊？</p>
<p>是不是想到了什么？对，就是动态代理。</p>
<p>此处获取到的Mapper实例，就是Mybatis框架帮我们创建出的代理对象。</p>
<blockquote>
<p>进入 DefaultSqlSession#getMapper 方法</p>
</blockquote>
<pre><code>@Override
public &lt;T&gt; T getMapper(Class&lt;T&gt; type) {
  return configuration.getMapper(type, this);
}
</code></pre><p>ok，继续往下看：</p>
<pre><code>public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) {
  return mapperRegistry.getMapper(type, sqlSession);
}
</code></pre><p>这里，我们发现Mapper对象是通过 mapperRegistry 这个所谓的Mapper注册中心中获取到的，它的数据结构是一个HashMap:</p>
<pre><code># org.apache.ibatis.session.Configuration
protected final MapperRegistry mapperRegistry = new MapperRegistry(this);

# org.apache.ibatis.binding.MapperRegistry
public class MapperRegistry {
  private final Configuration config;
  private final Map&lt;Class&lt;?&gt;, MapperProxyFactory&lt;?&gt;&gt; knownMappers = new HashMap&lt;&gt;();
</code></pre><p>既然我们能够通过Mapper接口类型get到接口的代理类，那它是多会儿put到Map里的?</p>
<p>仔细想一下应当能够想到，我们此时已经是在sql的执行期了，在这之前必然是配置文件的解析期间执行的put操作。具体代码如下：</p>
<pre><code>/**
* org.apache.ibatis.builder.xml.XMLConfigBuilder#mapperElement
* Mapper解析
* @param parent
* @throws Exception
*/
private void mapperElement(XNode parent) throws Exception {
  if (parent != null) {
    for (XNode child : parent.getChildren()) {
      // 不同的定义方式的扫描，最终都是调用 addMapper()方法
      // （添加到 MapperRegistry）。这个方法和 getMapper() 对应

      // package    包

      if (&quot;package&quot;.equals(child.getName())) {
        String mapperPackage = child.getStringAttribute(&quot;name&quot;);
        configuration.addMappers(mapperPackage);

      } else {
        String resource = child.getStringAttribute(&quot;resource&quot;);
        String url = child.getStringAttribute(&quot;url&quot;);
        String mapperClass = child.getStringAttribute(&quot;class&quot;);

        if (resource != null &amp;&amp; url == null &amp;&amp; mapperClass == null) {

          // resource    相对路径

          ErrorContext.instance().resource(resource);
          InputStream inputStream = Resources.getResourceAsStream(resource);
          XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, resource, configuration.getSqlFragments());
          // 解析 Mapper.xml，总体上做了两件事情 &gt;&gt;
          mapperParser.parse();

        } else if (resource == null &amp;&amp; url != null &amp;&amp; mapperClass == null) {

          // url    绝对路径

          ErrorContext.instance().resource(url);
          InputStream inputStream = Resources.getUrlAsStream(url);
          XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, url, configuration.getSqlFragments());
          mapperParser.parse();

        } else if (resource == null &amp;&amp; url == null &amp;&amp; mapperClass != null) {
          // class     单个接口
          Class&lt;?&gt; mapperInterface = Resources.classForName(mapperClass);
          configuration.addMapper(mapperInterface);
        } else {
          throw new BuilderException(&quot;A mapper element may only specify a url, resource or class, but not more than one.&quot;);
        }
      }
    }
  }
}
</code></pre><p>通过这段代码我们可以看到，无论是通过指定扫描包路径，还是resources相对路径，或者url绝对路径，或者单个Mapper添加的方式，Mybatis本质上都是通过 <strong>addMapper()方法添加到 MapperRegistry</strong>。</p>
<blockquote>
<p>继续回到Mapper代理对象创建过程中来。</p>
</blockquote>
<pre><code># org.apache.ibatis.session.Configuration#getMapper
public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) {
  return mapperRegistry.getMapper(type, sqlSession);
}
</code></pre><p>继续看mapperRegistry.getMapper方法逻辑。</p>
<pre><code>public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) {
  final MapperProxyFactory&lt;T&gt; mapperProxyFactory = (MapperProxyFactory&lt;T&gt;) knownMappers.get(type);
  if (mapperProxyFactory == null) {
    throw new BindingException(&quot;Type &quot; + type + &quot; is not known to the MapperRegistry.&quot;);
  }
  try {
    return mapperProxyFactory.newInstance(sqlSession);
  } catch (Exception e) {
    throw new BindingException(&quot;Error getting mapper instance. Cause: &quot; + e, e);
  }
}
</code></pre><p>我们发现，通过接口类型从HashMap中取到了一个 <strong>MapperProxyFactory</strong> Mapper代理工厂的实例。</p>
<blockquote>
<p>MapperProxyFactory实际上是对Mapper接口的包装，我们只需要看源码就知道了。</p>
</blockquote>
<pre><code>public class MapperProxyFactory&lt;T&gt; {

  private final Class&lt;T&gt; mapperInterface;
  private final Map&lt;Method, MapperMethodInvoker&gt; methodCache = new ConcurrentHashMap&lt;&gt;();
</code></pre><blockquote>
<p>构造方法接受一个Mapper的class类型，对其进行封装。</p>
</blockquote>
<pre><code>public MapperProxyFactory(Class&lt;T&gt; mapperInterface) {
  this.mapperInterface = mapperInterface;
}
</code></pre><p>获取到MapperProxyFactory实例之后，通过 <strong>mapperProxyFactory.newInstance(sqlSession)</strong> 就创建出了Mapper的代理对象。</p>
<pre><code>public T newInstance(SqlSession sqlSession) {
  final MapperProxy&lt;T&gt; mapperProxy = new MapperProxy&lt;&gt;(sqlSession, mapperInterface, methodCache);
  return newInstance(mapperProxy);
}
</code></pre><p>这里通过SqlSession、Mapper接口、方法缓存（<strong>简单的说就是Mapper的那一堆方法，每次反射创建太耗费性能了，就缓存到一个Map里</strong>）创建出MapperProxy 对象，进一步调用的如下方法：</p>
<pre><code>@SuppressWarnings(&quot;unchecked&quot;)
protected T newInstance(MapperProxy&lt;T&gt; mapperProxy) {
  // 1：类加载器:2：被代理类实现的接口、3：实现了 InvocationHandler 的触发管理类
  return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] { mapperInterface }, mapperProxy);
}
</code></pre><p>这里把创建代理对象的操作委托给了MapperProxy，<strong>我们发现，它的核心就是创建代理Mapper的代理对象 （h对象）。</strong></p>
<h3 id="MapperProxy具体是如何创建的Mapper代理？"><a href="#MapperProxy具体是如何创建的Mapper代理？" class="headerlink" title="MapperProxy具体是如何创建的Mapper代理？"></a>MapperProxy具体是如何创建的Mapper代理？</h3><p>我们都知道，动态代理在JDK中是通过实现InvocationHandler接口实现的，那么大胆猜想MapperProxy必然实现了InvocationHandler接口。</p>
<pre><code>public class MapperProxy&lt;T&gt; implements InvocationHandler, Serializable {
</code></pre><p>果然如此。</p>
<p>我们来看它的invoke方法实现：</p>
<pre><code>@Override
public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
  try {
    // toString hashCode equals getClass等方法，无需走到执行SQL的流程
    if (Object.class.equals(method.getDeclaringClass())) {
      return method.invoke(this, args);
    } else {
      // 提升获取 mapperMethod 的效率，到 MapperMethodInvoker（内部接口） 的 invoke
      // 普通方法会走到 PlainMethodInvoker（内部类） 的 invoke
      return cachedInvoker(method).invoke(proxy, method, args, sqlSession);
    }
  } catch (Throwable t) {
    throw ExceptionUtil.unwrapThrowable(t);
  }
}
</code></pre><p>可以看到，如果是普通方法，直接执行，不需要特殊处理；</p>
<p>否则就获取匹配的缓存Mapper方法，执行数据库操作。</p>
<blockquote>
<p>重点看一下  cachedInvoker(method).invoke(proxy, method, args, sqlSession); 逻辑。</p>
</blockquote>
<pre><code>private MapperMethodInvoker cachedInvoker(Method method) throws Throwable {
  try {

    // Java8 中 Map 的方法，根据 key 获取值，如果值是 null，则把后面Object 的值赋给 key
    // 如果获取不到，就创建
    // 获取的是 MapperMethodInvoker（接口） 对象，只有一个invoke方法

    return methodCache.computeIfAbsent(method, m -&gt; {
      if (m.isDefault()) {

        // 接口的默认方法(Java8)，只要实现接口都会继承接口的默认方法，例如 List.sort()

        try {
          if (privateLookupInMethod == null) {
            return new DefaultMethodInvoker(getMethodHandleJava8(method));
          } else {
            return new DefaultMethodInvoker(getMethodHandleJava9(method));
          }
        } catch (IllegalAccessException | InstantiationException | InvocationTargetException
            | NoSuchMethodException e) {
          throw new RuntimeException(e);
        }

      } else {

        // 创建了一个 MapperMethod
        return new PlainMethodInvoker(new MapperMethod(mapperInterface, method, sqlSession.getConfiguration()));

      }
    });
  } catch (RuntimeException re) {
    Throwable cause = re.getCause();
    throw cause == null ? re : cause;
  }
}
</code></pre><p>这里针对Java8接口的默认方法做了些处理，这个地方不用特殊关注，我们重点看else逻辑：</p>
<pre><code>// 创建了一个 MapperMethod
return new PlainMethodInvoker(
    new MapperMethod(
      mapperInterface, 
      method,
      sqlSession.getConfiguration()));
</code></pre><h2 id="Mybatis执行sql语句的真正开端："><a href="#Mybatis执行sql语句的真正开端：" class="headerlink" title="Mybatis执行sql语句的真正开端："></a>Mybatis执行sql语句的真正开端：</h2><blockquote>
<p>上文中，我们费尽努力，获取到了 <strong>PlainMethodInvoker</strong> 实例，其实到这里，才是Mybatis执行SQL真正的起点。</p>
</blockquote>
<p>不要慌，继续跟上我的脚步，我们一鼓作气往后看。</p>
<p>上文中，我们知道Mapper对象实际上是Mapper接口的代理对象，而且是JDK的动态代理。</p>
<p>当执行Mapper的各种数据库操作方法时，实际上是调用的代理对象的方法，也就是invoke方法。</p>
<p>对于Mapper方法而言，其实就是调用的PlainMethodInvoker的invoke方法。</p>
<p>忘了？那么我们再复习一下这部分的代码：</p>
<pre><code>// org.apache.ibatis.binding.MapperProxy#invoke
// 普通方法会走到 PlainMethodInvoker（内部类） 的 invoke
return cachedInvoker(method).invoke(proxy, method, args, sqlSession);
</code></pre><p>接着来看PlainMethodInvoker的invoke方法：</p>
<pre><code>@Override
public Object invoke(
                    Object proxy, 
                    Method method, 
                    Object[] args, 
                    SqlSession sqlSession) throws Throwable {
  // SQL执行的真正起点
  return mapperMethod.execute(sqlSession, args);
}
</code></pre><p>实际上这里的mapperMethod就是我们Mapper接口或者说XML文件中定义的方法名了。</p>
<blockquote>
<p>接着就是重头戏，MapperMethod#execute 方法，完整代码我贴这儿了。</p>
</blockquote>
<pre><code>// org.apache.ibatis.binding.MapperMethod#execute
public Object execute(SqlSession sqlSession, Object[] args) {
  Object result;
  switch (command.getType()) {
    case INSERT: {
      Object param = method.convertArgsToSqlCommandParam(args);
      result = rowCountResult(sqlSession.insert(command.getName(), param));
      break;
    }
    case UPDATE: {
      Object param = method.convertArgsToSqlCommandParam(args);
      result = rowCountResult(sqlSession.update(command.getName(), param));
      break;
    }
    case DELETE: {
      Object param = method.convertArgsToSqlCommandParam(args);
      result = rowCountResult(sqlSession.delete(command.getName(), param));
      break;
    }
    case SELECT:
      if (method.returnsVoid() &amp;&amp; method.hasResultHandler()) {
        executeWithResultHandler(sqlSession, args);
        result = null;
      } else if (method.returnsMany()) {
        result = executeForMany(sqlSession, args);
      } else if (method.returnsMap()) {
        result = executeForMap(sqlSession, args);
      } else if (method.returnsCursor()) {
        result = executeForCursor(sqlSession, args);
      } else {
        Object param = method.convertArgsToSqlCommandParam(args);
        // 普通 select 语句的执行入口 &gt;&gt;
        result = sqlSession.selectOne(command.getName(), param);
        if (method.returnsOptional()
            &amp;&amp; (result == null || !method.getReturnType().equals(result.getClass()))) {
          result = Optional.ofNullable(result);
        }
      }
      break;
    case FLUSH:
      result = sqlSession.flushStatements();
      break;
    default:
      throw new BindingException(&quot;Unknown execution method for: &quot; + command.getName());
  }
  if (result == null &amp;&amp; method.getReturnType().isPrimitive() &amp;&amp; !method.returnsVoid()) {
    throw new BindingException(&quot;Mapper method &apos;&quot; + command.getName()
        + &quot; attempted to return null from a method with a primitive return type (&quot; + method.getReturnType() + &quot;).&quot;);
  }
  return result;
}
</code></pre><p>重点看那个switch case，不用注释一眼看过去基本上也能看个八九不离十，这里就是通过sql的类型去执行不同的jdbc操作。</p>
<blockquote>
<p>可以看到，熟悉的操作他来了，通过SqlSession完成一系列的数据库操作。</p>
</blockquote>
<p>我们的demo是一个查询操作，那么我们就挑select来看看。</p>
<p>普通select语句的入口如下：</p>
<pre><code>result = sqlSession.selectOne(command.getName(), param);
</code></pre><p>继续深入：</p>
<pre><code>// DefaultSqlSession#selectOne(java.lang.String, java.lang.Object)
@Override
public &lt;T&gt; T selectOne(String statement, Object parameter) {
  // 来到了 DefaultSqlSession
  // Popular vote was to return null on 0 results and throw exception on too many.
  List&lt;T&gt; list = this.selectList(statement, parameter);
  if (list.size() == 1) {
    return list.get(0);
  } else if (list.size() &gt; 1) {
    throw new TooManyResultsException(&quot;Expected one result (or null) to be returned by selectOne(), but found: &quot; + list.size());
  } else {
    return null;
  }
}
</code></pre><p>可以看到是通过selectList来完成查询多个和单个。</p>
<pre><code>@Override
public &lt;E&gt; List&lt;E&gt; selectList(String statement, Object parameter) {
  // 为了提供多种重载（简化方法使用），和默认值
  // 让参数少的调用参数多的方法，只实现一次
  return this.selectList(statement, parameter, RowBounds.DEFAULT);
}
</code></pre><p>继续看多参重载方法：</p>
<pre><code>@Override
public &lt;E&gt; List&lt;E&gt; selectList(String statement, Object parameter, RowBounds rowBounds) {
  try {
    MappedStatement ms = configuration.getMappedStatement(statement);
    // 如果 cacheEnabled = true（默认），Executor会被 CachingExecutor装饰
    return executor.query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER);
  } catch (Exception e) {
    throw ExceptionFactory.wrapException(&quot;Error querying database.  Cause: &quot; + e, e);
  } finally {
    ErrorContext.instance().reset();
  }
}
</code></pre><p>核心代码就是executor.query，我们进去看看：</p>
<pre><code>@Override
public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException {
  BoundSql boundSql = ms.getBoundSql(parameter);
  // 一级缓存和二级缓存的CacheKey是同一个
  CacheKey key = createCacheKey(ms, parameter, rowBounds, boundSql);
  return query(ms, parameter, rowBounds, resultHandler, key, boundSql);
}
</code></pre><p>这里涉及到一级缓存和二级缓存，不是重点，我们就想看看最终是怎么执行的jdbc操作，那么就只需要继续看query重载。</p>
<pre><code>// org.apache.ibatis.executor.BaseExecutor#query
@Override
public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException {

  // 异常体系之 ErrorContext
  ErrorContext.instance().resource(ms.getResource()).activity(&quot;executing a query&quot;).object(ms.getId());

  if (closed) {
    throw new ExecutorException(&quot;Executor was closed.&quot;);
  }

  if (queryStack == 0 &amp;&amp; ms.isFlushCacheRequired()) {
    // flushCache=&quot;true&quot;时，即使是查询，也清空一级缓存
    clearLocalCache();
  }

  List&lt;E&gt; list;
  try {

    // 防止递归查询重复处理缓存
    queryStack++;
    // 查询一级缓存
    // ResultHandler 和 ResultSetHandler的区别
    list = resultHandler == null ? (List&lt;E&gt;) localCache.getObject(key) : null;

    if (list != null) {
      handleLocallyCachedOutputParameters(ms, key, parameter, boundSql);
    } else {

      // 真正的查询流程
      list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql);

      ...省略N行代码...
</code></pre><p>涉及到缓存的，通通与我无关，只看真正的查询流程 <strong>queryFromDatabase</strong>。</p>
<pre><code>private &lt;E&gt; List&lt;E&gt; queryFromDatabase(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException {
  List&lt;E&gt; list;
  // 先占位
  localCache.putObject(key, EXECUTION_PLACEHOLDER);
  try {
    // 三种 Executor 的区别，看doUpdate
    // 默认Simple
    list = doQuery(ms, parameter, rowBounds, resultHandler, boundSql);
  } finally {
    // 移除占位符
    localCache.removeObject(key);
  }
  // 写入一级缓存
  localCache.putObject(key, list);
  if (ms.getStatementType() == StatementType.CALLABLE) {
    localOutputParameterCache.putObject(key, parameter);
  }
  return list;
}
</code></pre><h3 id="看到jdbc了，胜利的曙光。"><a href="#看到jdbc了，胜利的曙光。" class="headerlink" title="看到jdbc了，胜利的曙光。"></a>看到jdbc了，胜利的曙光。</h3><p>舒服，继续看doQuery方法，看到resultHandler了么，结果处理器，感觉离结果更近了。</p>
<pre><code>// org.apache.ibatis.executor.SimpleExecutor#doQuery
@Override
public &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException {
  Statement stmt = null;
  try {
    Configuration configuration = ms.getConfiguration();
    // 注意，已经来到SQL处理的关键对象 StatementHandler &gt;&gt;
    StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql);
    // 获取一个 Statement对象
    stmt = prepareStatement(handler, ms.getStatementLog());
    // 执行查询
    return handler.query(stmt, resultHandler);
  } finally {
    // 用完就关闭
    closeStatement(stmt);
  }
}
</code></pre><p>查询用的Exucutor就是默认的SimpleExecutor，看到了熟悉的prepareStatement获取流程，基本上就到底层jdbc了。那么我们就看看 <strong>prepareStatement(handler, ms.getStatementLog());</strong></p>
<pre><code>private Statement prepareStatement(StatementHandler handler, Log statementLog) throws SQLException {
  Statement stmt;
  Connection connection = getConnection(statementLog);
  // 获取 Statement 对象
  stmt = handler.prepare(connection, transaction.getTimeout());
  // 为 Statement 设置参数
  handler.parameterize(stmt);
  return stmt;
}
</code></pre><p>看到这里，就到jdbc层面了，我们看到了熟悉的Connection，获取到connection之后再获取Statement。</p>
<p>这里的Statement就是java.sql的statement接口。</p>
<blockquote>
<p>org.apache.ibatis.executor.statement.SimpleStatementHandler#query</p>
</blockquote>
<pre><code>@Override
public &lt;E&gt; List&lt;E&gt; query(Statement statement, ResultHandler resultHandler) throws SQLException {
  String sql = boundSql.getSql();
  statement.execute(sql);
  return resultSetHandler.handleResultSets(statement);
}
</code></pre><p>已经获取到了sql，通过Statement去执行sql，在通过resultSetHandler处理结果集。</p>
<h4 id="通过Statement去执行sql"><a href="#通过Statement去执行sql" class="headerlink" title="通过Statement去执行sql"></a>通过Statement去执行sql</h4><pre><code>statement.execute(sql);
</code></pre><p>这里就已经是jdbc层面的操作了，通过与数据库建立的connection提交并执行sql。</p>
<h4 id="通过resultSetHandler处理结果集"><a href="#通过resultSetHandler处理结果集" class="headerlink" title="通过resultSetHandler处理结果集"></a>通过resultSetHandler处理结果集</h4><blockquote>
<p>都到最后了，我们也不慌了，那么就看看org.apache.ibatis.executor.resultset.DefaultResultSetHandler#handleResultSets是如何处理结果集的。</p>
</blockquote>
<pre><code>@Override
public List&lt;Object&gt; handleResultSets(Statement stmt) throws SQLException {
  ErrorContext.instance().activity(&quot;handling results&quot;).object(mappedStatement.getId());

  final List&lt;Object&gt; multipleResults = new ArrayList&lt;&gt;();

  int resultSetCount = 0;
  ResultSetWrapper rsw = getFirstResultSet(stmt);

  List&lt;ResultMap&gt; resultMaps = mappedStatement.getResultMaps();
  int resultMapCount = resultMaps.size();
  validateResultMapsCount(rsw, resultMapCount);
  while (rsw != null &amp;&amp; resultMapCount &gt; resultSetCount) {
    ResultMap resultMap = resultMaps.get(resultSetCount);
    handleResultSet(rsw, resultMap, multipleResults, null);
    rsw = getNextResultSet(stmt);
    cleanUpAfterHandlingResultSet();
    resultSetCount++;
  }

  String[] resultSets = mappedStatement.getResultSets();
  if (resultSets != null) {
    while (rsw != null &amp;&amp; resultSetCount &lt; resultSets.length) {
      ResultMapping parentMapping = nextResultMaps.get(resultSets[resultSetCount]);
      if (parentMapping != null) {
        String nestedResultMapId = parentMapping.getNestedResultMapId();
        ResultMap resultMap = configuration.getResultMap(nestedResultMapId);
        // 在此处处理结果集
        handleResultSet(rsw, resultMap, null, parentMapping);
      }
      rsw = getNextResultSet(stmt);
      cleanUpAfterHandlingResultSet();
      resultSetCount++;
    }
  }

  return collapseSingleResultList(multipleResults);
}
</code></pre><p>这么一坨代码，只需要重点看</p>
<pre><code>handleResultSet(rsw, resultMap, null, parentMapping);

private void handleResultSet(ResultSetWrapper rsw, ResultMap resultMap, List&lt;Object&gt; multipleResults, ResultMapping parentMapping) throws SQLException {
  try {
    if (parentMapping != null) {
      handleRowValues(rsw, resultMap, null, RowBounds.DEFAULT, parentMapping);
    } else {
      if (resultHandler == null) {
        DefaultResultHandler defaultResultHandler = new DefaultResultHandler(objectFactory);
        handleRowValues(rsw, resultMap, defaultResultHandler, rowBounds, null);
        multipleResults.add(defaultResultHandler.getResultList());
      } else {
        handleRowValues(rsw, resultMap, resultHandler, rowBounds, null);
      }
    }
  } finally {
    // issue #228 (close resultsets)
    closeResultSet(rsw.getResultSet());
  }
}
</code></pre><p>看看handleRowValues的逻辑 (有点心累)</p>
<p>最终，来到了这个地方：</p>
<pre><code>// org.apache.ibatis.executor.resultset.DefaultResultSetHandler
//         #handleRowValuesForSimpleResultMap
private void handleRowValuesForSimpleResultMap(ResultSetWrapper rsw, ResultMap resultMap, ResultHandler&lt;?&gt; resultHandler, RowBounds rowBounds, ResultMapping parentMapping)
    throws SQLException {
  DefaultResultContext&lt;Object&gt; resultContext = new DefaultResultContext&lt;&gt;();

  // 看到了吧，没什么好说的，就是jdbc的结果集处理
  ResultSet resultSet = rsw.getResultSet();

  skipRows(resultSet, rowBounds);
  while (shouldProcessMoreRows(resultContext, rowBounds) &amp;&amp; !resultSet.isClosed() &amp;&amp; resultSet.next()) {
    ResultMap discriminatedResultMap = resolveDiscriminatedResultMap(resultSet, resultMap, null);
    Object rowValue = getRowValue(rsw, discriminatedResultMap, null);
    storeObject(resultHandler, resultContext, rowValue, parentMapping, resultSet);
  }
}
</code></pre><p>看到了熟悉的ResultSet获取结果集的操作，Mybatis执行sql的流程基本就结束了。</p>
<p>底层还是熟悉的JDBC操作。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>其实写了这么多，也没啥想总结的，我们通过一个查询操作，完整的把Mybatis从解析文件到执行sql，再到结果集处理都从源码级别剖析了一遍。</p>
<p>那么我们回答一下开头的问题：</p>
<h3 id="我只是写了个Mapper接口，再配合xml或者注解，把SQL一写，就可以执行数据库操作，这是为何？"><a href="#我只是写了个Mapper接口，再配合xml或者注解，把SQL一写，就可以执行数据库操作，这是为何？" class="headerlink" title="我只是写了个Mapper接口，再配合xml或者注解，把SQL一写，就可以执行数据库操作，这是为何？"></a>我只是写了个Mapper接口，再配合xml或者注解，把SQL一写，就可以执行数据库操作，这是为何？</h3><p>其实我们获取到的Mapper对象，已经是Mybatis帮我们生成的代理对象了，这个代理对象拥有与jdbc交互的一切必要条件。</p>
<h3 id="都说Mybatis是对JDBC的封装，可是我却看不到JDBC相关的接口和对象，它们到哪里去了？"><a href="#都说Mybatis是对JDBC的封装，可是我却看不到JDBC相关的接口和对象，它们到哪里去了？" class="headerlink" title="都说Mybatis是对JDBC的封装，可是我却看不到JDBC相关的接口和对象，它们到哪里去了？"></a>都说Mybatis是对JDBC的封装，可是我却看不到JDBC相关的接口和对象，它们到哪里去了？</h3><p>稍微往上翻翻，我们刚讲了，实际上最底层就是封装的jdbc的接口。</p>
<p>我们看不到但是用到了，并且用起来还很爽，这就是封装的魅力啊。</p>
<h3 id="为什么在Spring中使用Mybatis，不用加-Repository-Component之类的注解，就可以随用随注入（如：-Autowired）"><a href="#为什么在Spring中使用Mybatis，不用加-Repository-Component之类的注解，就可以随用随注入（如：-Autowired）" class="headerlink" title="为什么在Spring中使用Mybatis，不用加@Repository/@Component之类的注解，就可以随用随注入（如：@Autowired）?"></a>为什么在Spring中使用Mybatis，不用加@Repository/@Component之类的注解，就可以随用随注入（如：@Autowired）?</h3><p>这个问题，就放到之后的文章讲解吧，那么就敬请期待下一篇：Mybatis与Spring的爱情故事（从源码层面解析，Mybatis是如何利用Spring扩展点，实现与Spring整合的。）</p>
<p>最后，贴张图，概括一下这个过程。图是借来的，仅供学习讨论，侵删。</p>
<blockquote>
<p>创建会话工厂SqlSessionFactory</p>
</blockquote>
<p><img src="/2022/02/20/源码级探究Mybatis原理-以查询为例/flow/1.png" alt="flow/1.png"></p>
<blockquote>
<p>创建会话SqlSession</p>
</blockquote>
<p><img src="/2022/02/20/源码级探究Mybatis原理-以查询为例/flow/2.png" alt="flow/2.png"></p>
<blockquote>
<p>创建代理对象</p>
</blockquote>
<p><img src="/2022/02/20/源码级探究Mybatis原理-以查询为例/flow/3.png" alt="flow/3.png"></p>
<blockquote>
<p>调用代理对象，执行SQL流程</p>
</blockquote>
<p><img src="/2022/02/20/源码级探究Mybatis原理-以查询为例/flow/4.png" alt="flow/4.png"></p>
<p>那么，不见不散。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作为一名Java后端开发者，尤其是国内开发者，从刚参加工作开始就与Mybatis打交道了。&lt;/p&gt;
&lt;p&gt;用了这么久的Mybatis难免会心生疑问：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我只是写了个Mapper接口，再配合xml或者注解，把SQL一写，就可以执行数据库操作，这是为何？&lt;/li&gt;
&lt;li&gt;都说Mybatis是对JDBC的封装，可是我却看不到JDBC相关的接口和对象，它们到哪里去了？&lt;/li&gt;
&lt;li&gt;为什么在Spring中使用Mybatis，不用加@Repository/@Component之类的注解，就可以随用随注入（如：@Autowired）?&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;硬核万字长文，点个再看，转发，多谢啦~&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Java" scheme="http://wuwenliang.net/categories/Java/"/>
    
    
      <category term="Java" scheme="http://wuwenliang.net/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Spring扩展点1-研磨ImportBeanDefinitionRegistrar</title>
    <link href="http://wuwenliang.net/2022/01/29/Spring%E6%89%A9%E5%B1%95%E7%82%B91-%E7%A0%94%E7%A3%A8ImportBeanDefinitionRegistrar/"/>
    <id>http://wuwenliang.net/2022/01/29/Spring扩展点1-研磨ImportBeanDefinitionRegistrar/</id>
    <published>2022-01-29T03:05:41.000Z</published>
    <updated>2022-01-29T04:24:33.367Z</updated>
    
    <content type="html"><![CDATA[<p>本文开始，我们将系统地对Spring框架的扩展点进行学习，通过案例分析与图例结合，step by step地对Spring看似神秘的扩展点的机理与应用进行研究。</p>
<p>首先通过一张图对Spring框架各种扩展点的调用顺序（Bean生命周期）进行先入为主的概览。</p>
<p><img src="/2022/01/29/Spring扩展点1-研磨ImportBeanDefinitionRegistrar/0.png" alt="0.png"></p>
<a id="more"></a>
<p>可以看到图片的一开始便是Spring对Bean定义（BeanDefinition）进行解析和注册，Bean的注册主要就是通过ImportBeanDefinitionRegistrar实现的。</p>
<p>Spring框架主要就是通过ImportBeanDefinitionRegistrar实现对bean的动态注册。源码如下：</p>
<pre><code>public interface ImportBeanDefinitionRegistrar {
    // 通过解析给定的注解元信息，向Spring容器中注册Bean定义
    default void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry,
            BeanNameGenerator importBeanNameGenerator) {

        registerBeanDefinitions(importingClassMetadata, registry);
    }
    default void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) {
    }
}
</code></pre><p>实现ImportBeanDefinitionRegistrar接口的类的都会被ConfigurationClassPostProcessor处理，ConfigurationClassPostProcessor实现了BeanFactoryPostProcessor接口，所以ImportBeanDefinitionRegistrar中动态注册的bean是优先于依赖其的bean初始化的，同时它也可以被aop、validator等机制处理。</p>
<h2 id="编码实现手动Bean注入"><a href="#编码实现手动Bean注入" class="headerlink" title="编码实现手动Bean注入"></a>编码实现手动Bean注入</h2><blockquote>
<p>日常的业务开发中，我们很少会通过ImportBeanDefinitionRegistrar来对bean进行注入。</p>
<p>而是通过xml文件声明或者注解如：@Component、@Service、@Bean等方式对bean进行注入和声明。</p>
<p>那么什么场景下才需要通过ImportBeanDefinitionRegistrar注册并注入bean呢？</p>
</blockquote>
<p>在中间件开发场景下，就会用到手动bean注入。原因在于中间件/框架的开发者并不知道调用方/框架使用者是通过什么方式对bean进行注入的。</p>
<p>当然我们也可以让使用者们显式的对框架中的bean进行定义，但是这样就显著的增加了工作量和出错率，因此对于框架开发而言，常常通过ImportBeanDefinitionRegistrar实现bean的隐式注入和声明，减少调用方整合框架的复杂度。</p>
<blockquote>
<p>我们通过一个模拟场景来介绍一下如何通过编码实现bean的手动隐式注入。、</p>
</blockquote>
<h3 id="1、定义ImportBeanDefinitionRegistrar实现类"><a href="#1、定义ImportBeanDefinitionRegistrar实现类" class="headerlink" title="1、定义ImportBeanDefinitionRegistrar实现类"></a>1、定义ImportBeanDefinitionRegistrar实现类</h3><p>首先定义一个实现ImportBeanDefinitionRegistrar接口的类，并编写bean注册逻辑。</p>
<pre><code>public class MyBeanDefinationRegistry implements ImportBeanDefinitionRegistrar, ResourceLoaderAware, BeanFactoryAware {

    private BeanFactory beanFactory;
    private ResourceLoader resourceLoader;

    @Override
    public void setBeanFactory(BeanFactory beanFactory) throws BeansException {
        this.beanFactory = beanFactory;
    }

    @Override
    public void setResourceLoader(ResourceLoader resourceLoader) {
        this.resourceLoader = resourceLoader;
    }

    @Override
    public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) {

        MyClassPathBeanDefinitionScanner scanner = new MyClassPathBeanDefinitionScanner(registry, false);
        scanner.setResourceLoader(resourceLoader);
        scanner.registerFilters();
        scanner.doScan(&quot;com.spring.framework&quot;);

        GenericBeanDefinition genericBeanDefinition = new GenericBeanDefinition();
        genericBeanDefinition.setBeanClass(TestBean.class);
        genericBeanDefinition.setScope(BeanDefinition.SCOPE_SINGLETON);
        registry.registerBeanDefinition(&quot;testBean&quot;, genericBeanDefinition);
    }
}
</code></pre><p>重点关注 <strong>BeanDefinitionRegistry</strong> 方法，这里提供了两种bean扫描方式。</p>
<h4 id="方式1：基于包路径的扫描"><a href="#方式1：基于包路径的扫描" class="headerlink" title="方式1：基于包路径的扫描"></a>方式1：基于包路径的扫描</h4><pre><code>MyClassPathBeanDefinitionScanner scanner = 
    new MyClassPathBeanDefinitionScanner(registry, false);
scanner.setResourceLoader(resourceLoader);
scanner.registerFilters();
scanner.doScan(&quot;com.spring.framework&quot;);
</code></pre><ol>
<li>自定义一个ClassPathBeanDefinitionScanner实例，并将bean定义注册器BeanDefinitionRegistry引用传递进去，这是一种委托机制；</li>
<li>设置ResourceLoader，ResourceLoader的引用通过ResourceLoaderAware获得，并指向当前类的成员变量；</li>
<li>调用registerFilters方法（该方法为自定义方法，本质是调用了addIncludeFilter），让Spring去扫描带有特定标志的类进行管理与加载；（具体的代码稍后进行分析）；</li>
<li>调用doScan，传递需要扫描的包路径，这个路径就是框架开发者自定义的包路径，该路径下存放的就是框架本身的bean，<strong>这个路径是完全由框架的开发者决定的，而且我们一般可以认为，该路径一旦定义就不会更改。并且该路径也不适合暴露给框架的调用者</strong>。</li>
</ol>
<h4 id="方式2：直接注册BeanDefinition"><a href="#方式2：直接注册BeanDefinition" class="headerlink" title="方式2：直接注册BeanDefinition"></a>方式2：直接注册BeanDefinition</h4><pre><code>GenericBeanDefinition genericBeanDefinition = new GenericBeanDefinition();
genericBeanDefinition.setBeanClass(TestBean.class);
genericBeanDefinition.setScope(BeanDefinition.SCOPE_SINGLETON);
registry.registerBeanDefinition(&quot;testBean&quot;, genericBeanDefinition);
</code></pre><p>方式2比较简单，但是相对的也比方式1繁琐。</p>
<blockquote>
<p>TestBean 是模拟的一个框架的内部bean组件，实际开发中可以根据需要填充必要的属性和方法，这里只是作为演示。</p>
</blockquote>
<pre><code>public class TestBean {
}
</code></pre><p>通过声明GenericBeanDefinition，并未其添加需要注册的Bean的class，scope（单例or多例），beanName等属性，具体的属性可以看下图：</p>
<p><img src="/2022/01/29/Spring扩展点1-研磨ImportBeanDefinitionRegistrar/1,png" alt="1.png"></p>
<p>最后通过 <strong>registry.registerBeanDefinition</strong> 将设置好属性的GenericBeanDefinition注册，并设置beanName；</p>
<h4 id="对比方式1方式2"><a href="#对比方式1方式2" class="headerlink" title="对比方式1方式2"></a>对比方式1方式2</h4><p>通过代码我们可以直观的看到，方式1比方式2更加方便，可以实现批量bean的扫描与注入；</p>
<p>而方式2则需要逐个bean进行注入，但是相对的，方式2也更加灵活，能够实现 <strong>细粒度</strong> 的beanDefinition声明和定义。</p>
<h3 id="2、定义ClassPathBeanDefinitionScanner实现类"><a href="#2、定义ClassPathBeanDefinitionScanner实现类" class="headerlink" title="2、定义ClassPathBeanDefinitionScanner实现类"></a>2、定义ClassPathBeanDefinitionScanner实现类</h3><p>通过定义ClassPathBeanDefinitionScanner的实现类，告诉Spring需要对哪些类进行管理（addIncludeFilter）以及不需要关注哪些类（addExcludeFilter）。</p>
<pre><code>public class MyClassPathBeanDefinitionScanner extends ClassPathBeanDefinitionScanner {

    public MyClassPathBeanDefinitionScanner(BeanDefinitionRegistry registry, boolean useDefaultFilters) {
        super(registry, useDefaultFilters);
    }

    /**
    * 比较重要的一个点就是registerFilters()这个方法，
    * 在里面我们可以定义让Spring去扫描带有特定标志的类选择进行管理或者是选择不管理；
    * 通过addIncludeFilter()方法和通过addExcludeFilter()方法；
    */
    protected void registerFilters() {
        /**
        *  TODO addIncludeFilter  满足任意includeFilters会被加载
        */
        addIncludeFilter(new AnnotationTypeFilter(SnoWalkerAutoInject.class));
    }

    @Override
    protected Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) {
        return super.doScan(basePackages);
    }
}
</code></pre><p>可以看到，扫描器ClassPathBeanDefinitionScanner扫描类路径上的需要被管理的类，通过BeanFactory创建Bean给ApplicationComtext(Spring容器)管理；</p>
<h4 id="registerFilters分析"><a href="#registerFilters分析" class="headerlink" title="registerFilters分析"></a>registerFilters分析</h4><p>registerFilters是自定义的方法，核心的逻辑就是通过addIncludeFilter添加了一个包扫描的规则：</p>
<p>这里是通过注解类型的Filter通知Spring容器对添加了SnoWalkerAutoInject自定义注解的bean进行管理。</p>
<p>我们可以看到，自定义的MyClassPathBeanDefinitionScanner重写了父类的doScan方法，本质上调用了父类的doScan，以实现对指定路径下的bean进行扫描。</p>
<p>最终实际上是在ApplicationContext中调用了doScan，实现了对bean定义的扫描及实例化，我们可以看一下源码实现：</p>
<pre><code>/**
 * Create a new AnnotationConfigApplicationContext, scanning for components
 * in the given packages, registering bean definitions for those components,
 * and automatically refreshing the context.
 * @param basePackages the packages to scan for component classes
 */
public AnnotationConfigApplicationContext(String... basePackages) {
    this();
    scan(basePackages);
    refresh();
}
</code></pre><p>AnnotationConfigApplicationContext构造方法中，对package进行了扫描，并调用refresh方法对bean进行初始化和实例化。</p>
<h3 id="3、自定义注解"><a href="#3、自定义注解" class="headerlink" title="3、自定义注解"></a>3、自定义注解</h3><p>自定义注解，并添加到需要装载到Spring容器中的框架类上：</p>
<pre><code>@Documented
@Inherited
@Retention(RetentionPolicy.RUNTIME)
@Target({ElementType.TYPE, ElementType.FIELD, ElementType.METHOD, ElementType.PARAMETER})
public @interface SnoWalkerAutoInject {
}
</code></pre><p>定义几个模拟的框架类，用以模拟框架的逻辑。实际的开发中，我们可以按照需求的实际需要，开发框架代码，并标记自定义的注解。</p>
<pre><code>@SnoWalkerAutoInject
public class FrameWorkConfigA {

    public FrameWorkConfigA() {
        System.out.println(&quot;自定义框架组件A-初始化逻辑&quot;);
    }
}

@SnoWalkerAutoInject
public class FrameWorkConfigB {

    public FrameWorkConfigB() {
        System.out.println(&quot;自定义框架组件B-初始化逻辑&quot;);
    }
}

@SnoWalkerAutoInject
public class FrameWorkConfigC {

    public FrameWorkConfigC() {
        System.out.println(&quot;自定义框架组件C-初始化逻辑&quot;);
    }
}
</code></pre><h3 id="4、配置ImportBeanDefinitionRegistrar实现类"><a href="#4、配置ImportBeanDefinitionRegistrar实现类" class="headerlink" title="4、配置ImportBeanDefinitionRegistrar实现类"></a>4、配置ImportBeanDefinitionRegistrar实现类</h3><p>如何使用自定义的ImportBeanDefinitionRegistrar实现类对bean进行装载呢？</p>
<p>最终我们还是需要定义一个配置类，通过@Import注解配置ImportBeanDefinitionRegistrar实现。</p>
<pre><code>@Configuration
@Import(MyBeanDefinationRegistry.class)
@ComponentScan(&quot;com.spring.framework&quot;)
public class MyConf {
}
</code></pre><ol>
<li>MyConf是自定义的配置类，标注了 @Configuration 注解。</li>
<li>通过@Import将实现了ImportBeanDefinitionRegistrar接口的MyBeanDefinationRegistry包含进来；</li>
<li>添加扫描包，以方便spring对该包下的类进行扫描并进行选择性的装载；</li>
</ol>
<h3 id="4、测试"><a href="#4、测试" class="headerlink" title="4、测试"></a>4、测试</h3><p>编写测试类：</p>
<pre><code>public class App {

    public static void main(String[] args) {
        ApplicationContext applicationContext = new AnnotationConfigApplicationContext(&quot;com.spring&quot;);

        final TestBean testBean = (TestBean) applicationContext.getBean(&quot;testBean&quot;);
        System.out.println(testBean.getClass());
    }
}
</code></pre><ol>
<li>首先我们声明并初始化一个AnnotationConfigApplicationContext容器；</li>
<li>接着从容器中通过BeanName获取通过GenericBeanDefinition定义的TestBean实例，打印其Class类型；</li>
<li>观察日志输出，期望能够看到框架代码FrameWorkConfigA、FrameWorkConfigB、FrameWorkConfigC的构造方法日志打印，并看到TestgBean的Class类型打印。</li>
</ol>
<p>运行测试类，观察控制台日志输出：</p>
<pre><code>自定义框架组件A-初始化逻辑
自定义框架组件B-初始化逻辑
自定义框架组件C-初始化逻辑

class com.spring.TestBean
</code></pre><p>可以看到符合预期，这表明，通过ImportBeanDefinitionRegistrar自定义手动bean注入符合预期。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文我们全篇对ImportBeanDefinitionRegistrar在Spring容器装载bean的过程进行了综述，并通过一个模拟框架开发的案例，对如何通过ImportBeanDefinitionRegistrar实现bean的自定义注入进行了代码级别的讲解和分析。</p>
<p>如果在实际的开发案例中需要实现自定义的bean注入，减少调用方整合的复杂度，那么我们完全可以通过本文讲解的方式，利用ImportBeanDefinitionRegistrar扩展点实现。</p>
<h2 id="下期预告："><a href="#下期预告：" class="headerlink" title="下期预告："></a>下期预告：</h2><p>下期我们将分析讲解BeanPostProcessor扩展点在Spring框架中的作用，并讲解BeanPostProcessor在实战开发中的使用。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文开始，我们将系统地对Spring框架的扩展点进行学习，通过案例分析与图例结合，step by step地对Spring看似神秘的扩展点的机理与应用进行研究。&lt;/p&gt;
&lt;p&gt;首先通过一张图对Spring框架各种扩展点的调用顺序（Bean生命周期）进行先入为主的概览。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2022/01/29/Spring扩展点1-研磨ImportBeanDefinitionRegistrar/0.png&quot; alt=&quot;0.png&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Spring扩展点" scheme="http://wuwenliang.net/categories/Spring%E6%89%A9%E5%B1%95%E7%82%B9/"/>
    
    
      <category term="Spring扩展点" scheme="http://wuwenliang.net/tags/Spring%E6%89%A9%E5%B1%95%E7%82%B9/"/>
    
  </entry>
  
  <entry>
    <title>归于平静，甘于平凡</title>
    <link href="http://wuwenliang.net/2021/12/31/%E5%BD%92%E4%BA%8E%E5%B9%B3%E9%9D%99%EF%BC%8C%E7%94%98%E4%BA%8E%E5%B9%B3%E5%87%A1/"/>
    <id>http://wuwenliang.net/2021/12/31/归于平静，甘于平凡/</id>
    <published>2021-12-31T14:54:57.000Z</published>
    <updated>2021-12-31T15:15:12.686Z</updated>
    
    <content type="html"><![CDATA[<p>题诗：</p>
<pre><code>不要温和地走进那良夜，
老年应当在日暮时燃烧咆哮；
怒斥，怒斥光明的消逝。
虽然智慧的人临终时懂得黑暗有理，
因为他们的话没有迸发出闪电，他们
也并不温和地走进那个良夜。
善良的人，当最后一浪过去，高呼他们脆弱的善行
可能曾会多么光辉地在绿色的海湾里舞蹈，
怒斥，怒斥光明的消逝。
狂暴的人抓住并歌唱过翱翔的太阳，
懂得，但为时太晚，他们使太阳在途中悲伤，
也并不温和地走进那个良夜。
严肃的人，接近死亡，用炫目的视觉看出
失明的眼睛可以像流星一样闪耀欢欣，
怒斥，怒斥光明的消逝。
您啊，我的父亲．在那悲哀的高处．
现在用您的热泪诅咒我，祝福我吧．我求您
不要温和地走进那个良夜。
怒斥，怒斥光明的消逝。
</code></pre><p>平常的日子，地球又一次完成了它伟大的公转，于是，一年又过去。</p>
<p>往年每逢公历年的末尾，总是会像写故事一样，洋洋洒洒的罗列自己一年来达成的目标，嗟叹一番未完成的事情，然后立下当时自信能够在接下来一年<br>能够完成的flag，最后再下一次所谓年终总结中，继续这个循环。</p>
<p>这次，我承认我又不能免俗的继续写这个所谓的“年终总结”。只是觉得，如果不写的话，我将又丢掉一个本就少的可怜的习惯。</p>
<p>仅仅是出于习惯，我写给自己。</p>
<p>总得找个主题，这一年，复杂，我想不出别的词来概括我的一年，下意识的想到了复杂。</p>
<p>这是一个男孩变成所谓男人的故事，经历很多，结婚，生子，跳槽，网暴，写书…..太多的事情，让你变得急躁。</p>
<p>做加法容易，做减法难。</p>
<p>着急地想要做完这件事，奔赴下一件事；</p>
<p>从一个孩子变为一个父亲，只觉得，脚步都变得不同往常。</p>
<p>从此不是为了自己而活，一切的美好语言比不上陪伴二字。</p>
<p>感谢妻的辛苦，感谢父母的照顾，感谢陪伴。</p>
<p>经历的事情确实很多，但此时的心态却不同往常，往日肯定会大篇幅的去逐个罗列，然后写上一段所谓心得。这都是过去式了。</p>
<p>要向前看。</p>
<p>活着，生活着，努力生活着，就很满足了。</p>
<p>于是我想到了八个字，归于平静，甘于平凡。</p>
<p>事情太多，加法做太多，心情变得急躁，于是什么都想要，于是总会计较得失。</p>
<p>来年，接下来的日子里，要学会做减法，断舍离，关注重要的，忽略次要的，要接受自己是一个普通人的事实，不虚妄，不浮夸。</p>
<p>甘于平凡，修身修心，过好平常的每天，陪伴身边的人。</p>
<p>不炫耀，不盲从，负责任，扮演好每个需要扮演的角色，不逾矩。</p>
<p>不再立虚无的目标，学会衡量承诺的重量。</p>
<p>感谢过去的自己，做好现在的自己，迎接更好的自己。</p>
<p>迎接更好的2022。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;题诗：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;不要温和地走进那良夜，
老年应当在日暮时燃烧咆哮；
怒斥，怒斥光明的消逝。
虽然智慧的人临终时懂得黑暗有理，
因为他们的话没有迸发出闪电，他们
也并不温和地走进那个良夜。
善良的人，当最后一浪过去，高呼他们脆弱的善行
可能曾会多么光辉地
    
    </summary>
    
      <category term="年度总结" scheme="http://wuwenliang.net/categories/%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="年度总结" scheme="http://wuwenliang.net/tags/%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>RocksDB了解一下？</title>
    <link href="http://wuwenliang.net/2021/07/22/Rocksdb%E4%BA%86%E8%A7%A3%E4%B8%80%E4%B8%8B%EF%BC%9F/"/>
    <id>http://wuwenliang.net/2021/07/22/Rocksdb了解一下？/</id>
    <published>2021-07-22T14:55:04.000Z</published>
    <updated>2021-07-22T15:50:39.863Z</updated>
    
    <content type="html"><![CDATA[<p>项目中需要实现高效的IO操作，不仅支持查询、写入数据，还需要实现数据的持久化。选型最终选择了RocksDB，那么本文就来一睹RocksDB的芳容。</p>
<h2 id="RocksDB是什么？"><a href="#RocksDB是什么？" class="headerlink" title="RocksDB是什么？"></a>RocksDB是什么？</h2><blockquote>
<p>RocksDB是Facebook开发的一款高效的数据库软件，是采用C++编写而成的。</p>
</blockquote>
<p>RocksDB是一款key-value型数据存储设施，具备四个特点，其具有四大特点。</p>
<p><strong>高性能</strong>：RocksDB使用一套C++编写而成的高性能日志结构的数据库引擎。 它的Key和value支持任意大小的字节流。</p>
<p><strong>可适配性</strong>：RocksDB适合于多种不同工作场景。从像MyRocks这样的数据存储引擎到应用数据缓存, 甚至是嵌入式工作场景，RocksDB都可以从容面对这些不同的数据工作需求。</p>
<p><strong>为快速存储而优化</strong>：RocksDB为快速而又低延迟的存储设备（例如闪存或者高速硬盘）进行了特殊优化处理，将最大限度发挥闪存和RAM的高度率读写性能。</p>
<p><strong>基础和高级的数据库操作</strong>：RocksDB提供了一些基础的操作，例如打开和关闭数据库。它对于合并、压缩、过滤等高级操作，也提供了支持。</p>
<p>如果对RocksDB感兴趣，可以去读它的源码，地址为：<a href="https://github.com/facebook/rocksdb" target="_blank" rel="external">https://github.com/facebook/rocksdb</a></p>
<h2 id="在Java工程中使用RocksDB"><a href="#在Java工程中使用RocksDB" class="headerlink" title="在Java工程中使用RocksDB"></a>在Java工程中使用RocksDB</h2><p>如何在Java工程中使用RocksDB呢？</p>
<p>首先建立一个maven工程，在pom.xml中引入RocksDB依赖：</p>
<pre><code>&lt;!-- https://mvnrepository.com/artifact/org.rocksdb/rocksdbjni --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.rocksdb&lt;/groupId&gt;
    &lt;artifactId&gt;rocksdbjni&lt;/artifactId&gt;
    &lt;version&gt;6.20.3&lt;/version&gt;
&lt;/dependency&gt;
</code></pre><p>接着我们通过一个demo尝试在Java中使用RocksDB。</p>
<h3 id="初始化RocksDB"><a href="#初始化RocksDB" class="headerlink" title="初始化RocksDB"></a>初始化RocksDB</h3><pre><code>private RocksDB rocksDB;

private String path = &quot;D:/rocksdb&quot;;

public RocksDBDemo() {
    RocksDB.loadLibrary();
    Options options = new Options();
    options.setCreateIfMissing(true);
    try {
        rocksDB = RocksDB.open(options, path);
    } catch (RocksDBException e) {
        e.printStackTrace();
    }
}

public RocksDB rocksDB() {
    return this.rocksDB;
}
</code></pre><p>首先指定一个路径用于创建RocksDB的log文件：rocksdb写入时，直接以append方式写到log文件以及memtable，随即返回，因此非常快速。</p>
<p>接着通过RocksDB.loadLibrary();导入库，然后设置Options，并打开rocksDB，此时成员变量rocksDB就可以拿来进行操作了。</p>
<h3 id="RocksDB读写"><a href="#RocksDB读写" class="headerlink" title="RocksDB读写"></a>RocksDB读写</h3><pre><code>RocksDBDemo rocksDBDemo = new RocksDBDemo();
RocksDB rocksDB = rocksDBDemo.rocksDB();
// 写入
rocksDB.put(&quot;name&quot;.getBytes(), &quot;snowalker&quot;.getBytes());
// 读取
byte[] bytes = rocksDB.get((&quot;name&quot;.getBytes()));
System.out.println(&quot;读取结果:&quot; + new String(bytes));

// 遍历
RocksIterator iter = rocksDB.newIterator();
for (iter.seekToFirst();iter.isValid();iter.next()) {
    System.out.println(&quot;iter key: &quot; + new String(iter.key()) + &quot;,iter value: &quot; +
            new String(iter.value()));
}
</code></pre><p>RocksDBDemo是我们的测试类名，首先获取rocksDB引用，然后调用put，get方法进行读写操作。</p>
<p>其中put方法签名为：</p>
<pre><code>public void put(final byte[] key, final byte[] value)
    throws RocksDBException {
    put(nativeHandle_, key, 0, key.length, value, 0, value.length);
}
</code></pre><p>get方法签名为：</p>
<pre><code>public byte[] get(final byte[] key) throws RocksDBException {
    return get(nativeHandle_, key, 0, key.length);
}
</code></pre><p>通过rocksDB.newIterator()可以获取迭代器，借助迭代器能够执行迭代操作，这里是读取了一下key与value。</p>
<h3 id="rocksDB的write操作"><a href="#rocksDB的write操作" class="headerlink" title="rocksDB的write操作"></a>rocksDB的write操作</h3><p>rocksdb的一个WriteBatch是原子操作，要么全部成功，要么全部失败，</p>
<blockquote>
<p>具体的实现原理是在整个log的写的过程中只会调用Write操作，最后会调用一次flush，所以如果中间发生机器crash，所有的都会失败，否则所有的都会成功。</p>
</blockquote>
<p>看一段实际代码：</p>
<pre><code>// write batch test
try (final WriteOptions writeOpt = new WriteOptions()) {
    for (int i = 0; i &lt;= 10; ++i) {
        try (final WriteBatch batch = new WriteBatch()) {
            for (int j = 0; j &lt;= 10; ++j) {
                batch.put(String.format(&quot;%d * %d%s&quot;, i, j, &quot;--batch&quot;).getBytes(),
                        String.format(&quot;%d&quot;, i * j).getBytes());
            }
            rocksDB.write(writeOpt, batch);
        }
    }
}
</code></pre><p>这里实际上将乘法表写入了rocksDB。</p>
<p>运行代码，观察目录D:/rocksdb中出现了以下文件：</p>
<p><img src="/2021/07/22/Rocksdb了解一下？/1.PNG" alt="1.PNG"></p>
<p>简单对这几种文件进行讲解：</p>
<p>我们可以从后缀看出：主要有这几种类型</p>
<ul>
<li>sst文件</li>
<li>CURRENT文件</li>
<li>manifest文件</li>
<li>log文件</li>
<li>LOG文件和LOCK文件</li>
</ul>
<p>其中</p>
<ol>
<li>sst文件存储的是落地的数据</li>
<li>CURRENT文件存储的是当前最新的是哪个manifest文件</li>
<li>manifest文件存储的是Version的变化</li>
<li>log文件是rocksdb的write ahead log，就是在写db之前写的数据日志文件，类似binlog</li>
<li>LOG文件是一些日志信息，是供调试用的</li>
<li>LOCK是打开db锁，只允许同时有一个进程打开db</li>
</ol>
<p>这里我们重点看一下log文件中的内容，由于写入的byte，可能有乱码。</p>
<p><img src="/2021/07/22/Rocksdb了解一下？/2.PNG" alt="2.PNG"></p>
<p>从图中可以看到，实际上是顺序写入了我们在代码中设置的key-value。</p>
<h2 id="解释一下rocksdb的flush操作"><a href="#解释一下rocksdb的flush操作" class="headerlink" title="解释一下rocksdb的flush操作"></a>解释一下rocksdb的flush操作</h2><p>Flush是指将memtable的数据导入到sst中，变成持久化存储，从而不必担心数据丢失了。</p>
<pre><code>1.首先在memtable的add的时候，
会检测是否memtable的大小达到了max write buffer，
如果是就将should_flush_置为true，
并会在WriteBatch的Handler里面调用CheckMemtableFull，
将当前column family加入flush_scheduler。

2.在Write的时候，调用ScheduleFlushes，
将需要flush的column family的memtable切换一个新的，
同时将原来的memtable加入cfd的imm中，
如果这个column family data的imm数量大于min_write_buffer_number_to_merge，
并启动一个新的线程调用BGWorkFlush

由于真正的Flush过程是在另一个线程完成的，所以这个地方并不会block写过程
</code></pre><h2 id="rocksDB的WAL（write-ahead-log）"><a href="#rocksDB的WAL（write-ahead-log）" class="headerlink" title="rocksDB的WAL（write ahead log）"></a>rocksDB的WAL（write ahead log）</h2><p>rocksdb的write ahead log（WAL）是指：<br>每次写操作，rocksdb会先写write ahead log，然后才会写db<br>write ahead log可以配置到单独的空间，并且可以配置WAL文件的单独的删除机制。</p>
<p>这种原因是为了保存WAL文件，达到特殊的目的，比如，其他sst文件放在不可靠存储里面，而WAL放到可靠存储里面。</p>
<p>对RocksDB 的写操作而言，每次都必写到两个地方：</p>
<ol>
<li>基于内存的数据结构memtable（达到quota 后会flush 至SST file）。</li>
<li>预写日志-Write Ahead Log（WAL）。<br>如果出现异常情况，WAL 可以用来完整恢复memtable 中的数据，恢复db 的原有的状态。</li>
</ol>
<p>默认配置下，RocksDB 通过每次用户写之后flush WAL，来保证进程crash 后的一致性。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文我们主要对rocksDB做了一个了解和学习，一般来说，使用它的目的在于高性能的写入，实现数据的快速持久化。</p>
<p>业界不乏优秀的中间件底层依赖了rocksDB，如TiDB。</p>
<p>###</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;项目中需要实现高效的IO操作，不仅支持查询、写入数据，还需要实现数据的持久化。选型最终选择了RocksDB，那么本文就来一睹RocksDB的芳容。&lt;/p&gt;
&lt;h2 id=&quot;RocksDB是什么？&quot;&gt;&lt;a href=&quot;#RocksDB是什么？&quot; class=&quot;headerli
    
    </summary>
    
      <category term="专题-分布式" scheme="http://wuwenliang.net/categories/%E4%B8%93%E9%A2%98-%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="专题-分布式" scheme="http://wuwenliang.net/tags/%E4%B8%93%E9%A2%98-%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>复杂软件开发之道4-小试牛刀,教练我想写代码</title>
    <link href="http://wuwenliang.net/2021/04/15/%E5%A4%8D%E6%9D%82%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91%E4%B9%8B%E9%81%934-%E5%B0%8F%E8%AF%95%E7%89%9B%E5%88%80-%E6%95%99%E7%BB%83%E6%88%91%E6%83%B3%E5%86%99%E4%BB%A3%E7%A0%81/"/>
    <id>http://wuwenliang.net/2021/04/15/复杂软件开发之道4-小试牛刀-教练我想写代码/</id>
    <published>2021-04-14T23:59:31.000Z</published>
    <updated>2021-04-15T00:49:31.999Z</updated>
    
    <content type="html"><![CDATA[<p>复杂软件开发之道系列进行到现在，主要讲的还是理论和思考，但是如何针对DDD编写代码这一问题想必是大家一直关心的问题。</p>
<p>本文我们就小试牛刀，展示一下通过DDD方式编写代码。</p>
<h2 id="1-只有新项⽬才能考虑⽤DDD吗"><a href="#1-只有新项⽬才能考虑⽤DDD吗" class="headerlink" title="1.只有新项⽬才能考虑⽤DDD吗?"></a>1.只有新项⽬才能考虑⽤DDD吗?</h2><p><strong>当然不是</strong>，DDD这套⽅法论不仅适合从零开始的新项⽬的建模，⽽且适 合复杂业务系统的重构。 当然如果能在新模型的建⽴的过程中就使⽤DDD作为指导，是最好不过的事情，原因在于你会省略对原 有业务系统代码逻辑的梳理和适配过程，众所周知，这不是⼀件容易的事情。</p>
<a id="more"></a>
<h2 id="2-我想在遗留项⽬重构中使⽤DDD，我该怎么做？"><a href="#2-我想在遗留项⽬重构中使⽤DDD，我该怎么做？" class="headerlink" title="2 我想在遗留项⽬重构中使⽤DDD，我该怎么做？"></a>2 我想在遗留项⽬重构中使⽤DDD，我该怎么做？</h2><p>emmmm，恭喜你提出了⼀个好问题，这个问题展开讲的时⻓甚⾄会超过我们本次分享的所有内容加起来的时⻓。（展开讲涉及到领域建模的战略 战术设计，这个后续专题分享） 不过这个问题的本质还是值得探究⼀番。 </p>
<p>⾸先，遗留系统，DDD这两个加起来本就不是那么容易的事情，所以⼤家难免有以下顾虑：</p>
<ol>
<li>懂这块儿业务的同学并不多;</li>
<li>没有足够的落地资料进行参考;</li>
<li>对使用DDD没有底气，不知道从何下手;</li>
<li>客观上，开发周期紧张，排期难以准确预估;</li>
<li>代码逻辑复杂，梳理起来具备一定难度;</li>
<li>对原有模型的二次抽象过于复杂，不知从何下手。</li>
</ol>
<p>有顾虑在所难免，但是如果我们⽤了DDD去建模并且最终成功的落地了这件事情，对我们有什么收益或者说好处呢？好处/收益有如下几点：</p>
<ol>
<li>最直接的受益是对DDD具备了落地经验;</li>
<li>对复杂业务重构具备了落地经验;</li>
<li>积累了丰富的文档和资料，方便新人快速理解业务并上手;</li>
<li>能够对领域划分有所思考和实践;</li>
<li>使业务代码腐化速率降低，稳定支持一定时间内的正常迭代;</li>
<li>客观上拥有了一个具备稳定业务核心的系统，方便快速迭代核心外的业务逻辑，而且可以尽量保证内部模型健壮沉稳地发展;</li>
<li>对于参与者本身的沟通能力和思考能力也是十分明显的。</li>
</ol>
<p>伟⼈说，道路是曲折的，前途是光明的。对于DDD⽽⾔亦如是，只要最终得以落地，那么我们的受益就会⼤幅度<br>⾼于产出，对于我们RD⾃身的影响也是⻓⾜可观的。 那么具体应该如何去做呢，我们需要按照图中的这些步骤去做：</p>
<p><img src="/2021/04/15/复杂软件开发之道4-小试牛刀-教练我想写代码/1.png" alt="1.png"></p>
<h2 id="3-具体的代码是如何应⽤DDD建模思想的"><a href="#3-具体的代码是如何应⽤DDD建模思想的" class="headerlink" title="3. 具体的代码是如何应⽤DDD建模思想的"></a>3. 具体的代码是如何应⽤DDD建模思想的</h2><p>限于篇幅和准备时间，我们通过⼀个简单的业务场景，展示⼀下充⾎模型、领域事件发布、 命令查询分离的代码书写⽅式，权当抛砖引⽟了。</p>
<blockquote>
<p>背景介绍，我们就⼀个简单的为账户进⾏加款这个业务场景，通过DDD的分包和编码⽅式，直观展示⼀下具体的 代码编写⽅式。这个场景的主要流程如下图</p>
</blockquote>
<p><img src="/2021/04/15/复杂软件开发之道4-小试牛刀-教练我想写代码/13.png" alt="13.png"></p>
<p>这个过程中涉及到的对象及其关系⼜是怎样的？</p>
<p>通过名词动词法，我们能够得出以下的交互过程 </p>
<ol>
<li>[执行]-&gt;转账请求-&gt;[发布]-&gt;转账请求已接受事件</li>
<li>账户-&gt;[执⾏]-&gt;充值动作-&gt;[发布]-&gt;账户已完成事件</li>
</ol>
<p>引⼊命令查询模式，旨在展示另⼀种编码⻛格，不⽤命令查询模式（CQRS）也是可以的。 这⾥想补充的是，通过DDD编码没有⼀个统⼀的规范或者样板，我这⾥展示的也并不⼀定是最优的，但是我们始终还是要秉承⼀个观念<br><strong>“还对象以⾏为，⽤代码映射真实世界”</strong>。</p>
<p>简单看⼀下代码的结构，采⽤了经典的四层分包进⾏组织：</p>
<p><img src="/2021/04/15/复杂软件开发之道4-小试牛刀-教练我想写代码/2.png" alt="2.png"></p>
<p>展开来看如下：</p>
<p><img src="/2021/04/15/复杂软件开发之道4-小试牛刀-教练我想写代码/3.png" alt="3.png"></p>
<h3 id="3-1-通过use-case导向，从业务⻆度去看代码，最后再进⾏总结分析"><a href="#3-1-通过use-case导向，从业务⻆度去看代码，最后再进⾏总结分析" class="headerlink" title="3.1 通过use case导向，从业务⻆度去看代码，最后再进⾏总结分析"></a>3.1 通过use case导向，从业务⻆度去看代码，最后再进⾏总结分析</h3><blockquote>
<p>⾸先是账户充值请求的⼊⼝，发⽣在application层，这⼀层主要提供⽤例级别的⽅法逻辑。</p>
</blockquote>
<p><img src="/2021/04/15/复杂软件开发之道4-小试牛刀-教练我想写代码/4.png" alt="4.png"></p>
<p>通过⼯⼚对命令进⾏转换，转换为内部的请求对象，先对请求持久化之后，认为请求已接受，随即发布事件（事件⼀般都是过去式，此处为充值请求已接受事件），事件发布后，会有监听器进⾏处理。</p>
<p><img src="/2021/04/15/复杂软件开发之道4-小试牛刀-教练我想写代码/5.png" alt="5.png"></p>
<p>从事件中还原请求，并转换为扣款命令，再次请求账户应⽤服务的账户增加服务。</p>
<p><img src="/2021/04/15/复杂软件开发之道4-小试牛刀-教练我想写代码/6.png" alt="6.png"></p>
<p>账户实体通过id唯⼀标识，从持久设施中取出后进⾏处理，⽽不是直接传递该实体，这也是DDD编码中的⼀个实践，传递标识，⽽不是直接传递引⽤。</p>
<p>尽量弱化代码耦合 获取到账户实体，通过账户⾃身的⾏为执⾏充值，这⾥其实就是所谓的<strong>充⾎模型</strong>，即：</p>
<blockquote>
<p>领域⾃身的职责 让领域对象⾃⼰完成，⽽不是借助事务脚本完（传统的xxxxService就是事务脚本，将⾏为从领域对象中 抽离，领域对象退化为数据承载的容器，或者说就是⼀个数据结构）</p>
</blockquote>
<p><img src="/2021/04/15/复杂软件开发之道4-小试牛刀-教练我想写代码/7.png" alt="7.png"></p>
<p><img src="/2021/04/15/复杂软件开发之道4-小试牛刀-教练我想写代码/8.png" alt="8.png"></p>
<p>通过领域对象的⾏为完成充值之后，发布充值完成事件，将变更后的账户持久化（借助Spring的同步事 件发布订阅，⽀持事务传播机制）。</p>
<p><img src="/2021/04/15/复杂软件开发之道4-小试牛刀-教练我想写代码/9.png" alt="9.png"></p>
<p><img src="/2021/04/15/复杂软件开发之道4-小试牛刀-教练我想写代码/10.png" alt="10.png"></p>
<p>账户更新事件监听器，对事件进⾏处理，将充值完成的账户持久化到持久化设施，如DB中。</p>
<p><img src="/2021/04/15/复杂软件开发之道4-小试牛刀-教练我想写代码/11.png" alt="11.png"></p>
<p>通过仓储持久化变更的账户余额（可以使⽤乐观锁，此处不实现）。</p>
<h3 id="小结DDD编码"><a href="#小结DDD编码" class="headerlink" title="小结DDD编码"></a>小结DDD编码</h3><p>简单的总结下吧： </p>
<p>我们通过这个简单的 <strong>账户充值请求接收-&gt;执⾏账户充值-&gt;充值完成后更新账户</strong> 的业务场景，<br>通过领域驱动的⽅式 进⾏编码，可以看到最直接的变化就是：我们把业务的核⼼实现放在账户聚合的内部，而账户实体成为⼀个充⾎模型。 </p>
<p>借助命令查询分离（查询我没有实现，并不复杂，⼤家感兴趣可以⾃⾏了解），领域事件发布订阅等⽅式，以不同于传统的事务脚本的⽅式实现了这个业务。</p>
<p>我们通过这个简单的流程，能够很容易根据事件的发布划分出整个业务流程执⾏的不同阶段，通过领域⾏为可以将核⼼业务操作牢牢把握在领域内部，保证我们的模型不会更快的随着需求迭代⽽腐化。</p>
<p>样例确实简单了些，主要是笔者的时间确实⽐较紧张，权当抛砖引⽟，后续有机会针对编码这块⼉还有更多的分享。</p>
<h3 id="补充：对DDD上下文映射的思考"><a href="#补充：对DDD上下文映射的思考" class="headerlink" title="补充：对DDD上下文映射的思考"></a>补充：对DDD上下文映射的思考</h3><p>软件是对现实世界的抽象和映射，如下图：</p>
<p><img src="/2021/04/15/复杂软件开发之道4-小试牛刀-教练我想写代码/12.png" alt="12.png"></p>
<p>软件发展的规律就是逐步由简单软件向复杂软件转变，使变更总是满⾜当下的需求，通过领域努⼒还原 真实世界，避免过度设计，让代码具备开放封闭的特性，能够避免软件过快腐化。</p>
<p>对于上下文而言，上下⽂关系有以下几种： </p>
<ol>
<li><strong>U(Upstream 上游)/D(DownStream 下游)</strong> : 上游的变动会影响下游，⽐如下游在代码上依赖上游（或者 模型结构），这⾥的上下游不是指数据的流向。</li>
<li><strong>OHS(Open Host Service 开放主机服务/发布语⾔)</strong> : 上游定义⼀种协议，让下游通过协议去使⽤该服 务，并公开这份协议（接⼝），让想⽤的⼈可以使⽤它。 </li>
<li><strong>PL(Published Language 发布语⾔)</strong> : 协定传送资料的语⾔格式，如 XML、JSON 或是 Protocol Buffer等等。</li>
<li><strong>ACL(Anti-corruption Layer 防腐层)</strong> : 是⼀种在不同模型间转换概念与资料的机制。为了要避免你 Bounded Context 的 domain model 概念受到来⾃外部的污染，你可以藉由 ACL 来建⽴⼀层隔离层，利 ⽤Facade模式来将外部概念转换成内部 Domain Model 能理解的概念。此种关系多⽤于遗留系统和团队 外部系统。 </li>
<li><strong>Shared Kernel(共享内核)</strong> : 两个 Bounded Context 共⽤同⼀个模块。当两个团队在开发同⼀个应⽤程 序，并且各⾃的 Bounded Context 共享⼀块重复的领域知识，为了加快开发的脚步，就会将部分共⽤的逻辑抽成 Shared Kernel。这也表明这部分的业务语⾔和领域知识在共享的两个上下⽂是不存在歧义，可以通⽤的。<strong>例如</strong>：两个 Bounded Context 依赖同⼀个⼆⽅库。</li>
<li><strong>Customer-Supplier(客户-供应商)</strong> : 当 Bounded Context 或团队间有上下游关系(单向依赖)时，上游⽅可以独⽴于下游⽅完成开发，⽽下游⽅必须受限于上游⽅的开发计划。当上游⽅开会或做决策时，下游⽅也需要被通知甚⾄⼀起参加会议。这种关系情况下上下游⼀般会有⼀整套的测试⽤例，⽤于维护相互之间的不变性。上游的更改只要能够满⾜约定的不变性，即可不⽤通知下游进⾏变更。例如：事件发布或 者消息队列等⽅式； </li>
<li><strong>Conformist(遵奉者)</strong> : 同样在 Bounded Context 或团队间有上下游关系时出现，但此时上游⽅没有任何<br>动⼒要满⾜下游⽅的需求，这种关係我们就称下游⽅为 Conformist。此关系下有可能出现上游变更后， 短时间内下游逻辑异常的情况，此时需要下游对新的变更进⾏适配。 </li>
<li><strong>Seperate Way(另谋他路)</strong> : 当两个 Bounded Context 或团队间因为技术、沟通或政治因素导致合作成本 过⾼时，就可以考虑断开两者的依赖关系。这并不代表两者毫⽆关系，仍有可能透过 UI 或是⼿动的模式 来进⾏整合限界上下⽂不仅是业务语⾔和领域知识的边界，也是团队合作的边界，清晰地定义不同上下⽂的关系不 仅有助于梳理业务之间的关系，也有助于理解不同团队的合作关系。</li>
</ol>
<h2 id="以终为始，道法⾃然"><a href="#以终为始，道法⾃然" class="headerlink" title="以终为始，道法⾃然"></a>以终为始，道法⾃然</h2><p>唠了这么多，其实我们反复在讨论的只有⼀个问题，<strong>那就是DDD本身并不可怕</strong>，可怕的是⽣搬硬套所谓最佳实践以及对⽅法要解决的问题本质分析不透彻就硬上，这最终会对我们的系统造成反噬。 </p>
<p>即便对DDD整套理论没有系统全⾯的认知，如果你始终秉承着⾯向对象设计、⾯向对象建模的思路，通过 <strong>核⼼模型领域建模 + 结构化编程思想 + ⾯向对象设计模式的合理使⽤</strong>（针对问题域 适度封装与预留扩展点），我们写出来的代码质量的坏味道就会少很多。 </p>
<p>简单的说，是不是DDD驱动的不重要，重要在于够不够OO，⾜够OO，⾜够健壮，是否DDD已经不再重要，我们只需要从DDD中适度的借鉴采⽤适合我们的⽅法/⼯具，达成软件的落地就可以。 </p>
<p>所谓的⼤象⽆形，融汇贯通就是这样的，（就好⽐：张⽆忌当初练习太极剑，从开始到结束，忘记了所有招数， 达到运⽤⾃如，融会贯通的化境。）DDD对于你完全成为⼀套⼯具箱。</p>
<p>⼀切的⼀切都是为了 <strong>“Get things Done”</strong>，让事情是他本来的样⼦，让事情能够落地。这才是我们要使用DDD的价值，这亦是我所认为的DDD的⽬的。因为DDD本质上就是解决问题的一套思想的沉淀。</p>
<h2 id="DDD推荐学习资料"><a href="#DDD推荐学习资料" class="headerlink" title="DDD推荐学习资料"></a>DDD推荐学习资料</h2><p>如果想继续了解DDD，那么可以阅读以下资料，排名不分先后：</p>
<ul>
<li>实现领域驱动设计</li>
<li>领域驱动设计精粹</li>
<li>微服务架构设计模式</li>
<li>极客时间《DDD实战课》</li>
<li>Gitchat《领域驱动设计实践战略+战术》</li>
</ul>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;复杂软件开发之道系列进行到现在，主要讲的还是理论和思考，但是如何针对DDD编写代码这一问题想必是大家一直关心的问题。&lt;/p&gt;
&lt;p&gt;本文我们就小试牛刀，展示一下通过DDD方式编写代码。&lt;/p&gt;
&lt;h2 id=&quot;1-只有新项⽬才能考虑⽤DDD吗&quot;&gt;&lt;a href=&quot;#1-只有新项⽬才能考虑⽤DDD吗&quot; class=&quot;headerlink&quot; title=&quot;1.只有新项⽬才能考虑⽤DDD吗?&quot;&gt;&lt;/a&gt;1.只有新项⽬才能考虑⽤DDD吗?&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;当然不是&lt;/strong&gt;，DDD这套⽅法论不仅适合从零开始的新项⽬的建模，⽽且适 合复杂业务系统的重构。 当然如果能在新模型的建⽴的过程中就使⽤DDD作为指导，是最好不过的事情，原因在于你会省略对原 有业务系统代码逻辑的梳理和适配过程，众所周知，这不是⼀件容易的事情。&lt;/p&gt;
    
    </summary>
    
      <category term="DDD" scheme="http://wuwenliang.net/categories/DDD/"/>
    
    
      <category term="DDD" scheme="http://wuwenliang.net/tags/DDD/"/>
    
  </entry>
  
  <entry>
    <title>灵魂拷问,我理解的DDD是DDD吗?</title>
    <link href="http://wuwenliang.net/2021/04/11/%E7%81%B5%E9%AD%82%E6%8B%B7%E9%97%AE-%E6%88%91%E7%90%86%E8%A7%A3%E7%9A%84DDD%E6%98%AFDDD%E5%90%97/"/>
    <id>http://wuwenliang.net/2021/04/11/灵魂拷问-我理解的DDD是DDD吗/</id>
    <published>2021-04-11T08:58:18.000Z</published>
    <updated>2021-04-11T09:55:55.973Z</updated>
    
    <content type="html"><![CDATA[<p>DDD领域驱动设计今年真的是大火了，这是好事，表明我们的软件开发领域是一直在向前发展的。</p>
<p>但是很多的文章或者培训，都是在说DDD如何如何优秀，简单的举一些例子就行了，有些甚至是完全错误的。</p>
<p>因此笔者决定将自己的实践心得以及与他人讨论的关于DDD的问题整理为一篇文章，通过问题驱动的方式，将领域驱动设计中的一些注意点进行总结，希望能够对读者有所帮助。</p>
<p>主要的问题如下：</p>
<ul>
<li>到底什么才是统⼀语⾔，它有那么重要么？</li>
<li>领域驱动设计仅仅需要开发者参与吗？</li>
<li>领域驱动设计的那些个概念到底是在说什么？实体和值对象有啥区别？</li>
<li>DDD四层架构的好处有哪些？</li>
<li>限界上下文如何划分比较好呢？有没有工具推荐？</li>
<li>聚合粒度如何控制呢？一个聚合根就够了，为什么还要细分各种子域？</li>
<li>ACL(防腐层)应该怎么用？它的作用和优势有哪些？它在DDD分层中处于哪个位置？</li>
</ul>
<a id="more"></a>
<h2 id="到底什么才是统⼀语⾔，它有那么重要么？"><a href="#到底什么才是统⼀语⾔，它有那么重要么？" class="headerlink" title="到底什么才是统⼀语⾔，它有那么重要么？"></a>到底什么才是统⼀语⾔，它有那么重要么？</h2><p>统⼀语⾔，并不是某种具体的标记。⽽是针对不同的业务需求场景，由领域专家、开发⼈员、需求提出⽅、客户（有时候没有该⻆⾊）共同参与讨论，提炼出的领域知识的产出物。 </p>
<p>这套语⾔，可以理解为是不同⻆⾊间同步信息的媒介，⼤家都认同它的定义和含义，只要是基于这套共 识机制进⾏讨论，那么就能较为顺畅的推进需求迭代。</p>
<blockquote>
<p>实际上，统⼀语⾔在DDD中不是单独存在的，⽽是⼀个中间产物，得到它的过程伴随着领域建模的事件⻛暴过程。</p>
</blockquote>
<p>其他建模⽅式有： 名词动词法、四⾊建模法、职责驱动法、事件驱动法等，这些场景属于领域建模的<strong>战略设计部分</strong>，因此我们不在这⾥做过多的解释。</p>
<p>以事件风暴建模过程为例，举⼀个统⼀语⾔的例⼦：</p>
<blockquote>
<p>绿⾊代表 实体 </p>
<p>蓝⾊代表 ⾏为 </p>
<p>橙⾊代表 事件</p>
</blockquote>
<p><img src="/2021/04/11/灵魂拷问-我理解的DDD是DDD吗/1.png" alt="1.png"></p>
<p>图中，我们对账户信息进行了事件风暴，围绕着账户的行为进行了定义，主要有：</p>
<ul>
<li>创建账户</li>
<li>查询账户信息</li>
<li>账户充值</li>
<li>账户扣款</li>
<li>账户退款</li>
<li>账户冻结等行为</li>
</ul>
<p>这些行为本身又会触发一些事件的发送，主要有以下事件：</p>
<ul>
<li>账户已创建</li>
<li>账户已充值</li>
<li>账户已扣款</li>
<li>账户已退款</li>
<li>账户已冻结</li>
</ul>
<h2 id="领域驱动设计仅仅需要开发者参与吗？"><a href="#领域驱动设计仅仅需要开发者参与吗？" class="headerlink" title="领域驱动设计仅仅需要开发者参与吗？"></a>领域驱动设计仅仅需要开发者参与吗？</h2><p>当然不是。领域驱动设计建模过程需要多⽅参与，最后的落地主要是研发参与。</p>
<p>在建模过程中，往往需要以下⻆⾊共同作⽤：</p>
<ul>
<li>领域专家（有些时候，领域专家是产品经理，运营兼职的，甚⾄可能直接由RD同学扮演领域专家） </li>
<li>开发⼈员 </li>
<li>需求提出⽅（如：运营 产品） </li>
<li>客户（有些场景下 产品/运营扮演该⻆⾊）</li>
</ul>
<p>总的来说，领域驱动设计是⼀个团队⾏为，并⾮开发者单独参与。</p>
<h2 id="领域驱动设计的那些个概念到底是在说什么？"><a href="#领域驱动设计的那些个概念到底是在说什么？" class="headerlink" title="领域驱动设计的那些个概念到底是在说什么？"></a>领域驱动设计的那些个概念到底是在说什么？</h2><p>领域驱动设计的概念主要涉及到这些，我们可以全⾯了解，有选择性的使⽤。 实际在开发中常⽤的也就那么⼏个。</p>
<p><img src="/2021/04/11/灵魂拷问-我理解的DDD是DDD吗/2.png" alt="2.png"></p>
<p>这⾥单独说⼀下<strong>实体</strong>和<strong>值对象</strong>吧：</p>
<ul>
<li>实体有主键ID，值对象没有； </li>
<li>值对象本质上就是⼀个数据集合，⽐如说：收货地址、家庭住址就可以⽤值对象表达，只对属性进⾏归类，没有唯⼀ID； </li>
<li>⼈员信息，⽤实体表达，原因在于：我们可以对⼀个实体对象进⾏多次修改，修改后的数据和原来的数据可能会⼤不相同。但是，由于它们拥有相同的 ID，它们依然是同⼀个实体。</li>
</ul>
<h2 id="DDD四层架构的好处有哪些？"><a href="#DDD四层架构的好处有哪些？" class="headerlink" title="DDD四层架构的好处有哪些？"></a>DDD四层架构的好处有哪些？</h2><p>其实DDD四层架构的本质还是分层架构，而软件分层架构本质上还是 <strong>通过层来隔离不同的关注点</strong> （变化相似的地方），以此来解决不同需求变化的问题，使得这种变化可以被控制在一个层里。</p>
<p>因此我认为最大的好处还是分离关注点，屏蔽因下层变更导致的上层变更，使得层间松耦合。</p>
<h2 id="限界上下文如何划分比较好呢？有没有工具推荐？"><a href="#限界上下文如何划分比较好呢？有没有工具推荐？" class="headerlink" title="限界上下文如何划分比较好呢？有没有工具推荐？"></a>限界上下文如何划分比较好呢？有没有工具推荐？</h2><p>重点还是要基于战略设计中的 <strong>事件风暴</strong>，即event storming，这个过程可以多做几次。尽量不要一个人闭门造车，要带着产品，领域专家一起把这个过程做好，做透。</p>
<p>因为从本质上说，事件风暴这个事情没有好或者不好，但是要保证限界上下文的划分是产研和领域专家的共识。</p>
<p>因为每个人对一个领域的认识没有对错，只有深度和角度的不同，甚至于你在不同的时间，团队，对同一个业务，限界上下文的划分也不完全一致。所以说，衡量的标准是，团队协作过程中不同角色间是否达成了共识。</p>
<p>详细展开说，首先还是要建立统一语言，达成共识，及时调整，多做沟通。然后多去推演，发现不合理的地方随时修改。</p>
<p>退一步讲，即便因为条件所限，没有进行标准的领域风暴流程，设计者自己也可以模拟这个过程，把领域，值对象，事件，都拆分出来，平摊在一个版面上，</p>
<ul>
<li>通过分类划分不同的限界上下文；</li>
<li>在每个上下文里找到聚合根</li>
</ul>
<p>总归还是需要走一次这个过程，只不过有时候可能参与的人比较多，有时候就开发自己去做这个事情了。</p>
<p>而且，对领域驱动设计而言，它还是蛮兼容并包的，尤其是战略设计阶段，我们完全可以利用已知的工具去辅助建模，比如说强大的UML语言，使用何种工作是没有一个统一标准的，只要能够完成建模的目标，都是合理的。</p>
<p>至于最终落地的时候采用哪种架构方式，就看团队喜好了，一般还是建议用分层架构，比较容易上手。</p>
<p>实际上在我们的实践过程中发现，想要达到纯正的领域，驱动建模还是比较复杂的，就是说你总归有一些代码是胶水代码，这些胶水代码实际上我们最终还是放到了一些service里面，通过这些service然后去串联各个不同的聚合。</p>
<p>我的建议就是说建模的时候尽量采用纯领域驱动去做（尽量采用充血模型），然后在实际操作的时候还是可以使用一些传统的事务脚本式的编程方法，通过核心的领域驱动建模，加上流程化的穿插去完成建模和开发。我们这种采用的是折中后的充血模型，就是没有采用完全的充血模型，而是半充血，通过application Service将不同领域的能力归拢起来，将流程化的操作沉到domain Service，然后去调用实体本身的行为去完成业务操作。</p>
<p>这种方式在实践中证明是可行的，而且接受度高，参与开发的同学能够很快上手。</p>
<p>总结很赞，一定要结合本公司、业务、团队、产品的实际情况。</p>
<p>总之，限界上下文的划分的确是初期最重要的事情，这件事情需要参与的每个人付出非常多的思考，如果在战略设计阶段产、研、领域专家这个共识没有建立，后面的工作很容易走样。</p>
<h2 id="聚合粒度如何控制呢？一个聚合根就够了，为什么还要细分各种子域？"><a href="#聚合粒度如何控制呢？一个聚合根就够了，为什么还要细分各种子域？" class="headerlink" title="聚合粒度如何控制呢？一个聚合根就够了，为什么还要细分各种子域？"></a>聚合粒度如何控制呢？一个聚合根就够了，为什么还要细分各种子域？</h2><p>首先我们要明确的是DDD中的方案和思路是从业务领域建模出发的，而DDD最大的特点和所谓缺陷 也是领域建模。我们以下单过程中，保存一个订单为例来讨论这个问题。</p>
<p>如果建模不合理，导致出现一个较大的聚合根，那么从聚合根触发的一个save操作必然需要同时联动多个实体。</p>
<p>一般来说，为了保证聚合内实体状态一致，我们还是会采用和事务脚本编码<br>类似的本地事务，我默认你用的是Spring，当然或多或少会有性能问题，至于影响多大，我觉得我说了不算，实践是检验真理的唯一标准。</p>
<p>另一方面，如果是跨聚合的，领域事件就派上用场了。我发表一个不成熟的观点，<strong>DDD本身就是反性能的</strong>，为了高性能，聚合太充血以及聚合过于复杂，本身就是违背对性能要求的初衷。</p>
<p>所以save类操作，还是需要控制一下事务的粒度，但是根本上还是要控制聚合的粒度<br>防止出现一个上帝对象。</p>
<p>另一方面，如果是跨聚合的，领域事件就派上用场了，这时候追求的是最终一致，不太适合采用强一致的事务。</p>
<p>因此还是需要case  by case，结合具体的案例去分析，方案是有很多的。</p>
<p>甚至在非交易场景下，放弃事务也是一种方式，比如，异步持久化。失败重试，异步补偿。</p>
<p>如果交易类场景，聚合过于复杂的情况下，单机性能提升确实不明显，这是DDD的天然特性（说的难听点，这是DDD的问题）。</p>
<h2 id="ACL-防腐层-应该怎么用？它的作用和优势有哪些？它在DDD分层中处于哪个位置？"><a href="#ACL-防腐层-应该怎么用？它的作用和优势有哪些？它在DDD分层中处于哪个位置？" class="headerlink" title="ACL(防腐层)应该怎么用？它的作用和优势有哪些？它在DDD分层中处于哪个位置？"></a>ACL(防腐层)应该怎么用？它的作用和优势有哪些？它在DDD分层中处于哪个位置？</h2><p>首先我们要明确的是，对于跨领域的调用，我们要用到ACL。</p>
<p>严格的做法是，对于所有跨域的调用都必须要经过acl，去跟对方的application层进行交互，一句话就是 <strong>通过application去聚合领域的内部能力，通过acl去防腐，通过事件去进行广播，进行异步交互，通过CQRS来进行一些读服务的优化</strong>。</p>
<p>ACL具体如何使用比较优雅？</p>
<p>我们的实践是，面向接口编程。具体的做法是，将对外访问通过接口提取出一个抽象，将抽象的接口和具体的业务逻辑放在同一层，如：可以放在domainService中。</p>
<p>而ACL接口的实现类则要放在基础设施层，因为基础设施层在DDD的六边形架构中，处于南向网关的位置，而ACL本身是对外的调用，因此属于本业务领域的出口，也就是南向网关。</p>
<p>举个例子，比方说你的一个orderDomainService需要去调用你的账户account ApplicationService这些能力，那么你就需要在你的订单的域内去定义一个账户的acl接口，然后你用你的订单的域去依赖这个acl接口，但是你acl的实现要放在你的infrastructure里面去，如图所示：</p>
<p><img src="/2021/04/11/灵魂拷问-我理解的DDD是DDD吗/3.png" alt="3.png"></p>
<p>为什么这么做呢？其实它本质就体现了一种面向抽象编程的思想。也就是说 <strong>高层模块不应该依赖低层模块，二者都应该依赖其抽象</strong>。</p>
<p>也许有的读者会疑惑，对于domainService和applicationService，感觉他们没什么区别，业务逻辑写在哪儿都差不多。</p>
<p>其实原因很简单，这恰恰说明你面对的业务并不复杂，一个领域实体就是一个聚合根、然后一个领域服务就是一个应用服务，因此看起来applicationService就是domainService的委派。</p>
<p>对于复杂一些的场景，一个聚合根下需要联动超过2个子域，就需要用applicationService对多个domainService进行组合，组合的结果就是一种复合服务，说的高端一些，这样的一个applicationService就是沉淀了一组领域能力。而这样的applicationSerivce就是在对domainSerivce进行编排。</p>
<p>其实你的application层本质上是一种聚合层，它的作用是用来协调整合下面的domain层，然后基于这些domain具体的细分的原子能力进行组合，组织成复合能力并且进行一些事件的发送和通知。</p>
<p>所以我觉得叫application层，叫它聚合能力层也是可以的。我们在一些复杂业务流程中，用到了一些类似于服务编排的一些功能或者方式吧，这里编排的实际上就是application。</p>
<p>其实对于一些复杂的业务来说，你的applications其实是没有事务的，因为你的事物全部都拆分为若干小事务，下沉在各种domainService里面去了，然后你的application层是去聚合这样一个一个的小事务，完成一个复杂的事情，并且在完成了这些事情之后，发送一些事件通知来通知别的领域，或者说别的上下文中的某些词语去完成一些他们自己的工作，这种时候发送的事件就不是简单的领域内事件，而是一些跨领域的事件。</p>
<p>而领域事件本质上是一种最终一致性的事务实现机制。</p>
<p>回到问题上来，我们总结一下：</p>
<ul>
<li>凡是需要提供出去的能力都是自己的领域模型和自己的领域服务；通过application层进行领域能力的聚合和透出；</li>
<li>凡是从别人那里要来的东西，都需要经过防腐层ACL进行屏蔽和处理，以及执行实体转换等二次加工逻辑。</li>
</ul>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;DDD领域驱动设计今年真的是大火了，这是好事，表明我们的软件开发领域是一直在向前发展的。&lt;/p&gt;
&lt;p&gt;但是很多的文章或者培训，都是在说DDD如何如何优秀，简单的举一些例子就行了，有些甚至是完全错误的。&lt;/p&gt;
&lt;p&gt;因此笔者决定将自己的实践心得以及与他人讨论的关于DDD的问题整理为一篇文章，通过问题驱动的方式，将领域驱动设计中的一些注意点进行总结，希望能够对读者有所帮助。&lt;/p&gt;
&lt;p&gt;主要的问题如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;到底什么才是统⼀语⾔，它有那么重要么？&lt;/li&gt;
&lt;li&gt;领域驱动设计仅仅需要开发者参与吗？&lt;/li&gt;
&lt;li&gt;领域驱动设计的那些个概念到底是在说什么？实体和值对象有啥区别？&lt;/li&gt;
&lt;li&gt;DDD四层架构的好处有哪些？&lt;/li&gt;
&lt;li&gt;限界上下文如何划分比较好呢？有没有工具推荐？&lt;/li&gt;
&lt;li&gt;聚合粒度如何控制呢？一个聚合根就够了，为什么还要细分各种子域？&lt;/li&gt;
&lt;li&gt;ACL(防腐层)应该怎么用？它的作用和优势有哪些？它在DDD分层中处于哪个位置？&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="DDD" scheme="http://wuwenliang.net/categories/DDD/"/>
    
    
      <category term="DDD" scheme="http://wuwenliang.net/tags/DDD/"/>
    
  </entry>
  
  <entry>
    <title>一个对账框架的代码实现</title>
    <link href="http://wuwenliang.net/2021/03/06/%E4%B8%80%E4%B8%AA%E5%AF%B9%E8%B4%A6%E6%A1%86%E6%9E%B6%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"/>
    <id>http://wuwenliang.net/2021/03/06/一个对账框架的代码实现/</id>
    <published>2021-03-05T17:22:46.000Z</published>
    <updated>2021-03-05T18:41:19.431Z</updated>
    
    <content type="html"><![CDATA[<p>在笔者的公众号上发布了关于 <strong>对账</strong> 业务分析的一篇文章，<a href=""></a>, 该文也是笔者新书中的一节内容。</p>
<p>本文作为补充，我们从实战角度，从代码角度呈现一个对账框架的实现。</p>
<p>注意：本文中提供的对账框架为广义上的对账，也就是说不局限于支付、交易领域的对账场景，凡是需要通过数据比对进行数据校准、比对、核准的场景，均能够采用本文提供的思路进行实现。</p>
<a id="more"></a>
<h2 id="核心流程"><a href="#核心流程" class="headerlink" title="核心流程"></a>核心流程</h2><p>首先提供一张框架的核心流程图：</p>
<p><img src="/2021/03/06/一个对账框架的代码实现/framework.png" alt="framework.png"></p>
<p>通过该流程图可以看到，我们将获取对账基准数据、获取对账目标数据、定义平账依据、异常数据修复等功能通过接口方式提供了扩展点给用户，方便用户根据自己的业务特点进行定制化的开发，这里是对“开闭原则”的实践。</p>
<p>图中绿色部分为调用者实现的代码逻辑，橙色部分为框架自身的业务逻辑。具体的实现细节在接下来的代码实现中将会详细分析。</p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>最好的描述实际上还是代码，我们根据上文中的流程图，提供代码实现。</p>
<h3 id="卖个关子，先跑一下样例看看效果"><a href="#卖个关子，先跑一下样例看看效果" class="headerlink" title="卖个关子，先跑一下样例看看效果"></a>卖个关子，先跑一下样例看看效果</h3><p>我们先通过运行样例代码，看一下框架实际的使用效果。</p>
<p>具体的调用代码如下：</p>
<pre><code>public static void main(String[] args) {
    // 声明对账处理器
    DataCheckingDefaultProcessor processor = new DataCheckingDefaultProcessor();
    // 执行对账操作
    testHashStrategy(processor);
}

private static void testHashStrategy(DataCheckingDefaultProcessor processor) {
    // 加载Map对账监听器实现
    DataCheckingOnLoadHashListener dataCheckingOnLoadHashListener = new DataCheckingOnLoadHashListenerImpl();
    // 加载数据一致性对比监听器实现
    DataCheckingConsistenceListener dataCheckingConsistenceListener = new DataCheckingConsistenceListenerImpl();

    // 依赖注入
    processor.setDataCheckingConsistenceListener(dataCheckingConsistenceListener);
    processor.setDataCheckingOnLoadHashListener(dataCheckingOnLoadHashListener);

    // 执行对账
    processor.execute();
    // 打印结果
    System.out.println(processor.printCheckResult(&quot;测试对账&quot;));
}
</code></pre><p>具体调用方式，注释写的比较清楚了，我们直接关注一下控制台输出：</p>
<pre><code>模拟执行数据修复
[测试对账],successCount:34,failureCount:66,doubleCheckSuccessCount:0,doubleCheckFailureCount:0

Process finished with exit code 0
</code></pre><p>可见输出了对账的结果，有34个成功，66个不一致</p>
<h3 id="这么优秀的功能，是如何实现的呢？"><a href="#这么优秀的功能，是如何实现的呢？" class="headerlink" title="这么优秀的功能，是如何实现的呢？"></a>这么优秀的功能，是如何实现的呢？</h3><p>通过样例代码可以看出，用户只需要实现对基准数据、目标数据的获取，以及定义平账的依据，框架就能够自动的对基准数据和目标数据进行比对。</p>
<p>并且如果我们定义了数据修复能力，框架还能够实现对数据的修复功能。</p>
<h3 id="数据加载监听器：DataCheckingOnLoadHashListener"><a href="#数据加载监听器：DataCheckingOnLoadHashListener" class="headerlink" title="数据加载监听器：DataCheckingOnLoadHashListener"></a>数据加载监听器：DataCheckingOnLoadHashListener</h3><pre><code>public interface DataCheckingOnLoadHashListener&lt;K&gt; {

    /**
    * 加载对账数据到Map，中，如果采用hash结构对账，则实现该方法
    * Map:
    *      key:    关联id
    *      value:  BasicCheckData 基准对账实体
    * @return
    */
    Map&lt;K, BasicCheckData&gt; loadBasicData2Map();

    /**
    * 加载对账数据到Map，中，如果采用hash结构对账，则实现该方法
    * Map:
    *      key:    关联id
    *      value:  TargetCheckData 目标对账实体
    * @return
    */
    Map&lt;K, TargetCheckData&gt; loadTargeDataMap();
}
</code></pre><p>该接口用于加载对账基准数据与对账的目标数据到内容中，加载之后的数据结构为Map，key为业务唯一标识。</p>
<h3 id="数据一致性定义监听器：DataCheckingConsistenceListener"><a href="#数据一致性定义监听器：DataCheckingConsistenceListener" class="headerlink" title="数据一致性定义监听器：DataCheckingConsistenceListener"></a>数据一致性定义监听器：DataCheckingConsistenceListener</h3><pre><code>public interface DataCheckingConsistenceListener&lt;T&gt; {

    /**
    * 是否一致
    * @param basicCheckEntity
    * @param targetCheckEntity
    * @return
    */
    boolean isCheckConsistent(BasicCheckData basicCheckEntity, TargetCheckData targetCheckEntity);

    /**
    * 数据修复
    */
    void fixData();

    /**
    * 是否需要二次对账
    * @return
    */
    boolean needDoubleCheck();
}
</code></pre><p>DataCheckingConsistenceListener为数据一致性声明的监听器接口，主要方法为 <strong>isCheckConsistent</strong> ，该方法需要调用者实现，根据具体业务场景定义对账是否成功，成功返回true，不一致则返回false。</p>
<h3 id="对账核心处理器：DataCheckingDefaultProcessor"><a href="#对账核心处理器：DataCheckingDefaultProcessor" class="headerlink" title="对账核心处理器：DataCheckingDefaultProcessor"></a>对账核心处理器：DataCheckingDefaultProcessor</h3><p>DataCheckingDefaultProcessor为对账的核心处理器。</p>
<pre><code>public DataCheckingDefaultProcessor(DataCheckingOnLoadHashListener dataCheckingOnLoadHashListener,
                                    DataCheckingConsistenceListener dataCheckingConsistenceListener) {
    Preconditions.checkNotNull(dataCheckingOnLoadHashListener);
    Preconditions.checkNotNull(dataCheckingConsistenceListener);
    this.dataCheckingOnLoadHashListener = dataCheckingOnLoadHashListener;
    this.dataCheckingConsistenceListener = dataCheckingConsistenceListener;
}
</code></pre><p>首先是DataCheckingDefaultProcessor的构造方法，它接收DataCheckingOnLoadHashListener和DataCheckingConsistenceListener的实例。</p>
<p>调用者通过实现接口，并将接口的实现通过该构造方法注入到DataCheckingDefaultProcessor之中。</p>
<pre><code>/**
 * 执行对账
 */
public void execute() {
    check();
}

/**
 * 执行对账
 */
private void check() {
    // 对账前数据准备
    Map&lt;String, BasicCheckData&gt; basicCheckDataMap = dataCheckingOnLoadHashListener.loadBasicData2Map();
    Map&lt;String, TargetCheckData&gt; targetCheckDataMap = dataCheckingOnLoadHashListener.loadTargeDataMap();
    Preconditions.checkNotNull(basicCheckDataMap);
    Preconditions.checkNotNull(targetCheckDataMap);

    // 执行对账
    handleCheckByHashStrategy(basicCheckDataMap, targetCheckDataMap, successCount, failureCount);

    // 需要二次校验则二次校验
    if (dataCheckingConsistenceListener.needDoubleCheck()) {
        handleCheckByHashStrategy(basicCheckDataMap, targetCheckDataMap, doubleCheckSuccessCount, doubleCheckFailureCount);
    }

    // 数据修复
    dataCheckingConsistenceListener.fixData();
}
</code></pre><p>check()方法为核心的对账逻辑。</p>
<ol>
<li>首先通过DataCheckingOnLoadHashListener加载调用者回传的对账基准Map，以及对账目标Map；两个Map的key均为业务唯一标识；</li>
<li>接着通过 <strong>handleCheckByHashStrategy</strong> 执行对账操作，对两个Map进行比对；</li>
<li>如果调用方允许二次校验，则再次执行一次对账操作；</li>
<li>执行业务方实现的数据修复接口，根据业务方的数据修复逻辑进行数据修复。这里实际上是需要通过一个上下文对象将待修复的数据回传给框架，暂时未实现，就留给读者自行实现吧。（<strong>提示：</strong> 通过定义一个上下文对象，通过fixData方法入参传递给调用者）</li>
</ol>
<h4 id="handleCheckByHashStrategy对账核心逻辑"><a href="#handleCheckByHashStrategy对账核心逻辑" class="headerlink" title="handleCheckByHashStrategy对账核心逻辑"></a>handleCheckByHashStrategy对账核心逻辑</h4><p>我们重点关注一下handleCheckByHashStrategy对账核心逻辑：</p>
<pre><code>/**
 * hash结构对账逻辑
 * @param basicCheckDataMap
 * @param targetCheckDataMap
 * @param successCount
 * @param failureCount
 */
private void handleCheckByHashStrategy(Map&lt;String, BasicCheckData&gt; basicCheckDataMap,
                                       Map&lt;String, TargetCheckData&gt; targetCheckDataMap,
                                       AtomicLong successCount,
                                       AtomicLong failureCount) {
    for (Map.Entry&lt;String, BasicCheckData&gt; checkEntry : basicCheckDataMap.entrySet()) {
        String checkEntryKey = checkEntry.getKey();

        BasicCheckData basicCheckData = checkEntry.getValue();
        if (basicCheckData == null) {
            failureCount.incrementAndGet();
            continue;
        }

        TargetCheckData targetCheckData = targetCheckDataMap.get(checkEntryKey);
        if (targetCheckData == null) {
            failureCount.incrementAndGet();
            continue;
        }

        // 校验checkEntryKey是否与对账实体的id一致
        String basicCheckBizId = basicCheckData.getCheckBizId();
        String targetCheckBizId = targetCheckData.getCheckBizId();
        if (!isCheckBizIdEqual(checkEntryKey, basicCheckBizId, targetCheckBizId)) {
            throw new DataCheckRuntimeException(&quot;checkEntryKey must equals basicCheckBizId and checkEntryKey must equals targetCheckBizId!&quot;);
        }

        // 执行对账
        if (!dataCheckingConsistenceListener.isCheckConsistent(basicCheckData, targetCheckData)) {
            failureCount.incrementAndGet();
            continue;
        }

        successCount.incrementAndGet();
    }
}
</code></pre><p>通过逻辑，我们能够清楚的看到，对账核心逻辑实际上是通过对基准对账Map进行迭代，去key（对账唯一依据）所在的目标对账Map查找对应的目标对账实体，并将基准对账实体与目标对账实体进行比对。</p>
<p>比对的核心逻辑为用户实现的 <strong>DataCheckingConsistenceListener.isCheckConsistent</strong> 方法，框架根据用户返回的数据是否一致的标识，决定是对账成功或者失败，并进行相关数据的统计。</p>
<h3 id="为什么这样设计"><a href="#为什么这样设计" class="headerlink" title="为什么这样设计?"></a>为什么这样设计?</h3><p>实际上，我在开发这个对账框架的时候，是参考了RocketMQ中的某些思想。</p>
<p>RocketMQ在进行消息消费时，允许用户通过实现消费监听器接口，来完成不同种类的消费逻辑，比如说通过实现MessageListenerConcurrently接口，实现并发消息消费。</p>
<p>我开发的对账框架中，也通过定义监听器接口，让用户自定义数据加载、数据比对的具体逻辑，将业务相关的逻辑交给用户，框架本身只关注不变的东西。</p>
<p>这里实际上就是一种依赖倒置思想的集中体现，即：</p>
<blockquote>
<p>1、上层模块不应该依赖底层模块，它们都应该依赖于抽象。</p>
<p>2、抽象不应该依赖于细节，细节应该依赖于抽象。</p>
</blockquote>
<p>框架通过依赖抽象，做到了对用户具体逻辑的灵活适配。对框架而言，通过依赖抽象，提高了扩展性，完全不需要耦合具体的实现；对使用者而言，只需要实现框架提供的回调方法，不需要关注框架是如何对自己编写的业务代码进行调用的，这实际上就是依赖倒置带来的优越性。做到了对扩展开放。</p>
<p>实际上，回调接口/方法就是一种介于框架和使用者之间的协议，只要遵从该协议进行开发，就能够达到完成业务逻辑的目的。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文中，我们通过编写一个简单的对账框架，实现了广义对账场景。</p>
<p>同时通过对代码进行分析，也体会到了面向对象设计原则带来的好处，希望本文能够对你有所帮助，更多精彩的内容敬请持续关注我，也欢迎你关注公众号“分布式朝闻道”，与我一同感受代码之美，技术之貌。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在笔者的公众号上发布了关于 &lt;strong&gt;对账&lt;/strong&gt; 业务分析的一篇文章，&lt;a href=&quot;&quot;&gt;&lt;/a&gt;, 该文也是笔者新书中的一节内容。&lt;/p&gt;
&lt;p&gt;本文作为补充，我们从实战角度，从代码角度呈现一个对账框架的实现。&lt;/p&gt;
&lt;p&gt;注意：本文中提供的对账框架为广义上的对账，也就是说不局限于支付、交易领域的对账场景，凡是需要通过数据比对进行数据校准、比对、核准的场景，均能够采用本文提供的思路进行实现。&lt;/p&gt;
    
    </summary>
    
      <category term="专题-分布式" scheme="http://wuwenliang.net/categories/%E4%B8%93%E9%A2%98-%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="专题-分布式" scheme="http://wuwenliang.net/tags/%E4%B8%93%E9%A2%98-%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>聊聊异构交易场景交互流程及一致性保证</title>
    <link href="http://wuwenliang.net/2021/02/04/%E8%81%8A%E8%81%8A%E5%BC%82%E6%9E%84%E4%BA%A4%E6%98%93%E5%9C%BA%E6%99%AF%E4%BA%A4%E4%BA%92%E6%B5%81%E7%A8%8B%E5%8F%8A%E4%B8%80%E8%87%B4%E6%80%A7%E4%BF%9D%E8%AF%81/"/>
    <id>http://wuwenliang.net/2021/02/04/聊聊异构交易场景交互流程及一致性保证/</id>
    <published>2021-02-04T15:45:13.000Z</published>
    <updated>2021-02-04T15:46:01.921Z</updated>
    
    <content type="html"><![CDATA[<p>事情的经过是这样的，群友四哥发来一个问题，问大家有什么看法，我看了下，刚好之前接触过类似的业务场景，因此斗胆就问题谈谈自己的看法，抛砖引玉。</p>
<p>问题如下：</p>
<blockquote>
<p>A系统联机同步调用B系统（A和B不是同一公司系统，不能用分布式事务），</p>
<p>如何保证系统间数据准实时一致性（聊聊设计思路即可）？</p>
<p>提醒：需要考虑调用超时、并发、幂等、反交易先到等。</p>
<p>各种异常场景怎么处理要考虑更完善些，如事务隔离、并发、反交易先到调用方和服务方约定（前端客户不可能一直等着）</p>
</blockquote>
<a id="more"></a>
<p>这种聊思路的问题，往往问的都很大，或者说比较唬人，实际上遇到这种问题，我们要做的就是抽象。</p>
<p>抽象出场景，抽象出问题的核心要点。</p>
<p>我们能够提炼出要点，非同一公司系统（跨网络，异构）、反交易先到（我们基本能确定提问者大概想知道的思路与交易有关）、服务方预定，前端客户不可能一直等待（交易流程往往是长事务流程，不能简单依靠单个接口调用，基本上是异步流程）。</p>
<p>有了这些前提，我们就可以基本抽象出讨论的背景和模型：</p>
<h2 id="模型与背景提炼"><a href="#模型与背景提炼" class="headerlink" title="模型与背景提炼"></a>模型与背景提炼</h2><p>因为前提是A、B系统分属不同的公司，也就是说A B系统是通过公网进行交互的两套异构系统，极有可能实现的技术栈也各不相同，因此互相之间只能通过暴露在外的接口进行交互，我们就认为是通过http接口进行的交互。</p>
<p>由于是A系统调用B系统，因此我们可以抽象为点对点的消息通信场景，其中A为主动拉取方，B为被拉取方。</p>
<p>问题提到说，我们说不能用分布式事务，其实是在说不能使用强一致/类2PC的事务实现，如2PC、3PC、SEATA等，但是可以利用诸如最大努力通知的柔性方式进行数据的同步。</p>
<p>关于最大努力通知方案，笔者之前的一篇文章已经有过详细的讨论</p>
<p>图</p>
<p>有了方案，我们接着抽象出 <strong>交易单</strong> 这个模型，并为其指定状态机：</p>
<ul>
<li>交易单创建时，状态为 <strong>初始化</strong>，</li>
<li>A系统向B系统发送交易单时改为， <strong>处理中</strong></li>
<li>如果B系统同步响应收单失败，则A系统修改状态为 <strong>失败</strong></li>
<li>同步B系统同步响应收单成功，则A系统修改状态为 <strong>已提单</strong></li>
<li>当B系统处理交易完成，通知A系统交易完成，则A系统修改交易单状态为 <strong>成功</strong>，（此处的成功为真实成功，因为已经发生了资金扣除/积分等标的物的消耗）</li>
<li>当B系统处理交易失败，则通知A系统交易失败，则A系统修改交易单状态为 <strong>失败</strong> （此时的失败假定为B系统在扣钱之前就失败）</li>
</ul>
<h1 id="超时处理方式"><a href="#超时处理方式" class="headerlink" title="超时处理方式"></a>超时处理方式</h1><p>我们讨论一下提单请求发生超时应当如何处理。</p>
<p>A系统的出口网关向B系统的入口网关发起提单请求，这是一个同步通信，对于同步请求的失败（如：签名失败，参数异常失败等），A系统可以发起重试，此时这种请求属于真实的失败，因为压根没有发起交易行为，所以原则上数据是一致的，对于资金而言就是没有发生扣减等行为。</p>
<h2 id="掉单查询"><a href="#掉单查询" class="headerlink" title="掉单查询"></a>掉单查询</h2><p>如果A系统提交提单请求超时，此时未能收到B系统回复的同步 <strong>收单成功</strong> 的响应，则这时候就存在数据不一致的情况。这个场景就是所谓的 <strong>掉单</strong>，则A系统需要对掉单的数据（状态为处理中）发起掉单查询操作，思路就是定时发起查询，获取B系统对交易单的处理情况。</p>
<p>一般而言B系统都会通知A系统发起掉单查询的建议时间，如发起交易单10分钟后即可有处理的确定结果，那么A系统就可以对已提交10分钟以上，状态为 <strong>处理中</strong> 的交易单发起掉单查询。也就是说，10分钟后，这类中间态的数据，AB系统间可以达成一致。</p>
<p>特别的，如果一次掉单查询没能查到确定的结果，则可以设置下一次继续查询，这里推荐采用 <strong>时间衰减策略</strong> 进行查询，这是交易场景乃至中间件中常用的一种未知数据定时同步的通用思路。</p>
<p>图</p>
<h2 id="结果通知"><a href="#结果通知" class="headerlink" title="结果通知"></a>结果通知</h2><p>对于交易场景，处于对数据实时性的考虑，我们常常希望下游系统处理完数据之后能够及时通知我们结果。</p>
<p>在这个场景中就是A系统需要对接B系统的 <strong>交易结果实时通知接口</strong>，当交易单被B系统处理完成之后，B系统会对交易单处理结果发起通知，及时回调A系统处理的结果。此时，A系统成为被调用方，B系统为调用方，相比于掉单查询，结果通知几乎是准实时的，从B系统发起通知到A系统接收到通知往往都在百毫秒级别（支付宝支付结果通知能够达到数十毫秒）。</p>
<p>简单总结下，对于超时的处理，我们就是通过掉单查询和实时通知方式，通过主动轮询处理结果与被动接受结果通知的方式，通过推拉结合的方式共同保证AB系统之间的数据达成最终一致。</p>
<h2 id="并发提单"><a href="#并发提单" class="headerlink" title="并发提单"></a>并发提单</h2><p>对于并发提单而言，其实属于老生常谈类的话题。其本质在于分布式场景下请求的防重放处理思路。</p>
<p>核心就在于请求串行化，我们往往通过CAS、加锁等方式进行处理。</p>
<p>具体到具体的实现细节，CAS方式有数据库状态标识（状态机）、加锁方式其实就是分布式锁，简单的说就是通过分布式锁方式进行处理，通过对一笔交易单加分布式锁，获取分布式锁成功的请求才能发起请求，发起请求后写入幂等记录，完成请求后释放锁，防止并发提交。</p>
<h2 id="幂等思路"><a href="#幂等思路" class="headerlink" title="幂等思路"></a>幂等思路</h2><p>关于幂等，展开说可以单独写一篇文章，那么择日不如状态，我们下一篇文章就聊聊幂等处理的那些常用姿势。</p>
<p>这里为了解答问题，我们说说主要思路，对于细节就不展开了，懂的同学们应该能够很快的心领神会，不懂的也没关系，我们下篇文章就会对幂等进行详细的展开。</p>
<p>对于幂等而言，我们通常需要通过幂等校验来进行，比如：</p>
<ul>
<li>高并发场景下，将幂等标识写入Redis缓存，用于对写请求幂等</li>
<li>或者请求如果量不大，则通过数据库唯一约束进行幂等处理，保证只有一笔交易单落库（如唯一约束 订单号），唯一约束是最后一道防线，用于对写请求幂等</li>
<li>低并发场景下，通过先查询，后插入（更新）的方式也可以进行幂等校验，但是高并发场景下会有重复更新/新增的风险，因此往往需要配合分布式锁共同作用，将并发请求串行化</li>
</ul>
<p>单单就幂等来说，查询天然幂等，更新则可以通过上面的方式进行幂等保证。具体的细节我们后续文章专门讲解。</p>
<h2 id="反交易先到"><a href="#反交易先到" class="headerlink" title="反交易先到"></a>反交易先到</h2><p>首先明确何为“反交易”，反交易，顾名思义，反向交易，我们举个例子就好懂了。</p>
<p>比如说，扣款的反交易，就是冲正（比如说，转账操作，扣除A的钱，给B加钱失败。则A扣除的钱需要补回，这个过程就是冲正。实际的冲正涵盖的范围更广，我们只需要简单认为是扣款的反向操作，但是要区别于提现和充值。）</p>
<p>比如说，A系统请求对交易单支付100元，B系统扣款成功后向A系统返回支付成功的通知消息；此时B系统后续操作故障，导致该交易无法继续进行下去，则B系统对A系统扣除的100元执行了冲正之后，通知A系统交易已冲正退单。</p>
<p>所谓反交易先到，就是说网络发生拥塞，导致冲正退单的消息，先于支付成功的消息先到了。</p>
<p>我们的A系统的交易单不是有状态机么，状态机就是处理反交易先到的利器。</p>
<p>我们要求对于交易的处理是串行的，如何串行，其实简单的说，通过状态机就能很好地实现。</p>
<p>当然要说明的一点是，对于实际情况，需要具体业务具体分析，对于我们当前讨论的场景而言，我们通过状态机能够解决问题，具体过程如下，</p>
<p>我们假定，A系统的交易单的状态机只能按照  处理中-&gt;支付成功-&gt;退单 这个流程进行流转，当退单先于支付成功到达时，我们需要在一个事务中同时完成流水的插入，交易单状态的更新。对于更新操作而言，我们的sql期望如下</p>
<blockquote>
<p>update order set order_status=退单 where order_status=支付成功 and order_id=xxxxx</p>
</blockquote>
<p>由于状态机只允许固定的订单状态迁移，我们在更新状态的时候带上老状态，实际上当前的order_status=处理中，因此update失败。最终处理为通知处理失败，A系统告知B系统对该通知进行重发。那么B系统就只能老老实实的重新发起通知，这也是一个合格的交易系统所必须具备的能力。否则你的系统不支持通知重复发起，用户体验也太差了。</p>
<p>此时由于状态机的原因，交易单状态还是处理中，当被拥塞的支付成功的通知到达，交易单状态成功更新为 <strong>支付成功</strong> 此时执行的update语句为</p>
<blockquote>
<p>update order set order_status=支付成功 where order_status=处理中 and order_id=xxxxx</p>
</blockquote>
<p>后续重试的 退单通知（所谓的反交易）到达后，交易单根据状态机便能够成功进行流转，具体的update语句如下：</p>
<blockquote>
<p>update order set order_status=退单 where order_status=支付成功 and order_id=xxxxx</p>
</blockquote>
<p>从我们的分析看出，只要有状态机存在，无论如何，交易单的状态只能按照 <strong>处理中-&gt;支付成功-&gt;退单</strong>   这个方式流转而不会发生状态的跃迁跳跃。</p>
<p>所以我们说，状态机，就是系统间处理反交易先到的利器，状态机也是交易类系统通用的神兵利器。</p>
<h2 id="前端用户不能一直等待处理思路"><a href="#前端用户不能一直等待处理思路" class="headerlink" title="前端用户不能一直等待处理思路"></a>前端用户不能一直等待处理思路</h2><p>还有一点就是前端客户不可能一直等着，实际上在上述的过程中我们已经解答了这个问题。</p>
<p>我们本次分析问题采用整体的方案是基于最大努力通知的思路，核心的步骤就是 <strong>同步提单</strong>，<strong>掉单查询</strong>，<strong>结果通知</strong>。通过对这几个步骤进行结合，我们就能够避免前端一直等待，因为交易属于一个长事务业务，上游/前端只需要提交成功就可以去干别的事情了，剩下的复杂操作让下游系统慢慢处理，这其实就是体现了异步的思维。</p>
<h2 id="通过对账保障数据一致性"><a href="#通过对账保障数据一致性" class="headerlink" title="通过对账保障数据一致性"></a>通过对账保障数据一致性</h2><p>最后还要提一下，对于交易系统而言，数据一致性保证的兜底方案就是对账机制，关于对账，我在近期也会单独写一篇文章进行详细讨论（又一个flag）。</p>
<p>交易系统通常具备t+1的对账，简单的说就是，<strong>每天生成前一天的对账单</strong>，在我们的这个场景中，A系统每天都向B系统请求自己前一天的交易对账单，下载到本地，通过A系统自己的渠道流水号/交易单号，与B系统提供的交易单进行逐条的对账，这个过程往往能够通过定时任务来自动化的执行，把不一致的交易单对平。从而将两个系统之间的数据达成最终一致，比如说，A系统没收到B系统的通知，掉单查询也没有查到的交易单，往往最终通过对账都能够获取到数据的最终状态。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文，我们针对一个问题，给出了交易场景中常见的数据一致性的保障思路，并通过场景提炼，介绍了交易类场景设计过程中需要注意的思路，希望能够对读者朋友们有所帮助。如果有想法或者建议，欢迎进群讨论，笔者建立该微信群用于与读者朋友交流，只要是技术类的问题，都欢迎进群讨论，技术之路，感谢有你。</p>
<pre><code>3
</code></pre><p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;事情的经过是这样的，群友四哥发来一个问题，问大家有什么看法，我看了下，刚好之前接触过类似的业务场景，因此斗胆就问题谈谈自己的看法，抛砖引玉。&lt;/p&gt;
&lt;p&gt;问题如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A系统联机同步调用B系统（A和B不是同一公司系统，不能用分布式事务），&lt;/p&gt;
&lt;p&gt;如何保证系统间数据准实时一致性（聊聊设计思路即可）？&lt;/p&gt;
&lt;p&gt;提醒：需要考虑调用超时、并发、幂等、反交易先到等。&lt;/p&gt;
&lt;p&gt;各种异常场景怎么处理要考虑更完善些，如事务隔离、并发、反交易先到调用方和服务方约定（前端客户不可能一直等着）&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="专题-分布式" scheme="http://wuwenliang.net/categories/%E4%B8%93%E9%A2%98-%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="专题-分布式" scheme="http://wuwenliang.net/tags/%E4%B8%93%E9%A2%98-%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>软素质: 如何快速熟悉业务逻辑并付诸落地？</title>
    <link href="http://wuwenliang.net/2021/01/30/%E8%BD%AF%E7%B4%A0%E8%B4%A8-%E5%A6%82%E4%BD%95%E5%BF%AB%E9%80%9F%E7%86%9F%E6%82%89%E4%B8%9A%E5%8A%A1%E9%80%BB%E8%BE%91%E5%B9%B6%E4%BB%98%E8%AF%B8%E8%90%BD%E5%9C%B0%EF%BC%9F/"/>
    <id>http://wuwenliang.net/2021/01/30/软素质-如何快速熟悉业务逻辑并付诸落地？/</id>
    <published>2021-01-30T13:52:43.000Z</published>
    <updated>2021-01-30T13:56:03.018Z</updated>
    
    <content type="html"><![CDATA[<p>本次我们不分享技术，我们来聊聊软素质，具体点说，我们来聊聊新人程序员如何快速熟悉业务逻辑并付诸落地。</p>
<p>一个新人程序员，经历了面试的层层磨炼，终于尘埃落定入职心仪的公司。初来乍到，对周围的一切都不熟悉，业务不熟悉，同事也不熟悉。</p>
<p>这其中关系最大的就是对业务和代码的熟悉，如果能够掌握快速熟悉业务逻辑的方法，就能够很快进入到工作角色中，从容不迫的开展新的工作。</p>
<p>那么我们本次分享就从这几个方面展开：</p>
<ul>
<li>如何通过读代码建立对系统的全局观，cover链路上下游</li>
<li>如何画图来辅助自己熟悉业务流程</li>
<li>应当如何学习掌握领域知识</li>
<li>对于方案设计有哪些技巧和注意点</li>
<li>问题排查的大概思路</li>
</ul>
<p>PS： 由于大部分的开发者都是面向业务，因此本次讨论对于中间件类的开发不做进一步展开，后面有机会再分享。</p>
<a id="more"></a>
<h2 id="如何通过读代码建立对系统的全局观，cover链路上下游"><a href="#如何通过读代码建立对系统的全局观，cover链路上下游" class="headerlink" title="如何通过读代码建立对系统的全局观，cover链路上下游"></a>如何通过读代码建立对系统的全局观，cover链路上下游</h2><p>不可否认的是读代码本身不是一件轻松的事情，这意味着我们需要强迫自己站在写代码人的角度去揣摩他当初的想法和意图。<br>而这恰恰就是问题的矛盾点：一段代码质量的高低和当事人当初的心境、所处的环境、经验的高低，甚至和当事人的性格都是息息相关的。</p>
<p>这就造成了即便是同样一个需求，由不同年龄、不同背景、不同工作经验的人来写，最终的效果也是风格各异。</p>
<p>但是基本上每个人都有一套自己对于好代码的评判标准，这里不细说。重点还是要站在代码角度去思考业务。</p>
<p>既然代码不得不去读，那么我们首先要明确的是，<strong>读代码的目的是什么</strong>。</p>
<p>私以为看代码的主要目的是，通过读代码，从代码中梳理上下游之间如何进行交互，以及内部业务逻辑是如何处理以达到某种具体的目的。</p>
<p>读代码基本上都有目的，明确从何处开始读以及怎样读很重要。</p>
<p>如果拿到需求就直接冲到代码细节中去，这往往都得不偿失，其实最好先了解下背景。比如说看一下公司内部有没有成熟的文档，这能够让我们对当前的所做的业务有一个全局的认识；尤其是当文档中还画了系统的架构图、主要业务逻辑的流程图，那简直就是雪中送炭，乐不可支了。即便随着时间推移，项目迭代，有些设计已经发生了变化，但是他也能为加深你对系统的理解起到重要作用。如果运气不好，没有图，也没有文档，那就只好自己去摸索梳理了。</p>
<p>那么如何对新业务新系统进行摸索梳理呢，这里主要指出两个大方向，一个就是通过系统的读代码建立认知，一个就是通过查问题/做需求的方式来逐步对系统进行由点到面的认识。</p>
<p>代码如何去读也是一门学问。</p>
<p>如果乱读一气，抓不住重点，往往使自己陷入焦急的心境之中。我认为比较好的方式是 <strong>带着问题去看。</strong></p>
<p>公司级的项目都是有模块划分的，先明确自己想看哪个模块的代码，如果不知道，一是看文档，文档没有就问一下周围的同学，向他们请教这个模块大概的作用，基本上态度诚恳谦逊，大家都会乐于帮你的。如果所在的团队有着成熟的命名规范，其实通过项目/模块的名称基本上也能大概猜个八九不离十。</p>
<p>确定了模块的大概职责之后，就去寻找代码的入口，从入口开始看起，层层往下，自顶向下的去读去梳理。</p>
<blockquote>
<p>如何发现入口？</p>
</blockquote>
<p>这里我举几个常见的代码入口的例子：</p>
<ul>
<li>RPC 接口</li>
<li>Http接口 </li>
<li>消息生产、消费  </li>
</ul>
<p>对于业务而言，主要有以上的三种方式，其余的方式注入：线程池任务提交、binlog数据同步等相对比较小众，而且都具有显著的特征，很容易找到入口，就不再赘述。</p>
<p>举个例子，比方说，我们找到一个名为auth的包，那么就可以大概的猜想，它应该是用户认证相关的业务逻辑，那么就从这个包入手开始梳理。</p>
<p>梳理的主要目的为明确该模块提供了哪些能力。</p>
<p><strong>从一个方法开始</strong>-&gt;<strong>每个方法执行了哪些内部的业务处理/计算</strong>-&gt;<strong>调用了哪些外部接口</strong>-&gt;<strong>与哪些基础设施进行了交互</strong>（数据持久化了哪些表，写了哪些缓存，发了哪些消息都值得记下来）。边梳理边画个图留作一个重构的依据或者以后反复看的一个依据。</p>
<p>这个过程中最好边梳理边整理文档，必要的时候可以画图，比如使用 <strong>visio、processon</strong> 等工具。</p>
<p>一般而言，同一个包/Class中的方法都是一类能力的聚合，因此我们可以分业务场景、业务能力去看，这样一直梳理下去，基本上就能够对这个项目/模块对外提供的能力有一个系统的认知。</p>
<p>这种地毯式读代码的方式往往需要花费较多的时间和精力，如果没有耐心，很可能坚持不下去。</p>
<blockquote>
<p>那么有没有一种方法，能够让自己快速了解系统的坑点，锻炼自己的排错能力呢？</p>
</blockquote>
<p>当然有，那就是查问题。</p>
<p>基本上对于新人，往往不会直接让你做流程复杂的需求，我们团队的实践是，新人可以去查问题，通过查问题反向跟踪代码逻辑，发现问题修复问题。</p>
<p>如果出现了线上问题，通过查看日志、分析告警、监控，定位异常点，最后定位到业务逻辑有异常，通过异常堆栈反向查找代码，确定问题出现的原因，带着问题去看代码，印象是很深刻的。相信聪明的读者也有类似的体会吧。</p>
<p>这里要多说一句，如果是较为严重的错误或者异常，可以和老员工一起排查，发现问题之后最好是赶紧定位问题，不要发散，不要急着总结。先解决问题，等问题解决以后再复盘整理。</p>
<h3 id="对于复杂业务场景，应该如何整理业务逻辑呢？"><a href="#对于复杂业务场景，应该如何整理业务逻辑呢？" class="headerlink" title="对于复杂业务场景，应该如何整理业务逻辑呢？"></a>对于复杂业务场景，应该如何整理业务逻辑呢？</h3><p>太极有阴阳，业务也有复杂与简单。</p>
<p>对于复杂的业务，比如支付、广告、银行等系统，我们应该如何整理业务逻辑呢？</p>
<p>首先要明确的是，这个过程不会是三两天，而是需要在迭代业务需求的过程中不断思考整理总结，时间短则一两年，长则三五年，甚至五年以上。</p>
<p>对于新人而言，初次接触复杂业务，如果有条件就多参与业务组的代码走读与串讲分享，如果条件不具备，就找和同组的同学吃个饭聊聊天，对业务的背景大致有个了解，这样心里会有些底气。</p>
<p>有句玩笑话是这么说的，业务不在文档里，都在老鸟的脑子里。其实不无道理，熟能生巧嘛。</p>
<p>具体到如何进行逻辑的梳理和走读，我们可以先执行问题分类，对大流程主干的梗概进行罗列，需要明确上下游与本模块有哪些交互，最好落地到一个文档。我始终认为并且付诸实践的就是，好记性不如烂笔头，多做笔记多总结是普通人的良药。</p>
<blockquote>
<p>对于一个复杂的需求，如何梳理？</p>
</blockquote>
<p>我觉得，细节很重要。</p>
<ul>
<li>根据PM业务的需求点着手，去思考背后的问题，权衡一下成本，ROI，找一个比较折中经济适用的设计方法，避免过度设计。</li>
<li>对设计方案进行斟酌取舍，不断在大脑中推演；这是笔者的一个优秀的同事给笔者的建议，他说，当你对一个业务比较了解的时候，就可以自己去推演。基本上能够提前推出哪里有问题和风险，并且能够有充足的时间和PM对接，对需求点进行完善。</li>
<li>邀请同组的同学对自己的方案进行check，不识庐山真面目，只缘身在此山中。有些问题，旁观者看的更清楚。</li>
<li>对于需要进行check的点，需要反复check，如上线计划，急停手段；带着主人翁意识去做事，面向失败设计。</li>
</ul>
<h2 id="如何画图来辅助自己熟悉业务流程"><a href="#如何画图来辅助自己熟悉业务流程" class="headerlink" title="如何画图来辅助自己熟悉业务流程"></a>如何画图来辅助自己熟悉业务流程</h2><p>在上文中，我们提到读代码的过程中往往伴随着画图，那么我们应当如何画图来辅助自己熟悉业务流程？</p>
<p>首先我们应当选择一款适合自己的画图工具，比如visio、processon、亿图图示工具等。</p>
<p>有了工具之后，我们需要了解常用的图例，系统学习UML，对主要的几种图形有所了解，比如泳道图、用例图、流程图、ER图。</p>
<p>画图不在于形式，而在于突出思路和重点，画图的过程中，尽量使图形有层次感，想清楚图是给谁看的，先保证内容契合思路、业务，再进行优化与进一步美化。</p>
<h2 id="应当如何学习掌握领域知识"><a href="#应当如何学习掌握领域知识" class="headerlink" title="应当如何学习掌握领域知识"></a>应当如何学习掌握领域知识</h2><p>我们常说，技术是为业务服务的，技术为业务赋能，而业务又促进了技术的演进和发展。</p>
<p>这里的业务往深了说，其实就是所谓的领域，每个领域都有自身领域的知识，用时髦的说法就是所谓的“统一语言”。</p>
<p>我们说，要有深度和广度，单论广度，就是要学习本行业的领域知识，完善自己的对业务体系的认知。</p>
<p>我们对常见的一些领域进行举例：比如说电商中的订单、 物流、支付、销运、清结算、风控、广告等，都是一个一个的业务领域。每个领域都有自己领域内的统一语言。</p>
<p>我们需要对领域内的统一语言、通用名词进行学习和掌握，这样既能够方便与他人的沟通，还能促使我们用专业的语言描述业务，进而促进代码编写的准确性。</p>
<p>这里我简单介绍几种学习业务领域知识的方法：</p>
<ol>
<li>看书，看书是学习领域知识的一个通用方法。随着互联网的发展，业界已经有很多先驱对自己熟悉的领域进行了梳理和总结，我们如果能够进行学习，就站在了巨人的肩膀上，免去了自己进行探索所花费的时间。比如说，广告行业，基本不错的书籍如《程序化广告》、 《计算广告》、 《信息流广告》，电商领域的《电商产品经理》等书籍都是不错的学习资料；</li>
<li>和别人交流，进入新的工作环境，周围的同事都是老师。带着自己的思考和问题，友好的与同事讨论，沟通，请教，也是提高自己业务领域知识了解的一种方式，大部分情况下，有经验的同事会给出一个学习的方向，这是很宝贵的资源。</li>
<li>多看文档，成熟的企业内部往往都有文档的沉淀。找到这些资料并加以学习，对于自己的提高是相当显著的。如果恰巧你的公司就有这样的条件，那么千万不要忽略。</li>
</ol>
<p>对于新人来讲，对一个新的业务领域建立了一个初步的认知之后，基本上能够应对简单的需求开发任务了。否则连需求都理解不了，那还谈何开展工作呢？</p>
<p>这里我还要多说两句，除了掌握业务领域知识外，最好去了解学习一些 <strong>领域驱动设计</strong> 的思想和概念，不断促使自己站在系统整体的思想高度去思考设计自己的系统。毫不夸张的说，“领域驱动设计”是开发者能力突破的秘诀之一。</p>
<h2 id="对于方案设计有哪些技巧和注意点"><a href="#对于方案设计有哪些技巧和注意点" class="headerlink" title="对于方案设计有哪些技巧和注意点"></a>对于方案设计有哪些技巧和注意点</h2><p>这一部分，我们了解一下一个需求的方案设计要注意哪些点。</p>
<p>这部分内容是从笔者的工作中抽象总结出来的，去除了工作特征明显的点，提炼出了共性的注意点。基本上需求的快速迭代需要注意的点都包含进去了：</p>
<p>方案设计我们主要从以下几个点进行说明：</p>
<ul>
<li>需求背景与目标：交代一下这个需求要解决什么问题，达到怎样的目的。这部分内容一般都是PM直接提供的；</li>
<li>概要设计：为了满足产品需求，我们主要需要从哪些地方进行设计，主要有哪些功能点，这里尽量提供一个全流程的泳道图；</li>
<li>详细设计：对概要设计中提到的功能点进行细化，针对每个功能点，给出流程图；不一定非得细化到伪代码级别，但是关键的条件判断和分支都需要体现，能够促使我们提前对逻辑进行深入的思考，也能提升编码效率；</li>
<li>数据结构：重要的领域模型是如何进行建模的，类如何设计，在这部分展示。一般需要提供类图/ER图；</li>
<li>接口设计：如果需要对外提供接口，那么我们就需要提供对外的接口文档，作为对外交互的依据；</li>
<li>配置设计：配置设计主要是针对关键逻辑的降级开关和某些业务阈值，如果线上确实出现问题需要紧急降级，那么我们就可以在文档中快速获取到开关配置，短时间内通过配置急停开关对问题逻辑进行快速下线；</li>
<li>灰度计划：对于重要的项目，我们都不会直接全量，都会通过灰度计划逐步将新逻辑推到全量；提前设计好灰度计划，能够让自己在灰度的过程中从容不迫；</li>
<li>监控指标：对于关键业务逻辑，我们需要设计一些监控告警指标，比如通过钉钉告警，飞书告警，短信告警 电话告警，保证出现严重问题能够感知到，缩短处理问题的时间。对于监控而言，可以考虑使用CAT进行打点上报； </li>
</ul>
<p>针对配置，我们再补充几点：</p>
<ul>
<li>关于灰度，笔者之前发过一篇文章，专门进行过讲解，感兴趣的读者可以点击查看</li>
<li>急停开关，本质上是面向失败设计，让我们能够在不进行代码打包和重复上线的前提下，实现代码逻辑的热下线操作；</li>
</ul>
<p>这里提到的，基本上就是一个方案设计过程中需要考虑的点，如果有遗留还请多多见谅。读者朋友也可以基于这些要点发展出适合自己的方案设计模板。</p>
<h2 id="问题排查的大概思路"><a href="#问题排查的大概思路" class="headerlink" title="问题排查的大概思路"></a>问题排查的大概思路</h2><p>最后，来介绍一下问题排查的大概思路。</p>
<ol>
<li>快速定位问题，经验很重要。同样的问题，不同经验的同学解决耗费的时间是有明显的区别的，因此我们需要不断了解系统的设计，了解业务上下游交互链路，并对业务中容易导致问题发生的节点进行重点排查和优化；</li>
<li>需要对公司内部的常见的监控/问题排查组件进行了解，知道使用什么工具解决什么问题，这样在出现问题的时候能够借助工具提升问题排查的速度。对于开源的问题排查工具也需要了解，重点吸收工具背后的原理和设计思路；</li>
<li>特殊问题需要特殊处理，如果问题定位困难，先想办法止损。待损失控制之后，再进行进一步的排查，要灵活一些。对于常规问题可以通过沉淀问题排查手册来进行辅助；</li>
</ol>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>写了这么多技术类的文章，本文应该算是目前最不技术的一篇。</p>
<p>我们主要讨论了“快速熟悉业务逻辑并辅助逻辑”的手段和一些常见的思路，如果你恰巧刚入职场，那么本文中的内容应该能够帮助你快速度过菜鸟阶段。</p>
<p>如果你觉得文章不错，欢迎点赞转发，祝每位读者都能建立起自己的一套思维框架，在职场中游刃有余。</p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本次我们不分享技术，我们来聊聊软素质，具体点说，我们来聊聊新人程序员如何快速熟悉业务逻辑并付诸落地。&lt;/p&gt;
&lt;p&gt;一个新人程序员，经历了面试的层层磨炼，终于尘埃落定入职心仪的公司。初来乍到，对周围的一切都不熟悉，业务不熟悉，同事也不熟悉。&lt;/p&gt;
&lt;p&gt;这其中关系最大的就是对业务和代码的熟悉，如果能够掌握快速熟悉业务逻辑的方法，就能够很快进入到工作角色中，从容不迫的开展新的工作。&lt;/p&gt;
&lt;p&gt;那么我们本次分享就从这几个方面展开：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如何通过读代码建立对系统的全局观，cover链路上下游&lt;/li&gt;
&lt;li&gt;如何画图来辅助自己熟悉业务流程&lt;/li&gt;
&lt;li&gt;应当如何学习掌握领域知识&lt;/li&gt;
&lt;li&gt;对于方案设计有哪些技巧和注意点&lt;/li&gt;
&lt;li&gt;问题排查的大概思路&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;PS： 由于大部分的开发者都是面向业务，因此本次讨论对于中间件类的开发不做进一步展开，后面有机会再分享。&lt;/p&gt;
    
    </summary>
    
      <category term="随笔" scheme="http://wuwenliang.net/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="随笔" scheme="http://wuwenliang.net/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>分布式套路之分库分表漫谈</title>
    <link href="http://wuwenliang.net/2021/01/09/%E5%88%86%E5%B8%83%E5%BC%8F%E5%A5%97%E8%B7%AF%E4%B9%8B%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E6%BC%AB%E8%B0%88/"/>
    <id>http://wuwenliang.net/2021/01/09/分布式套路之分库分表漫谈/</id>
    <published>2021-01-09T09:33:36.000Z</published>
    <updated>2021-01-09T10:59:16.041Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>本文是笔者在一次技术直播过程中的文字大纲，基本上是即兴的，口语化严重。<br>因此对大纲进行整理，用文字方式进行展现。</p>
</blockquote>
<p>既然是“漫谈分库分表”，那么我们需要确定我们要谈什么，不谈什么。</p>
<ol>
<li><p>首先，我们不讨论具体的分库分表框架的实现和源码，这不是我们讨论的范围。</p>
</li>
<li><p>我们讨论的是思路，主要讨论如何分库分表的套路，有什么坑，有什么心得，不针对具体的细节进行展开式讨论。当然我自己的能力有限，只是希望能够抛砖引玉。</p>
</li>
<li><p>我们要明确，分库分表，<strong>并不是一个银弹</strong>，它只是我们针对MySQL单机性能不够的情况下，想要节约成本的一种方式。对于boss来说，既想要想要节约成本，又想要支撑业务，提供稳定持久度性能。</p>
</li>
</ol>
<a id="more"></a>
<p>程序员发挥出聪明才智，绞尽脑汁，日复一日的努力与实践，最终产生出主要的两种方式：</p>
<ol>
<li>agent嵌入式模式，用一个jar包，集成到我们的代码里，在代码里通过路由规则，分片键方式进行分库分表，属于嵌入式方式。</li>
<li>cs模式（客户端-服务端模式），提供一个三方组件， 如： mycat，sharding-sphere中的proxy方式，类似于mycat；存在中心化，需要保证三方组件的高可用。</li>
</ol>
<p>如果有更好的技术选型，我们宁愿不用分库分表，因为它本身就是一个复杂的解决方案。只是一种折中，更合适的是NewSQL、商业化数据库（比方说，Oracle，在大部分场景下，性能足够用，但是费用高昂）。</p>
<p>如果真的有一天，出现了一个优秀的、经济的newSQL, 比方说 oceanbase，tidb，那么我们基本上可以告别分库分表。</p>
<p>我们之所以选择使用分库分表策略，根本上还是因为，一方面是因为我们的使用成本不能太高；一方面，单机DB数据库性能不够了；一方面，newSQL当前还不成熟，太贵，不敢用。</p>
<p>分库分表用的厂家挺多的，有丰富的开源框架，有社区，还有成熟的案例，所以我们采用，</p>
<p>直接原因在于，阿里站台了，我们国内的风气是，阿里用啥我用啥，阿里怎么做我这么 跟风严重。我的想法是，我们还是有自己的技术前瞻性一些看法，最好不要唯阿里，唯技术。</p>
<p>说了这么多，我们回归正题，开始看问题。</p>
<h3 id="1-只做分表可以吗？还是必须要分表又分库，如果是分库的话-库是在多个服务器上吗？这个怎么来考虑"><a href="#1-只做分表可以吗？还是必须要分表又分库，如果是分库的话-库是在多个服务器上吗？这个怎么来考虑" class="headerlink" title="1. 只做分表可以吗？还是必须要分表又分库，如果是分库的话 库是在多个服务器上吗？这个怎么来考虑"></a>1. 只做分表可以吗？还是必须要分表又分库，如果是分库的话 库是在多个服务器上吗？这个怎么来考虑</h3><p>我想说，还是要<strong>看业务规模</strong>，既看当前的业务规模，也看未来3-5年的业务发展趋势。</p>
<p>涉及到技术选型，我们的宗旨是，<strong>永远选择最适合当下业务的、成本最低的，收益最高的</strong>，合适的就是最好的。</p>
<p>我们选择的方案最好是技术团队刚刚好能够hold住的选型。如果选型已经不适合当前的业务发展，那么大可以换套更适合的。这个本来就是事物发展的必然规律。</p>
<p>要么，业务还没发展到一个更高层次，就已经GG了，那么刚刚好，不用浪费钱买更好的设施，刚好止损；</p>
<p>要么，就是当前的方案确实不够用了，我们换了一套更牛X的，虽然说这样会花更多的钱，请更多的人，但是，这不正和我们的心意么，我们的目的本身就是通过合适的技术架构，更加优秀的代码，支持业务发展。</p>
<p>一句话总结就是，既然不得不花钱，那该花就花吧。</p>
<h4 id="分场景讨论"><a href="#分场景讨论" class="headerlink" title="分场景讨论"></a>分场景讨论</h4><p>一图胜千言，我们分别看看这两种场景。</p>
<p>对于 <strong>离线数据分析场景</strong></p>
<p>只分表是够的，因为你主要用来分析数据，分析数据完成之后的数据就可以删掉了。异步任务删掉若干月/天的数据。</p>
<p><img src="/2021/01/09/分布式套路之分库分表漫谈/offline-app.png" alt="offline-app.png"></p>
<p>对于 <strong>实时业务系统</strong></p>
<p>如果是一个分布式的业务系统 2C，需要承载巨量的流量的，建议 <strong>分库分表</strong> 同时考虑。</p>
<p><img src="/2021/01/09/分布式套路之分库分表漫谈/online-app.png" alt="online-app.png"></p>
<h4 id="分库分库的前提，预估业务量"><a href="#分库分库的前提，预估业务量" class="headerlink" title="分库分库的前提，预估业务量"></a>分库分库的前提，预估业务量</h4><p>分库分表的前提，是预估业务量，我们提供一个经验值，不代表最合适的，只是一个定性的分析：</p>
<pre><code>QPS 500-1000以下，   那么采用主从读写分离，基本上足够支撑业务了；

QPS 1000-10000，考虑分布分表是一个比较合适的事情 

12000TPS 30000QPS 32库 1024表 
1000多万 16000QPS 16库512表
</code></pre><p>本质上来说：分库分表是<strong>一锤子买卖</strong>，前期的设计很重要，决定了后期扩容以及数据迁移的难度。在前期设计的时候，大概率我们需要做好未来3-5年的规划，短的话需要做1-2年的规划，根据规划来确定是不是要分库分表，以及分多少库、多少表。</p>
<p>回到问题本身，这个主要取决于当前的业务量，以及业务量的增速。</p>
<p>我们根据这几个维度，给出一组公式：</p>
<pre><code>某年数据增量M = （1 + 数据年增速K）^ n  * 初始数据量 N

第一年增量 M1 = (1+k)   * N 
第二年增量 M2 = (1+K)^2 * N
第三年增量 M3 = (1+K)^3 * N

三年数据总量 M&apos; = N + m1 + m2 + m3
</code></pre><p>我们就以单表承载1000万数据来算，一共要有几张表，当前不一定是1000w，2000w-5000w都可以，这个首先是一个经验值，其次还需要定量分析。</p>
<p>定量的分析，就需要进行压测。我们需要针对你的线上的配置，用一个库的实例去压测，压出你的这个配置下，在不影响系统吞吐量的前提下，单表的最大容量，压测是一个稳妥的环节，能够在前期很好的指导我们进行设计。</p>
<h4 id="我们接着讨论，什么时候需要分库，必须要保证每个数据库都是一个独立的实例么？"><a href="#我们接着讨论，什么时候需要分库，必须要保证每个数据库都是一个独立的实例么？" class="headerlink" title="我们接着讨论，什么时候需要分库，必须要保证每个数据库都是一个独立的实例么？"></a>我们接着讨论，什么时候需要分库，必须要保证每个数据库都是一个独立的实例么？</h4><p>并不是，我们还是要具体问题具体分析。</p>
<p>如果是开发环境，也就是研发RD自己写代码用的库，那么多套库在一台机器上也可以，毕竟开发环境没有并发量，最多拿来开发，只要不用来压测就没啥问题。</p>
<p>如果是线上环境，除了要将库部署到多台机器，还得考虑读写分离，以及库的高可用。线上线下的主要区别在于，<strong>线上有高可用的要求，而线下不需要</strong>。</p>
<p>思考一下，两者区别是什么，区别就在于<strong>成本的控制</strong>。</p>
<p>我们给出结论，具体什么时候要把数据库部署到一台机器实例，还是要看场景，看成本，看自己需不需要。具体问题具体分析。</p>
<h3 id="2-路由键怎么生成？用雪花算法可以吗？如果原来的数据库主键是自增的，没有业务唯一约束，如果迁移之后，原先的数据怎么在分库分表中进行路由"><a href="#2-路由键怎么生成？用雪花算法可以吗？如果原来的数据库主键是自增的，没有业务唯一约束，如果迁移之后，原先的数据怎么在分库分表中进行路由" class="headerlink" title="2. 路由键怎么生成？用雪花算法可以吗？如果原来的数据库主键是自增的，没有业务唯一约束，如果迁移之后，原先的数据怎么在分库分表中进行路由"></a>2. 路由键怎么生成？用雪花算法可以吗？如果原来的数据库主键是自增的，没有业务唯一约束，如果迁移之后，原先的数据怎么在分库分表中进行路由</h3><p>好问题。</p>
<p>首先说，路由键怎么生成？</p>
<p>本质上，<strong>这是一个如何实现一个可靠的分布式发号器的问题</strong>。我们只说思路，因为展开说都能但单独说好半天了。</p>
<p>思路：</p>
<p>对于某些框架而言，他们有自己的主键生成器，比如说shardingSphere/ShardingJDBC 类SnowFlake算法；</p>
<ol>
<li>UUID：字符串形式，确实是唯一，但是可读性差，不好做数学计算，不直观，比较长，占用空间大</li>
<li>SNOWFLAKE：可以用，也可以用改进leaf，leaf本身就是一套完善的分布式发号器，自己也有高可用保障。</li>
</ol>
<p>当然还有别的方式：</p>
<p>因为既然已经做了分库分表，大概率你的系统也是分布式的吧，那么用进程内的发号不是一个理想的方式。</p>
<p>如果要简单实现一种分布式发号服务，我们可以利用 redis increment 实现一套发号器，也可以借助数据库的自增唯一id来做，但是我们还是需要自己进行开发，实现一个发号系统。</p>
<p>简单的上一个图，表达一下思路，这块儿内容之后会单独写文章来讲。</p>
<p><img src="/2021/01/09/分布式套路之分库分表漫谈/2-routekey.png" alt="2-routekey.png"></p>
<p>总结一下就是，本质上，这是一个如何实现一个可靠的分布式发号器的问题。</p>
<p>所以得依赖某个具体的分布式发号机制  这个问题不用纠结，关注一下最终的选型就好，多进行权衡。</p>
<h3 id="3-如果本身是一个单库，并且没有路由键，完全拿主键当唯一标识了，我分库分表怎么玩？"><a href="#3-如果本身是一个单库，并且没有路由键，完全拿主键当唯一标识了，我分库分表怎么玩？" class="headerlink" title="3. 如果本身是一个单库，并且没有路由键，完全拿主键当唯一标识了，我分库分表怎么玩？"></a>3. 如果本身是一个单库，并且没有路由键，完全拿主键当唯一标识了，我分库分表怎么玩？</h3><p>很简单，你原来的唯一标识是什么，分库分表之后还用这个就行了。</p>
<p>但是，因为本身没有一个业务属性的键，所以建议在进行数据迁移之后，加入一个业务属性的自然主键，并且大概率你需要配置一下新的路由规则。</p>
<p>具体的过程为：</p>
<ol>
<li>迁移数据</li>
<li>更改路由配置  指定一个新的查询规则，分库分表的路由规则</li>
<li>改代码，把代码中涉及到C R U D 的代码，比如说DAO、repository中包含的代码，代码都加上路由规则，简单的说你还是可以用原来的id去执行查询 、插入 、删除的，但是主要的改动点就在于你需要有一个路由规则。</li>
</ol>
<p>我们说，数据库迁移到分不分表的核心：是保证数据的完整性，代码该重构就重构，很难有一个全面的不需要改代码的方案，我们只能折中权衡，降低复杂度。</p>
<p>原先的主键id，迁移到分库分表新库中，已经不是连续的了，但是还需要保证unique，新的数据库表中的自增主键还需要有，但是没有业务属性了，之所以分库分表之后还需要有自增主键，主要在于提升插入效率，查询效率。通过主键索引树，进行回表操作。</p>
<p>相当于你原先用了自增id是有业务属性的，这里说句题外话，<strong>请尽量不要使用自增主键代表业务含义</strong>。</p>
<h3 id="3-分片键怎么选择"><a href="#3-分片键怎么选择" class="headerlink" title="3. 分片键怎么选择"></a>3. 分片键怎么选择</h3><p>我们的答案依旧不能给出一个准确的说法，我只能说，要根据业务场景的要求去选择。</p>
<p>这么说太笼统了，我们通过几个例子来表达一下。</p>
<pre><code>对于用户表，使用用户唯一标识， 如：userId作为分片键；
对于账户表，使用账户唯一标识，如：accountId作为分片键；
对于订单表，使用订单唯一标识， 如：orderId作为分片键；
对于商家相关信息表，使用商家唯一标识， 如：merchantId作为分片键；
......
</code></pre><p>如果我们要查一个用户的订单，那么我们应该用userId去路由表，插入订单到订单表，保证一个用户的所有订单都能够分布在一个表分片上。这样做能够很好的避免引入分布式事务。</p>
<p>如果说，维度不是用户，而是其他维度，比方说，我们想<strong>查询某个商家的所有用户的订单</strong>，</p>
<p>那么我们就应该用商家的merchantId也去存一份数据，路由的时候用商家id去路由，只要是这个商家的用户订单，我们写入到商家的订单表里，那么对于商家所属的订单，我们就可以从某个分片上获取到。</p>
<p>用一个图表达，能够很明确的体现上述的说明内容：</p>
<blockquote>
<p>对于用户而言，分片键作用方式如下图：<br><img src="/2021/01/09/分布式套路之分库分表漫谈/usertable.png" alt="usertable.png"></p>
<p>对于商家而言，分片键作用方式如下图：<br><img src="/2021/01/09/分布式套路之分库分表漫谈/merchanttable.png" alt="merchanttable.png"></p>
</blockquote>
<p>所以我们的结论就是：要根据业务场景的要求去选择，具体问题具体分析，尽量保证不引入分布式事务，提升查询效率。</p>
<p>补充一句，对于主流的做法，如果需要有复杂查询，要么依据不同维度去进行双写，要么直接通过引入异构的方式去查询，比方说使用elastic search，或者使用hive等方式。</p>
<h3 id="4-批量插入数据的时候，会往各个分库去插，在实际业务中是否要做分布式事务"><a href="#4-批量插入数据的时候，会往各个分库去插，在实际业务中是否要做分布式事务" class="headerlink" title="4.批量插入数据的时候，会往各个分库去插，在实际业务中是否要做分布式事务"></a>4.批量插入数据的时候，会往各个分库去插，在实际业务中是否要做分布式事务</h3><p>第三个问题或多或少也提到了这个问题的答案。</p>
<p>我们在落地分库分表的过程中，<strong>要尽量避免引入分布式事务</strong>。</p>
<p>因为从上面第三个问题，你会发现，如果我们有路由键，问题就简单的多了，我们大部分情况下不需要引入分布式事务，但是如果没有就很痛苦。</p>
<p>对于乱序插入且需要保证插入事务性的场景，就需要分布式事务。但是这样做效率太低，也不合适。</p>
<p>首先乱序插入的场景并不多，其次如果引入分布式事务，那么事务的粒度也不小，而且对于插入的性能有着显著的影响。不是最佳的方式。</p>
<p>我的建议就是，还是基于最终一致性去做，否则引入分布式事务，太影响效率了，而且也会增加系统的复杂度，我觉得我们设计系统的宗旨就是，能不用复杂的方案就不用，有时间喝喝茶，干点别的何乐而不为呢。</p>
<blockquote>
<p>所以这个问题的结论就是：尽量避免分布式事务，如果不得不引入，需要尽量缩小事务的范围和粒度。通过折中，多去考虑一下方案的可行性，<br>性能很重要，没有分布式事务也能做，怎么做，就是通过最终一致性。</p>
</blockquote>
<p>但是，如果你说 “我就是避免不了分布式事务啊，那咋办嘛”。那就用吧，若无必要，勿增实体。不得不用，就用，没什么好说的。</p>
<h3 id="5-如果一个库有很多张表，对一张表进行分库分表了，此时不分库不分表的表怎么放置，-是否指定到分库里某一个库里面？"><a href="#5-如果一个库有很多张表，对一张表进行分库分表了，此时不分库不分表的表怎么放置，-是否指定到分库里某一个库里面？" class="headerlink" title="5.如果一个库有很多张表，对一张表进行分库分表了，此时不分库不分表的表怎么放置， 是否指定到分库里某一个库里面？"></a>5.如果一个库有很多张表，对一张表进行分库分表了，此时不分库不分表的表怎么放置， 是否指定到分库里某一个库里面？</h3><p>本质上：这是非分库分表的数据与分库分表数据的分布的一个问题。</p>
<p>实际上，分库分表中间件往往都有对应功能，这个功能往往叫做<strong>默认路由规则</strong>，怎么理解呢？</p>
<p>就是说，对于没有分库分表的这些表，走<strong>默认路由规则</strong>  就行了，这样的话始终会路由到default DataSource上去。</p>
<p>相当于是一个白名单。找一下中间件的文档，看看默认路由规则怎么配，基本上中间件都考虑这个问题了，对于ShardingSphere而言，一个配置样例如下：</p>
<pre><code>CustomerNoShardingDBAlgorithm
    default-table-strategy: （缺省表分区策略）
        complex:
        sharding-columns: db_sharding_id
        algorithm-class-name: com.xxx.XxxClass
    tables:
        ops_account_info: （必须要配置这个，才能使用缺省分表策略）
        actual-data-nodes: db-001.ops_account_info
</code></pre><p>详细的举个例子，比方说：</p>
<blockquote>
<p>一个服务在原有的数据库进行分库（比如user库分为了user01,user02）的时候，是把不分表的表强制路由走某一个数据库吗(比如把不分表的表都路由到user01)？</p>
</blockquote>
<p>这里说到的本质就是： 默认路由规则，我们只需要配置某些表走默认路由规则就行了，比方说，我们现在有user 表 order表，config表，其中user表、 order分库分表，而config没有分库分表。</p>
<p>那么我们只需要把config表放在user库的0库，1库，2库，随便某个位置，</p>
<p>放好之后，我们只需要在分库分表中间件的配置文件中配置默认路由规则，把config表特殊配置一下，只要查config表，就走到这个指定的库上去。</p>
<p>其他的也类似 ，只要有这种需求，就增加对应的配置。</p>
<p>一定要显式告诉中间件，哪些表不走路由规则，并且要告诉它，这些表具体放在哪儿，<br>最好是放在请求量不大的库里，或者说单独搞一个库也可以，这个库放的都是不进行分库分表的表，<br>并配置不走路由规则就完事儿了，其实还是默认路由规则。</p>
<p>为什么这么做呢？有什么意图呢？</p>
<blockquote>
<p>我的理解就是：之所以我们分库分表的原因，就是因为请求很大需要降低并发度；而对于请求频率小的表，我们可以不分库分表还是通过单表方式使用，那么就可以配置为默认路由规则就好。</p>
</blockquote>
<h3 id="8-数据迁移流程以及如何保证数据一致性"><a href="#8-数据迁移流程以及如何保证数据一致性" class="headerlink" title="8.数据迁移流程以及如何保证数据一致性"></a>8.数据迁移流程以及如何保证数据一致性</h3><p>简单的概括，数据迁移依赖于数据的双写；数据一致性，依赖于数据完整性校验。</p>
<p>对于迁移而言，我们有以下步骤：</p>
<p><img src="/2021/01/09/分布式套路之分库分表漫谈/sync.png" alt="sync.png"></p>
<ol>
<li>先修改代码，加入双写分库分表代码；进行上线</li>
<li><p>开始进行数据双写，同步增量数据 ；</p>
<p>双写，主要目的是追上实时数据，给全量同步数据一个deadline，保证从这个时间之后的数据都是完整的（同时，通过异步数据完整性校验程序去校验数据完整性，但是如果我们能够保证双写可靠性，这个对比可做可不做。最好还是做一下）</p>
</li>
<li><p>全量历史数据同步，并校验数据完整性；</p>
<p>一般全量数据同步，不用同步写的方式，原因在于同步写入一方面代码耦合度高，一方面是对系统有影响。所以我们往往通过异步方式进行写入，这个过程后文有图进行说明；</p>
</li>
<li><p>去掉双写代码，将查询分库分表的逻辑全量；<br>通过开关切换，在全量数据同步完成之后切换到全量读写分库分表逻辑即可。此时老的逻辑已经没有请求路由过去了，我们只需要找个发版窗口把老逻辑下线就可以，此时线上已经完全迁移到分库分表的代码流程。</p>
</li>
</ol>
<p>最后我想说，一定要回归，一定要回归，一定要回归！！！</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文本来没有计划要写，之所以还是写出来，主要需要感谢群里的朱兄，他给我提供了很多思考的问题，让我能够比较系统的整理了分库分表的思路。</p>
<p>本文其实是一场直播的现场即兴大纲，后来被我总结为一个文章，感兴趣的朋友可以去看下视频，已经上传到哔哩哔哩。</p>
<p><a href="https://www.bilibili.com/video/BV15h41127oQ/" target="_blank" rel="external">图文并茂, 分库分表套路与方案详解</a></p>
<p><hr><br>版权声明：<br><br>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。<br></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文是笔者在一次技术直播过程中的文字大纲，基本上是即兴的，口语化严重。&lt;br&gt;因此对大纲进行整理，用文字方式进行展现。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;既然是“漫谈分库分表”，那么我们需要确定我们要谈什么，不谈什么。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;首先，我们不讨论具体的分库分表框架的实现和源码，这不是我们讨论的范围。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;我们讨论的是思路，主要讨论如何分库分表的套路，有什么坑，有什么心得，不针对具体的细节进行展开式讨论。当然我自己的能力有限，只是希望能够抛砖引玉。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;我们要明确，分库分表，&lt;strong&gt;并不是一个银弹&lt;/strong&gt;，它只是我们针对MySQL单机性能不够的情况下，想要节约成本的一种方式。对于boss来说，既想要想要节约成本，又想要支撑业务，提供稳定持久度性能。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="Java" scheme="http://wuwenliang.net/categories/Java/"/>
    
    
      <category term="Java" scheme="http://wuwenliang.net/tags/Java/"/>
    
  </entry>
  
</feed>
